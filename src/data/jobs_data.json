[{
    "Title": "Machine Learning Engineer",
    "Description": "Role Description:\nWe are seeking a Machine Learning Engineer with approximately 5 years of experience in the field. The ideal candidate will have a strong foundation in low-level machine learning skills, data science, and advanced AI techniques. You will be working with Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and other state-of-the-art toolchains. Additionally, familiarity with cloud operations will be beneficial. If you are passionate about pushing the boundaries of AI and enjoy working on complex challenges, we want to hear from you!\nKey Responsibilities:\nModel Development: Design, implement, and optimize machine learning models and algorithms, focusing on low-level techniques and cutting-edge AI methodologies.\nData Handling: Develop and maintain data pipelines, perform exploratory data analysis, and apply data preprocessing techniques to ensure high-quality input for machine learning models. LLM & RAG Implementation: Leverage and fine-tune Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems to create innovative solutions and enhance model performance.\nToolchain Expertise: Utilize and integrate modern toolchains and frameworks (e.g., TensorFlow, PyTorch, Hugging Face) to build and deploy machine learning models.\nCloud Operations: Manage and optimize machine learning workflows in cloud environments (e.g., AWS, Google Cloud, Azure), ensuring scalability and efficiency.\nCollaboration: Work closely with cross-functional teams, including data scientists, software engineers, and product managers, to align on project goals and deliver high-impact solutions.\nContinuous Learning: Stay current with the latest advancements in AI and machine learning, and actively contribute to the knowledge base of the team.\nQualifications:\nExperience: Approximately 5 years of professional experience in machine learning and AI engineering.\nTechnical Skills: Proficiency in Python and relevant libraries (e.g., NumPy, pandas, scikit-learn). Strong understanding of machine learning algorithms, statistical analysis, and model evaluation techniques.\nLLMs & RAG: Hands-on experience with Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) technologies, including fine-tuning and deployment.\nData Science Foundations: Solid background in data science principles, including data preprocessing, feature engineering, and model selection.\nCloud Operations: Experience with cloud platforms (AWS, Google Cloud, Azure) and knowledge of cloud-based machine learning services and deployment strategies.\nToolchain Knowledge: Familiarity with machine learning frameworks and tools (e.g., TensorFlow, PyTorch, Hugging Face Transformers) and version control systems (e.g., Git).\nProblem-Solving: Strong analytical and problem-solving skills, with the ability to tackle complex challenges and derive actionable insights.\nCommunication: Excellent communication skills, with the ability to present technical concepts clearly and effectively to non-technical stakeholders.\nPreferred Qualifications:\nAdvanced Degrees: Master\u2019s or PhD in Computer Science, Data Science, Artificial Intelligence, or a related field.\nResearch Experience: Experience in conducting and publishing research in the field of machine learning or AI.\nCertifications: Relevant certifications in cloud platforms or machine learning.\nBenefits:\nCompetitive salaryEquity in line with company stage and roleComprehensive health, dental, and vision insuranceGenerous PTO and flexible work arrangementsOpportunities for professional growth and developmentCollaborative and inclusive work environment with a passionate and talented team",
    "Primary Description": "Statt  \u00b7 Austin, TX (Hybrid)",
    "Detail URL": "https://www.linkedin.com/jobs/view/4056026645",
    "Location": "Austin, Texas, United States",
    "Skill": null,
    "Insight": null,
    "Job State": "LISTED",
    
    "Poster Id": 25195718.0,
    "Company Name": "Statt",
    "Company Logo": "https://media.licdn.com/dms/image/v2/D560BAQFfETfk4CxbTg/company-logo_400_400/company-logo_400_400/0/1720890643158/stattinc_logo?e=1747872000&v=beta&t=qZqFqh9VhdqCJd_c-1X8ujmRHqfnnPtJHcfurZKGQRk",
    "Created At": "2024-10-22 18:15:23",
    "Scraped At": "2025-02-18 02:03:03"
  },
  {
    "Title": "Machine Learning Software Engineer",
    "Description": "Compensation: $120,000 - $140,000/year\n\nLocation: Onsite - Oklahoma City, OK\n\nPosition: Machine Learning Software Engineer\n\nInceed has partnered with a great company to help find a skilled Machine Learning Engineer to join their team!\n\nResponsibilities:\n\nWorking on machine learning projects -- will be both new and maintenance development \n\nRequired Qualifications & Experience:\n\nProfessional experience in a machine learningAI/Machine LearningSoftware Engineering -- open on tech stackSQL ExperienceLinux Experience\n\nPerks & Benefits:\n\nHealth, dental, and vision insurance401K with matchPaid time off and company paid holidaysProfit sharing\n\nIf you are interested in learning more about the Machine Learning Software Engineer opportunity, please submit your resume for consideration. Our client unable to provide sponsorship at this time.\n\nWe are Inceed, a staffing direct placement firm who believes in the possibility of something better. Our mission is simple\u201d We\u2019re here to help every person, whether client, candidate, or employee, find and secure what\u2019s better for them.\n\nInceed is an equal opportunity employer. Inceed prohibits discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, sexual orientation, gender identity, or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.",
    "Primary Description": "Inceed \u00b7 Oklahoma City, OK (On-site)",
    "Detail URL": "https://www.linkedin.com/jobs/view/4142506122",
    "Location": "Oklahoma City, Oklahoma, United States",
    "Skill": null,
    "Insight": null,
    "Job State": "LISTED",
    "Poster Id": 640138030.0,
    "Company Name": "Inceed",
    "Company Logo": "https://media.licdn.com/dms/image/v2/C560BAQFeKKclNfQh8w/company-logo_400_400/company-logo_400_400/0/1676503327706/inceed_logo?e=1747872000&v=beta&t=rTsuv_YNCojG9zu1tZfDGmook-4BH73ZZBMbjZB4W0c",
    "Created At": "2025-02-05 18:53:31",
    "Scraped At": "2025-02-18 02:03:03"
  },
  {
    "Title": "Machine Learning Engineer",
    "Description": "Job Description\n\nWe are looking for a Machine Learning Engineer to join our team. The ideal candidate will have a strong background in machine learning, data science, and software engineering. You will be responsible for designing, implementing, and deploying machine learning models and algorithms to solve complex problems.\n\nResponsibilities:\n\nDesign and implement machine learning models and algorithms.\nCollaborate with data scientists and software engineers to develop scalable solutions.\nAnalyze large datasets to extract insights and improve model performance.\nDeploy machine learning models into production environments.\nMonitor and maintain model performance over time.\nStay up-to-date with the latest advancements in machine learning and AI technologies.\n\nQualifications:\n\nBachelor's or Master's degree in Computer Science, Data Science, or a related field.\n3+ years of experience in machine learning and data science.\nStrong programming skills in Python, Java, or C++.\nExperience with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn.\nFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud.\nExcellent problem-solving skills and attention to detail.\nStrong communication skills and ability to work in a team environment.",
    "Primary Description": "Cognizant Technology Solutions \u00b7 Remote",
    "Detail URL": "https://www.linkedin.com/jobs/view/4142506122",
    "Location": "Remote",
    "Skill": null,
    "Insight": null,
    "Job State": "LISTED",
    "Poster Id": 640138030.0,
    "Company Name": "Cognizant Technology Solutions",
    "Company Logo": "https://media.licdn.com/dms/image/C560BAQFfETfk4CxbTg/company-logo_400_400/company-logo_400_400/0/1720890643158/stattinc_logo?e=1747872000&v=beta&t=qZqFqh9VhdqCJd_c-1X8ujmRHqfnnPtJHcfurZKGQRk",      
    "Created At": "2025-02-05 18:53:31",
    "Scraped At": "2025-02-18 02:03:03"
  
},

  {
      "job_title":"Data Scientist",
      "company":"ERPMARK INC",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-erpmark-inc-3783594893",
      "search_city":"Winslow",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Summary\nA client of ours in Austin, TX (Onsite - Hybrid) is looking for a Data Scientist for a Contract on W2 opportunity.\nMandatory Skills\nPython, R, Tensorflow\nHadoop, Spark, and Hive\nCloud platforms like AWS\/Azure\/GCP\nKey Responsibilities\nDevelop and implement machine learning models and algorithms to support our program objectives\nCollaborate with cross-functional teams including data science, software engineering, and product management to build predictive models, forecasting tools, and recommendation systems\nAnalyze, optimize and maintain existing machine learning models\nParticipate in data model and architecture design\nTrain and evaluate models using statistical methods\nTroubleshoot and identify issues with data models and data pipelines\nQualifications\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in computer science, data science, statistics, or related fields\n10+ years of Data Scientist Experience.\nMinimum of 3 years of experience in Machine learning and data analysis\nStrong programming skills in Python, R, Tensorflow and prompt engineering\nExperience in data modeling, data architecture, and data pipeline design\nExperience with big data platforms such as Hadoop, Spark, and Hive\nExperience in cloud platforms like AWS\/Azure\/GCP\nExperience in NLP, computer vision, deep learning techniques\nExcellent communication and collaboration skills\nJob Type:\nContract on W2\nLocation:\nPreferred location is\nAustin, TX (Onsite - Hybrid)\nShow more\nShow less",
      "job_skills":"Python, R, TensorFlow, Hadoop, Spark, Hive, AWS, Azure, GCP, Machine learning, Data analysis, Data modeling, Data architecture, Data pipeline design, NLP, Computer vision, Deep learning, Statistical methods",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Archetype Permanent Solutions",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-archetype-permanent-solutions-3787919070",
      "search_city":"Winslow",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are seeking a highly skilled and analytical Data Scientist to join our team. The ideal candidate will be adept at using large data sets to find opportunities for product and process optimization, and using models to test the effectiveness of different courses of action. This role will require both a strong technical background in data analysis and the ability to communicate findings to non-technical teams and stakeholders.\nKey Responsibilities:\nWork with stakeholders to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nQualifications:\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Statistics, Mathematics, Computer Science, or another quantitative field.\n2 years of experience in a Data Scientist or Data Analyst role.\nStrong problem-solving skills with an emphasis on product development.\nExperience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages\/drawbacks.\nExcellent written and verbal communication skills for coordinating across teams.\nPreferred Skills:\nExperience with distributed data\/computing tools: Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\nExperience with AWS, Azure, or another cloud service.\nExperience visualizing\/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.\nBenefits:\nCompetitive salary and benefits package.\nDynamic and innovative work environment.\nOpportunities for professional growth and development.\n[Other company-specific benefits like remote work options, flexible schedules, wellness programs, etc.]\nHow to Apply:\nPlease submit your resume, cover letter, and any relevant work samples\nPowered by JazzHR\n3tBUY1AUTb\nShow more\nShow less",
      "job_skills":"Data Science, Data Analysis, Data Mining, Machine Learning, Data Modeling, Statistical Programming, Data Visualization, R, Python, SQL, Distributed Computing, Cloud Computing, AWS, Azure, Data Architecture, Product Development, Problem Solving, Communication Skills",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Archetype Permanent Solutions",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-archetype-permanent-solutions-3787910756",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are seeking a highly skilled and analytical Data Scientist to join our team. The ideal candidate will be adept at using large data sets to find opportunities for product and process optimization, and using models to test the effectiveness of different courses of action. This role will require both a strong technical background in data analysis and the ability to communicate findings to non-technical teams and stakeholders.\nKey Responsibilities:\nWork with stakeholders to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nQualifications:\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Statistics, Mathematics, Computer Science, or another quantitative field.\n2 years of experience in a Data Scientist or Data Analyst role.\nStrong problem-solving skills with an emphasis on product development.\nExperience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages\/drawbacks.\nExcellent written and verbal communication skills for coordinating across teams.\nPreferred Skills:\nExperience with distributed data\/computing tools: Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\nExperience with AWS, Azure, or another cloud service.\nExperience visualizing\/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.\nBenefits:\nCompetitive salary and benefits package.\nDynamic and innovative work environment.\nOpportunities for professional growth and development.\n[Other company-specific benefits like remote work options, flexible schedules, wellness programs, etc.]\nHow to Apply:\nPlease submit your resume, cover letter, and any relevant work samples\nPowered by JazzHR\nPBgVJw6zNw\nShow more\nShow less",
      "job_skills":"Data Science, Data Analysis, Statistics, Mathematics, Computer Science, R, Python, SQL, Machine Learning, Clustering, Decision Tree Learning, Artificial Neural Networks, Hadoop, Hive, Spark, MySQL, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, AWS, Azure, Cloud Services, Periscope, Business Objects, D3, ggplot, Data Visualization, Data Presentation",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Scientist",
      "company":"Fanatics",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-scientist-at-fanatics-3738976904",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Overview\nFanatics is building a leading global digital sports platform. The company ignites the passions of global sports fans and maximizes the presence and reach for hundreds of sports partners globally by offering innovative products and services across Fanatics Commerce, Fanatics Collectibles, and Fanatics Betting & Gaming, allowing sports fans to Buy, Collect and Bet. Through the Fanatics platform, sports fans can buy licensed fan gear, jerseys, lifestyle and streetwear products, headwear, and hardgoods; collect physical and digital trading cards, sports memorabilia, and other digital assets; and bet as the company builds its Sportsbook and iGaming platform. Fanatics has an established database of over 100 million global sports fans, a global partner network with over 900 sports properties, including major national and international professional sports leagues, teams, players associations, athletes, celebrities, colleges, and college conferences, and over 2,000 retail locations, including its Lids retail business stores.\nAs a market leader with more than 18,000 employees, and hundreds of partners, suppliers, and vendors worldwide, we take responsibility for driving toward more ethical and sustainable practices. We are committed to building an inclusive Fanatics community, reflecting and representing society at every level of the business, including our employees, vendors, partners and fans. Fanatics is also dedicated to making a positive impact in the communities where we all live, work, and play through strategic philanthropic initiatives.\nWe are looking for senior-level Data Scientists to join our Data Engineering, Science, and Analytics team. Do you thrive at applying data science to solve business problems? As a data scientist, you will have ample opportunities to apply your data science skillset to unlock vast business opportunities by extracting key insights using a wide range of data sources, advanced statistical models, and machine learning algorithms and translating results into meaningful, goal-oriented business actions. Each day, you will be presented with a variety of new challenges and interesting projects that tap your interests and strengths.\nResponsibilities\nCollaborate with cross-functional partners in operations, finance, marketing, and engineering to understand business need and scope data science projects.\nWrangle, process, cleanse, verify, and enrich data from different sources used for analysis.\nHelp build data-informed business strategy and roadmaps.\nTranslate business needs into data product requirements, evaluate technologies, and identify opportunities to innovate and improve our data science capabilities.\nUse creative problem-solving skills to analyze data and build statistical \/ machine learning models to help solve business problems from different perspectives.\nWork closely with data engineers to create services that can ingest and supply data to and from both internal and external sources and ensure data quality and timeliness.\nLead the development of data visualization and dashboards to help the organization monitor performance, generate insights, and continuously improve user experience.\nEstablish playbooks to drive process and consistent outcomes.\nParticipating in the full life cycle of model development, which spans from business problem discovery, data discovery to model deployment and monitoring.\nQualifications\nMaster\u201a\u00c4\u00f4s or Doctoral degree in Computer Science (with a focus on Deep Learning, Generative AI, Machine Learning, and Data Mining), Statistics, Econometrics, Physics, or other rigorous quantitative disciplines that require processing and modeling data at a complex and large scale.\n6+ years of professional experience as a data scientist or an AI specialist.\nProficient in Python, SQL, Spark, the associated Python and Spark packages commonly used by data scientists, and Deep Learning libraries, such as PyTorch.\nProficient in wrangle and analyze data with complex relationships and time scale.\nStrong understanding of and practical experience in a wide range of machine learning algorithms and statistical modeling.\nExperience in using data visualization and dashboard tools.\nWorking experience in cloud-native technology.\nExperience working with large structured and unstructured datasets stored in relational and NOSQL databases.\nOut of-the-box thinker and problem solver who can turn ambiguous business problems into clear data-driven solutions that deliver meaningful business impacts.\nExcellent organizational skills, verbal and written communication skills, and presentation skills.\nThe Following Is a Plus\nProficient in other languages, such as R, used in data science.\nBasic knowledge of data engineering and MLOps.\nCertificates earned in data mining, machine learning, deep learning, statistical modeling, cloud computing, and data engineering.\nEnsure your Fanatics job offer is legitimate and don\u201a\u00c4\u00f4t fall victim to fraud. Fanatics never seeks payment from job applicants. Feel free to ask your recruiter for a phone call or other type of communication for interview, and ensure your communication is coming from a Fanatics or Fanatics Brand email address. For added security, where possible, apply through our company website at www.fanaticsinc.com\/careers\nTryouts are open at Fanatics! Our team is passionate, talented, unified, and charged with creating the fan experience of tomorrow. The ball is in your court now.\nFanatics is committed to responsible planning and purchasing (RPP) practices, working with its business partners across its global and multi-layered supply chain, to ensure that planning, sourcing, and purchasing decisions, along with other supporting processes, do not impede or conflict with the fulfillment of Fanatics\u201a\u00c4\u00f4 fair labor practices.\nNOTICE TO CALIFORNIA RESIDENTS\/APPLICANTS\n: In connection with your application, we collect information that identifies, reasonably relates to or describes you (\u201a\u00c4\u00faPersonal Information\u201a\u00c4\u00f9). The categories of Personal Information that we collect include your name, government issued identification number(s), email address, mailing address, other contact information, emergency contact information, employment history, educational history, criminal record, and demographic information. We collect and use those categories of Personal Information about you for human resources and other business management purposes, including identifying and evaluating you as a candidate for potential or future employment or other types of positions, recordkeeping in relation to recruiting and hiring, conducting criminal background checks as permitted by law, conducting analytics, and ensuring compliance with applicable legal requirements and Company policies. For additional information on how we collect and use personal information in connection with your job application, review our Candidate Privacy Policy-CA\nShow more\nShow less",
      "job_skills":"Python, SQL, Spark, PyTorch, Data Mining, Machine Learning, Deep Learning, Statistical Modeling, Data Visualization, Cloud Computing, Data Engineering, MLOps, R, NOSQL databases, Relational databases",
      "Category":"Backend Development"
  },
  {
      "job_title":"(USA) Senior, Data Scientist",
      "company":"Sam's Club",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/usa-senior-data-scientist-at-sam-s-club-3767281210",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position Summary...\nWhat you'll do...\nThe Senior Data Scientist in Sam's Supply Chain will be responsible for leveraging mathematical optimization, simulation, AI\/ML modeling to improve supply chain operations and decision-making processes. This role involves utilizing mathematical modeling, statistical analysis, and data-driven insights to optimize inventory management, demand forecasting, network optimization, replenishment and logistics planning.\nAbout Team\nSupply Chain at Sam's Club is all about delivering plans that help provide our members with the products they want, where they want them, at the best price possible. To accomplish this, associates must think critically and create efficiencies, using data and experience to overcome complex challenges. We invite you to join the Sam's Club Supply Chain Team; a quick moving group of motivated individuals with skills ranging from data analytics to strategy and execution. Together we will design the supply chain of the future and improve our members' lives.\nWhat You'll Do\nLead the design, development, and implementation of OR (LP\/MILP\/IP) models and methodologies to solve complex supply chain problems.\nCollaborate with stakeholders to identify opportunities in supply chain and perform data analysis, gather relevant information to develop mathematical models, algorithms, and simulation tools.\nApply optimization methods, statistical techniques, and AI\/ML models to generate actionable insights.\nDevelop and maintain decision support systems, dashboards, and reporting tools to facilitate data-driven decision-making.\nCollaborate with IT teams to integrate OR models and tools into existing systems and ensure their seamless implementation.\nPresent research findings and insights to stakeholders, including senior management, in a clear and concise manner and collaborate with cross-functional teams to drive process improvements, optimize resource allocation, and enhance operational efficiency.\nWhat You'll Bring\nStrong knowledge of mathematical modeling, optimization techniques, simulation methodologies, and AI\/ML models.\nProficiency in programming languages such as Python, R, Java, and experience with statistical analysis and data visualization tools.\nExpertise in applying OR techniques to complex business problems, preferably in a corporate or consulting environment.\nExcellent problem-solving skills and the ability to think critically and analytically.\nStrong communication and presentation skills, with the ability to convey complex concepts to both technical and non-technical stakeholders.\nAdditonal Comments From The Hiring Manager\nMaster's or Ph.D. in Operations Research, Industrial Engineering, Mathematics, or a related field. 2. Proven track record of leading and managing cross-functional projects, delivering high-quality results within specified timeframes. 3. Experience with database management systems, cloud computing, data mining, and ML algorithms is a plus. 4. Ability to work independently and collaboratively in a fast-paced, dynamic environment. 5. Strong attention to detail, organizational skills, and the ability to multitask effectively.\nAbout Walmart Sam's Club Supply Chain\nSam Walton opened the first Sam's Club in 1983 to meet a growing need among customers who wanted to buy merchandise in bulk. Since then, Sam's Club has grown rapidly, opening more than 600 clubs in the U.S. and 100 clubs internationally. By offering affordable, wholesale merchandise to members, Sam's Club helps make saving simple for families and small business owners. Sam's Club employs about 110,000 associates in the U.S. The average club is 134,000 square feet and offers bulk groceries and general merchandise. Most clubs also have specialty services, such as a pharmacy, an optical department, a photo center, or a tire and battery center.\nFuture Ways Of Working\nOur company's success can be attributed to our employees. While technology has allowed us to be effective while working remotely, there is no substitute for being in the office together; it helps to shape our culture, collaborate, innovate, build relationships, and move more quickly. We strive to provide flexibility in order to promote a healthy work-life balance but recognize that in-person interactions are important to our culture and shared success. We'll meet in person on a regular and purposeful basis.\nBenefits\nBenefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.\nEqual Opportunity Employer\nSam's Club is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, abilities, ideas and opinions- while being inclusive of all people.\nThe above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.\nMinimum Qualifications...\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\nOption 1- Bachelor's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.\nPreferred Qualifications...\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\nData science, machine learning, optimization models, Master's degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)\nPrimary Location...\n603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America\nShow more\nShow less",
      "job_skills":"Mathematical optimization, Simulation, AI\/ML, Mathematical modeling, Statistical analysis, Datadriven insights, Inventory management, Demand forecasting, Network optimization, Replenishment, Logistics planning, Data analytics, Strategy, Execution, OR, LP\/MILP\/IP, Algorithms, Decision support systems, Dashboards, Reporting tools, Python, R, Java, Statistical analysis, Data visualization, Operations Research, Industrial Engineering, Mathematics, Database management systems, Cloud computing, Data mining, ML algorithms",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist - Aerospace",
      "company":"The Patriot Group, Inc. (TPGI)",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-aerospace-at-the-patriot-group-inc-tpgi-3786001604",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Data Scientist \u201a\u00c4\u00ec Growing Aerospace Company\nWork for one of the most dynamic and fastest growing Aerospace companies in Texas. With a great leadership team, incredible employee appreciation and undeniable chances to grow \u201a\u00c4\u00ec look what we have to offer you!\nWork Schedule:\n9\/80 work schedule, in-office position, some flexibility may be considered.\nPay:\n$110-$130K annually plus benefits\nCompany Profile\nBased in Fort Worth Texas area, the company was founded with a vision of bringing advanced vertical lift solutions to the civil market.\nCompany has established a strong reputation as a technology innovator in vertical takeoff and landing (VTOL) aircraft design.\nCompany strategy incorporates three elements of the business: Science and Technology (S&T), Unmanned Aircraft Systems (UAS), and Sustainment Products and Services.\nMade up of highly experienced engineers and aerospace professionals that have come together as a team to create innovative designs, that use modern technology, that delivers visionary performance in the vertical lift environment.\nFeatures And Benefits\n9\/80 work schedule, in-office position, some flexibility may be considered.\nHealth Insurance Options\nCompetitive 401K with employer matching.\nIn-office position with work from home flexibility.\nRole You Will Play\nCompany is developing cutting-edge, algorithmic-based simulation, operational awareness, and mission planning capabilities to a wide variety of Dept of Defense (DoD) customers. Company specially selected team of industry partners\/academia including engineers, software developers and scientists develop algorithms, software integrated prototypes and solutions for Artificial Intelligence, Machine Learning, Mission Planning, and Operational Awareness.\nThe successful candidate will work on a team developing new code bases that are heavily object-oriented, extensible, and maintainable. The team follows Agile development processes and ensures fast and secure delivery of software services.\nResponsibilities\n: As a Senior Data Scientist, you will:\nWork with a team of data engineers, software developers, and data scientists to develop and deploy capabilities to address highly complex AI\/ML challenges.\nCollaborate with data and subject matter experts from customers to seek, understand, validate, interpret, and correctly use new data elements.\nLead a small university team of data engineers through an Agile development process, maintain schedules, and provide overall technical direction for successful completion of projects.\nExternally, maintain customer relationships and serve as a subject matter expert.\nBe the subject matter expert for the team in data science and algorithm development in a variety of fields including data transformation, predictive analytics, time series data, visualization, and advanced metrics.\nTake a holistic approach to algorithm development to ensure the most value added to the warfighter. This includes considering not just the algorithm itself, but the whole system including labels, software infrastructure, and user interface.\nBACKGROUND PROFILE\nMust Haves\n5+ years of relevant experience.\nAerospace\/aviation industry experience is a must.\nExperience in predictive maintenance and performance-based logistics PBL.\nExpertise using Python to solve data science problems.\nExperience with data management pipeline technology\nMySQL and MS Azure experience.\nDemonstrated performance in managing program schedules to successful program conclusion in an Agile environment.\nBachelor\u201a\u00c4\u00f4s degree or higher in Engineering, Applied Mathematics, Physics, or a related field.\nNice To Haves\nExperience implementing cloud services, a plus.\nExperience evaluating the quality of advanced models, a plus.\nNatural language processing experience, a plus\nShow more\nShow less",
      "job_skills":"Python, MySQL, MS Azure, Agile development, Data management pipeline technology, Artificial Intelligence, Machine Learning, Mission Planning, Operational Awareness, Predictive analytics, Time series data, Visualization, Advanced metrics, Data transformation, Cloud services, Natural language processing, Algorithms, Software infrastructure, User interface, Labels, Engineering, Applied Mathematics, Physics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"ClickJobs.io",
      "job_location":"Paris, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-clickjobs-io-3789142208",
      "search_city":"Hugo",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Plano 1 (31061), United States of America, Plano, TexasLead Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, i nclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Lead Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do:\nCollaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\nWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems\nUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake\nShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community\nCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\nPerform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 6 years of experience in application development (Internship experience does not apply)\nAt least 2 years of experience in big data technologies\nAt least 1 year experience with cloud computing (AWS, Microsoft Azure, Google Cloud)\nPreferred Qualifications:\n7+ years of experience in application development including Python, SQL, Scala, or Java\n4+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n4+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)\n4+ year experience working on real-time data and streaming applications\n4+ years of experience with NoSQL implementation (Mongo, Cassandra)\n4+ years of data warehousing experience (Redshift or Snowflake)\n4+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Java, Scala, Python, Open Source RDBMS, NoSQL, Redshift, Snowflake, AWS, Microsoft Azure, Google Cloud, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL, Mongo, Cassandra, UNIX\/Linux, Agile",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Archetype Permanent Solutions",
      "job_location":"El Paso, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-archetype-permanent-solutions-3787916075",
      "search_city":"Santa Clara",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are seeking a highly skilled and analytical Data Scientist to join our team. The ideal candidate will be adept at using large data sets to find opportunities for product and process optimization, and using models to test the effectiveness of different courses of action. This role will require both a strong technical background in data analysis and the ability to communicate findings to non-technical teams and stakeholders.\nKey Responsibilities:\nWork with stakeholders to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nQualifications:\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Statistics, Mathematics, Computer Science, or another quantitative field.\n2 years of experience in a Data Scientist or Data Analyst role.\nStrong problem-solving skills with an emphasis on product development.\nExperience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages\/drawbacks.\nExcellent written and verbal communication skills for coordinating across teams.\nPreferred Skills:\nExperience with distributed data\/computing tools: Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\nExperience with AWS, Azure, or another cloud service.\nExperience visualizing\/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.\nBenefits:\nCompetitive salary and benefits package.\nDynamic and innovative work environment.\nOpportunities for professional growth and development.\n[Other company-specific benefits like remote work options, flexible schedules, wellness programs, etc.]\nHow to Apply:\nPlease submit your resume, cover letter, and any relevant work samples\nPowered by JazzHR\n2c7D8cKfPG\nShow more\nShow less",
      "job_skills":"Data science, Data analysis, Statistics, Mathematics, Computer science, Machine learning, Predictive modeling, Data modeling, Data visualization, Communication, R, Python, SQL, Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, AWS, Azure, Cloud computing, Periscope, Business Objects, D3, ggplot",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer (Python)",
      "company":"ClickJobs.io",
      "job_location":"Waco, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-python-at-clickjobs-io-3790456791",
      "search_city":"Waco",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Center 1 (19052), United States of America, McLean, Virginia Senior Data Engineer (Python) Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs.\nWe are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do: Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply) At least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java 2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud) 3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL) 2+ year experience working on real-time data and streaming applications\n2+ years of experience with NoSQL implementation (Mongo, Cassandra)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting 2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position. The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. San Francisco, California (Hybrid On-Site): $171,500 - $195,800 for Senior Data Engineer Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u201a\u00c4\u00f4s offer letter. This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and\/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan. Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the\nCapital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. This role is expected to accept applications for a minimum of 5 business days. No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Java, Scala, Python, RDBMS, NoSQL, Redshift, Snowflake, Cloud data warehousing, Machine learning, Distributed microservices, Full stack systems, Unit testing, Agile engineering practices, UNIX\/Linux, Shell scripting, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL, Mongo, Cassandra",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"ClickJobs.io",
      "job_location":"Waco, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-clickjobs-io-3789138927",
      "search_city":"Waco",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Center 1 (19052), United States of America, McLean, VirginiaSenior Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking\nData Engineers\nwho are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do:\nCollaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\nWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems\nUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake\nShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community\nCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\nPerform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply)\nAt least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java\n2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)\n2+ year experience working on real-time data and streaming applications\n2+ years of experience with NoSQL implementation (Mongo, Cassandra)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Java, Scala, Python, Open Source RDBMS, NoSQL databases, Redshift, Snowflake, Machine learning, Distributed microservices, Full stack systems, Agile engineering practices, Cloud based data warehousing services, UNIX\/Linux, Shell scripting, Data warehousing, Realtime data, Streaming applications, Big data technologies, MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL, Mongo, Cassandra",
      "Category":"Backend Development"
  },
  {
      "job_title":"Machine Learning Engineer\/Data Scientist",
      "company":"Newlineinfo Corp - IT Services and IT Consulting",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/machine-learning-engineer-data-scientist-at-newlineinfo-corp-it-services-and-it-consulting-3780050458",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Sr ML Engineer \/ Data Scientist\nLocation: Irving TX (Onsite) (Local candidates only)\nContract\n10+ years\nBachelor\u201a\u00c4\u00f4s degree.\nFour or more years of work experience in software development\/ML Engineering jobs.\nAt least two years of experience are in ML Engineering areas.\nExperience with Python\/Java programming\nExperience in cloud based development and production environments - AWS, GCP and On-prem clusters\nFamiliarity with large scale cloud-based platform\/pipeline development and productization.\nHave experience with basic ML practices and standard workflows.\nEven better if you have one or more of the following:\nUnderstand basic data science concepts and common needs from data scientists.\nStrong collaboration skills and communication skills, especially when involving (non-tech) business stakeholders.\nExperience with cloud infrastructures\/cloud Ops\nFamiliar with CI\/CD process and common frameworks.\nFamiliar with MLOps\/DevOps.\nShow more\nShow less",
      "job_skills":"Machine Learning Engineering, Data Science, Python, Java, Cloud Development, Cloud Production Environments, AWS, GCP, Onprem Clusters, Large Scale CloudBased Platform\/Pipeline Development and Productization, Basic ML Practices, Standard Workflows, Data Science Concepts, Collaboration Skills, Communication Skills, Cloud Infrastructure\/Cloud Ops, CI\/CD Process, Frameworks, MLOps\/DevOps",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Science Manager (Workforce Planning)",
      "company":"JPMorgan Chase & Co.",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-science-manager-workforce-planning-at-jpmorgan-chase-co-3773574983",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"When joining the Workforce Planning (WFP) organization it is a part of Consumer and Community (CCB) Operations division. The WFP Data Science organization is tasked with delivering quantitatively driven solutions to support the core WFP functions (demand forecasting, capacity planning, resource scheduling, and business analysis & support). The WFP organization supports Chase\u201a\u00c4\u00f4s call centers, back office, and ~5,200 retail branches\nAs a Senior Data Science Manager in Workforce Planning, you will be expected to analyze the topic in question, develop solution proposals and review their results and next steps with management for prioritization, timing, and delivery. The\nAI\/ML team is tasked with building next-gen data science solutions that move us closer to real-time inference and decision making. Projects engaged by the Artificial Intelligence(AI)\/Machine Learning(ML) team can be complex, data intensive, and of a high level of difficulty, each having significant impact on the business. Typically these problems will be of an unstructured nature, whereby the employee will be expected to quickly assess and comprehend the situation then develop a practical problem solving strategy.\nJob responsibilities:\nDefine the data science vision, strategy and roadmap for the organization.\nManage a team of highly-capable and independent sole contributors, along with mentor, coach and grow people earlier in their careers In this role.\nAttract, develop and retain data science talent to ensure the team continues to enhance its value to the company.\nOversees the design and development of Machine Learning, Artificial Intelligence and Statistical models.\nEnsure the robustness of any data science solution.\nDevelop and communicate recommendations and data science solutions in easy-to-understand-way leveraging data to tell a story.\nLead and persuade others while positively influencing the outcome of team efforts and help frame a business problem into a technical problem resulting in a feasible solution.\nRequired qualifications, capabilities, and skills:\nMaster\u201a\u00c4\u00f4s Degree with 5+ years or Doctorate (PhD) with 3+ years of experience operating as an data science professional (e.g. data scientist, statistician, or related professions) in a quantitative field: Statistics, Analytics, Data Science, Engineering, Operations Research, Economics, Mathematics, Machine Learning, Artificial Intelligence, and related disciplines.\n4+ years of direct people leadership experience.\nHands-on experience developing statistical models, machine learning models, and\/or artificial intelligence models.\nDeep understanding of math and theory behind AI\/ML algorithms.\nProficient in data science programming languages like Python, R or Scala.\nExperience with big-data technologies such as Hadoop, Spark, SparkML, etc. & familiarity with basic data table operations (SQL, Hive, etc.).\nDemonstrated relationship building skills, with a superior ability to make things happen through the use of positive influence.\nPreferred qualifications, capabilities, and skills:\nAdvanced expertise with Time Series and Operations Research techniques.\nNatural Language Processing(NLP)\/Natural Language Generation(NLG), Neural Nets, or other ML\/AI skills.\nPrior experience with public cloud technologies such as Amazon Web Services(AWS), Azure or Google Cloud Platform(GCP).\nPrevious experience leading highly complex cross-functional technical projects with multiple stakeholders.\nThis is a Hybrid position which will require the incumbent to commute\/work on site 3 days a week and work from home 2 days a week.\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Artificial Intelligence, Statistics, Analytics, Engineering, Operations Research, Economics, Mathematics, Python, R, Scala, Hadoop, Spark, SparkML, SQL, Hive, Time Series, Operations Research, Natural Language Processing, Natural Language Generation, Neural Nets, Amazon Web Services, Azure, Google Cloud Platform",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Scientist",
      "company":"McKesson",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-scientist-at-mckesson-3771733336",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve \u201a\u00c4\u00ec we care. What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow\u201a\u00c4\u00f4s health today, we want to hear from you.\nThe Lead Data Scientist role is responsible for architecting and implementing data science products to enhance the efficiency and effectiveness of McKesson\u201a\u00c4\u00f4s supply chain network as part of McKesson\u201a\u00c4\u00f4s Supply Chain Analytics Center of Excellence.\nOur team applies data science methodologies to interdisciplinary business problems across Operations & Supply Chain. This position will work on strategic in-flight use cases around supply disruption and in-flight inventory programs. The position\u201a\u00c4\u00f4s objectives are:\nLead development of enhancements to supply disruption prediction and associated inventory programs.\nUtilize advanced analytics, machine learning, and predictive modeling to identify trends, risks, and opportunities within McKesson supply chain.\nResponsible for evaluation of new inventory opportunities, as well as quantifying & tracking financial impact of inventory actions and programs.\nAssist in the development of customer level inventory programs and policies.\nThe candidate should possess the ability to perform statistical modelling techniques and derive business insights that are required to drive analytic innovation at McKesson. The candidate should also be an active learner able to grasp and apply new analytic approaches, as well as mentor both senior and junior resources.\nPosition Description:\nThe purpose of this position is to architect, implement, drive adoption, and measure impact of innovative analytic solutions at McKesson, as well as make significant improvements to existing solutions.\nAnalytic Responsibilities:\nLead development & implementation of supply disruption analytics for supply chain leaders.\nDevelop continuous monitoring systems in order to dynamically track McKesson network and continuously identify areas of working capital opportunity.\nPlay a leading role in shaping and developing McKesson\u201a\u00c4\u00f4s digital supply chain strategy.\nOther Responsibilities:\nSupport stakeholders\u201a\u00c4\u00f4 analytic needs, gather user requirements, help drive adoption .\nCultivate business development opportunities.\nAssist in developing and maintaining long-term stakeholder relationships and networks.\nMinimum Requirements:\nExperience: 7+ years data science \/ analytics \/ programming experience based on combination of industry and academic experience\nEducation: bachelor\u201a\u00c4\u00f4s degree in a technical field such as: Operations Research, Computer Science, Statistics, Applied Mathematics, Economics, Engineering or related quantitative \/ STEM majors\nCritical Skills:\nDemonstrated expertise working closely with business stakeholders to leverage analytics to shape corporate strategy\nKnowledge of statistical methods and advanced modeling techniques (e.g., SVM, Random Forest, Bayesian inference, graph models, NLP, Computer Vision, neural networks, etc.)\nDemonstrated ability to tackle problems across the full data stack, from data wrangling (leveraging SQL or other methodologies) to stakeholder consumption at scale\nKnowledge of machine learning \/ data science best practices\nKnowledge of statistical programming (SAS, R, MATLAB)\nAbility to communicate technical concepts to non-technical audiences\nDemonstrated experience with objected oriented programming (Python, Java, C#, VBA, etc.)\nStrong grasp of fundamental statistical concepts: linear regression, A\/B testing, outlier analysis, probability distributions, tests for independence, etc.\nAdditional Knowledge & Skills:\nAnalysis\/Process Thinking\nTeam player\nStrong verbal and written communication\nKnowledge of relational databases (e.g. MS SQL Server, Snowflake, Oracle)\nKnowledge of cloud computing platforms is a plus (e.g. Azure, AWS, Google Cloud, Databricks)\nProficient with Excel spreadsheets, financial modeling, and reporting\nPrior data mining experience using enterprise systems (SAP or JD Edwards preferred)\nKnowledge of data warehousing & ETL best practices is a plus\nAt McKesson, we care about the well-being of the patients and communities we serve, and that starts with caring for our people. That\u201a\u00c4\u00f4s why we have a Total Rewards package that includes comprehensive benefits to support physical, mental, and financial well-being. Our Total Rewards offerings serve the different needs of our diverse employee population and ensure they are the healthiest versions of themselves. For more information regarding benefits at McKesson, please click here.\nAs part of Total Rewards, we are proud to offer a competitive compensation package at McKesson. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered.\nOur Base Pay Range for this position\n$147,500 - $245,800\nMcKesson is an Equal Opportunity\/Affirmative Action employer.\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.Qualified applicants will not be disqualified from consideration for employment based upon criminal history.\nMcKesson is committed to being an Equal Employment Opportunity Employer and offers opportunities to all job seekers including job seekers with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to Disability_Accommodation@McKesson.com. Resumes or CVs submitted to this email box will not be accepted.\nCurrent employees must apply through the internal career site.\nJoin us at McKesson!\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Predictive Modeling, Statistical Modeling, Supply Chain Analytics, SQL, Python, Java, C#, VBA, Microsoft SQL Server, Snowflake, Oracle, Azure, AWS, Google Cloud, Databricks, Excel, SAP, JD Edwards, Data Warehousing, ETL, Natural Language Processing, Computer Vision, Neural Networks",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Engineer (Blockchain) - (Remote in the US)",
      "company":"Resource Informatics Group, Inc",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-blockchain-remote-in-the-us-at-resource-informatics-group-inc-3767592303",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Sr. Data Engineer (Blockchain) - (Remote in the US) - 1571\nSalary Range\n: ABC + bonus + stock options\nLocation:\n100% Remote (within US)\nPosition Type:\nFTE - no contracting\nWork Authorization:\nNo sponsorship offered. USC and GC only\nCommunication:\nExcellent in verbal, written and comprehension\nThe Role\nYou'll work with a cross-functional team of research scientists and engineers to contribute to our software and data platforms.\nDrive the design and implementation of data models, ETL pipelines, and data processing logic while working closely with the other teams in order to translate operational data with microservices into business value.\nCollaborate in proof of concepts (POCs) from research concepts and then lead building those in a production environment.\nWork on complex problems ranging from mathematical proofs to big data processes to fueling research with blockchain, financial, and gaming metrics.\nWe are looking for someone with a curiosity for data and the ability to iterate quickly in an ambiguous environment.\nPreferred experience with finance, gaming\/crypto gaming, blockchain, or crypto protocols.\nBonus Domain expertise in one or more areas: finance, gaming, DeFi, cryptocurrency, blockchain, and smart contracts.\nRequired Experience\nAdvanced skills with python (or similar language) for data collection, analysis, and communication including familiarity with pandas package, object-oriented programming, and built-in functions.\nExperience in Web3 including smart contract development, blockchain data, and DeFi protocols such as Uniswap.\nHands-on experience in AWS Cloud services including building and implementing server and serverless data engineering, data science, and analytics infrastructure. Bonus for experience integrating services such as Airflow.\nExperience communicating and delivering results with data scientists, machine learning, and modeling valuable to implementing use cases.\nUnderstanding of Test-Driven Development.\nGood knowledge of ETL, data warehousing, and pipelines design.\nPreferred 5+ years of experience in a data focused role including ETL, querying data with SQL, data modeling, data collection, data analysis, and data science.\nCuriosity, empathy, and an interest in working with a team with a high degree of collaboration.\nAn ability to adapt and work under large amounts of uncertainty and ambiguity.\nShow more\nShow less",
      "job_skills":"Python, Pandas, Objectoriented programming, Smart contract development, Blockchain data, DeFi protocols, AWS Cloud services, Serverless data engineering, Data science, Analytics, Airflow, TestDriven Development, ETL, Data warehousing, Pipelines design, SQL, Data modeling, Data collection, Data analysis",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"Dynatron Software, Inc.",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-dynatron-software-inc-3768749551",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Lead Data Engineer\n100% Remote | Full Time\nWe are seeking a dynamic and experienced Lead Data Engineer to join our newly formed Data Platform Team. As a Lead Data Engineer, you will have the opportunity to collaborate with a team of data scientists, engineers, and analysts to create and maintain scalable data pipelines. You will be responsible for writing big data pipelines in Python and DBT transformations in SQL. The ideal candidate will have a strong technical background, a passion for data processing, and the ability to think creatively and strategically to solve complex challenges.\nKey Responsibilities:\nWrite, test, and maintain robust, high-quality code in Python and DBT data models on Snowflake.\nWork with data and analytics experts to strive for greater functionality in our data systems.\nCollaborate with cross-functional teams to gather requirements and develop software solutions.\nDesign, construct, install, test, and maintain highly scalable data management systems.\nProvide debugging and troubleshooting support for existing systems.\nParticipate in code reviews to ensure software quality and adherence to standards.\nAssist in database design and the development of our Snowflake data warehouse.\nLeverage AWS and other cloud technologies for efficient software deployment and scalability.\nUse Python to process and clean data, manage ETL pipelines, and create automated workflows.\nMinimum Qualifications:\nBachelor's degree in Computer Science, Engineering, or a related field.\n5+ years of experience in designing, implementing, and maintaining relational\/data warehousing environments.\nStrong proficiency in programming languages commonly used in data engineering, such as Python, SQL, and big data technologies like Snowflake, Spark, Kafka, and distributed computing frameworks.\nExperience working with data warehouses and relational databases.\nFamiliarity with AWS and\/or other cloud-based technologies.\nExperience with Big Data technologies such as Hadoop, Spark, Beam, Flink, or similar technologies is a plus.\nExcellent problem-solving skills with a strong attention to detail.\nAbility to work both independently and as part of a team.\nExcellent verbal and written communication skills.\nPreferred Qualifications:\nExperience working on a project that involved multi-classification\nExperience with hybrid cloud workflows\nIn Return for Your Expertise, You Will Receive:\nExcellent benefits including health, dental, and vision insurance, stock options, work from home and flexible scheduling depending on job requirements, professional development opportunities, 9 paid holidays, and 15 days PTO.\nHome office setup support for remote employees.\nA welcome \u201a\u00c4\u00faswag bag\u201a\u00c4\u00f9 with branded clothing as an official welcome to the team.\nThe chance to work for an organization that puts people first and fosters a culture of teamwork, integrity, communication, accountability, and positive attitude!\nDynatron Software is an Equal Opportunity Employer and encourages all qualified individuals to apply.\nCompensation:\n$130,000 - $160,000\nShow more\nShow less",
      "job_skills":"Python, DBT, SQL, Snowflake, AWS, Hadoop, Spark, Beam, Flink, Kafka, Multiclassification, Hybrid cloud workflows, ETL pipelines, Data warehouses, Relational databases, Distributed computing frameworks, Big data technologies",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist - National Defense\/Python\/SQL\/AWS\/MLOps\/Clearances",
      "company":"Motion Recruitment",
      "job_location":"Laughlin AFB, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-national-defense-python-sql-aws-mlops-clearances-at-motion-recruitment-3732144864",
      "search_city":"Del Rio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"An Artificial Intelligence\/National Defense start-up is searching for Data Scientists to join their team. You would be solving complex problems by being a systems-level thinker, all the while transforming the nation\u201a\u00c4\u00f4s defense and national security. This team handles abstract problems regarding the public policy surrounding climate change, energy, and national security, among other pressing issues.\nSome of your responsibilities would include discovering datasets that could help in solution development; curating data, analyzing, and performing quantitative modeling; validating the quality of data, models, and results; deploying and implementing solutions in collaboration with product team; and interacting with the product team on current and upcoming user requirements.\nRequired Skills & Experience\nMasters or Ph.D. in Sciences, Mathematics or Engineering, especially numerical methods and simulations\nAt least 4 years of professional experience in a Data Scientist position\nPython (pandas, numpy, scipy, sci-kit learn, etc)\nSQL \/ MySQL\nCloud computing, preferably in an AWS environment\nLarge-scale data processing and implementing batch processing pipelines in HPC or cloud architecture\nActive government clearance (secret, top secret, ts\/sci - no Poly required)\nWhat You Will Be Doing\nDaily Responsibilities\n70% Hands On\n30% Team Collaboration\nThe Offer\nBonus eligible\nYou Will Receive The Following Benefits\nFull medical, dental, vision coverage for employee and dependents\n401k matching program\nPTO and Holidays\nBonus and other incentive programs\nAccess to mental health program\nAccess to Flexible Spending Accounts for Health Care, Dependent and Commuter\nApplicants must be currently authorized to work in the US on a full-time basis now and in the future. Possession of at minimum a Secret Clearance is required.**\nPosted By:\nLindsay Troyer\nShow more\nShow less",
      "job_skills":"Data Science, Systems Thinking, Numerical Methods, Simulations, Python, Pandas, Numpy, Scipy, Scikit Learn, SQL, MySQL, Cloud Computing, AWS, HPC, Batch Processing Pipelines, Government Clearance, Team Collaboration, Full Medical Coverage, Dental Coverage, Vision Coverage, 401k Matching Program, PTO, Holidays, Bonus Programs, Incentive Programs, Mental Health Program, Flexible Spending Accounts for Health Care, Dependent Accounts, Commuter Accounts",
      "Category":"Backend Development"
  },
  {
      "job_title":"Staff Data Scientist",
      "company":"Michaels Stores",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/staff-data-scientist-at-michaels-stores-3711754844",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Support Center - Irving\nMichaels Staff Data Scientists will develop systems and techniques for identifying business trends and challenges through complex big data analysis. As a Staff Data Scientist at Michaels, you will design, develop, and implement data system solutions for the organization. You will interpret results from multiple sources using techniques including statistical analysis, machine learning, and data mining. You will work with teams to design architectures, breaking down tasks, and reviewing code.\nThe ideal candidate will have a passion for developing machine learning models, analyzing data, and identifying trends, has a high degree of customer obsession, and a track record for delivering results.\nLead the Development of new techniques for inferring user interests from online activity\nOversee the development and investigate machine learning algorithms to improve current processes.\nReview the analysis of large amounts of Michaels's historical business data to detect patterns, trends, correlations, and casualties\nDesign and run A\/B experiments that affect millions of customers and evaluate the impact of optimizations and communicate results to various business stakeholders.\nEnhance applications by identifying opportunities for improvement and making recommendations\nManage individual project priorities, deadlines, and deliverables\nWork with teams to implement solutions based on data findings\nDesign architectures, breaking down tasks, and reviewing code\nInvestigate and use new technologies where relevant\nOther duties as assigned\nMinimum Knowledge\/Skills\/Abilities\nMinimum Education\nBachelor\u201a\u00c4\u00f4s Degree or higher in Computer Science, Statistics, Math, or a related technical field.\nMinimum Special Certifications Or Technical Skills\nProficiency in Python, SQL, and distributed data technologies (Hive, Spark)\nMinimum Type Of Experience The Job Requires\n6+ years of industry experience, with experience in machine learning, data analysis, and business analysis\nFluency in Python, R, SQL\nExperience in computer vision or natural language processing is a plus\nOther\nAbility to draw insights and present conclusions from data to inform model development and business decisions\nAbility to conduct rigorous analysis and communicate conclusions to both technical and non-technical audiences\nDeep understanding of Machine Learning concepts and statistical methods\nSolid communication and collaboration skills with the ability to work effectively with internal teams\nExcellent problem-solving and debugging skills\nExcellent communication and collaboration skills.\nMentor and lead other data scientist in the team\nHave a strong business acumen and experience working in a client-facing role.\nApplicants in the U.S. must satisfy federal, state, and local legal requirements of the job.\nTo review a comprehensive list of benefits, please visit\nMichaels Benefits (MIKBenefits.com)\nCA, CO, CT, WA, RI and select New York cities only\n- To review pay ranges for the position you are applying for, please visit\nMichaels Pay Ranges - CA, CO, CT, WA, RI, and select New York cities only. (MIKBenefits.com)\nFor nearly 50 years, Michaels has been the destination where Makers get inspired, learn, shop, and create. We strive to cultivate an inclusive shopping environment for all Makers and work environment for all Team Members, providing a place of belonging and empowering everyone to bring their creative dreams to life. At Michaels, every Team Member is encouraged to hone their craft with opportunities for personal and professional growth. From our Stores and Distribution Centers to Artistree and our Support Center, our best-in-class team is passionate about leaving the world a better, more creative place by contributing to every \u201a\u00c4\u00famake\u201a\u00c4\u00f9.\nMichaels is an Equal Opportunity Employer. We are here for all Team Members and all Makers to create, innovate and be better together.\nMichaels is committed to the full inclusion of all qualified individuals. In keeping with this commitment, Michaels will assure that people with disabilities are provided reasonable accommodations. Accordingly, if a reasonable accommodation is required to fully participate in the job application or interview process, to perform the essential functions of the job, and\/or to receive all other benefits and privileges of employment, please contact Customer Care at 1-800-642-4235 (1800-MICHAEL).\nEEOC Know Your Rights Poster in English\nEEOC Know Your Rights Poster in Spanish\nEEOC Poster Optimized for Screen Readers\nFederal FMLA Poster\nFederal EPPAC Poster\nShow more\nShow less",
      "job_skills":"Data Analysis, Machine Learning, Python, SQL, Spark, Hive, R, Natural Language Processing, Computer Vision, Statistical Analysis, Data Mining, Hadoop, NoSQL, Data Science, Data Warehousing, Data Visualization, Business Intelligence, Agile Methodology, Software Development, Software Engineering, Cloud Computing, Big Data",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Archetype Permanent Solutions",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-archetype-permanent-solutions-3787919061",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are seeking a highly skilled and analytical Data Scientist to join our team. The ideal candidate will be adept at using large data sets to find opportunities for product and process optimization, and using models to test the effectiveness of different courses of action. This role will require both a strong technical background in data analysis and the ability to communicate findings to non-technical teams and stakeholders.\nKey Responsibilities:\nWork with stakeholders to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nQualifications:\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Statistics, Mathematics, Computer Science, or another quantitative field.\n2 years of experience in a Data Scientist or Data Analyst role.\nStrong problem-solving skills with an emphasis on product development.\nExperience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages\/drawbacks.\nExcellent written and verbal communication skills for coordinating across teams.\nPreferred Skills:\nExperience with distributed data\/computing tools: Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\nExperience with AWS, Azure, or another cloud service.\nExperience visualizing\/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.\nBenefits:\nCompetitive salary and benefits package.\nDynamic and innovative work environment.\nOpportunities for professional growth and development.\n[Other company-specific benefits like remote work options, flexible schedules, wellness programs, etc.]\nHow to Apply:\nPlease submit your resume, cover letter, and any relevant work samples\nPowered by JazzHR\nTlUnM2Gp6d\nShow more\nShow less",
      "job_skills":"Data Science, Predictive modeling, Machine learning, R, Python, SQL, Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, AWS, Azure, Periscope, Business Objects, D3, ggplot",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Ledgent Technology",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-ledgent-technology-3764317173",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Python Programming:\nCore Python for general programming tasks.\nAdvanced Python concepts for efficient coding.\nLarge Language Models:\nLlama 2\nGPT-based models\nOther LLM frameworks as they become relevant.\nsophisticated agent creation\nMachine Learning Frameworks:\nTensorFlow\nPyTorch\nNatural Language Processing (NLP):\nNLTK (Natural Language Toolkit)\nspaCy\nNER\nTransformers (by Hugging Face)\nCloud Platforms:\nAmazon Web Services (AWS)\nGoogle Cloud Platform (GCP)\nMicrosoft Azure\nVersion Control:\nGit\nContainerization and Orchestration:\nDocker\nKubernetes\nCI\/CD Tools:\nGithub\nIntegrated Development Environments (IDEs):\nPyCharm\nVisual Studio Code\nJupyter Notebook\nDatabases:\nSQL-based (e.g., PostgreSQL, MySQL)\nNoSQL (e.g., MongoDB, Cassandra)\nPinecone or other vector\nAll qualified applicants will receive consideration for employment without regard to\nrace, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, medical condition, genetic information, pregnancy, or military or veteran status.\nWe consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.\nShow more\nShow less",
      "job_skills":"Python, Advanced Python Concepts, Large Language Models, Llama 2, GPTbased Models, Other LLM Frameworks, TensorFlow, PyTorch, Natural Language Processing (NLP), NLTK (Natural Language Toolkit), spaCy, Named Entity Recognition (NER), Transformers (by Hugging Face), Amazon Web Services (AWS), Google Cloud Platform (GCP), Microsoft Azure, Git, Docker, Kubernetes, Github, PyCharm, Visual Studio Code, Jupyter Notebook, SQLbased Databases, NoSQL Databases, Pinecone, Vector Databases",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"snipeHIRE",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-snipehire-3787766842",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company\nThe Company specializes in digital enablement and transformation using industry-leading process mining, data management and automation platforms. They help Fortune 500 companies become more process-efficient and improve their end-customer experience through the use of RPA, AI & ML powered solutions. The company has been growing at an accelerated pace and is looking to add experienced folks to their core technology team.\nPosition Summary\nwe are looking for a Senior Data Scientist to help drive actionable insights using artificial intelligence and machine learning algorithms. The candidate should conduct and manage analysis and modelling in the areas of machine learning, neural networks, robotics etc.\nKey Responsibilities\nWork with business partners within one business process to align technology solutions with business strategies.\nAbility to translate business questions into analytical problems and recommend solutions using statistical modelling, text mining, machine learning, artificial intelligence techniques\nUtilize technologies to collect, clean and analyze data from multiple systems and mine insights\nConceptualize, design, and deliver high quality solutions and insightful analysis using algorithms like Neutral Networks, Genetic Algorithm, Deep Learning, Reinforcement Learning and effectively communicates information\nContribute to multiple projects and collaborate with other team members for timely and successful delivery.\nRequired Experience, Skills & Education\n9+ years of relevant experience conducting text mining, NLP, machine learning, deep learning, artificial intelligence techniques-based models\nTool Expertise - Python, R, SQL, SAS Good To Have Experience in working on Big data, Cloud, Hadoop, Spark, End to end deployment\nStrong background in developing and supporting very large-scale analytical solutions\nAbility to be an independent contributor to solve complex data-analytics problems\nIndustry experience in High-Tech, Manufacturing, Retail, Pharma\nMaster's degree in statistics, mathematics, computer science, business analytics\nPowered by JazzHR\nkeE1wsk4I4\nShow more\nShow less",
      "job_skills":"Artificial Intelligence, Machine Learning, Neural Networks, Robotics, Statistical Modelling, Text Mining, Data Analysis, Data Mining, Algorithms, Python, R, SQL, SAS, Hadoop, Spark, Big Data, Cloud, Endtoend Deployment",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"SNIPEBRIDGE",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-snipebridge-3733718666",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"COMPANY\nThe Company specializes in digital enablement and transformation using industry-leading process mining, data management and automation platforms. They help Fortune 500 companies become more process-efficient and improve their end-customer experience through the use of RPA, AI & ML powered solutions. The company has been growing at an accelerated pace and is looking to add experienced folks to their core technology team.\nPOSITION SUMMARY\nwe are looking for a Senior Data Scientist to help drive actionable insights using artificial intelligence and machine learning algorithms. The candidate should conduct and manage analysis and modelling in the areas of machine learning, neural networks, robotics etc.\nKEY RESPONSIBILITIES\nWork with business partners within one business process to align technology solutions with business strategies.\nAbility to translate business questions into analytical problems and recommend solutions using statistical modelling, text mining, machine learning, artificial intelligence techniques\nUtilize technologies to collect, clean and analyze data from multiple systems and mine insights\nConceptualize, design, and deliver high quality solutions and insightful analysis using algorithms like Neutral Networks, Genetic Algorithm, Deep Learning, Reinforcement Learning and effectively communicates information\nContribute to multiple projects and collaborate with other team members for timely and successful delivery.\nREQUIRED EXPERIENCE, SKILLS & EDUCATION\n9+ years of relevant experience conducting text mining, NLP, machine learning, deep learning, artificial intelligence techniques-based models\nTool Expertise -\nPython, R, SQL, SAS Good To Have Experience in working on Big data, Cloud, Hadoop, Spark, End to end deployment\nStrong background in developing and supporting very large-scale analytical solutions\nAbility to be an independent contributor to solve complex data-analytics problems\nIndustry experience in High-Tech, Manufacturing, Retail, Pharma\nMaster's degree in statistics, mathematics, computer science, business analytics\nShow more\nShow less",
      "job_skills":"Artificial Intelligence, Machine Learning, Data Mining, NLP, Deep Learning, Neural Networks, Genetic Algorithm, Reinforcement Learning, Statistical Modelling, Python, R, SQL, SAS, Big Data, Hadoop, Spark, Endtoend deployment, Cloud",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Scientist",
      "company":"Steneral Consulting",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-scientist-at-steneral-consulting-3782038038",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Houston, TX 77002,\n5 days a week onsite | 7:30am-5pm | **Fridays are half days** (totaling 40 hrs.\/week).\nMust be local to Houston.\nI\nnterview Process: First round will be a 1 hr. zoom interview and second round interview will be onsite for 1.5 hours\nTop Skills\n5+ years of practical experience framing and solving optimization problems in supply chain, logistics, or operations\n5+ years of hands on experience with applied statistics \/ math and optimization techniques\nProfessional experience with optimization techniques such as numerical optimization, linear programming, nonlinear programming, dynamic programming, integer programming, numerical methods, or heuristic methods\nAdditional Notes\nNeed to be able to solve real-world optimization problems\/opportunities. Strategize what moves need to be made. Bring in all the data, try to frame it as a problem that can be solved with optimization techniques so we can end up with an application we can use \u201a\u00c4\u00ec recommend the process.\nDomain knowledge is secondary to ability to frame real-world problem and being able to solve it.\nWe are currently seeking an experienced data scientist to join the Big Data and Advanced Analytics department. As part of the Data Analytics team, the Lead Data Scientist will work closely with the Data Engineering team and business functions to solve real-world oil and gas midstream problems using machine learning, data science algorithms and artificial intelligence.\nResponsibilities Include\nWork independently on optimization projects for multiple business functions\nIdentify and frame the optimization opportunity from understanding the business problem \/ opportunity\nGather, cleanse, and transform internal and external data\nAnalyze data and deliver insights via visualizations and dashboards\nCreate, productionize, and maintain models \/ solutions that address business problems\nPresent, explain and defend results from analysis and modeling, and approach taken\nParticipate in strategic planning discussions around optimizations, data science and big data analytics\nThe Successful Candidate Will Meet The Following Qualifications\n5+ years of practical experience framing and solving optimization problems in supply chain, logistics, or operations\n5+ years of hands on experience with applied statistics \/ math and optimization techniques\nProfessional experience with optimization techniques such as numerical optimization, linear programming, nonlinear programming, dynamic programming, integer programming, numerical methods, or heuristic methods\nProfessional experience programming in Python\nExperience using tools such as Google OR Tools, Scipy.Optimize, CPLEX, Gurobi, GAMS, LINGO, Pyomo, MATLAB, Arena, Vensim on real-world problems\nExperience building solutions in AWS is a plus\nEducational background in Operations Research, Applied Mathematics, or Industrial Engineering is a plus\nAbility to adapt in a rapidly changing environment\nAbility to communicate insights and approaches in a simple, actionable manner\nAbility to work independently and with team members from different backgrounds\nExcellent attention to detail and problem-solving skills\nShow more\nShow less",
      "job_skills":"Optimization techniques, Applied statistics, Math, Numerical optimization, Linear programming, Nonlinear programming, Dynamic programming, Integer programming, Numerical methods, Heuristic methods, Python, Google OR Tools, Scipy.Optimize, CPLEX, Gurobi, GAMS, LINGO, Pyomo, MATLAB, Arena, Vensim, AWS, Operations Research, Applied Mathematics, Industrial Engineering, Data Engineering, Machine learning, Data science algorithms, Artificial intelligence, Data Analytics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Science Manager",
      "company":"CITGO",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-science-manager-at-citgo-3743629641",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Remote Work options available for eligible positions\nOptions are department and\/or location specific\n9\/80 Work Schedule Option (where applicable)\nAnnual Vacation Incentive (40-120 hours of additional pay) for Eligible Employees\nPaid Vacation Time\nCompany-Paid Holidays\nParental Leave\nExcellent 401(k) Match\nPension Plan\nCompany-Paid Sick Leave and Long-Term Disability\nMedical, Dental, & Vision Plans; FSA and HSA options\nCompany-Paid Life Insurance for Active Employees\nHealthy Rewards Program\nService Awards Program\nEducational Assistance Plan\nDependent Children Scholarships\nReimbursement for Gym Membership\nEmployee Discount Programs\nOn-site Health Clinic\nOn-site Cafeteria (select locations)\nOn-site Credit Union and ATM (Corporate office only)\nOn-site Fitness Center (select locations)\nPLEASE NOTE ALL JOBS DO NOT QUALIFY FOR ALL PERKS\nRelocation Benefits are not available for this position.\nEmployer will sponsor visas for position\nWork with Commercial Analytics Research & Development team to establish data science capabilities within CITGO. Design, develop and implement data-driven solutions that help the organization make better decisions, and drive the adoption of data-driven decision making within the organization. The role requires a combination of technical skills in data science, software engineering and machine learning, as well as communication and project management skills.\nAnalysis is concerned with three primary areas (1) Optimization Solutions, such as measurement of competitive performance and its drivers, customer\/product mix, sales lift studies, price elasticities, etc., (2) Predictive & Exploratory Analytics, such as demand forecasting, prioritization of trends, market potential for new business models, (3) Thought Leadership, such as applying augmented decision making with ML\/AI, creative use of internal and external data sources with pragmatic curiosity.\nIndividual will act as an individual contributor within a group of technical personnel.\nIdentify business areas where data science approaches can enrich decision making & implement appropriate solutions.\nIndividual will function in the capacity of a full stack decision scientist to address majority of initial hard data science needs as data science team begins establishment.\nIndividual will develop and implement predictive modelling to optimize profitability and decision-making capabilities.\nIndividual will collaborate with stakeholders to understand business needs and decision-making processes.\nRequires very strong understanding of the business drivers of decision making and communicating complex insights to a diverse audience.\nRequires application of well-developed technical knowledge in data science, conducting and coordinating difficult, responsible assignments.\nRequires comfortability taking the lead on data science efforts for identifying, justying & implementing advanced analytics efforts.\nDegree\nBachelor\u201a\u00c4\u00f4s Degree.\nMasters degree or higher in computer science, statistics, data science or similar strongly preferred\nThe minimun number of years of job related experience required by this job is\n7-10+ years.\nList any specialized training or unique skills required\nDeep understanding of data science\/decision science concepts and techniques, as well as hands on experience building data-driven solutions using machine learning algorithms, statistical models and data visualization tools, required.\nExperience with major cloud computing platforms (Azure, AWS, etc.) required.\nExperience with Azure platforms strongly preferred.\nProficiency in data analytics tools such as Python, R, SQL preferred.\nComfortability with taking initiative & having an entrepreneurial spirit is strongly preferred.\nUnderstanding of downstream oil & gas business preferred.\nAbility to effectively manage project timelines, budgets and resources is necessary.\nExcellent written and verbal communication skills preferred.\nStrong knowledge of data privacy, security and governance regulations\/best practices.\nAbility to simplify complex information.\nDesire and willingness to continuously expand knowledge and skills.\nPassionate and creative about solving complex and difficult problems, both in group and individual settings\nApplicant must be self-starter and comfortable with situations where solutions are not always clear or obvious.\nDevelop & implement data-driven solutions to support decision making, such as predictive models, data visualization dashboards and machine learning algorithms. Communicate the results of data science projects to key stakeholders and executive leadership, promoting the adoption and integration of data science into decision-making processes.\nCollaborate with Commercial Analytics R&D & business units to identify and prioritize data science projects that can deliver business value. This may involve conducting data analysis and data discovery activities to understand the current state of the data assets and how they can be leveraged to support decision making.\nCollaborate with Commercial Analytics R&D team to establish the necessary strategies, technical infrastructure and tools to support data science activities, including data storage, data processing and machine learning. Approaches for this should have a heightened focus on approaches that are innovative, organizationally sustainable, modern, transparent and efficient.\nEnsure that data privacy, security and governance standards are met in all data science projects. Work with IT and Commercial Analytics R&D to implement appropriate measures for data collection, processing, storage and protection. Ensure that data is of high quality, properly documented, and stored and managed in a manner that meets regulatory and organizational requirements.\nStay current on new techniques, technologies and tools in data science, machine learning and the oil and gas industry and evaluate and determine their potential applications for the organization. Requires a commitment to ongoing professional development and a willingness to continuously expand expertise, which includes attending regular training, industry events, reading trade publications and engaging with colleagues and peers in the field.\nShow more\nShow less",
      "job_skills":"Machine Learning, Data Science, Data Analytics, Python, R, SQL, Statistical Models, Azure, AWS, Data Visualization, Predictive Modeling, Data Privacy, Data Security, Data Governance, Cloud Computing, Business Intelligence, Project Management, Communication Skills, Business Acumen, Decision Making, Problem Solving, Creativity, Data Warehousing, Data Storage, Data Processing",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Scientist\/Optimization Specialist",
      "company":"EPMA",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-scientist-optimization-specialist-at-epma-3782588918",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are currently seeking an experienced data scientist to join the Big Data and Advanced Analytics department. As part of the Data Analytics team, the Lead Data Scientist will work closely with the Data Engineering team and business functions to solve real-world oil and gas midstream problems using machine learning, data science algorithms and artificial intelligence.\nResponsibilities include:\nWork independently on optimization projects for multiple business functions\nIdentify and frame the optimization opportunity from understanding the business problem \/ opportunity\nGather, cleanse, and transform internal and external data\nAnalyze data and deliver insights via visualizations and dashboards\nCreate, productionize, and maintain models \/ solutions that address business problems\nPresent, explain and defend results from analysis and modeling, and approach taken\nParticipate in strategic planning discussions around optimizations, data science and big data analytics\nThe successful candidate will meet the following qualifications:\n5+ years of practical experience framing and solving optimization problems in supply chain, logistics, or operations\n5+ years of hands on experience with applied statistics \/ math and optimization techniques\nProfessional experience with optimization techniques such as numerical optimization, linear programming, nonlinear programming, dynamic programming, integer programming, numerical methods, or heuristic methods\nProfessional experience programming in Python\nExperience using tools such as Google OR Tools, Scipy.Optimize, CPLEX, Gurobi, GAMS, LINGO, Pyomo, MATLAB, Arena, Vensim on real-world problems\nExperience building solutions in AWS is a plus\nEducational background in Operations Research, Applied Mathematics, or Industrial Engineering is a plus\nAbility to adapt in a rapidly changing environment\nAbility to communicate insights and approaches in a simple, actionable manner\nAbility to work independently and with team members from different backgrounds\nExcellent attention to detail and problem-solving skills\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Optimization, Python, Linear Programming, Nonlinear Programming, Dynamic Programming, Integer Programming, Google OR Tools, Scipy.Optimize, CPLEX, Gurobi, GAMS, LINGO, Pyomo, MATLAB, Arena, Vensim, AWS",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist for Oil and Gas",
      "company":"Ayata",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-for-oil-and-gas-at-ayata-3679691920",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Ayata\nis developing its Prescriptive Analytics\u00ac\u00c6 software by integrating the latest Artificial Intelligence (AI) and related technologies. We are looking for people with multi-disciplinary skills, especially in software design and artificial intelligence, who can write solid clean code and who are excited about applying those skills to build industrial strength software. You will be part of a multi-disciplinary team working to design, develop and implement our unique software. Your contributions will directly impact the success of the company.\nJob Responsibilities And Duties\nAyata\nis looking for\nSenior Data Scientist\nwho will develop AI techniques for business applications in various industries and build cloud-based AI software for predictive analytics business solutions.\nResponsibilities\nAI technique development, providing methodology, strategy, ideas, architect, and solutions for real-word, industrial-scale and mission-critical business operations\nBuild and integrate AI technique components into a full-functioning AI business software\nInteract with business clients, understand business requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients\nUnderstand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering\nDocument data dictionary, data understanding, modeling strategy and approaches, and build company\u201a\u00c4\u00f4s knowledge base of data and models\nCommunicate effectively with team members, management, and clients\nRequirements\nPh.D. degree in computer science, or mathematics\/statistics\/physics or engineering\n3-5 years of experience in machine learning\/AI technology and software development\nNatural Language Processing (NLP) Information retrieval and information extraction\nDigital Image Processing experience including OpenCV, OCR experience to convert images to text\nExcellent hands-on code development skills in Python\nProven ability as a quick learner\nAdditional Qualifications\nExpertise in ETL is a plus (Spark, Hadoop, SQL) in big data environments\nFront-end software development experience is a plus\nThis position is remote at this time. When we are over the Covid concerns, Ayata will move to a flexible schedule where working out of an office could be requested at times.\nYou must live in the Houston Area to be considered for this postition!!\nYou must have a PHD to be considered for this position!\nBenefits\nCompensation package (base salary + performance bonus + stock options) commensurate with experience.\nIndustry (tech\/software industry) standard benefits package - medical, dental, vision, 401(k) plan, work-from-home (if applicable), flexible holidays, and more.\nShow more\nShow less",
      "job_skills":"Artificial Intelligence (AI), Prescriptive Analytics, Software design, Machine Learning, Cloud Computing, Python, Natural Language Processing (NLP), Information Retrieval, Information Extraction, Digital Image Processing, OpenCV, OCR, ETL (Spark Hadoop SQL), Frontend development",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Science Specialist",
      "company":"Hydrogen Group",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-science-specialist-at-hydrogen-group-3780021087",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Ob Description\nWe are currently seeking an experienced data scientist to join the Big Data and Advanced Analytics department. As part of the Data Analytics team, the Lead Data Scientist will work closely with the Data Engineering team and business functions to solve real-world oil and gas midstream problems using machine learning, data science algorithms and artificial intelligence.\nResponsibilities Include\nWork independently on optimization projects for multiple business functions\nIdentify and frame the optimization opportunity from understanding the business problem \/ opportunity\nGather, cleanse, and transform internal and external data\nAnalyze data and deliver insights via visualizations and dashboards\nCreate, productionize, and maintain models \/ solutions that address business problems\nPresent, explain and defend results from analysis and modeling, and approach taken\nParticipate in strategic planning discussions around optimizations, data science and big data analytics\nThe Successful Candidate Will Meet The Following Qualifications\n5+ years of practical experience framing and solving optimization problems in supply chain, logistics, or operations\n5+ years of hands on experience with applied statistics \/ math and optimization techniques\nProfessional experience with optimization tools such as linear programming, integer programming, or heuristic methods\nProfessional experience programming in Python\nExperience with AWS is a plus\nEducational background in Operations Research, Applied Mathematics, or Industrial Engineering is a plus\nAbility to adapt in a rapidly changing environment\nAbility to communicate insights and approaches in a simple, actionable manner\nAbility to work independently and with team members from different backgrounds\nExcellent attention to detail and problem-solving skills\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Artificial Intelligence, Big Data, Advanced Analytics, Python, Optimization, Linear Programming, Integer Programming, Heuristic Methods, AWS, Statistics, Mathematics, Operations Research, Applied Mathematics, Industrial Engineering, Data Gathering, Data Cleansing, Data Transformation, Data Analysis, Data Visualization, Dashboarding, Model Creation, Model Productionization, Model Maintenance, Presentation, Communication, Teamwork, Attention to Detail, Problem Solving",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist \/ Senior Data Scientist",
      "company":"NOV",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-senior-data-scientist-at-nov-3781003066",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nYour Responsibilities:\nYou will develop data science solutions for challenging engineering and business problems within NOV.\nYou will have the opportunity to develop data driven predictive models that will lay the foundation for our Predictive Maintenance, Condition Based Maintenance, and Optimized Operations.\nYou also have opportunities to research and develop applications in applied artificial intelligence using computer vision, natural language processing (NLP) and large language models (LLM).\nWorking with Big Data infrastructure, Engineering, and Operations, you will develop a scalable and sustainable analytics process.\nYour Data Science responsibilities will include understanding project needs, data science framing, performing exploratory data analysis (EDA), building, and validating models, and deploying models into production.\nYou will engage in knowledge management and effective solution delivery.\nYou will assess risk, benefit, and cost of pre-existing and suggested engineering practices.\nYour Qualifications\nAre you a motivated self-starter with the dedication to work independently and as part of a team, and an ability to multi-task? Do you have the flexibility and adaptability, to make decisions quickly? Do you thrive in dynamic environments with multiple changing priorities, where prioritization and time management are necessary tools? You may be a good fit for our team, if you also meet the following requirements:\nYou have 2-5 years of successful technical experience in the domain of predictive analytics (e.g. data science, machine learning, data mining, and statistics related work); preferably in the Oil & Gas industry.\nYour strong academic qualifications include an advanced degree (master\u201a\u00c4\u00f4s or Ph.D.) in a relevant STEM field (Computer Science, Engineering, Mathematics, Statistics, etc.); preferably a PhD.\nProgramming experience with Python is a must, and additional programming experience with PySpark, MATLAB, Java, C#, or R is a plus.\nModeling experience with core data science packages (Pandas, Scikit-learn, Keras, TensorFlow, PyTorch, etc.)\nModeling experience with traditional machine learning and deep learning techniques (CNN, RNNs, LSTMs, GANs, Transformers, etc.)\nExperience with signal processing on industrial equipment (rotating machinery, reciprocating machinery, hydraulic systems), data driven reliability, and operation efficiency is a plus.\nHaving experience with computer vision, natural language processing (NLP) or large language model (LLM) is a plus.\nHaving experience with productizing machine learning models within a cloud service (e.g., AWS, Azure, GCP) and data science environments (e.g., Databricks) is a plus.\nYou have a proven history of conducting research and producing viable solutions for engineering problems.\nYou are skilled in problem analysis and resolution, impact verification, troubleshooting, coaching, facilitation experience, and diagnosing problems across multiple disciplines.\nYou excel in organizational and analytical skills; you're able to focus and deliver precise results, yet understand impacts across multiple projects and systems.\nYou communicate proficiently in English and have good interpersonal skills, with the ability to build trust and integrity in your relationships with our business partners.\nShow more\nShow less",
      "job_skills":"Data science, Predictive analytics, Machine learning, Data mining, Statistics, Computer science, Engineering, Mathematics, Python, PySpark, MATLAB, Java, C#, R, Pandas, Scikitlearn, Keras, TensorFlow, PyTorch, CNN, RNNs, LSTMs, GANs, Transformers, Signal processing, Computer vision, Natural language processing, Large language models, AWS, Azure, GCP, Databricks",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer, Infrastructure-Dallas, Austin, or San Antonio, TX",
      "company":"H-E-B",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-infrastructure-dallas-austin-or-san-antonio-tx-at-h-e-b-3740525124",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Since H-E-B Digital Technology's inception, we've been investing heavily in our customers' digital experience, reinventing how they find inspiration from food, how they make food decisions, and how they ultimately get food into their homes. This is an exciting time to join H-E-B Digital--we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience. If you enjoy taking on new challenges, working in a rapidly changing environment, learning new skills, and applying it all to solve large and impactful business problems, we want you as part of our team.\nOur Partners thrive The H-E-B Way. In the\nSenior Data Engineer, Infrastructure\njob, that means you have a...\nHEART FOR PEOPLE... you can organize multiple engineers, negotiate solutions, and provide upward communication\nHEAD FOR BUSINESS... you consistently demonstrate and uphold the standards of coding, infrastructure, and process\nPASSION FOR RESULTS... you're capable of high-velocity contributions in multiple technical domains\nWhat you will do:\nDesign and deploy batch and streaming data pipeline infrastructure using IaC and CI\/CD\nImplement features to ensure data platform performance, reliability, and security\nDevelop solutions to improve monitoring and observability for data pipelines and platform infrastructure\nBuild data platform components using hybrid cloud services (AWS, GCP, and Azure)\nUse configuration management tools to provision system images and install and configure Linux application servers\nHelp contain costs by delivering solutions to monitor data platform utilization and expenditure\nProject you will impact:\nBuild a world class data platform that can handle petabytes of data\nImprove the data quality and consumer experience for 100K+ enterprise data consumers\nWho you are:\nHands-on experience in DevOps for cloud infrastructure and data pipelines\nSolid background in Linux, networking, SSL\/TLS cert management, secrets management, IAM and security best practices\nExperienced programmer in one or more languages such as Bash\/Shell, Python, Java, Go, Ruby\nUnderstanding of Big Data and Hybrid Cloud infrastructure. Experienced in technologies such as Kafka, Kubernetes, Spark, Databricks, AWS EMR, S3, data warehouses (Snowflake, Teradata)\nSignificant experience with one or more cloud infrastructure providers (AWS, GCP, Azure)\nExperienced in cloud administration and Infrastructure as Code (Terraform, Cloud Formation, AWS CDK, Pulumi)\nComfortable with configuration management tools (Ansible, Puppet, Chef, Salt)\nHave worked with enterprise monitoring, APM, and log analysis tools like Datadog, Splunk, ELK Stack, New Relic\nExperienced with CI\/CD tools such as GitLab CI\/CD and Jenkins\nUp to date on the latest technology developments. Should be able to evaluate and propose new tooling\/solutions for data platform\nExcellent written, oral communication and presentation skills\nBonus:\nDevOps certifications\nCloud certifications\nDATA3232\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Pipelines, Infrastructure as Code (IaC), CI\/CD, DevOps, Linux, Networking, Security, Bash, Shell, Python, Java, Go, Ruby, Big Data, Kafka, Kubernetes, Spark, Databricks, AWS EMR, S3, Data Warehouses, Snowflake, Teradata, Cloud Infrastructure, AWS, GCP, Azure, Cloud Administration, Terraform, Cloud Formation, AWS CDK, Pulumi, Configuration Management Tools, Ansible, Puppet, Chef, Salt, Enterprise Monitoring, APM, Log Analysis Tools, Datadog, Splunk, ELK Stack, New Relic, CI\/CD Tools, GitLab CI\/CD, Jenkins",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Archetype Permanent Solutions",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-archetype-permanent-solutions-3787916377",
      "search_city":"Monroeville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are seeking a highly skilled and analytical Data Scientist to join our team. The ideal candidate will be adept at using large data sets to find opportunities for product and process optimization, and using models to test the effectiveness of different courses of action. This role will require both a strong technical background in data analysis and the ability to communicate findings to non-technical teams and stakeholders.\nKey Responsibilities:\nWork with stakeholders to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nQualifications:\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Statistics, Mathematics, Computer Science, or another quantitative field.\n2 years of experience in a Data Scientist or Data Analyst role.\nStrong problem-solving skills with an emphasis on product development.\nExperience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages\/drawbacks.\nExcellent written and verbal communication skills for coordinating across teams.\nPreferred Skills:\nExperience with distributed data\/computing tools: Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\nExperience with AWS, Azure, or another cloud service.\nExperience visualizing\/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.\nBenefits:\nCompetitive salary and benefits package.\nDynamic and innovative work environment.\nOpportunities for professional growth and development.\n[Other company-specific benefits like remote work options, flexible schedules, wellness programs, etc.]\nHow to Apply:\nPlease submit your resume, cover letter, and any relevant work samples\nPowered by JazzHR\nyPGhUHXKgQ\nShow more\nShow less",
      "job_skills":"Data Analysis, Predictive Modeling, Data Science, Data Mining, Data Visualization, Machine Learning, Statistics, Algorithms, R, Python, SQL, AWS, Azure, Hadoop, Hive, Spark, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, NoSQL, Map\/Reduce, Gurobi, MySQL, Periscope, Business Objects, D3, ggplot",
      "Category":"Backend Development"
  },
  {
      "job_title":"Urgent Role || Oracle Database Developer || Westlake, TX (Hybrid) ||  Citizen,GC",
      "company":"Steneral Consulting",
      "job_location":"Westlake, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/urgent-role-oracle-database-developer-westlake-tx-hybrid-citizen-gc-at-steneral-consulting-3659217411",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job: Oracle Database Developer (PL\/SQL, Shell, Unix, AWS)\nLocation: Westlake, TX or Jersey City, NJ (hybrid 1 week\/month)\nTerm: 6 month+ contract\nLocation: Jersey City or Westlake only for this one If sending a candidate from the Brooklyn or Long Island side of NYC make sure they are 100% certain they can do the long commute to NJ. Must have skills:\nOracle 19.x\nPLSQL development skills, sored procedures, triggers, privilege's, etc. SQL query skills\nShell Scripting\nUnix\/Linux\/Control M\nAWS They will be developing the Securities finance database which interfaces with trading applications.\nThe Oracle Database Developer will work with a team of Software Engineers across the globe to develop high quality applications servicing the financial trading industry. First and foremost we look for a proven database developer, with a strong desire to grow their knowledge and capabilities while passionate about the tasks at hand.\nThe primary technologies will be Oracle 12.x, PLSQL, SQL Tuning, Perl and Shell Scripting, solid grasp of Extract\/Transform\/Load (ETL) processes to support Data Conversion \/ Migration \/ Consolidation. J2EE, Spring and experience integrating the Java Services with database procedures, PLSQL Statements is a must. Working with DevOps tools (Git, Stash, Jenkins, UDeploy) is necessary.\nThe Expertise And Skills You Bring\nBuild New, Enhance and maintain the number Middle tier services for existing applications or new initiatives using Java, J2EE, and Spring Framework.\nAbility to write, maintain & debug oracle queries, stored procedures.\nCollaborate with other team members on shared items of work to ensure end to end delivery of features\nProvide estimation of work and ensure team is kept informed of progress\nShare your knowledge across the team and mentor other team members\nEnsure standard methodology is followed and supply to improving how we get things done\nClosely work with Off-shore team to make sure production stability.\nClosely work with DBA team to ensure the quality of code that goes to production.\nBachelor level degree in Computer Science, Engineering or other technical field.\n5+ years of experience in software development, primarily in Oracle PLSQL Development, Unix Shell scripting. Experience in J2EE, Tomcat Application Server, Spring Framework, JDBC is also necessary. Knowledgeable in messaging like MQ.\nSuperb experience loading and handling large volume of data.\nChampion experience in working closely with business to understand and develop the business requirements.\nExperience using database profiler, scheduler like Control-M\nExperience of agile development. Participated in Sprint planning, backlog, sprint retrospection etc\nExperience working with dispersed teams.\nExperience in leading Server Migrations\nExperience with software engineering tools such as GIT, Stash, Jenkins and uDeploy.\nKnowledgeable of AWS.\nExcellent Analytical and problem-solving skills\nSuperb Communication, written and oral skills\nStrong development abilities in building highly scalable & flexible Trading applications.\nAbility to mentor other members of the team\nExcellent knowledge of finance business\nShow more\nShow less",
      "job_skills":"Oracle, PL\/SQL, Shell, Unix, Linux, AWS, SQL, Perl, Java, J2EE, Spring Framework, ETL, DevOps, Git, Stash, Jenkins, UDeploy, Tomcat, JDBC, MQ Series, Agile development, ControlM, Server migrations",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior DevOps Data Platform Engineer \/ Kafka Administrator",
      "company":"RedRiver Systems, LLC",
      "job_location":"Addison, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-devops-data-platform-engineer-kafka-administrator-at-redriver-systems-llc-3785492982",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Senior DevOps Data Platform Engineer - Kafka\nLocation:\nAddison, TX Hybrid 3-days In \/ 2-days WFH\nEmployment Type:\nDirect-HIRE\nNo Sponsorship is offered NOW or in the Future \/ NO 3rd Party Candidates Accepted\nJoin a growing AWARD WINNING organization named on Forbes America\u201a\u00c4\u00f4s Best Small Companies and recognized as one of Deloitte\u201a\u00c4\u00f4s \u201a\u00c4\u00faThe Exceptional 100 List of Top Performing U.S. Companies.\u201a\u00c4\u00f9 The organization continues to experience dynamic worldwide growth with a state of the art, industry leading business model \/ platform and a slate of benefits ensuring your physical and financial health!!\nThis Dallas based technology company is looking for a talented Sr. Data Platform Engineer to join their DevOps team supporting their data, search and messaging platforms, as well as partner with the product team to ensure data integrity across the enterprise.\nRESPONSIBILITIES:\nBuild, deploy, manage, and monitor scalable, fault-tolerant, secure, and high-performance data platforms and data movement solutions.\nPartner with agile data development teams and using DevOps methodologies to create efficient, automated, CI\/CD processes to promote, test and deploy code.\nPartner with InfoSec team to ensure data is secure at-rest and in-flight.\nDevelop, test, deploy and maintain efficient reusable patterns of streaming and batch data ingestion pipeline architectures.\nMaintain key architecture and coding standards for all platforms.\nEnsure data platforms operate efficiently and maximum uptime.\nTake advantage of the latest features and support for data pipelines.\nBACKGROUND:\nSr. level experience with deploying, configuring, scaling, and troubleshooting data and search infrastructure.\nSr. level experience with Kafka technologies (Hive, Hadoop, Spark, Storm, Zookeeper)\nStrong experience managing Kafka with Confluent Platform and Confluent Cloud\nExpert level experience with alerting, monitoring, and auto-remediation in a large-scale distributed environment\nStrong experience with Solr technologies (Solr, Elastic Search, Lucene API, etc.)\nStrong experience supporting stream processing solutions in Big Data and Kafka, Kinesis\nStrong knowledge of messaging\/events architecture Concepts and PUB\/SUB Pattern\nSolid knowledge of Java, Python, XML, XML Schema, XSD, XSLT\/XPath and JSON technologies\nExperience in building and deploying Microservices on containers such as Pivotal Foundry Cloud, Docker, or Kubernetes etc.\nSolid experience designing and supporting Enterprise Redis Platforms\nExperience with Source control\/Bug Tracking\/Automated Build tools Jira, Jenkins, and Git\nExperience with http web servers and load balancers\nExperience with Reporting and ETL platforms\nShow more\nShow less",
      "job_skills":"DevOps, Kafka, Hadoop, Spark, Storm, Zookeeper, Confluent Platform, Confluent Cloud, Solr, Elastic Search, Lucene API, Java, Python, XML, XML Schema, XSD, XSLT\/XPath, JSON, Microservices, Pivotal Foundry Cloud, Docker, Kubernetes, Redis, Jira, Jenkins, Git, ETL",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"BeaconFire Inc.",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-beaconfire-inc-3784573122",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job title : Data Scientist\nDuration : Long Term Contract\nLocation : Austin,TX (hybrid)\nJob Description:\n\u00ac\u2211 Develop and implement machine learning models and algorithms to support our program objectives\n\u00ac\u2211 Collaborate with cross-functional teams including data science, software engineering, and product management to build predictive models, forecasting tools, and recommendation systems\n\u00ac\u2211 Analyze, optimize and maintain existing machine learning models\n\u00ac\u2211 Participate in data model and architecture design\n\u00ac\u2211 Train and evaluate models using statistical methods\n\u00ac\u2211 Troubleshoot and identify issues with data models and data pipelines\nQualifications:\n\u00ac\u2211 Bachelor's or Master's degree in computer science, data science, statistics, or related fields\n\u00ac\u2211 Minimum of 3 years of experience in machine learning and data analysis\n\u00ac\u2211 Strong programming skills in Python, R, Tensorflow and prompt engineering\n\u00ac\u2211 Experience in data modeling, data architecture, and data pipeline design\n\u00ac\u2211 Experience with big data platforms such as Hadoop, Spark, and Hive\n\u00ac\u2211 Experience in cloud platforms like AWS\/Azure\/GCP\n\u00ac\u2211 Experience in NLP, computer vision, deep learning techniques\n\u00ac\u2211 Excellent communication and collaboration skills\nShow more\nShow less",
      "job_skills":"Machine learning, Python, R, Tensorflow, Prompt engineering, Data modeling, Data architecture, Data pipeline design, Hadoop, Spark, Hive, AWS, Azure, GCP, NLP, Computer vision, Deep learning",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Science + Python",
      "company":"Wipro",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-science-%2B-python-at-wipro-3780378373",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading global information technology, consulting and business process services company. We harness the power of cognitive computing, hyper-automation, robotics, cloud, analytics and emerging technologies to help our clients adapt to the digital world and make them successful. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 220,000 dedicated employees serving clients across six continents. Together, we discover ideas and connect the dots to build a better and a bold new future.\nPython + Data Science\nLocation: Austin\nLLM, DL, ML ( Mandatory\nJD:\nPython (TMS and Illuminate)\nPandas and NumPy (TMS)\nLLMs (Language Model Models) (Illuminate)\nModel Deployment (Illuminate),\nData Scraping (Illuminate)\nEmbedding and Vector Retrieval Algorithms (Illuminate)\nVersion and Dependency Management (TMS and Illuminate)\nLangchains (Illuminate)\nAWS\/Sagemaker (Illuminate)\nDocker (TMS and Illuminate)\nFlask\/Django (Good to have for illuminate not mandatory)\nRest API\nWipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation, or any other status protected by applicable law.\nShow more\nShow less",
      "job_skills":"Python, Data Science, Pandas, NumPy, Tensorflow, Keras, Model Deployment, Data Scraping, Embedding, Vector Retrieval Algorithms, Version Control, Dependency Management, AWS, Sagemaker, Docker, Flask, Django, Rest API",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Vings Technologies",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-vings-technologies-3788338609",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Submission Details\nImplementation Partner: HCL\nEnd Client: Google\nHCL Recruiter: Sumit Chaudhary.\nRate: $75\/HR\nSR Number: APPS\/APPS\/2023\/(phone number removed)\nAuto Req ID\nSubmission Format: (SUBM 2)\nITAP Primary Skills\nJob Details:\nRole: Senior Data Scientist.\nContract: 6-9+ months.\nExperience: 8+ years.\nLocation: Austin, TX Only Local (Day 1 Onsite)\nResponsibilities\nJob Description:\nContribute to development on multiple work streams \/ projects \/ programs simultaneously.\nWork with product lead, eng lead and program manager to understand business\/functional requirements and roadmap\/timeline for delivery.\nDevelop data model, pipelines and reports\/dashboards per requirements and project plan.\nPlan and execute test plans and test cases.\nParticipate in project team meetings.\nProactively communicate the status of development, raise\/escalate issues\/challenges as they arise.\nRequired Skills\nExpert-level data science, data modeling, data pipeline skills.\nSolid understanding of data management concepts - data processing, analytics, machine learning and visualization.\nExperience with Data Manipulation using Python\/Pyspark\nExperience with Jupyter\/COLAB using Python libraries such as Pandas, Sklearn, NLTK, Gensim\nInterested in Text analytics, Natural Language processing, Classification and Clustering\nSignificant experience creating clean, insightful dashboards for executives and non-technical audiences, using Tableau, Microstrategy, Qlik or similar products.\nEye for product excellence - developing low-latency, reliable reports\/pipelines; designing with data visualization best practices.\nExcellent written and verbal communication skills.\nAbility to organize, prioritize and plan their own work, while aligning with project\/program priorities and changes to priorities.\nAbility to work with a diverse team of engineers & analysts, across locations, and on multiple programs simultaneously.\nPreferred Skills\nExperience working with self-service reporting platforms\/solutions.\nExperience with Google & GCP data technologies (BigQuery, Cloud SQL, Data Studio), or equivalent technologies in the market.\nExperience with Data Visualization libraries such as Matplotlib\nShow more\nShow less",
      "job_skills":"Data Science, Data Modeling, Data Pipelines, Data Management, Data Processing, Analytics, Machine Learning, Data Visualization, Python, Pyspark, Jupyter\/COLAB, Pandas, Sklearn, NLTK, Gensim, Text Analytics, Natural Language Processing, Classification, Clustering, Tableau, Microstrategy, Qlik, Data Visualization, Communication, Organization, Prioritization, Planning, Teamwork, SelfService Reporting Platforms, Google & GCP data technologies (BigQuery Cloud SQL Data Studio), Matplotlib",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Ayata",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-ayata-3679698223",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Ayata\nis developing its Prescriptive Analytics\u00ac\u00c6 software by integrating the latest Artificial Intelligence (AI) and related technologies. We are looking for people with multi-disciplinary skills, especially in software design and artificial intelligence, who can write solid clean code and who are excited about applying those skills to build industrial strength software. You will be part of a multi-disciplinary team working to design, develop and implement our unique software. Your contributions will directly impact the success of the company.\nJob Responsibilities And Duties\nAyata\nis looking for\nAI Scientist\nwho will develop AI techniques for business applications in various industries and build cloud-based AI software for predictive analytics business solutions.\nResponsibilities\nAI technique development, providing methodology, strategy, ideas, architect, and solutions for real-word, industrial-scale and mission-critical business operations\nBuild and integrate AI technique components into a full-functioning AI business software\nInteract with business clients, understand business requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients\nUnderstand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering\nDocument data dictionary, data understanding, modeling strategy and approaches, and build company\u201a\u00c4\u00f4s knowledge base of data and models\nCommunicate effectively with team members, management, and clients\nRequirements\nPh.D. degree in computer science, or mathematics\/statistics\/physics or engineering\n3-5 years of experience in machine learning\/AI technology and software development\nNatural Language Processing (NLP) Information retrieval and information extraction\nDigital Image Processing experience including OpenCV, OCR experience to convert images to text\nExcellent hands-on code development skills in Python\nProven ability as a quick learner\nAdditional Qualifications\nExpertise in ETL is a plus (Spark, Hadoop, SQL) in big data environments\nFront-end software development experience is a plus\nThis position is remote at this time. When we are over the Covid concerns, Ayata may move to a flexible schedule where working out of an office could be requested at times.\nYou must have a PHD to be considered for this position.\nBenefits\nCompensation package (base salary + performance bonus + stock options) commensurate with experience.\nIndustry (tech\/software industry) standard benefits package - medical, dental, vision, 401(k) plan, work-from-home (if applicable), flexible holidays, and more.\nShow more\nShow less",
      "job_skills":"Artificial Intelligence, AI techniques, AI software development, Natural Language Processing (NLP), Information retrieval, Information extraction, OpenCV, OCR, Python, Machine learning, Data Preprocessing, Data Modelling, Data Engineering, Data Dictionary, Data Understanding, Data Visualization, Cloud Computing, Frontend Software Development, Hadoop, Spark, SQL, ETL",
      "Category":"Backend Development"
  },
  {
      "job_title":"Principal Engineer ( DevOps Data Platform , Generative AI , Gitlab , Cloud ) - Remote",
      "company":"CVS Health",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-engineer-devops-data-platform-generative-ai-gitlab-cloud-remote-at-cvs-health-3715218510",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand \u201a\u00c4\u00ee with heart at its center \u201a\u00c4\u00ee our purpose sends a personal message that how we deliver our services is just as important as what we deliver.\nOur Heart At Work Behaviors\u201a\u00d1\u00a2 support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.\nCVS Health, a healthcare innovation company, is committed to providing Individuals, Employers, Healthcare professionals, producers, and others with innovative benefits, products, and services. The industry is evolving and the opportunities to drive real change and improve the health of millions are endless. If you are passionate about making a difference in the work you do, being recognized for your talent and expertise in solving complex and challenging clinical data problems while contributing to the success of key strategic initiatives, consider growing your career with a Fortune 6 healthcare leader!\nThe Principal DevOps Engineer will be a Technical Subject Matter Expert \/ Individual Contributor accountable for leading the organizational transformation in developing devops tooling, practices, and culture. You will contribute to enterprise wide requirements and ensure adoption of same, including observability, scalability, availability, security, cost performance.\nThe Principal DevOps Engineer will:\nLead DevOps strategy covering design, development of tools, practices and culture.\nEstablish and enforce DevOps best practices, including version control, code review, automated testing, and deployment strategies.\nArchitect and manage infrastructure as code, utilizing tools like Terraform, Ansible, or similar, to provision and manage resources across cloud environments.\nImplement and manage CI\/CD pipelines using tools like Jenkins, CircleCI or like ensuring rapid and reliable application deployment.\nCollaborate with security and compliance teams to ensure teams are adhering to industry best practices and regulatory requirements.\nMonitor and analyze DevOps pipelines and practices, identifying areas for improvement, optimization, and automation to enhance launch\/failback consistency and accuracy.\nKeep up-to-date with emerging data technologies, trends, and best practices, and make recommendations for their adoption within the organization's DevOps ecosystem.\nMentor and provide technical guidance to junior team members, fostering a culture of knowledge sharing and continuous learning.\nIf you are excited about the opportunity to work as a Technical Senior IC leading Devops development \/ transformation and meet the qualifications mentioned above, we encourage you to apply.\nFull-time Remote will be considered for this role.\nRequired Qualifications:\nProven track record with at least 10 years of experience in DevOps data platform development, preferably in a senior or lead capacity.\nExperience working in public cloud environments, GCP (preferred) \/ Azure \/ AWS and containerization technologies (e.g., Docker, Kubernetes).\nProficiency in infrastructure as code concepts and tools (e.g., Terraform, Ansible) for automating resource provisioning and configuration.\nHands-on experience with CI\/CD pipeline tools (e.g., Jenkins, CircleCI) and version control systems (e.g., Git).\nSolid scripting skills in languages such as Python, Bash, or similar.\nStrong problem-solving and analytical skills, with the ability to troubleshoot complex DevOps platform issues and provide effective solutions.\nExcellent communication and collaboration skills, with the ability to work effectively with cross-functional teams and stakeholders.\nPreferredQualifications:\nFamiliarity with monitoring and logging tools (e.g., Prometheus, Grafana, Splunk, Cloud Logging Solutions) to ensure application performance and system health.\nKnowledge of security best practices in DevOps, including experience with vulnerability scanning, compliance frameworks, and secure deployment practices.\nExperience with Generative AI and\/or Gitlab\nLeadership experience, including mentoring and guiding junior engineers, is a plus.\nEducation:\nBachelor's or Master's degree in Computer Science, Data Science, or a related field. Master's degree preferred.\nPay Range\nThe typical pay range for this role is:\n$140,000.00 - $280,000.00\nThis pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. This position also includes an award target in the company\u201a\u00c4\u00f4s equity award program.\nIn addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company\u201a\u00c4\u00f4s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (\u201a\u00c4\u00faPTO\u201a\u00c4\u00f9) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.\nFor more detailed information on available benefits, please visitjobs.CVSHealth.com\/benefits\nCVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.\nYou are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.\nCVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services throughColleagueRelations@CVSHealth.comIf you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.\nShow more\nShow less",
      "job_skills":"DevOps, Cloud computing, GCP, Azure, AWS, Docker, Kubernetes, Terraform, Ansible, Jenkins, CircleCI, Git, Python, Bash, Prometheus, Grafana, Splunk, Generative AI, Gitlab, Computer Science, Data Science",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer with SDET",
      "company":"Prime Software Technologies, Inc.",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-with-sdet-at-prime-software-technologies-inc-3785360655",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Role -\nData Engineer with SDET experience.\nLocation:\nAustin, TX - Hybrid\nType:\nContract on C2C\nStrong in QE(SDET) + Programming skills in python\nPySpark\nSnowflake or other data warehouse experience\nAWS\nResponsibilities\nData Quality Management : Write Pipelines and help Automate the Quality engineering aspects in there\nBuild new data pipelines and validate the pipelines for data accuracy -- by automating..\nShow more\nShow less",
      "job_skills":"Data Engineering, SDET, Python, PySpark, Snowflake, AWS, Data Quality Management, Data Pipelines, Data Accuracy",
      "Category":"Backend Development"
  },
  {
      "job_title":"Job Opportunity - Data Engineer with Python Coding.",
      "company":"Donato Technologies, Inc.",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/job-opportunity-data-engineer-with-python-coding-at-donato-technologies-inc-3766669358",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Title:\nData Engineer with Python Coding.\nLocation:\nAustin, TX or Bay Area, CA (Hybrid 3 days onsite).\nDuration:\n12+ Months.\nEx-Facebook consultant is mandatory\nJob Description\n10+ years of professional work experience designing and implementing data pipelines in a cloud environment is required.\n5+ years of experience migrating\/developing data solutions in the AWS cloud is required.\n5+ years of experience building\/implementing data pipelines using Databricks or similar cloud database.\nExpert level knowledge of using SQL to write complex, highly optimized queries across large volumes of data.\n5+ years hands-on object-oriented programming experience using Python is required.\nShow more\nShow less",
      "job_skills":"Python, SQL, AWS, Databricks, Cloud Database, Objectoriented programming",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist - Up to $150,000 + Huge Bonus + Package",
      "company":"Hunter Bond",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-up-to-%24150-000-%2B-huge-bonus-%2B-package-at-hunter-bond-3784570993",
      "search_city":"Fitzgerald",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job title: Data Scientist- Up to $140,000 + Huge Bonus + Package\nClient: Scaling fintech\nExperience Level: 1+ years'\nSalary: Up to $140,000 + Huge Bonus + Package\nLocation: Houston (Hybrid)\nSells: Cutting-edge tech, ownership of multiple greenfield projects, no red tape, gold medal Olympiads, highest regarded technologists around, a welcoming\/ collaborative environment, fantastic office spaces\nAn elite scaling fintech are searching for Data Scientists to join a group of the highest-regarded talent around!\nThis team has an unlimited tech budget, promotes a great culture, and is made up of incredible like-minded individuals.\nRole:\nDevelop a deep understanding of North American Energy Markets and build cutting edge analytics tools for ML models.\nWorking as part of a high performing team solving complex data issues and making deductions which you'll see directly impact the business.\nSkills\/Experience:\n3+ years Experience as a Data Scientist\nDegree in Computer Science\/ Engineering or Mathematics (or related field)\nGood skills in Python\nStrong SQL proficiency and understanding of database technologies, such as AWS RDS and Snowflake\nStrong proficiency in Python, with knowledge of common ML and statistical packages such as Scikit-Learn, SciPy, Prophet, etc\nExcellent exposure to Generalized Linear and Non-Linear Models, Time Series Analysis, Random Forest.\nShow more\nShow less",
      "job_skills":"Python, SQL, AWS RDS, Snowflake, ScikitLearn, SciPy, Prophet, Generalized Linear and NonLinear Models, Time Series Analysis, Random Forest",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist (IV) \u201a\u00c4\u00ec Generative AI",
      "company":"HP",
      "job_location":"Spring, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-iv-%E2%80%93-generative-ai-at-hp-3713201274",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Locations include Spring, Texas (preferred location), and US remote.\nTypically need at least Master's degree and minimum 0-2 years full-time relevant work experience.\nThe Team\nWe are a growing centralized team helping HP take advantage of new AI\/ML technology, especially around Generative AI and large language models. We engage with business units to advise and prototype solutions, and we develop and run software applications for internal use.\nThe Role\nAs a Data Scientist with a focus on Generative AI you will work on multiple engagements across HP involving large language models and other new Generative AI capabilities. Beyond our team, you will work with business stakeholders and developers from other business units. Your primary focus and mindset is to help deliver business solutions to our (mostly internal) customers. You are expected to stay up to date on important new Gen AI papers and releases, but note that this is not an AI research role.\nSkills And Profile\nKnowledge of data science and machine learning core skills.\nExperience with NLP, Large Language Models, LLM prompt engineering, vector databases, Retrieval Augmented Generation (RAG), and search engines.\nGood computer science skills. Experience in a software development team is a big plus, especially with business applications in a cloud environment.\nTools you may use include Azure services such as Azure Machine Learning and Azure prompt flow, as well as python, langchain, streamlit, docker, git, and elastic search.\nSome experience from a large complex organization is a plus.\nAbility to participate in meetings with a multitude of stakeholders and communicate in a crisp manner. Mastery in English is required.\nYou enjoy explaining technical concepts (such as LLM's) to a non-technical audience.\nYou propose pragmatic solutions that are as simple as possible, which sometimes mean that no Gen AI component is necessary.\nInterest in working in a distributed team with diverse backgrounds.\nThe recent AI progress is disruptive, and our team is in the midst of it. As a consequence, day-to-day priorities, tasks, and team structure may change rapidly. We are looking for somebody who thrives in such an environment. The role is not a fit if you value \"business as usual\".\nEducation And Length Of Experience\nFor this position, we prefer at least a relevant Master's degree (e.g. Computer Science) or demonstrated competence, and a minimum of 6-10 years experience.\nAbout HP\nYou\u201a\u00c4\u00f4re out to reimagine and reinvent what\u201a\u00c4\u00f4s possible\u201a\u00c4\u00eein your career as well as the world around you.\nSo are we. We love taking on tough challenges, disrupting the status quo, and creating what\u201a\u00c4\u00f4s next. We\u201a\u00c4\u00f4re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.\nHP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.\nOur history: HP\u201a\u00c4\u00f4s commitment to diversity, equity and inclusion \u201a\u00c4\u00ec it's just who we are.\nFrom the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you\u201a\u00c4\u00f4re more innovative and that helps grow our bottom line. Come to HP and thrive!\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Natural Language Processing, Large Language Models, Retrieval Augmented Generation, Search Engines, Agile Development, Azure Services, Python, Langchain, Streamlit, Docker, Git, Elastic Search, Cloud Computing, Business Applications",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist JT3S7",
      "company":"iSphere",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-jt3s7-at-isphere-3725579166",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"iSphere, a leading IT recruiting firm in Houston, TX, is seeking a full-time Senior Data Scientist with expertise in the energy markets of North America. Join our team and play a pivotal role in driving business growth and innovation through advanced data analysis and machine learning.\nResponsibilities:\n- Lead end-to-end data science projects, from problem formulation to result presentation\n- Collaborate with cross-functional teams to identify business challenges and opportunities\n- Design and implement innovative machine learning algorithms to solve complex problems\n- Deliver technical solutions to enhance trading platforms and address business needs\n- Explore, clean, and preprocess large datasets to ensure data quality\n- Apply statistical analysis methods to uncover patterns and insights\n- Mentor and guide junior data scientists\n- Stay up-to-date with the latest advancements in data science and machine learning techniques\n- Collaborate with engineering teams to integrate data-driven solutions into production systems\n- Contribute to data-driven decision-making discussions with senior management\nSkills and Experience:\n- BS\/MS in Engineering\/Statistics\/Computer Science\/Economics or related field\n- Experience working with energy and financial data in North American Gas and Power Markets\n- 7-10+ years' experience developing enterprise-level models and applications with cloud-based microservices\n- Strong SQL proficiency and understanding of database technologies\n- Proficiency in Python and knowledge of statistical packages\n- Advanced knowledge of various machine learning models and techniques\n- Proficiency in data visualization tools such as Tableau\n- Solid understanding of statistical concepts and hypothesis testing\n- Experience working with large-scale datasets and data processing tools\n- Portfolio showcasing previous data science projects and their business impact is highly desirable\nJoin iSphere as a Senior Data Scientist and make a significant impact in the energy markets. Apply now.\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Data Analysis, Statistical Analysis, Advanced Analytics, Python, SQL, Tableau, Data Visualization, Natural Language Processing, Largescale Dataset Processing, Cloudbased Microservices, Data Warehousing, Data Mining, Hypothesis Testing, Business Intelligence, Financial Modeling, Energy Markets, North American Gas and Power Markets",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist - Crude & Products Trading",
      "company":"Jobs via eFinancialCareers",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-crude-products-trading-at-jobs-via-efinancialcareers-3735478783",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Main Purpose:\nWe are recruiting an experienced data scientist to develop and support decision support and optimisation analytics in our Global Crude and Products Trading businesses. The candidate will work closely with our traders, research analysts and data scientists to develop and manage a number of analytical tools to improve decision making on the trading desks. These tools will include applications of computational statistics, machine learning, operations research and classical AI optimisation methods. The objective is to increase the profitability and efficiency of our trading businesses.\nKnowledge Skills and Abilities, Key Responsibilities:\nExperience working as a data scientist, quant, research analyst, or trader in a commodity trading environment.\nA Masters or PhD in Applied Mathematics\/Statistics, Computer Science, Operations Research, Mathematical Finance or other relevant field.\nExcellent Python and SQL skills.\nPractical experience developing and deploying machine learning and statistical models in a business setting.\nAbility to work productively with commercial stakeholders.\nThe following knowledge, skills and abilities are desirable for this role:\nExperience developing and deploying optimisation applications in a business setting (e.g. linear optimisation, vehicle routing)\nData engineering skills such as ETL pipeline development.\nAWS experience and certifications.\nExperience with Tableau, Streamlit, or Django.\nKey Responsibilities\nDevelopment and maintenance of models, analytics applications for Crude and Products trading desks.\nKey Relationships and Department Overview:\nReport to Lead Energy Data Scientist (Geneva).\nWork closely with the global crude and product business heads.\nWork closely with global head of crude and products research and research analyst team.\nWork closely with data scientists, data engineers and devops engineers in the Data Science and Engineering Team.\nCompetencies\nAbility to communicate technical issues effectively with a diverse set of stakeholders across business lines and technology.\nAbility to creatively apply data and analytics technology to solve commercial problems.\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Computational Statistics, Operations Research, Classical AI Optimization, Python, SQL, Tableau, Streamlit, Django, Data Engineering, ETL, AWS, Linear Optimization, Vehicle Routing",
      "Category":"Backend Development"
  },
  {
      "job_title":"Big Data Developer",
      "company":"Advanced Knowledge Tech LLC",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-developer-at-advanced-knowledge-tech-llc-3667475451",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Title:\nBig Data Developer\nLocation:\nHouston, TX (Onsite Hybrid)\nJob Description\nAdvanced knowledge of application, data, and infrastructure architecture disciplines\nUnderstanding of architecture and design across all systems\nWorking proficiency in developmental toolsets\nKnowledge of industry-wide technology trends and best practices\nAbility to work in large, collaborative teams to achieve organizational goals\nPassionate about building an innovative culture\nProficiency in one or more modern programming languages\nUnderstanding of software skills such as business analysis, development, maintenance, and software improvement\n4+ years of software design and application development experience using any OOPs Languages (C#, C++ JAVA)\n2+ years' experience with any of the following data orchestration stack, ingestion frameworks, cloud-native patterns: Apache Airflow, Kafka, Nomad\/Terraform, Kubernetes\/Docker, etc.\n2+ years of experience with scripting languages like Python, Bash or PowerShell, etc.\nHands-on experience with any of the \"open-source\" distributed ingestion\/processing stack like Hadoop, Spark and Kafka is a must.\nSolid exposure working in data engineering team, and can demonstrate best practices for building robust data controls and governance practices\nExperience with infrastructure automation technologies like Docker and K8s is huge plus.\nExposure with building APIs and services using REST.\nDesigned and developed scalable data solutions using cloud infra such as AWS, Azure or GCP.\nAbility to manage multiple tasks and thrive in a fast-paced team environment.\nStrong written and verbal communications skills.\nWorking knowledge of Agile and scrum practices.\nThanks & Regards\n,\nVipin kumar\nAdvanced Knowledge Tech, LLC\nHebron Office Plaza, 751 Hebron Pkwy, Suite# 325, Lewisville, Texas 75057\n:- US: +1 7322761667\nEmail:\nvipin@akt-corp.com\nWebsite\n:\nwww.akt-corp.com\nLinkedIn Link: https:\/\/www.linkedin.com\/in\/vipin-kumar-3008b4221\nShow more\nShow less",
      "job_skills":"Application Architecture, Data Architecture, Infrastructure Architecture, OOPs Languages (C# C++ Java), Apache Airflow, Kafka, Nomad, Terraform, Kubernetes, Docker, Python, Bash, PowerShell, Hadoop, Spark, Distributed Ingestion Stack, Cloud Infra (AWS Azure GCP), REST APIs, Agile, Scrum",
      "Category":"Backend Development"
  },
  {
      "job_title":"Big Data Developer - Fulltime opportunity",
      "company":"Advanced Knowledge Tech LLC",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-developer-fulltime-opportunity-at-advanced-knowledge-tech-llc-3667479014",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Big Data Developer\nLocation: Plano, TX\/ Houston, TX\/ Jersey City, NJ\/ Wilmington, DE\nBig Data Developer\nBS\/BA degree or equivalent experience\nAdvanced knowledge of application, data, and infrastructure architecture disciplines\nUnderstanding of architecture and design across all systems\nWorking proficiency in developmental toolsets\nKnowledge of industry-wide technology trends and best practices\nAbility to work in large, collaborative teams to achieve organizational goals\nPassionate about building an innovative culture\nProficiency in one or more modern programming languages\nUnderstanding of software skills such as business analysis, development, maintenance, and software improvement\n9+ years of software design and application development experience using any OOPs Languages (C#, C++ JAVA, etc. )\n2+ years' experience with any of the following data orchestration stack, ingestion frameworks, cloud-native patterns: Apache Airflow, Kafka, Nomad\/Terraform, Kubernetes\/Docker, etc.\n2+ years of experience with scripting languages like Python, Bash or PowerShell, etc.\nHands-on experience with any of the \"open-source\" distributed ingestion\/processing stack like Hadoop, Spark and Kafka is a must.\nSolid exposure working in data engineering team, and can demonstrate best practices for building robust data controls and governance practices\nExperience with infrastructure automation technologies like Docker and K8s is huge plus.\nExposure with building APIs and services using REST.\nDesigned and developed scalable data solutions using cloud infra such as AWS, Azure or GCP.\nAbility to manage multiple tasks and thrive in a fast-paced team environment.\nStrong written and verbal communications skills.\nWorking knowledge of Agile and scrum practices.\nBest regards,\nAdvanced Knowledge Tech, LLC\nwww.akt-corp.com\nAkash Rathore\nTeam Lead\nEmail: akash@akt-corp.com\nDesk : (732) 922 6563\nLinkedIn Link : Akash Rathore | LinkedIn\nHebron Office Plaza, 751 Hebron Pkwy, Suite# 325, Lewisville, Texas 75057\nRecycle always | Save Paper - Save Trees | Go Green\nShow more\nShow less",
      "job_skills":"Apache Airflow, Kafka, Nomad, Terraform, Kubernetes, Docker, Hadoop, Spark, Python, Bash, PowerShell, AWS, Azure, GCP, REST, OOPs Languages, Agile, Scrum",
      "Category":"Backend Development"
  },
  {
      "job_title":"Product Manager, Data Science",
      "company":"HP",
      "job_location":"Spring, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/product-manager-data-science-at-hp-3785300923",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"About Us\nInnovation is in HP\u201a\u00c4\u00f4s DNA. From our origins in a Palo Alto garage in 1939, to our current position as one of the world\u201a\u00c4\u00f4s leading technology companies, HP has grown to become a leader in technology and corporate culture, inspiring innovators, and entrepreneurs around the globe.\nHP brings together a portfolio that spans printing, personal computing, software, and services to serve more than 1 billion customers in over 170 countries. We are committed to fostering a diverse and inclusive workplace that attracts exceptional talent and to supporting our employees to succeed at all levels. We dream in over 35 languages and share one mission: to engineer experiences that amaze.\nRole Overview\nThis position is on the Data Science & AI Solutions team at HP and is specifically focused on pioneering transformative products and services targeting the creation of data science and AI models developed on local or hybrid environments. As a Product Manager, you will be responsible for supporting the development of the vision, roadmap, and definition of software products within HP\u201a\u00c4\u00f4s larger DS & AI solutions portfolio. The ideal candidate will exhibit robust technical proficiency in AI tools and workflows, possess a blend of tactical and strategic abilities, and excel as an effective communicator.\nThis position is located in Fort Collins, Colorado; Palo Alto, CA; or Houston, TX.\nKey Responsibilities For This Role Include\nConduct in-depth market research and competitive analysis to identify opportunities, customer pain points, and differentiation areas in Data Science & AI.\nDefine and articulate a clear product vision aligned with the company's overall strategic goals, staying up to date with industry trends and customer needs to continuously enhance the product roadmap.\nUtilize strong business acumen to connect product initiatives to business objectives and develop well-defined business models for new products.\nLead the ideation, definition, and development of software products and services solve complex problems and meet customer needs.\nCommunicate feature prioritization, timelines, and acceptance criteria to engineering teams to ensure timely and successful product development.\nChampion user-centric design principles to deliver an intuitive and delightful user experience, working closely with product designers to create wireframes, prototypes, and UI\/UX improvements.\nSupport product marketing and sales teams with the development of effective Go-to-Market strategies, product positioning, and sales enablement materials.\nDefine and track key product performance metrics. Analyze data to gain insights into user behavior and product usage, using this information to guide future product improvements.\nAct as the voice of the customer within the company, communicating customer feedback, needs, and pains throughout the organization.\nExperience Knowledge & Skills\nProven experience (2+ years) in software product management.\nExperience using R, Python, and cloud computing platforms (AWS, Azure)\nExceptional analytical and problem-solving skills, with a data-driven approach to decision-making.\nExceptional communication and interpersonal skills, with the capacity to engage effectively with diverse teams and articulate ideas at the executive level.\nDemonstrated ability to lead and influence cross-functional teams without direct authority.\nFamiliarity with agile development methodologies and project management processes.\nPrior experience with artificial intelligence, machine learning, or deep learning\nPrior experience in the enterprise software market (preferable, but not required)\nEducation\nBachelor's degree in computer science, Engineering, Data Science, or related fields.\nMBA preferred.\nAbout HP\nYou\u201a\u00c4\u00f4re out to reimagine and reinvent what\u201a\u00c4\u00f4s possible\u201a\u00c4\u00eein your career as well as the world around you.\nSo are we. We love taking on tough challenges, disrupting the status quo, and creating what\u201a\u00c4\u00f4s next. We\u201a\u00c4\u00f4re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.\nHP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.\nOur history: HP\u201a\u00c4\u00f4s commitment to diversity, equity and inclusion \u201a\u00c4\u00ec it's just who we are.\nFrom the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you\u201a\u00c4\u00f4re more innovative and that helps grow our bottom line. Come to HP and thrive!\nShow more\nShow less",
      "job_skills":"AI, Machine Learning, Deep Learning, Software Product Management, R, Python, AWS, Azure, Agile Development, Project Management, UserCentric Design, Data Analysis, Communication, Interpersonal Skills, Cloud Computing, Data Science, UI\/UX",
      "Category":"Backend Development"
  },
  {
      "job_title":"Spatiotemporal Data Scientist - 4669",
      "company":"Delphi-US, LLC",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/spatiotemporal-data-scientist-4669-at-delphi-us-llc-3766684694",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Title: Senior Data Scientist (Contract) - Job#4669\nLocation:\nRemote or Hybrid (Houston TX)\nJob Description:\nOur Machine Learning team tackles major opportunities for operational efficiency and revenue generation and deploys these models across environments where they re-shape the way we work. We are seeking a curious, proactive, and innovative Data Scientist to join our team. The ideal candidate has a strong scientific background, experience blending various datasets, building statistical\/machine learning models, and communicating the results back to business partners.\nCandidates Must Have the following background to be considered:\nDomain expertise with methane, air quality measurement, or atmospheric modeling would be very valuable since gas concentrations and movements are a lot of the modeling work. Modeling and studying other related scientific phenomena could be a good backup too.\nSpatiotemporal statistical modeling expertise. Time series expertise alone would also be a good backup even if we don\u201a\u00c4\u00f4t have the spatial statistics component. Bonus points for someone with Bayesian time series\/spatial experience.\nPython \/ R programming to model and analyze the data.\nSQL \u201a\u00c4\u00ec we\u201a\u00c4\u00f4re working with a variety of disparate datasets as we build out sensors at our environmental sites, so it\u201a\u00c4\u00f4s important that candidates can navigate uncharted datasets and quickly figure out how to link these accurately. SQL Expertise is a Must: to collect, aggregate new data sources & stage for modelling & analysis\nmethane measurement and atmospheric sciences\ndispersion models\nstatistical modeling\ndata management (SQL) experience\nResponsibilities:\nApply machine learning, advanced analytical techniques, and critical thinking to solve complex business problems\nSeek, build, and consolidate data inputs proactively to create and improve models\nTranslate business partners\u201a\u00c4\u00f4 needs into data science projects and make technical decisions based on the tradeoff between complexity and value\nDrive projects, individually and collaboratively, through the data science lifecycle including data collection, exploration\/analysis, model development, validation, and deployment\nDevelop presentations to communicate key messages to senior sponsors, non-technical partners, fellow data scientists, and other stakeholders\nWork with technical partners to deploy models and streamline the process to scale our work\nRequired Qualifications:\nBuilding statistical or machine learning models for prediction and inference\nAbility to code within Python (R also considered)\nAdvanced SQL knowledge to pull and transform data\nEducation and Experience\nQuantitative Foundation: B.S. degree in a quantitative field (e.g., Statistics, Engineering, Computer Science, Meteorology, Physics, Mathematics, Economics, Operations Research).\nExperience: 3+ years\u201a\u00c4\u00f4 experience in data science building and deploying models into production\nTechnical Skills\nProgramming: compose clean, efficient, and reusable code in Python and\/or R.\nMachine Learning \/ Modeling: understand what types of algorithms to use, their benefits and drawbacks, and how to implement them.\nData Wrangling: write efficient SQL queries from scratch that blend data from a variety of sources in the right form for modeling, analysis, and scoring.\nStatistical Analysis: investigate trends, patterns, and relationships using statistical methods and tests to reach actionable conclusions and understand causal relationships.\nData Visualization: grasp data-ink ratios and bring data-driven stories to life through visuals.\nScientific Research: experience using adjacent scientific literature to advance our thinking and modeling in novel areas where existing research is thin\nSoft Skills\nCurious: bring intellectual curiosity, an inquisitive nature, and a desire to deepen your knowledge and continue learning.\nOwnership: take responsibility to proactively advance projects, contribute to the team\/organization, and improve existing processes.\nBusiness acumen: understand the bigger picture for customers and the business while connecting your work to key objectives for both.\nStorytelling: write and present messages and insights clearly to persuade non-technical partners that they can confidently use our models and solutions.\nPreferred Qualifications\nA graduate degree (Masters or PhD) in a quantitative field\nExperience with spatial modeling, greenhouse gas emissions, atmospheric modeling, or remote sensing data\nProficiency using git for version control, collaboration, and releases\nExpertise with cloud services like AWS (SageMaker, S3, Redshift, etc.) and Snowflake\nBuilt dashboards for visualizing model outputs and performance monitoring using Microsoft PowerBI, Python dash, or similar tools\nAbout Delphi-US\nDelphi-US is a national recruiting firm based in Newport, Rhode Island. We specialize in IT, Engineering and Professional Staffing services for organizations from Main Street to Wall Street. Our mission is simple: To connect great people to great companies. We accomplish this with a proprietary skill-based and cultural matching process that results in higher qualified submissions along with increased interviews and offer rates. You\u201a\u00c4\u00f4ll find our team is friendly, professional and ready to advocate on your behalf, armed with industry trends, and an understanding of employer expectations.\nShow more\nShow less",
      "job_skills":"Python, R, SQL, Machine Learning, Artificial Intelligence, Statistics, Data Visualization, Data Wrangling, Data Analysis, Scientific Research, Git, Cloud Services, AWS, SageMaker, S3, Redshift, Snowflake, Microsoft PowerBI, Python Dash",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Associate Data Scientist - Machine Learning, Financial Services",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-associate-data-scientist-machine-learning-financial-services-at-capital-one-3774775745",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Plano 7 (31067), United States of America, Plano, TexasSenior Associate Data Scientist - Machine Learning, Financial Services\nAt Capital One, we think big and do big things. We are a Top-10 bank by deposits\u201a\u00c4\u00eea high-tech company, a data driven company, and a nationally recognized brand. Our products reach tens of millions of consumers and have been recognized by numerous prestigious awards for their customer-friendliness. Capital One was the first major bank to move to cloud computing and to publish APIs for the Open Banking future. AI is transforming every industry, at Capital One you will shape how it transforms financial services.\nTeam Description:\nAs a Data Scientist at Capital One's Auto Finance business, you\u201a\u00c4\u00f4ll be part of a high performing modeling and analytics team that\u201a\u00c4\u00f4s leading the next wave of disruption at a whole new scale. Our team has a relentless focus on the craft of modeling and innovation, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives. You\u201a\u00c4\u00f4ll drive the heart of business by working on an array of impactful and exciting applications like customer lifetime valuation, product recommendation, fraud detection, and productivity improvement via Generative AI.\nRole Description\nIn this role, you will:\nPartner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love\nLeverage a broad stack of technologies \u201a\u00c4\u00eePython, Huggingface, VectorDB, Pytorch, ElasticSearch and more \u201a\u00c4\u00ee to reveal the insights hidden within huge volumes of numeric and textual data\nBuild machine learning models through all phases of development, from design through training, evaluation, validation, and implementation\nFlex your interpersonal skills to translate the complexity of your work into tangible business goals\nThe Ideal Candidate is:\nCustomer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it\u201a\u00c4\u00f4s about making the right decision for our customers.\nTechnical. You\u201a\u00c4\u00f4re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.\nInnovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.\nCreative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You\u201a\u00c4\u00f4re not afraid to share a new idea.\nBasic Qualifications:\nCurrently has, or is in the process of obtaining a Bachelor\u201a\u00c4\u00f4s Degree plus 2 years of experience in data analytics, or currently has, or is in the process of obtaining Master\u201a\u00c4\u00f4s Degree, or currently has, or is in the process of obtaining PhD, with an expectation that required degree will be obtained on or before the scheduled start date\nAt least 1 year of experience in open source programming languages for large scale data analysis\nAt least 1 year of experience with machine learning\nAt least 1 year of experience with relational databases\nPreferred Qualifications:\nMaster\u201a\u00c4\u00f4s Degree in \u201a\u00c4\u00faSTEM\u201a\u00c4\u00f9 field (Science, Technology, Engineering, or Mathematics), or PhD in \u201a\u00c4\u00faSTEM\u201a\u00c4\u00f9 field (Science, Technology, Engineering, or Mathematics)\nAt least 2 years\u201a\u00c4\u00f4 experience with designing and optimizing large scale machine learning models, implementing large and complex data pipelines and deploying models into production\nAt least 2 years' experience utilizing cloud-based solutions (AWS, Azure, Google Cloud)\nAt least 2 years' experience in a broad stack of technologies (Python, Pytorch, Huggingface, VetorDB, ElasticSearch)\nExperience in modern model algorithms and architectures (Deep Learning, Large Language Models, Information Retrieval, Recommender Systems or Reinforcement Learning)\nCapital One will consider sponsoring a new qualified applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Capital One, Plano, Texas, Machine Learning, Data Scientist, Financial Services, Cloud Computing, APIs, Open Banking, Generative AI, Python, Huggingface, VectorDB, Pytorch, ElasticSearch, Data Science, Open Source, Cloud Computing Platforms, Data Analytics, Relational Databases, STEM, Deep Learning, Large Language Models, Information Retrieval, Recommender Systems, Reinforcement Learning, AWS, Azure, Google Cloud",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Associate Data Scientist - Statistical Analysis, Financial Services",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-associate-data-scientist-statistical-analysis-financial-services-at-capital-one-3774776616",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Plano 7 (31067), United States of America, Plano, TexasSenior Associate Data Scientist - Statistical Analysis, Financial Services\nAt Capital One, we think big and do big things. We are a Top-10 bank by deposits\u201a\u00c4\u00eea high-tech company, a data driven company, and a nationally recognized brand. Our products reach tens of millions of consumers and have been recognized by numerous prestigious awards for their customer-friendliness. Capital One was the first major bank to move to cloud computing and to publish APIs for the Open Banking future. AI is transforming every industry, at Capital One you will shape how it transforms financial services.\nTeam Description:\nAs a Data Scientist at Capital One's Auto Finance business, you\u201a\u00c4\u00f4ll be part of a high performing modeling and analytics team that\u201a\u00c4\u00f4s leading the next wave of disruption at a whole new scale. Our team has a relentless focus on the craft of modeling and innovation, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives. You\u201a\u00c4\u00f4ll drive the heart of business by working on an array of impactful and exciting applications like customer lifetime valuation, product recommendation, fraud detection, and productivity improvement via Generative AI.\nRole Description\nIn this role, you will:\nPartner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love\nLeverage a broad stack of technologies \u201a\u00c4\u00ee Python, GitHub, Sagemaker, SQL, AWS and more \u201a\u00c4\u00ee to reveal the insights hidden within huge volumes of numeric and textual data\nBuild machine learning models through all phases of development, from design through training, evaluation, validation, and implementation\nFlex your interpersonal skills to translate the complexity of your work into tangible business goals\nThe Ideal Candidate is:\nCustomer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it\u201a\u00c4\u00f4s about making the right decision for our customers.\nTechnical. You\u201a\u00c4\u00f4re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.\nStatistically-minded. You\u201a\u00c4\u00f4ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with hypothesis testing, classification, clustering, time series, and causal inference.\nInnovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.\nBasic Qualifications:\nCurrently has, or is in the process of obtaining a Bachelor\u201a\u00c4\u00f4s Degree plus 2 years of experience in data analytics, or currently has, or is in the process of obtaining Master\u201a\u00c4\u00f4s Degree, or currently has, or is in the process of obtaining PhD, with an expectation that required degree will be obtained on or before the scheduled start date\nAt least 1 year of experience in open source programming languages for large scale data analysis\nAt least 1 year of experience with machine learning\nAt least 1 year of experience with relational databases\nPreferred Qualifications:\nMaster\u201a\u00c4\u00f4s Degree in \u201a\u00c4\u00faSTEM\u201a\u00c4\u00f9 field (Science, Technology, Engineering, or Mathematics), or PhD in \u201a\u00c4\u00faSTEM\u201a\u00c4\u00f9 field (Science, Technology, Engineering, or Mathematics)\nAt least 2 years' experience utilizing cloud-based solutions (AWS, Azure, Google Cloud)\nAt least 2 years' experience in a broad stack of technologies (Python, GitHub, Sagemaker, SQL, R)\nExperience in advanced statistical modeling and optimization such as causal inference, hypothesis testing, linear regression, logistic regression, generalized additive models, Bayesian statistics, time-series and non-parametric modeling\nCapital One will consider sponsoring a new qualified applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Python, GitHub, Sagemaker, SQL, AWS, Data Science, Machine Learning, Relational Databases, Cloud Computing, Data Analytics, Hadoop, Spark, AWS, Azure, Google Cloud, Statistical Modeling, Optimization, Causal Inference, Hypothesis Testing, Linear Regression, Logistic Regression, Generalized Additive Models, Bayesian Statistics, TimeSeries, NonParametric Modeling",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Verizon",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-verizon-3776449594",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"When you join Verizon\nVerizon is one of the world's leading providers of technology and communications services, transforming the way we connect around the world. We're a human network that reaches across the globe and works behind the scenes. We anticipate, lead, and believe that listening is where learning begins. In crisis and in celebration, we come together-lifting up our communities and striving to make an impact to move the world forward. If you're fueled by purpose, and powered by persistence, explore a career with us. Here, you'll discover the rigor it takes to make a difference and the fulfillment that comes with living the #NetworkLife.\nWhat you'll be doing...\nAt Verizon, we are on a multi-year journey to industrialize our data science and AI capabilities. Very simply, this means that AI will fuel all decisions and business processes across the company. At $130B+ in annual revenue, this is a pioneering opportunity to design and shape AI at scale in the Telco industry. With our leadership in bringing the 5G network nationwide, the opportunity for AI will only grow exponentially in going from enabling billions of predictions to possibly trillions of predictions that are automated and real-time. Therefore, an ideal candidate will have a keen passion in delivering AI for good, excellent communication skills, critical thinking above and beyond the technical knowledge and commercial application experience required.\nPartnering closely with business, scientists, engineers and different stakeholders to design and execute experiments to verify model effectiveness.\nConducting data analysis to make sense of the experiment results and generate insights.\nCommunicating findings to diverse technical and non-technical stakeholders with differing perspectives and needs.\nSupporting the effort to continuously mature experiment capabilities and scale up testing throughput.\nWhat we're looking for...\nThis is an individual contributor role with technical expertise in machine learning and statistics, experience with implementation of AI in commercial applications to drive better business outcomes, and passion for ensuring AI is used responsibly. This role will focus on improving model resilience through experimentation.\nYou'll need to have:\nBachelor's degree or four or more years of work experience.\nFour or more years of relevant work experience.\nSolid programming skills in SQL and Python.\nExcellent communication & cross-functional collaboration skills to understand business needs and deliver implementations\/solutions.\nEven better if you have one or more of the following:\nAdvanced degree in a quantitative field (e.g. Computer Science, Statistics, Applied Math, Econometrics, Operations Research, Quantitative Social Science).\nFamiliarity with hypothesis testing, sampling, experiment design (e.g. A\/B testing, MAB, etc.) and causal inference methods.\nKnowledgeable of commonly used AI\/ML techniques such as clustering, classification, regression, ensemble methods etc., and frameworks (Keras, Pytorch, etc.) and libraries\/packages\/APIs (e.g., Scikit, Pytorch).\nExperience in data ETL from different data sources, at different scales (big data and small data), and of different formats; Cloud computing experience a plus\nIf Verizon and this role sound like a fit for you, we encourage you to apply even if you don't meet every \"even better\" qualification listed above.\nThis role is eligible to be considered for the Department of Defense SkillBridge Program.\nWhere you'll be working\nIn this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.\nScheduled Weekly Hours\n40\nEqual Employment Opportunity\nWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.\nShow more\nShow less",
      "job_skills":"Machine Learning, Statistics, SQL, Python, Keras, Pytorch, Scikit, Pytorch, Clustering, Classification, Regression, Ensemble methods, Big data, Small data, Data ETL, Cloud computing, Apache Hadoop",
      "Category":"Backend Development"
  },
  {
      "job_title":"Junior Data Engineer",
      "company":"Dale WorkForce Solutions",
      "job_location":"Coppell, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/junior-data-engineer-at-dale-workforce-solutions-3782273397",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Our client is seeking a\nJunior Data Engineer\nwith 1-3 years of experience.\nJob Title:\nJunior Data Engineer\nLocation:\nOn-site in Coppell, TX 1x\/week (must currently live in the area)\nDuration:\nDirect hire\/Full-time\nKey Responsibilities:\nData Pipeline Development: Design, build, and maintain efficient data pipelines using Python, Apache Spark, and Apache Kafka.\nBig Data Processing: Work on large-scale data processing and engineering tasks, ensuring performance and scalability.\nData Quality and Integration: Ensure the integrity, reliability, and quality of data. Integrate data from various sources for analytical and operational purposes.\nCollaborative Development: Collaborate with cross-functional teams, including data scientists and analysts, to support data infrastructure needs and contribute to ongoing projects.\nProblem-Solving: Tackle complex data-related problems and engineer scalable solutions.\nContinuous Learning: Stay updated with the latest trends and technologies in big data engineering and apply them to improve existing systems.\nQualifications:\nBachelor's degree in Computer Science, Engineering, or a related field.\n1-3 years of experience in a Data Engineering role.\nStrong proficiency in Python, Java, Spark programming.\nHands-on experience with Confluent Kafka, Snowflake, BigQuery\nDemonstrated experience in working with big data technologies and large-scale data engineering projects.\nFamiliarity with cloud platforms like AWS, Azure, or GCP is a plus.\nExcellent problem-solving and analytical skills.\nStrong communication and teamwork abilities.\nShow more\nShow less",
      "job_skills":"Data Pipeline Development, Apache Spark, Apache Kafka, Python, Big Data Processing, Data Quality and Integration, Collaborative Development, ProblemSolving, Continuous Learning, Computer Science, Data Engineering, Java, Spark Programming, Confluent Kafka, Snowflake, BigQuery, AWS, Azure, GCP, Cloud Platforms",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Futran Solutions",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-futran-solutions-3712876085",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Title: Data Scientist\nContract Role\nDallas, Tx (Day 1 onsite)\nJob Description\nAt least 8+ yrs of exp as data scientist\nCollaborate with product design and engineering teams to develop an understanding of needs.\nWork closely with business units to identify use cases for real estate industry\nResearch and devise innovative statistical models for data analysis.\nSr data scientist having good experience on Gen AI >ML and will be working on below modules\nBoosted Gen AI-Driven Insights Module\nCustomer Behavior Analysis And Prediction\nAutomated Data Analytics Dashboard\nGen AI-Powered Product Road Map Optimizer\nAutomated Customer Interaction And Feedback Collection Tool\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, AI, Data Analysis, Statistics, Python, R, SAS, Tableau, Power BI, Data Warehousing, Data Mining, Hadoop, Spark, Hive, Pig, SQL, NoSQL, Cloud Computing, AWS, Azure, Google Cloud Platform, Big Data, Agile, Scrum, Kanban",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior, Data Scientist - Data Ventures",
      "company":"Walmart Luminate",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-data-ventures-at-walmart-luminate-3669254103",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position Summary...\nWhat you'll do...\nWhat you'll do...\nPosition Summary...\nData Ventures, akin to a nimble startup incubated within Walmart is building the best-in-class suite of Data Products to deliver actionable, customer-centric insights and help merchants and suppliers make better business decisions on omni channel 360 performance.\nAs a Senior Data Scientist, you will play a pivotal role in science projects\/products and take ownership of project delivery and responsibilities and be the technical SPOC for your team. You will work closely with product stakeholders and deliver outstanding business outcomes. Provide leadership with constant updates and align with directions and expectation.\nMust have: Machine Learning, Data Science, SQL, NoSQL, Python, R, CI\/CD, MLOps, Big Data, Cloud, Machine Learning\nWhat You'll Do\nWork in customer data science space building models for customer segmentation, customer LTV, etc.\nWork with marketing team to build algorithms that would help in better customer targeting.\nAnalyzes the business problem and recommends approach to resolve the business problem.\nSelects appropriate modeling techniques for complex problems with large scale, multiple structured and unstructured data sets.\nSelects and develops variables and features iteratively based on model responses in collaboration with the business.\nConducts exploratory data analysis activities (for example, basic statistical analysis, hypothesis testing, statistical inferences) on available data.\nWork on ad-hoc data science projects\nMentor junior data scientist in the team and act as a tech SPOC from your area\nWhat You'll Bring:\nPassion for problem-solving, come with Analytical mindset with critical-thinking, and data skills.\nExpertise in Machine Learning and Data Science\nStrong technical skills in SQL, Python, R, or other programming languages commonly used in data analysis.\nDeep expertise in Customer Data Science viz. customer segmentation, churn analysis, repeat purchase, market basket, A\/B testing, etc.\nAwareness of software engineering principles, ability to develop and deploy appropriate analytic code suitable for production.\nWorking knowledge of CI\/CD and MLOps\nExperience working with large datasets, finding insights, and telling stories using data.\nGood knowledge in working with distributed datastores (e.g., SQL, NoSQL), and Big Data and Cloud technologies like GCP BQ.\nExperience in leading and mentoring a team of data scientists.\nUnderstanding of advance ML topics viz. Deep learning (ENN, CNN, RNN, etc.), GAN, Transformers, NLP, LLM's is a plus.\nExcellent communication skills and ability to effectively communicate technical concepts to non-technical stakeholders.\nPrior experience working in the retail data sets is strongly preferred.\nAbout Walmart Global Tech\nImagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.\nFlexible, Hybrid Work\nWe use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.\nBenefits\nBenefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.\nEqual Opportunity Employer\nWalmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\nThe above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.\nMinimum Qualifications...\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\nOption 1- Bachelor's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.\nPreferred Qualifications...\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\nData science, machine learning, optimization models, Master's degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)\nPrimary Location...\n603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America\nShow more\nShow less",
      "job_skills":"Machine Learning, Data Science, SQL, NoSQL, Python, R, CI\/CD, MLOps, Big Data, Cloud, GCP BQ, Kubernetes, TensorFlow, PyTorch, Scikitlearn, Advanced ML topics, Deep Learning, NLP, Large Language Models (LLMs), SAS, Tableau, Power BI, QlikView, Data Visualization, Hadoop, Hive, Spark, Pig, Flume, Sqoop, Oozie, Data Warehousing, Data Mining, Data Analytics, Business Intelligence, Artificial Intelligence, Natural Language Processing, Computer Vision, Robotics, Automation, Edge Computing, Internet of Things (IoT), Blockchain, Quantum Computing, Software Engineering, Full Stack Development, DevOps, Agile, Scrum, Kanban, Jira, Confluence, Trello, Asana, Git, GitHub, Docker, Jenkins, Nagios, Splunk, ELK Stack, Prometheus, Grafana, Kibana, Logstash",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Research Data Scientist",
      "company":"Ayata",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-research-data-scientist-at-ayata-3679696524",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Ayata\nis developing its Prescriptive Analytics\u00ac\u00c6 software by integrating the latest Artificial Intelligence (AI) and related technologies. We are looking for people with multi-disciplinary skills, especially in software design and artificial intelligence, who can write solid clean code and who are excited about applying those skills to build industrial strength software. You will be part of a multi-disciplinary team working to design, develop and implement our unique software. Your contributions will directly impact the success of the company.\nJob Responsibilities And Duties\nAyata\nis looking for\nSenior Research Data Scientist\nwho will develop AI techniques for business applications in various industries and build cloud-based AI software for predictive analytics business solutions.\nResponsibilities\nAI technique development, providing methodology, strategy, ideas, architect, and solutions for real-word, industrial-scale and mission-critical business operations\nBuild and integrate AI technique components into a full-functioning AI business software\nInteract with business clients, understand business requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients\nUnderstand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering\nDocument data dictionary, data understanding, modeling strategy and approaches, and build company\u201a\u00c4\u00f4s knowledge base of data and models\nCommunicate effectively with team members, management, and clients\nRequirements\nPh.D. degree in computer science, or mathematics\/statistics\/physics or engineering\n1-5 years of experience in machine learning\/AI technology and software development\nNatural Language Processing (NLP) and Digital Image Processing experience\nExcellent hands-on code development skills in Python\nProven ability as a quick learner\nAdditional Qualifications\nExpertise in ETL is a plus (Spark, Hadoop, SQL) in big data environments is a plus!\nNatural Language Processing (NLP) Information retrieval and information extraction is a plus!\nDigital Image Processing experience including OpenCV, OCR experience to convert images to text experience would be great!\nFront-end software development experience is a plus\nThis position is remote at this time. When we are over the Covid concerns, Ayata may move to a flexible schedule where working out of an office could be requested at times.\nYou must have a PHD to be considered for this position.\nBenefits\nCompensation package (base salary + performance bonus + stock options) commensurate with experience.\nIndustry (tech\/software industry) standard benefits package - medical, dental, vision, 401(k) plan, work-from-home (if applicable), flexible holidays, and more.\nShow more\nShow less",
      "job_skills":"Artificial Intelligence (AI), Software Design, Machine Learning, Python, Cloud Computing, Predictive Analytics, Natural Language Processing (NLP), Digital Image Processing, Data Preprocessing, Model Training, Model Feature Engineering, Data Mining, Big Data, Data Modeling, Hadoop, SQL, Frontend Development, OpenCV, OCR",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Scientist",
      "company":"ClearBridge Technology Group",
      "job_location":"Frisco, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-scientist-at-clearbridge-technology-group-3786902891",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Our client, a large manufacturing company with offices in Frisco, TX, is in need of a Sr. Data Scientist to work onsite for a 12-month contract engagement. The Data Scientist will be working within our client\u201a\u00c4\u00f4s Data Science team which is focused on developing a home grown budgeting application for the company\u201a\u00c4\u00f4s marketing groups.\nResponsibilities\nOversee data science projects through the project lifecycle, from data-gathering through to implementation\nDesign and develop robust econometric and\/or mathematical optimization models\nActively assists in the operationalization and deployment of prototype models\nResearches and analyzes data to find deep relations within data to be used in the ML\/AI algorithms\nDesign, develop and program methods, processes, and systems to consolidate and analyze unstructured, diverse \u201a\u00c4\u00fabig data\u201a\u00c4\u00f9 sources to generate actionable insights and solutions to generate business impact\nWork across multi-disciplinary teams to translate business needs into testable hypotheses and then design experiments to test said hypotheses\nCollaborate with other members of the team to support investigation across a variety of topics\nResearch, recommend, and apply appropriate statistical, econometric, mathematical, and computational modeling concepts across domains\nWork with Machine Learning Engineers to convert experimental code to production code\nUnit test production model code to ensure quality\nRecruit, train, guide, and coach junior and mid-level analytics team members\nEnsure data and code integrity by conducting documentation and code reviews\nImplement strategic analyses with the know-how to balance getting the details right, while still moving at the speed of business\nRequired Skills\nA quantitative MS\/PhD and minimum of 7 years of demonstrated success in Data Science\n7+ years of experience in deploying data science in a business environment and fact-based evidence\/anecdotes of implementation and impact from such deployments\nExpertise in Time Series modeling and the complexity of Time Series\nDeep expertise in Bayesian modeling and Bayesian inference\nAn understanding of uncertainty principles in modeling and leverage distributional predictions to represent uncertainty and risk\nThe ability to accurately scope modeling projects\nCollaboration skills and experience working with cross-functional teams and effectively communicate findings and recommendations to non-technical stakeholders\nExcellent oral and written communication skills\nExcellent Data Story telling skills\nA highly detail\u201a\u00c4\u00ecoriented and organized working style\u201a\u00c4\u00eeensuring model documentation excellence\nNice to have\nThe ability to quantify indirect effect of treatments utilizing Bayesian Networks or Halo Effects\nExperience incorporating expert qualitative business knowledge and A\/B test results to adjust and tune model results\nExperience with Bayesian Belief Networks\nFamiliarity and experience with conformal prediction, diffusion methods is a plus\nDemonstrated experience with applying integer and linear optimization methods to drive business goals\/KPI outcomes\nDemonstrated success in Data Science within the Marketing Domain\nExperience working in CPG, Media, or Retail on the client or agency side\nDomain knowledge on marketing and\/or Market Mix Models\nUp to date and passion for staying current with various modeling techniques and a demonstrated history of utilizing champion challenger principles to ensure model\n3+ years of demonstrated experience working directly or indirectly with Python in a full-stack Data Science product environment\nExperience working with engineers to convert experimental code into production ready code\nExperience working with Bit Bucket, Git, Google Cloud Platform\nShow more\nShow less",
      "job_skills":"Data Science, Econometric Modeling, Mathematical Optimization, Machine Learning, Artificial Intelligence, SQL, Python, Git, Bit Bucket, Google Cloud Platform, Bayesian Modeling, Bayesian Inference, Uncertainty Principles, Time Series Modeling, Integer Optimization, Linear Optimization, Bayesian Networks, Conformal Prediction, Diffusion Methods, Data Story Telling",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"DriveTime",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-drivetime-3730493438",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"What\u201a\u00c4\u00f4s Under The Hood\nDriveTime Family of Brands includes in-house financing and servicing through Bridgecrest, which is one of the country\u201a\u00c4\u00f4s leading financial servicing providers. Bridgecrest services roughly $17 billion in finance receivables for DriveTime and other third parties. We service auto loans across a wide credit spectrum with the intent of creating a strong path to vehicle ownership for our customers.\nThat\u201a\u00c4\u00f4s Nice, But What\u201a\u00c4\u00f4s the Job?\nThat\u201a\u00c4\u00f4s Nice, But What\u201a\u00c4\u00f4s the Job?\nIn short, as a Senior Data Scientist you will design, develop and implement analytical solutions to support multiple products, business units and verticals.\nIn long, the Senior Data Scientist is responsible for:\nWork with business partners to define objectives and build appropriate analytical solutions\nPartner with business customers to manage data for modeling and analytics\nPartner with Machine Learning Engineers in development and implementation of models\nPresent results of analysis to leaders and colleagues\nWork with Jr Data Scientist(s) to develop and implement analytical solutions\nSo What Kind of Folks Are We Looking for?\nExcellent verbal and written communication skills. The ability to talk and write with confidence, charisma and competence for a wide variety of audiences including management.\nOrganization and time management skills in spades. You\u201a\u00c4\u00f4ll be handling multiple projects and deadlines that will require you to prioritize then re-prioritize\u201a\u00c4\u00b6 then\u201a\u00c4\u00b6 re-prioritize again.\nIntellectual curiosity. Why? What? How? Do you find yourself always wanting to learn more and broaden your knowledge base? If so, this could be the role for you.\nAgile in a fast-paced environment. We move, and we move quickly. Thriving in an environment that never stops, is a must.\nRebel with a cause. You are always looking beyond the obvious for continuous improvement.\nThe Requirements.\nBachelor\u201a\u00c4\u00f4s Degree in Math, Statistics, Physics, Computer Science, or related discipline. Master\u201a\u00c4\u00f4s degree preferred.\n3+ Years of Experience Working in a Data Scientist or Statistician Role\nDemonstrated expertise in Python\nExpertise leveraging MLOps methodology in Azure, AWS or GCP. Cloud certifications is a plus\nExperience coaching Jr Data Scientists and leading complete data science projects end-to-end\nExpertise in RDBMS and Big Data environments such as Snowflake.\nDemonstrated experience in developing and deploying statistical learning\/machine learning techniques with significant business outcomes\nExpertise with git\/version control and build\/release pipelines.\n#Dice\nThis is not a position for which sponsorship will be provided. Individuals with temporary visas or who need sponsorship now or in the future are not eligible for hire at this time.\nSo What About the Perks? Perks matter\nMedical, dental, and vision, oh my! DriveTime Family of Brands covers a sizable amount of insurance premiums to ensure our employees receive top-tier healthcare coverage.\nBut Wait, There\u201a\u00c4\u00f4s More. 401(K), Company paid life insurance policy, short and long-term disability coverage to name a few.\nGrowth Opportunities. You grow, I grow, we all grow! But seriously, DriveTime Family of Brands is committed to providing its employees with every opportunity to grow professionally with roughly over 1,000 employees promoted year over year.\nTuition Reimbursement. We\u201a\u00c4\u00f4re as passionate about your professional development as you are. With that, we\u201a\u00c4\u00f4ll put our money where our mouth is.\nWellness Program. Health is wealth! This program includes self-guided coaching and journeys, cash incentives and discounts on your medical premiums through engaging in fun activities!\nGratitude is Green. We offer competitive pay across the organization, because, well\u201a\u00c4\u00b6 money matters!\nIn-House Gym. We want our employees to be the best versions of themselves. So come early, take a break in your day or finish strong with a workout!\nGive Us a Reason (or not), and We\u201a\u00c4\u00f4ll Celebrate. Regardless of whether there is a holiday or not, we are finding ways to kick back and enjoy each other\u201a\u00c4\u00f4s company outside of day-to-day work.\nSmart-Casual Dress. Come dressed in jeans (you\u201a\u00c4\u00f4ll fit right in with the rest of us).\nPaid Time Off & Paid Holidays. Not just lip service: we work hard, to play hard.\nAnything Else? Absolutely.\nDriveTime Family of Brands is Great Place to Work Certified! And get this: 90% of our rockstar employees say they feel right at home here. We could spend a lot of time having you read about ALL our awards, but we\u201a\u00c4\u00f4ll save time (and practice some humility) just naming a few others; Comparably Awards: Best Company for Diversity, Best Company Culture and Best Company Leadership, oh and don\u201a\u00c4\u00f4t forget Phoenix Business Journal Healthiest Employers (okay, we\u201a\u00c4\u00f4ll stop there)!\nHiring is contingent upon successful completion of our background and drug screening process. DriveTime is a drug-free, tobacco-free workplace and an Equal Opportunity Employer.\nAnd when it comes to hiring, we don't just look for the right person for the job, we seek out the right person for DriveTime. Buckle up for plenty of opportunities to grow in a professional, fun, and high-energy environment!\nShow more\nShow less",
      "job_skills":"Python, MLOps, Azure, AWS, GCP, RDBMS, Big Data, Snowflake, Statistical learning, Machine learning, Git, Version control, Build\/release pipelines, Math, Statistics, Physics, Computer Science, Data Science, Statistician, Business analytics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist (Optimization + AWS), USA",
      "company":"Tiger Analytics",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-optimization-%2B-aws-usa-at-tiger-analytics-3770948636",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Tiger Analytics is looking for experienced Data Scientists to join our fast-growing advanced analytics consulting firm. Our employees bring deep expertise in Data Science, Machine Learning, and AI. We are the trusted analytics partner for multiple Fortune 500 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best global analytics consulting team in the world.\nWe are looking for a Senior Data Scientist with robust Optimization experience (in particular, integer programming, mixed integer programming), AWS experience, and strong coding capabilities, within preferably from Ad-Tech\/Media-Tech domains. This person will be responsible for writing complex production-level codes.\nKey Responsibilities\nEffectively communicate the analytics approach and how it will meet and address objectives to business partners\nAdvocate and educate on the value of data-driven decision-making; focus on the \u201a\u00c4\u00fahow and why\u201a\u00c4\u00f9 of solutions\nLead analytic approaches; integrate solutions collaboratively into applications and tools with data engineers, business leads, analysts, and developers\nCreate repeatable, interpretable, dynamic, and scalable models seamlessly incorporated into analytic data products\nCollaborate, coach, and learn with a growing team of experienced Data Scientists\nStay connected with external sources of ideas through conferences and community engagements\nSupport demands from regulators, investor relations, etc., to develop innovative solutions to meet objectives utilizing cutting-edge techniques and tools.\nRequirements\nPh.D. (highly preferred) or Master\u201a\u00c4\u00f4s in Computer Science, Statistics, Economics, Data Science, or a related field\nAt least 10+ years of extensive Data Science experience with robust Optimization experience, AWS experience, and capabilities and robust hands-on Python + Scala coding is a must\nRobust Optimization experience including, Combinatorial Optimization, Integer programming, Mixed Integer programming, Greedy Heuristics, Commercial and Open Source Solvers, Time Series and Forecasting Techniques, Cardinality Algorithms, and Retrieval Augmented Generation is a must.\nStrong statistics foundation and knowledge of statistical packages. Highly proficient with Python., Python + Scala, and SQL coding skills. This person will be responsible for writing complex production-level codes\nHands-on experience building time-series \/ forecasting models is a must.\nAd-Tech \/ Media-Tech industry experience is highly preferred\nExceptional communication and collaboration skills to understand business partner needs and deliver solutions\nBenefits\nThis position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, AI, Optimization, Integer programming, Mixed integer programming, AWS, Coding, Python, Scala, SQL, Statistical packages, Time series, Forecasting, AdTech, MediaTech, Combinatorial Optimization, Greedy Heuristics, Commercial Solvers, Open Source Solvers, Cardinality Algorithms, Retrieval Augmented Generation",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist (ML & AI)-locals || Irving, TX",
      "company":"Steneral Consulting",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-ml-ai-locals-irving-tx-at-steneral-consulting-3693984012",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Github\nLinkedin\nWork Authorization and ID\nUpdated Resume\nRole: Data Scientist (ML & AI)\nLocation: Onsite 4\/5 days a week in Irving, TX\nDuration:\n3-6 month contract to hire\nQualifications\nTOP SKILLS:\nMaster's or Ph.D. degree in Computer Science, Data Science, Statistics, or a related field.\nProven experience (X+ years) working as a Data Scientist, with a focus on machine learning and AI projects.\nSolid understanding of machine learning algorithms, both supervised and unsupervised, as well as deep learning frameworks.\nProficiency in programming languages such as Python or R for data manipulation, modeling, and analysis.\nHands on with wide variety of use cases like ETL, Data Hubs, Data warehousing, Data lakes\nGood understanding of Enterprise grade Layered Data Architectures\nGood experience in solving business problems with conceptual and detail technical solution\nExperience with data visualization tools and libraries (e.g., Matplotlib, Seaborn, Plotly) to effectively communicate results.\nFamiliarity with big data tools and platforms (e.g., Hadoop, Spark) is a plus.\nStrong problem-solving skills and the ability to approach challenges with creativity and innovation.\nExcellent communication skills to collaborate effectively with cross-functional teams and explain complex concepts to various audiences.\nExperience with cloud platforms (e.g., AWS, Azure, GCP) and containerization technologies (e.g., Docker, Kubernetes) is a plus.\nPrior publications, open-source contributions, or participation in relevant competitions (e.g., Kaggle) is a strong advantage.\nResponsibilities\nUtilize advanced statistical and machine learning techniques to analyze large datasets and extract actionable insights.\nDesign, develop, and deploy machine learning models that enhance product functionality, improve user experience, and drive business outcomes.\nYou will be responsible for prototyping machine learning algorithms and computer vision systems that improve customer experience, enable innovative user experiences, and increase revenue\nCollaborate with domain experts, engineers, and stakeholders to define problem statements and formulate data-driven solutions.\nImplement end-to-end AI solutions, from data preprocessing and feature engineering to model selection, training, validation, and deployment.\nConduct thorough exploratory data analysis to identify trends, patterns, and anomalies in the data.\nStay up-to-date with the latest advancements in machine learning, AI, and related technologies, and proactively integrate them into projects where applicable.\nCommunicate complex technical concepts and findings to both technical and non-technical stakeholders through effective data visualization and presentations.\nParticipate in code reviews, contribute to the development of best practices, and mentor junior team members.\nShow more\nShow less",
      "job_skills":"Machine learning, AI, Data science, Python, R, Matplotlib, Seaborn, Plotly, Hadoop, Spark, AWS, Azure, GCP, Docker, Kubernetes",
      "Category":"Backend Development"
  },
  {
      "job_title":"Hybrid Work - Data Engineer\/Senior Data Engineering (GCP, Python, Hadoop)-locals in Irving TX",
      "company":"Steneral Consulting",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/hybrid-work-data-engineer-senior-data-engineering-gcp-python-hadoop-locals-in-irving-tx-at-steneral-consulting-3675562418",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job\n: Data Engineer\/Senior Data Engineering (GCP, Python, Hadoop)\nLocation:\nHybrid- Irving, TX\nTerm\n: to end of Year + long term requirement\nInterview Process:\none and done screen Face to face\/ ONSITE in Irving, TX office\nPosition Summary\nAnalyzes complex data structures from disparate data sources and design large scale data engineering pipeline\nDevelops large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs\nCollaborates with product business and data science team to collect user stories and translate into technical specifications\nUses knowledge in Cloud & Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines\nUses strong programming skills in PySpark, Python, Java or any of the major languages to build robust data pipelines and dynamic systems\nBuilds highly scalable and extensible data marts and data models to support Data Science and other internal customers on Cloud. Integrates data from a variety of sources, assuring that they adhere to data quality and accessibility standards.\nAnalyzes current information technology environments to identify and assess critical capabilities and recommend solutions\nExperiments with available tools and advice on new tools to determine optimal solution given the requirements dictated by the model\/use case\nRequired Qualifications\n3+ years of progressively complex related experience in cloud data engineering and data analysis\n2+ years GCP experience- must be working with GCP in current role\n5+ years of US Based work experience\nKnowledge in programing languages such as PySpark, Java, Python, Hive, SQL\nKnowledge in Cloud Technology, Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment\nStrong knowledge of large-scale search applications and building high volume data pipelines, preferably using Dataproc, composer services on GCP o\nPreferred Qualifications\nAbility to leverage multiple tools and programming languages to analyze and manipulate datasets from disparate data sources\nAbility to understand complex systems and solve challenging analytical problems\nExperience with bash shell scripts, UNIX utilities & UNIX Commands\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Analysis, Cloud Computing, Google Cloud Platform (GCP), Hadoop, HDFS, PySpark, Python, Java, Hive, SQL, Dataproc, Composer Services, Bash Shell Scripting, Unix Utilities, Unix Commands, Data Structures, Data Pipelines, Data Marts, Data Models, Data Science, Data Quality, Accessibility Standards, Information Technology Environments, Scalability, Extensibility, User Stories, Technical Specifications, Tools and Programming Languages, Datasets, Disparate Data Sources",
      "Category":"Backend Development"
  },
  {
      "job_title":"Job Opening for GCP Data Engineer-locals - Irving, TX",
      "company":"Steneral Consulting",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/job-opening-for-gcp-data-engineer-locals-irving-tx-at-steneral-consulting-3681051162",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Hi,\nPlease find attached Job Description. If you are interested please do share with me your updated resume or call me on \"3025492448\".\nTitle:- GCP Data Engineer-locals\nLocation:- Irving, TX\nDuration:- 6+ Months\nVisa:- Citizen, GC, GC-EAD, TN Visa, EAD-H4\nInterview Mode:- Video\nDescription\nSeeking candidate who\nis currently a GCP Data engineer. With 3+ years as GCP Data engineer and is fine to go onsite 3 days per week and for the interview\n. Candidate must be local to Dallas currently (NOT open to relocation candidates, as the interview will be ONSITE in Irving.)\nRole:\nGCP Data Engineer\nLocation:\nIrving, TX- Hybrid- 3x\/week onsite\nTerm\n: 6+ Months contract with extensions\nTop Skills\n3+ years in GCP\n7+ years in Data Engineering\nPython\nPyspark\nPosition Summary\nAnalyzes complex data structures from disparate data sources and design large scale data engineering pipeline\nDevelops large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs\nCollaborates with product business and data science team to collect user stories and translate into technical specifications\nUses knowledge in Cloud & Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines\nUses strong programming skills in PySpark, Python, Java or any of the major languages to build robust data pipelines and dynamic systems\nBuilds highly scalable and extensible data marts and data models to support Data Science and other internal customers on Cloud. Integrates data from a variety of sources, assuring that they adhere to data quality and accessibility standards.\nAnalyzes current information technology environments to identify and assess critical capabilities and recommend solutions\nExperiments with available tools and advice on new tools to determine optimal solution given the requirements dictated by the model\/use case\nRequirements\n3+ years of progressively complex related experience in cloud data engineering and data analysis\nKnowledge in programing languages such as PySpark, Java, Python, Hive, SQL\nKnowledge in Cloud Technology, Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment\nStrong knowledge of large-scale search applications and building high volume data pipelines, preferably using Dataproc, composer services on GCP\nPreferred Qualifications\nAbility to leverage multiple tools and programming languages to analyze and manipulate datasets from disparate data sources\nAbility to understand complex systems and solve challenging analytical problems\nExperience with bash shell scripts, UNIX utilities & UNIX Commands\nTeradata is a plus\nGCP Certification (current or pursing)\nGaurav Verma\nTalent Acquisition -North America\nDirect:+1 3025492448\ngaurav.verma@steneral.com\nIn my absence please reach out to Mr. Harish Sharma at harish@steneral.com &\n302-721-6151\nShow more\nShow less",
      "job_skills":"GCP, Data Engineering, Python, PySpark, Data Structures, Data Pipelines, Cloud Architecture, Hadoop Architecture, Java, SQL, Hive, HDFS, Dataproc, Composer Services, Bash Shell Scripts, UNIX Utilities, UNIX Commands, Teradata, GCP Certification",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Keurig Dr Pepper Inc.",
      "job_location":"Frisco, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-keurig-dr-pepper-inc-3784549721",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"At Keurig Dr. Pepper we are quickly growing and expanding our capabilities around data science, data engineering, and data operationalization to create a comparative advantage for our diverse business. The Marketing Science & Technology team is an in-business analytics and product team responsible for enabling next-generation Data-Driven Modeling. The Marketing Science & Technology team features team members with a variety of both specialized and general skills to realize this vision.\nAs a Senior Data Scientist in this role, you will work as the primary modeler for our in-house Marketing Attribution (MMM) and Optimization model. You will be responsible for ensuring input data fidelity, and producing results that are statistically sound. In addition to your primary function, you will work with Principal Data Scientists to research and implement econometric\/statistical and mathematical optimization solutions to strengthen and enhance the Attribution and Optimization model.\nYou will work with Data Engineers, Machine Learning Engineers, and Front-End Designers\/Developers to ensure quality of data and results and debug errors as necessary. The Senior Data Scientist is expected to be a strong team-player and take on a player-coach role within the team. You must possess the desire to: (1) train junior data scientists on modeling procedure; (2) coach junior data scientists on understanding, shaping, and validating data; (3) ensure requirements are met or communicate roadblocks; and (4) train junior data scientists to execute, tune, and validate the model.\nWhat you will do:\nIndependently execute the Attribution and Optimization model balancing accuracy\nCommunicate and translate results in the context of the business and quantify uncertainty\nHelp Decision Scientists, Business Analysts, and Data Science leadership recommend strategies and operational tactics under uncertainty\nDevelop compelling measurement plans and model\/forecast scoring methods to track predictions against actuals (while considering the cumulative and delayed effects of marketing efforts and uncertainty)\nDesign, develop and program methods, processes, and systems to consolidate and analyze unstructured, diverse \u201a\u00c4\u00fabig data\u201a\u00c4\u00f9 sources to generate actionable insights and solutions to generate business impact\nWork across multi-disciplinary teams to translate business needs into testable hypotheses and design experiments to test said hypotheses\nCollaborate with other members of the team to support investigation across a variety of topics\nResearch, recommend, and apply appropriate statistical, econometric, mathematical, and computational modeling concepts across domains\nWork with Machine Learning Engineers to convert experimental code to production code\nUnit test production model code to ensure quality\nTake an active role in recruiting, training, guiding, and mentoring junior team members\nEnsure data and code integrity by conducting documentation and code reviews\nImplement strategic analyses with the know-how to balance getting the details right, while still moving at the speed of business\nRequirements:\nA quantitative MS\/PhD and minimum of 3 years of demonstrated success in Data Science\n3+ years of experience in deploying data science in a business environment and fact-based evidence\/anecdotes of implementation and impact from such deployments\nExperience in Time Series modeling and the complexity of Time Series\nExpertise in Bayesian modeling and Bayesian inference\nAn understanding of uncertainty principles in modeling and leverage distributional predictions to represent uncertainty and risk\nThe ability to accurately scope modeling projects and estimate levels of effort in sprint planning\nCollaboration skills and experience working with cross-functional teams and effectively communicate findings and recommendations to non-technical stakeholders\nA team-player and a team-first mentality\nExcellent oral and written communication skills\nExcellent Data Story telling skills\nA highly detail\u201a\u00c4\u00ecoriented and organized working style\u201a\u00c4\u00eeensuring model documentation excellence\nStrong business, economic, and financial acumen\nYou will stand out if you have one or more of the following:\nThe ability to quantify indirect effect of treatments utilizing Bayesian\/Causal Networks or Halo Effects\nExperience incorporating expert qualitative business knowledge and A\/B test results to adjust and tune model results\nFamiliarity and experience with conformal prediction, and diffusion methods is a plus\nDemonstrated experience with applying integer and linear optimization methods to drive business goals\/KPI outcomes\nStrong working knowledge of causal inference techniques\nFamiliarity of advanced optimization methods\nDemonstrated success in Data Science within the Marketing Domain\nExperience working in CPG, Media, or Retail on the client or agency side\nDomain knowledge on marketing and\/or Market Mix Models\nUp to date and passion for staying current with various modeling techniques and a demonstrated history of utilizing champion challenger principles to ensure model\n2+ years of demonstrated experience working directly or indirectly with Python in a full-stack Data Science product environment\nExperience working with engineers to convert prototype code into production ready code\nExperience working with Bit Bucket, Git, Google Cloud Platform\nExperience working in an agile setting and the familiarity of agile principles\nKeurig Dr Pepper (NASDAQ: KDP) is a modern beverage company with a bold vision built to deliver growth and opportunity. We operate with a differentiated business model and world-class brand portfolio, powered by a talented and engaged team that is anchored in our values. We work with big, exciting beverage brands and the #1 single-serve coffee brewing system in North America at KDP, and we have fun doing it!\nTogether, we have built a leading beverage company in North America offering hot and cold beverages together at scale. Whatever your area of expertise, at KDP you can be a part of a team that\u201a\u00c4\u00f4s proud of its brands, partnerships, innovation, and growth. Will you join us?\nWe strive to be an employer of choice, providing a culture and opportunities that empower our team of ~28,000 employees to grow and develop. We offer robust benefits to support your health and wellness as well as your personal and financial well-being. We also provide employee programs designed to enhance your professional growth and development, while ensuring you feel valued, inspired and appreciated at work.\nKeurig Dr Pepper is an equal opportunity employer and affirmatively seeks diversity in its workforce. Keurig Dr Pepper recruits qualified applicants and advances in employment its employees without regard to race, color, religion, gender, sexual orientation, gender identity, gender expression, age, disability or association with a person with a disability, medical condition, genetic information, ethnic or national origin, marital status, veteran status, or any other status protected by law.\nShow more\nShow less",
      "job_skills":"Bayesian modeling, Causal inference techniques, Conformal prediction, Data science, Diffusion methods, Git, Google Cloud Platform, Hypothesis testing, Integer and linear optimization methods, Marketing Mix Models, Measurement plans, Python, Statistical modeling, Time Series modeling, Machine Learning, Model documentation, Business analysis, Data engineering, Experimentation, Frontend development",
      "Category":"Backend Development"
  },
  {
      "job_title":"Staff Data Scientist",
      "company":"Walmart",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/staff-data-scientist-at-walmart-3772209089",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"The Staff Data Scientist at Sam's Club AI Labs will spearhead the development of AI and machine learning solutions across our retail domains across operations, merchandising, finance, conversational AI, and e-commerce. Your key focus will be on crafting and deploying machine learning models that drive business value and enhance our member experience. The role will be responsible to manage the full life cycle of projects, build MLOps framework for continuous deployment of data science algorithms, and engage cross-functional teams in an agile environment. This role offers a unique opportunity to merge retail expertise with AI to drive transformative change in our business. The Staff Data Scientist at Sam's Club AI Labs will spearhead the development of AI and machine learning solutions across our retail domains across operations, merchandising, finance, conversational AI, and e-commerce. Your key focus will be on crafting and deploying machine learning models that drive business value and enhance our member experience. The role will be responsible to manage the full life cycle of projects, build MLOps framework for continuous deployment of data science algorithms, and engage cross-functional teams in an agile environment. This role offers a unique opportunity to merge retail expertise with AI to drive transformative change in our business. The Staff Data Scientist at Sam's Club AI Labs will spearhead the development of AI and machine learning solutions across our retail domains across operations, merchandising, finance, conversational AI, and e-commerce. Your key focus will be on crafting and deploying machine learning models that drive business value and enhance our member experience. The role will be responsible to manage the full life cycle of projects, build MLOps framework for continuous deployment of data science algorithms, and engage cross-functional teams in an agile environment. This role offers a unique opportunity to merge retail expertise with AI to drive transformative change in our business.\nAbout Team:\nSam's Club is our membership warehouse club, a business model that provides our members with high-quality products at prices that are unrivaled by traditional retail. Sam's Club provides a carefully curated assortment of items, as well as developing and leading technologies and services such as Scan & Go, Club Pickup, and home delivery service in select markets. Sam's Club also provides travel, auto purchasing, pharmacy, optical, hearing aid centers, tire and battery centers, and a portfolio of business operations support services.\nWhat you'll do:\nLead a team of data scientists and machine learning engineers, collaborating with cross-functional teams in product, business, and engineering to address cutting edge retail problems using AI.\nDrive the design and development of innovative ML models and optimization solutions, focusing on retail core domains such as operations, merchandising, finance, conversational AI, and e-commerce.\nManage end-to-end project execution, from planning and data collection to model prototyping and deployment, while effectively communicating with stakeholders and cross-functional partners.\nWork closely with the Product and Engineering teams to inform, drive, and accelerate innovations in discovery experiences through insights, frameworks, causal inference solutions, and machine learning prototypes.\nDevelop and implement a robust MLOps framework to create, build, and deploy data science algorithms, enabling continuous testing and experimentation.\nWhat you'll bring:\nPassion for problem-solving, come with Analytical mindset with critical-thinking, and data skills.\nExpertise in\nMachine Learning\nand\nData Science\nStrong technical skills in\nSQL, Python, R\n, or other programming languages commonly used in data analysis.\nExpertise in retail and merchandising domain such as pricing, assortment\nAwareness of software engineering principles, ability to develop and deploy appropriate analytic code suitable for production.\nWorking knowledge of\nCI\/CD\nand\nMLOps\nExperience working with large datasets, finding insights, and telling stories using data.\nGood knowledge in working with\ndistributed datastores\n(e.g., SQL, NoSQL), and\nBig Data\nand\nCloud technologies\nlike GCP BQ.\nExperience in leading and mentoring a team of data scientists.\nExperience in agile\nUnderstanding of advance ML topics viz. Deep learning (ENN, CNN, RNN, etc.), GAN, Transformers, NLP, LLM\u201a\u00c4\u00f4s is a plus.\nExcellent communication skills and ability to effectively communicate technical concepts to non-technical stakeholders.\nPrior experience working in the retail data sets is strongly preferred.\nAbout Walmart Global Tech\nImagine working in an environment where one line of code can make life easier for hundreds of millions of people. That\u201a\u00c4\u00f4s what we do at Walmart Global Tech. We\u201a\u00c4\u00f4re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world\u201a\u00c4\u00f4s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.\nFlexible, hybrid work:\nWe use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.\nBenefits:\nBenefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.\nEqual Opportunity Employer:\nWalmart, Inc. is an Equal Opportunity Employer \u201a\u00c4\u00ec By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions \u201a\u00c4\u00ec while being inclusive of all people.\nThe above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, ML Models, MLOps, SQL, Python, R Programming, Retail, Merchandising, CI\/CD, Big Data, Cloud Technologies, Distributed Datastores, Deep Learning, ENN, CNN, RNN, GAN, Transformers, NLP, LLM\u201a\u00c4\u00f4s",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Verizon",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-verizon-3776450307",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"When you join Verizon\nVerizon is one of the world's leading providers of technology and communications services, transforming the way we connect around the world. We're a human network that reaches across the globe and works behind the scenes. We anticipate, lead, and believe that listening is where learning begins. In crisis and in celebration, we come together-lifting up our communities and striving to make an impact to move the world forward. If you're fueled by purpose, and powered by persistence, explore a career with us. Here, you'll discover the rigor it takes to make a difference and the fulfillment that comes with living the #NetworkLife.\nWhat you'll be doing...\nWe use digital data as the fuel to propel us beyond our competition. As a Senior Data Scientist, you'll lead projects that develop and perform complex analyses using Big Data technologies. You'll be constantly on the lookout for new modeling techniques, evolving technologies, and emerging industry trends so that we can stay ahead of the game. Your work will help us meet our customers' needs and make it even easier for them to do business with us.\nPerforming analyses to find actionable insights.\nDeveloping new predictive models and improve existing ones to solve complex data related questions.\nDeveloping systems, applications, and visual dashboards.\nConducting and guiding others through system usage assessments.\nEnsuring data quality and promoting process improvement.\nHandling security threats, and growing the dependability and reliability of our network through tools and software.\nWhat we're looking for...\nWith an eye towards improving performance and predictability, you like the science of analytics. Developing resolutions to complex problems, using your sharp judgment to develop methods, techniques, and evaluation criteria allows you to deliver solutions that make a huge impact. You're able to communicate technical information to non-technical audiences, and you take pride in your ability to share your considerable knowledge with your peers.\nYou'll need to have:\nBachelor's degree or four or more years of work experience.\nSix or more years of relevant work experience.\nExperience developing predictive models.\nExperience in developing and implementing analytical solutions.\nExperience in Data management, analysis and visualization.\nExperience with any of SAS\/R\/Python and experience programming in SQL, VBA, SPSS, MATLAB, JAVA, Tableau or other related tools.\nEven better if you have one or more of the following\n:\nA Master's degree in a quantitative discipline such as Mathematics, Statistics, Financial Economics\/Econometrics, Engineering, Computer Science, or Operations Research.\nFive or more years of experience in developing and implementing analytical solutions to complex business problems\/opportunities.\nExperience managing a team.\nFive or more years of active experience in Data management, analysis and visualization to realize absolute and incremental commercial gains.\nExperience working in the Consumer\/Retail space within the Financial Services, Telecommunications, Technology or other related mass market industries or related work in the Public Policy, Bio-statistics and Scientific Research industries.\nA passion for educating and communicating analytic findings and insights with integrity to all levels: from going over raw output with colleagues to creating PowerPoint presentations and storyboards that captivate and succinctly convey complex ideas to our strategic business partners.\nAn appetite for improvement of our analytical products and processes built on a solid foundation of a lifelong love of learning.\nHigh level of curiosity and investigative mind-set with an attention to detail, a tenacity of thought, the flexibility to adapt to new challenges and the resiliency to overcome short-term hurdles by staying focused on the team's deliverables.\nIf Verizon and this role sound like a fit for you, we encourage you to apply even if you don't meet every \"even better\" qualification listed above.\nWhere you'll be working\nIn this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.\nScheduled Weekly Hours\n40\nEqual Employment Opportunity\nWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.\nOur benefits are designed to help you move forward in your career, and in areas of your life outside of Verizon. From health and wellness benefits, short term incentives, 401(k) Savings Plan, stock incentive programs, paid time off, parental leave, adoption assistance and tuition assistance, plus other incentives, we've got you covered with our award-winning total rewards package. For part-timers, your coverage will vary as you may be eligible for some of these benefits depending on your individual circumstances.\nIf you are hired into a California, Colorado, Connecticut, Nevada, New York, Rhode Island or Washington work location, the compensation range for this position is between $133,000.00 and $248,000.00 annually based on a full-time schedule. The salary will vary depending on your location and confirmed job-related skills and experience. This is an incentive based position with the potential to earn more. For part time roles, your compensation will be adjusted to reflect your hours.\nShow more\nShow less",
      "job_skills":"Big Data, Predictive modeling, SAS, R, Python, SQL, VBA, SPSS, MATLAB, JAVA, Tableau, Tableau, Statistical analysis, Machine learning, Data visualization, Data management, Data quality, Data security",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer-Marketing Solutions (Remote)",
      "company":"Vericast",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-marketing-solutions-remote-at-vericast-3785888378",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Company Description\nVericast is a premier marketing solutions company that accelerates profitable revenue growth for thousands of businesses businesses it serves directly by influencing consumer purchasing and transaction behavior at scale while engaging with over 120 million households daily. We are recognized as leading providers of incentives, advertising, marketing services, transaction solutions, customer data and cross-channel campaign management, and intelligent media delivery that create millions of customer touch points annually for their clients. For more information, visit http:\/\/www.vericast.com or follow Vericast on LinkedIn.\nJob Description\nVericast is seeking for a motivated Data Engineer to build big data pipelines, marketing campaign automations, and support existing analytics and reporting data requirements. This role will be responsible for expanding our data infrastructure and data pipeline architecture, as well as optimizing data flow and collection towards our Data Lake environment.\nThe Data Engineer will work closely with our analytics and reporting as well as data scientists on data initiatives and will ensure that optimal data delivery architecture is consistent and always available throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products.\nThis position is a perfect fit for someone who really likes to work in an agile team and to contribute their skills for building high quality data-driven marketing products, working collaboratively with other developers and business partners.\nKey Duties\/Responsibilities\nDevelop scalable data pipelines and builds out new integrations to support continuing increases in data volume and complexity.\nCollaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization.\nImplements processes and systems to monitor data quality, ensure availability and accuracy of production data for key stakeholders and business processes that depend on it.\nPerforms data analysis required to troubleshoot data related issues and assist in the resolution of data issues.\nProvide post-deployment support and to quickly respond to and resolve unexpected service problems in production.\nWorks closely with all business units and engineering teams to develop strategy for long term data platform architecture.\nQualifications\nEDUCATION:\nBachelor of Technology in Computer Science\/Information Technology or any related field.\nOR\nMaster of Science in Computer Science\/Information Technology or any related field (preferred).\nExperience\n3+ years of experience in Data Engineering or ETL Development role.\nStrong experience with PySpark for building solid data pipelines.\nHands-on experience with relational databases and SQL queries.\nExperience with Agile Software Development methodologies.\nExperience with GitLab, CI\/CD process and ServiceNow etc.\nSolid programming skills in object-oriented\/functional scripting languages like Python, PySpark for building data pipelines with experience in testing, logging to ensure quality of code and data observability. (Required)\nExperience in distributed systems and parallel data processing using big data tools such as Spark, PySpark, Hadoop, Kafka, Hive. (Required)\nProficiency in querying with relational databases. (Required)\nStrong knowledge of Linux\/Unix-based computer systems.\nExperience in building Data Processing pipelines using ETL tools like Talend, SSIS etc. (Required)\nUnderstanding of Machine Learning models and algorithms interfacing with Data Science team. (preferred)\nProficiency in data visualization tools to showcase insights using Tableau, matplotlib etc. (preferred)\nNice to have AWS cloud experiences in Redshift, Lambda, Sage Maker, Glue etc.(preferred)\nExperience with building Rest API. (preferred)\nExcellent data analytical, conceptual, and problem-solving skills.\nExcellent communication skills to promote cross-team collaboration.\nAdditional Information\nSalary:\n$90,000 - $110,000\nThe ultimate compensation offered for the position will depend upon several factors such as skill level, cost of living, experience, and responsibilities.\nAll team members are responsible for demonstrating the company's Core Values at all times and for using Performance Excellence principles to continuously improve effectiveness, efficiency, products, and services. This includes, but is not limited to, participating on improvement teams, recommending, and implementing improvement ideas, and participating in training and other activities to keep up to date on processes, information, etc.\nAll team members are responsible for supporting and complying with safety and security policies to promote a healthy working environment.\nVericast offers a generous total rewards benefits package that includes medical, dental and vision coverage, 401K and flexible PTO. A wide variety of additional benefits like life insurance, employee assistance and pet insurance are also available, not to mention smart and friendly coworkers!\nAt Vericast, we don\u201a\u00c4\u00f4t just accept differences - we celebrate them, we support them, and we thrive on them for the benefit of our employees, our clients, and our community. As an Equal Opportunity employer, Vericast considers applicants for all positions without regard to race, color, creed, religion, national origin or ancestry, sex, sexual orientation, gender identity, age, disability, genetic information, veteran status, or any other classifications protected by law. Applicants who have disabilities may request that accommodations be made in order to complete the selection process by contacting our Talent Acquisition team at talentacquisition@vericast.com. EEO is the law. To review your rights under Equal Employment Opportunity please visit: www.dol.gov\/ofccp\/regs\/compliance\/posters\/pdf\/eeopost.pdf.\nShow more\nShow less",
      "job_skills":"Data Engineering, ETL Development, PySpark, Relational Databases, SQL, Agile Software Development, GitLab, CI\/CD, ServiceNow, Python, Objectoriented Programming, Functional Scripting, Spark, Hadoop, Kafka, Hive, Data Processing, ETL Tools, Talend, SSIS, Machine Learning, Data Science, Data Visualization, Tableau, Matplotlib, AWS Cloud, Redshift, Lambda, Sage Maker, Glue, Rest API, Communication Skills",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Conversion Developer, Senior Associate",
      "company":"PwC",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-conversion-developer-senior-associate-at-pwc-3749937532",
      "search_city":"Excelsior Springs",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nFunctional & Industry Technologies\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 80%\nA career within Functional and Industry Technologies services will provide you with the opportunity to build secure and new digital experiences for customers, employees, and suppliers. We focus on improving apps or developing new apps for traditional and mobile devices as well as conducting usability testing to find ways to improve our clients\u201a\u00c4\u00f4 user experience. Our team helps clients transform their business through enabling technologies across marketing, finance and operations in the functional areas such as Maximo and PowerPlant.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nBasic Qualifications\nMinimum Degree Required:\nBachelor Degree\nMinimum Years Of Experience\n4 years\nPreferred Qualifications\nDegree Preferred:\nMaster Degree\nCertification(s) Preferred\nAzure Data Engineer Associate\nDatabricks Certified Data Engineer Associate\nPreferred Fields Of Study\nComputer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology\nPreferred Knowledge\/Skills\nDemonstrates a thorough level of abilities with, and\/or a proven record of success as both an individual contributor and team member, identifying and addressing client needs:\nSupports in data analysis techniques to assess source data structures, identify mapping requirements, and define transformation rules for data conversion into Maximo;\nLeads Maximo's modules and functionalities related to Asset Management and Work Order Management and IBM Maximo, including its data structures, configuration settings, and integration capabilities;\nIdentifies relational databases, preferably experience in working with databases commonly used in Maximo, such as IBM DB2, Oracle, Microsoft SQL Server, along with familiarity with Maximo's Integration Framework (MIF) and its capabilities for data integration and conversion;\nSupports in designing and implementing data extraction, transformation, and loading processes for Maximo data conversion;\nShowcases understanding in SQL and database querying languages to extract and manipulate data from source systems along with understanding ETL tools and methodologies commonly used in Maximo data conversion;\nIdentifies technologies commonly used with Maximo, including web services (SOAP, RESTful APIs), XML, JSON, and other relevant data exchange formats;\nSupports in pipeline architecture and development using one of the tools such as Azure ADF, AWS Glue, SSIS, DataBricks (multiple preferred);\nUtilizes data cleansing techniques and methodologies to ensure the integrity and accuracy of converted data in Maximo;\nDevelopes data cleansing functional business rules as per Maximo Business Object (MBO) definitions for source to Maximo conversion requirements;and comprehensive testing plans and executing validation processes to verify the accuracy and integrity of converted data in Maximo;\nCustomizes Maximo options, such as Automation Scripts, Java Customizations, Database Configuration, or Application Designer, to support data conversion requirements;\nIdentifies integrations within Maximo with other enterprise systems, such as ERP systems, GIS systems, or asset management systems. Knowledge of integration patterns, data synchronization, and data exchange protocols; and,\nShowcases work experience as a Data Engineer, Data Architect or similar role, along with experience in programming languages including Python, PySpark, Scala, SQL.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-advisoryseniorassociate\nShow more\nShow less",
      "job_skills":"Azure ADF, AWS Glue, SSIS, DataBricks, SQL, Python, PySpark, Scala, Maximo, PowerPlant, IBM Maximo, IBM DB2, Oracle, Microsoft SQL Server, Maximo's Integration Framework (MIF), Web services, SOAP, RESTful APIs, XML, JSON, Data cleansing, Java, Python, Debugging, Communication, Leadership",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Merkle",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-merkle-3778437384",
      "search_city":"Excelsior Springs",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Company Description\nDentsu\/Merkle is a modern marketing solutions company. Our mission is to help clients navigate, progress and thrive in a world of change. Businesses rely on our integrated network of agencies and specialized practices to champion meaningful progress through creative, media, commerce, data and technology. Part of Dentsu Group, our global network comprises 66,000 diverse people in 143 countries, who are dedicated to teaming for growth and good. Some of our award-winning agencies include 360i, Carat, dentsu mcgarrybowen, DEG, dentsuX, iProspect and Merkle. Follow us on Twitter @DentsuUSA and visit dentsu.com\/us.\nWe are champions for meaningful progress and we strive to be a force for good\u201a\u00c4\u00eefor our people, for our clients, for the industry and for our society. We keep our people at the center, creating space for growth, understanding and learning so they can thrive. We embed diversity, in our mindset, in our solutions and in our teams to empower an inclusive, equitable and culturally fluent environment. Building this culture within our teams makes us better collaborators with each other and with our clients, driving better outcomes for all.\nWhy Join Us?\nMerkle is the leader in data-driven performance marketing. We help brands achieve tremendous competitive advantage. We thrive because we employ the best in the business. Merkle's energy lives in everything we do, and it shows in the way we deliver to our clients. Additionally, we are recognized as top global partners by some of the world's leading technology firms including Adobe, Google, AWS, Salesforce, and more.\nJob Description\nAs a Sr. Data Engineer, you will be a core member of the data engineering team: developing new or enhancing existing data products as we build a meta data driven, big data solution, processing and transforming data to produce high quality data assets for our customers. You will work with passionate, goal-oriented Data Engineers to solve complex problems. You will collaborate with Operations and Delivery teams to provide market focused data solutions to our customers. You will participate in a growing, high performing data engineering team that embraces change, is continuously improving, and rapidly builds, tests, enhances, and scales data transformational solutions that drive incremental business value for our customers and partners.\nKey Responsibilities:\nCreate or assemble large, complex data sets that meet functional and non-functional business requirements\nDocument requirements from End Users to development user stories, capturing all the details and acceptance criteria required\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data builds, and implementing data QA and reporting\nCoordinate with cross-functional teams, such as Identity and Data Science teams, to develop new data products, making sure each team has the data required\nWork with data and analytic experts to strive for greater functionality of the data\nDevelop Proof of Concepts for new or updated data needs as required\nTriage data build or release issues as required\nSupport integration with internal solutions\nQualifications\nBachelor's degree in Mathematics, Statistics, Economics, Computer Science or other equivalent experience\n10+ year experience with data engineering, data modeling and\/or data processing\n5+ years' experience with SQL, relational databases, and data warehouses\nExperience with Python\nExperience with Snowflake\nExperience in cloud base technologies (AWS, GCP, Azure)\nExperience working in Agile teams and CI\/CD environments\nExperience with Linux and Windows is a plus\nExperience with Jenkins, Airflow, or other orchestration tools is a plus\nExperience with code repositories such as Git, Bitbucket, Github, etc.\nExperience in Tableau is a plus\nSkills:\nStrong analytic skills working with B2B, B2C, and Digital data assets for the purposes of customer experience marketing and analytics\nAble to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement\nAble to build processes supporting data transformation, data structures, metadata, dependency and workload management\nDemonstrated ability to manipulate, process and extract value from large disconnected datasets\nDemonstrated strong organizational, leadership, and communication skills\nDemonstrated ability to work with cross-functional teams in a dynamic environment\nFamiliarity with statistical concepts, modeling, and the ability to integrate data and analytics\nAble to manage ambiguity, asking questions to gain clarity and understanding\nAble to learn new emerging technologies quickly and apply innovative ideas to resolve problems\nAble to investigate and determine solutions to solve complex problems, offering options and recommendations to business stakeholders or leadership for decisions\nAble to analyze data, with a high attention to detail, and identify data patterns and anomalies\nAble to assess and manage big data and data that scales\nAble to focus on results and business outcomes, meeting business expectations\nAdditional Information\nThe anticipated salary range for this position is (\n$94,000k-$152,375k\n). Actual salary will be based on a variety of factors including relevant experience, knowledge, skills and other factors permitted by law. A range of medical, dental, vision, 401(k) matching, paid time off, and\/or other benefits also are available. For more information regarding dentsu benefits, please visit dentsubenefitsplus.com.\nAbout Dentsu\nDentsu is the network designed for what\u201a\u00c4\u00f4s next, helping clients predict and plan for disruptive future opportunities in the sustainable economy. Taking a people-centered approach to business transformation, dentsu combines Japanese innovation with a diverse, global perspective to drive client growth and to shape society www.dentsu.com.\nWe are champions for meaningful progress and we strive to be a force for good\u201a\u00c4\u00eefor our people, for our clients, for the industry and for our society. We keep our people at the center, creating space for growth, understanding and learning so they can thrive. We embed diversity, in our mindset, in our solutions and in our teams to empower an inclusive, equitable and culturally fluent environment. Building this culture within our teams makes us better collaborators with each other and with our clients, driving better outcomes for all.\nDentsu (the \"Company\") is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant or employee of the Company, on the basis of age, sex, sexual orientation, race, color, creed, religion, ethnicity, national origin, alienage or citizenship, disability, marital status, veteran or military status, genetic information, or any other legally-recognized protected basis under federal, state or local laws, regulations or ordinances. Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and\/or certain state or local laws. A reasonable accommodation is a change in the way things are normally done that will ensure an equal employment opportunity without imposing an undue hardship on the Company. Please contact your recruiter if you need assistance completing any forms or to otherwise participate in the application process or to request or discuss an accommodation in connection with a job at the Company to which you are applying.\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Modeling, Data Processing, SQL, Relational Databases, Data Warehouses, Python, Snowflake, AWS, GCP, Azure, Agile, CI\/CD, Linux, Windows, Jenkins, Airflow, Git, Bitbucket, Github, Tableau, Customer Experience Marketing, Analytics, Root Cause Analysis, Data Transformation, Data Structures, Metadata, Dependency Management, Workload Management, Data Manipulation, Data Processing, Data Extraction, Organizational Skills, Leadership Skills, Communication Skills, CrossFunctional Teams, Statistical Concepts, Modeling, Data Integration, Ambiguity Management, Problem Solving, Data Analysis, Attention to Detail, Data Patterns, Data Anomalies, Big Data Management, Business Outcomes, Business Expectations",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Conversion Developer, Senior Associate",
      "company":"PwC",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-conversion-developer-senior-associate-at-pwc-3749936650",
      "search_city":"Excelsior Springs",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nFunctional & Industry Technologies\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 80%\nA career within Functional and Industry Technologies services will provide you with the opportunity to build secure and new digital experiences for customers, employees, and suppliers. We focus on improving apps or developing new apps for traditional and mobile devices as well as conducting usability testing to find ways to improve our clients\u201a\u00c4\u00f4 user experience. Our team helps clients transform their business through enabling technologies across marketing, finance and operations in the functional areas such as Maximo and PowerPlant.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nBasic Qualifications\nMinimum Degree Required:\nBachelor Degree\nMinimum Years Of Experience\n4 years\nPreferred Qualifications\nDegree Preferred:\nMaster Degree\nCertification(s) Preferred\nAzure Data Engineer Associate\nDatabricks Certified Data Engineer Associate\nPreferred Fields Of Study\nComputer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology\nPreferred Knowledge\/Skills\nDemonstrates a thorough level of abilities with, and\/or a proven record of success as both an individual contributor and team member, identifying and addressing client needs:\nSupports in data analysis techniques to assess source data structures, identify mapping requirements, and define transformation rules for data conversion into Maximo;\nLeads Maximo's modules and functionalities related to Asset Management and Work Order Management and IBM Maximo, including its data structures, configuration settings, and integration capabilities;\nIdentifies relational databases, preferably experience in working with databases commonly used in Maximo, such as IBM DB2, Oracle, Microsoft SQL Server, along with familiarity with Maximo's Integration Framework (MIF) and its capabilities for data integration and conversion;\nSupports in designing and implementing data extraction, transformation, and loading processes for Maximo data conversion;\nShowcases understanding in SQL and database querying languages to extract and manipulate data from source systems along with understanding ETL tools and methodologies commonly used in Maximo data conversion;\nIdentifies technologies commonly used with Maximo, including web services (SOAP, RESTful APIs), XML, JSON, and other relevant data exchange formats;\nSupports in pipeline architecture and development using one of the tools such as Azure ADF, AWS Glue, SSIS, DataBricks (multiple preferred);\nUtilizes data cleansing techniques and methodologies to ensure the integrity and accuracy of converted data in Maximo;\nDevelopes data cleansing functional business rules as per Maximo Business Object (MBO) definitions for source to Maximo conversion requirements;and comprehensive testing plans and executing validation processes to verify the accuracy and integrity of converted data in Maximo;\nCustomizes Maximo options, such as Automation Scripts, Java Customizations, Database Configuration, or Application Designer, to support data conversion requirements;\nIdentifies integrations within Maximo with other enterprise systems, such as ERP systems, GIS systems, or asset management systems. Knowledge of integration patterns, data synchronization, and data exchange protocols; and,\nShowcases work experience as a Data Engineer, Data Architect or similar role, along with experience in programming languages including Python, PySpark, Scala, SQL.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-advisoryseniorassociate\nShow more\nShow less",
      "job_skills":"Maximo, PowerPlant, Azure Data Engineer Associate, Databricks Certified Data Engineer Associate, Computer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology, Data analysis, Data conversion, Asset Management, Work Order Management, IBM Maximo, Data structures, Configuration settings, Integration capabilities, Relational databases, IBM DB2, Oracle, Microsoft SQL Server, Maximo's Integration Framework (MIF), Data extraction, Data transformation, Data loading, SQL, Database querying languages, ETL tools, Methodologies, Technologies, Web services (SOAP RESTful APIs), XML, JSON, Data exchange formats, Pipeline architecture, Development, Azure ADF, AWS Glue, SSIS, DataBricks, Data cleansing techniques, Methodologies, Maximo Business Object (MBO), Comprehensive testing plans, Validation processes, Maximo options, Automation Scripts, Java Customizations, Database Configuration, Application Designer, Data conversion requirements, Integrations, Maximo, Enterprise systems, ERP systems, GIS systems, Asset management systems, Integration patterns, Data synchronization, Data exchange protocols, Programming languages, Python, PySpark, Scala",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Conversion Developer, Senior Associate",
      "company":"PwC",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-conversion-developer-senior-associate-at-pwc-3749935677",
      "search_city":"Excelsior Springs",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nFunctional & Industry Technologies\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 80%\nA career within Functional and Industry Technologies services will provide you with the opportunity to build secure and new digital experiences for customers, employees, and suppliers. We focus on improving apps or developing new apps for traditional and mobile devices as well as conducting usability testing to find ways to improve our clients\u201a\u00c4\u00f4 user experience. Our team helps clients transform their business through enabling technologies across marketing, finance and operations in the functional areas such as Maximo and PowerPlant.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nBasic Qualifications\nMinimum Degree Required:\nBachelor Degree\nMinimum Years Of Experience\n4 years\nPreferred Qualifications\nDegree Preferred:\nMaster Degree\nCertification(s) Preferred\nAzure Data Engineer Associate\nDatabricks Certified Data Engineer Associate\nPreferred Fields Of Study\nComputer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology\nPreferred Knowledge\/Skills\nDemonstrates a thorough level of abilities with, and\/or a proven record of success as both an individual contributor and team member, identifying and addressing client needs:\nSupports in data analysis techniques to assess source data structures, identify mapping requirements, and define transformation rules for data conversion into Maximo;\nLeads Maximo's modules and functionalities related to Asset Management and Work Order Management and IBM Maximo, including its data structures, configuration settings, and integration capabilities;\nIdentifies relational databases, preferably experience in working with databases commonly used in Maximo, such as IBM DB2, Oracle, Microsoft SQL Server, along with familiarity with Maximo's Integration Framework (MIF) and its capabilities for data integration and conversion;\nSupports in designing and implementing data extraction, transformation, and loading processes for Maximo data conversion;\nShowcases understanding in SQL and database querying languages to extract and manipulate data from source systems along with understanding ETL tools and methodologies commonly used in Maximo data conversion;\nIdentifies technologies commonly used with Maximo, including web services (SOAP, RESTful APIs), XML, JSON, and other relevant data exchange formats;\nSupports in pipeline architecture and development using one of the tools such as Azure ADF, AWS Glue, SSIS, DataBricks (multiple preferred);\nUtilizes data cleansing techniques and methodologies to ensure the integrity and accuracy of converted data in Maximo;\nDevelopes data cleansing functional business rules as per Maximo Business Object (MBO) definitions for source to Maximo conversion requirements;and comprehensive testing plans and executing validation processes to verify the accuracy and integrity of converted data in Maximo;\nCustomizes Maximo options, such as Automation Scripts, Java Customizations, Database Configuration, or Application Designer, to support data conversion requirements;\nIdentifies integrations within Maximo with other enterprise systems, such as ERP systems, GIS systems, or asset management systems. Knowledge of integration patterns, data synchronization, and data exchange protocols; and,\nShowcases work experience as a Data Engineer, Data Architect or similar role, along with experience in programming languages including Python, PySpark, Scala, SQL.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-advisoryseniorassociate\nShow more\nShow less",
      "job_skills":"PwC Professional, Azure Data Engineer Associate, Databricks Certified Data Engineer Associate, Computer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology, Data analysis, Data conversion, Maximo, IBM Maximo, Data structures, Configuration settings, Integration, Relational databases, IBM DB2, Oracle, Microsoft SQL Server, Maximo's Integration Framework (MIF), Data extraction, Transformation, Loading, ETL, Azure ADF, AWS Glue, SSIS, DataBricks, Data cleansing, Data integrity, Data accuracy, Maximo Business Object (MBO), Testing, Validation, Data synchronization, Data exchange, Integration patterns, Data Engineer, Data Architect, Programming languages, Python, PySpark, Scala",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist-Deep Learning-Bioinformatics",
      "company":"neteffects",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-deep-learning-bioinformatics-at-neteffects-3775479912",
      "search_city":"Collinsville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Our direct client in St. Louis MO is looking for a DataScientist with Deep Learning & Bioinformatics\/ Biomolecular focus.\nContract\nHybrid \/ Remote for exceptional candidates\nNo c2c\nBasic requirements:\nThe candidate will join a cross divisional, global team to generate innovative machine learning solutions to better understand biomolecules.\nThe successful candidate will be responsible for\nimplementing machine learning models and work collaboratively with data scientists and research scientists leveraging available datasets and influencing new dataset generation.\nMust Haves:\n\u00ac\u2211\nPhD degree (or M.Sc. with 4 years of working experience) in computer sciences, computational chemistry, computational biology, physics\nor related fields.\n\u00ac\u2211 Profound experience with state-of-the-art\nadvanced mathematical models, machine learning methods and model selection concepts; previous experience with deep learning\nwould be of advantage.\n\u00ac\u2211 Real interest in\nbiology and the life sciences with knowledge of proteins\n. Proficient in applying deep learning algorithms to solve biomolecular problems.\n\u00ac\u2211 E\nxcellent programmin\ng and software engineering skills in\nPython are essential.\n\u00ac\u2211 Expertise in Python libraries like\nBiopython and NumPy\nwould be beneficial.\n\u00ac\u2211 The ability to write clean, efficient, and well-documented Python code is crucial.\n\u00ac\u2211 Proficiency in writing code and experience in cloud computing.\n\u00ac\u2211 Highly creative, independent, fast-learning person with outstanding problem-solving ability and the willingness to undertake challenging analysis tasks autonomously and in a timely fashion.\n\u00ac\u2211 Strong interpersonal skills, excellent written and verbal communication, and the ability to work effectively both independently and in cross-functional teams.\n\u00ac\u2211 Willingness to travel between research sites domestically and globally.\n\u00ac\u2211 Fluency in English, both written and spoken.\nAll qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\nShow more\nShow less",
      "job_skills":"Machine Learning, Biostatistics, Bioinformatics, Biomolecular, Deep Learning, Python, BioPython, NumPy, Cloud Computing",
      "Category":"Backend Development"
  },
  {
      "job_title":"Cloud Data Engineer",
      "company":"Kelly",
      "job_location":"Bridgeton, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/cloud-data-engineer-at-kelly-3778866801",
      "search_city":"Collinsville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Kelly Technology is seeking a Cloud Data Engineer to work with our premier client in the St. Louis. MO area.\nCloud Data Engineer\nBridgeton, Missouri\nFull Time\/Direct Hire\nsorry no C2C or relocation.\nOur premier client is the global industry leader in wheel alignment, wheel balancing, and vehicle inspection systems, as a Cloud Data Engineer based at our headquarters in St. Louis, Missouri. We are seeking a candidate with a passion for creating robust and scalable cloud data architectures.\nQualifications:\n\u00ac\u2211 Strong knowledge of SQL and data modeling techniques.\n\u00ac\u2211 Proven experience with cloud data services such as Azure SQL Databases\/Amazon RDS, Azure Data Factory\/AWS Glue, Azure or AWS Data Lake, or Google Cloud equivalents.\n\u00ac\u2211 Familiarity with Airflow and Python.\n\u00ac\u2211 Proficiency in Linux systems.\n\u00ac\u2211 Excellent problem-solving skills and attention to detail.\n\u00ac\u2211 Good communication skills and the ability to work collaboratively.\nResponsibilities:\nAs a Cloud Data Engineer, you will:\n\u00ac\u2211 Design, develop, and maintain reliable, scalable data infrastructure solutions using cloud services.\n\u00ac\u2211 Monitor, troubleshoot, and resolve issues within data operations infrastructure.\n\u00ac\u2211 Collaborate with the data engineering team, data scientists, and application developers to build maintainable solutions that meet business requirements.\n\u00ac\u2211 Ensure data privacy and compliance standards are met.\n\u00ac\u2211 Stay updated on the latest Microsoft data technologies and best practices.\n\u00ac\u2211 Drive technology direction by making recommendations based on experience and research.\n\u00ac\u2211 Create test plans and validation controls.\nAdditional Qualifications:\n\u00ac\u2211 Bachelor\u201a\u00c4\u00f4s degree in a computer-related field strongly preferred; equivalent combination of education and experience considered.\n\u00ac\u2211 5+ years of relevant experience required.\n\u00ac\u2211 Relevant Cloud or Data Engineering certifications.\n\u00ac\u2211 Experience with Software Development Life Cycle and DevOps.\n\u00ac\u2211 Familiarity with monitoring tools like Datadog.\n\u00ac\u2211 Experience with data and computing tools, including Airflow, dbt, and messaging queues like Kafka.\n\u00ac\u2211 Experience working on real-time data and streaming applications.\n#TJP2023-SPEC\nShow more\nShow less",
      "job_skills":"SQL, Data Modeling, Cloud Data Services, Azure SQL Databases, Amazon RDS, Azure Data Factory, AWS Glue, Azure Data Lake, Google Cloud, Airflow, Python, Linux, Data Infrastructure Solutions, Data Operations Infrastructure, Data Engineering, Data Science, Application Development, Data Privacy, Data Compliance, Microsoft Data Technologies, Software Development Life Cycle, DevOps, Datadog, Airflow, DBT, Kafka, RealTime Data, Streaming Applications",
      "Category":"Backend Development"
  },
  {
      "job_title":"Cloud Data Engineer",
      "company":"Golden Technology Inc",
      "job_location":"Bridgeton, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/cloud-data-engineer-at-golden-technology-inc-3784413014",
      "search_city":"Collinsville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Hiring a Cloud Data Engineer!\nOur client is looking to hire an experienced Cloud Data Engineer to join their Team in Bridgeton, MO.\nThe Position:\nThe Cloud Data Engineer will have the following responsibilities:\nDesign, develop, and maintain reliable, scalable data infrastructure solutions using cloud services.\nMonitor, troubleshoot, and resolve issues within data operations infrastructure.\nCollaborate with data engineering team, data scientists, and application developers to build maintainable solutions that satisfy business requirements.\nEnsure data privacy and compliance standards are met.\nStay up to date with the latest Microsoft data technologies and best practices.\nHelp drive technology direction by making recommendations based on experience and research.\nCreate test plans and validation controls.\nTop skills you need to have:\nStrong knowledge of SQL and data modeling techniques.\nProven experience with cloud data services such as Azure SQL Databases\/ Amazon RDS, Azure Data Factory\/ AWS Glue, Azure or AWS Data Lake or Google cloud equivalents.\nKnowledge of Airflow and Python.\nFamiliarity with Linux systems.\n5+ years of relevant experience required.\nRelevant Cloud or Data Engineering certifications.\nExperience with Software Development Life Cycle and DevOps.\nExperience with Datadog or other monitoring tools.\nExperience with data and computing tools, including Airflow, dbt, and messaging Queues like Kafka.\nExperience working on real-time data and streaming applications.\nO\nur client cultivates an environment that appreciates and recognizes their employees and offers a wide variety of benefits including but not limited to Tuition Reimbursement, Parental Leave, Advancement Opportunities, Healthcare, Profit Sharing, and much more! If you have the above qualifications and have a passion for cloud data architecture, apply today!\nAbout Golden Technology\nGolden Technology was founded in 1997 with the goal of developing people and driving innovation. In other words, our aim is to pair world-class technologists like you with amazing companies that are doing impactful work.\nAfter an initially slow start, and way too many late nights playing Final Fantasy 7, Golden Technology built a unique recruiting engine that would quickly prove itself to deliver top-tiered talent to fortune 500 clients across the US, time and time again.\nGolden Technology has built a culture around family and helping the people we touch succeed in both their work and personal lives. Oh, everyone says that? Try us, you\u201a\u00c4\u00f4ll see it.\nWe\u201a\u00c4\u00f4re helping people find their calling and their dream jobs; and through our Golden Community initiatives we are actively working to improve the communities in which we work, live, and play.\nShow more\nShow less",
      "job_skills":"SQL, Data modeling, Cloud data services, Azure SQL Databases, Amazon RDS, Azure Data Factory, AWS Glue, Azure or AWS Data Lake, Google cloud, Airflow, Python, Linux, Software Development Life Cycle, DevOps, Datadog, Monitoring tools, Airflow, dbt, Kafka, Realtime data, Streaming applications",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineering and Data Science CoE - Commercial\/Functions",
      "company":"Bunge",
      "job_location":"Chesterfield, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineering-and-data-science-coe-commercial-functions-at-bunge-3690670548",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Location : Field - Work from home\nCity : Chesterfield\nState : Missouri (US-MO)\nCountry : United States (US)\nRequisition Number : 30590\nBunge has an exciting opportunity available for a Data Engineering and Data Science COE Lead. In this role you will be part of a global team working on challenging, meaningful projects impacting core business activities. Since 1818, Bunge has been connecting farmers to consumers to deliver essential food, feed, and fuel to the world. Looking to the future, our ambition is to continuously reinvent ourselves, leveraging data to be at the forefront of analytics, technology and talent to accomplish our purpose in a better, faster and simpler way. Bunge is committed to operating and thriving in the digital world \u201a\u00c4\u00ec creating world class agile teams where teammates are empowered and encouraged to collaborate and test and learn to succeed. At Bunge, people don\u201a\u00c4\u00f4t just come here to work, they come here to grow \u201a\u00c4\u00ec solving challenges that directly impact the world with a diverse team of thinkers and doers. Bunge offers a strong compensation and benefits package, generous paid time off program, flexible work arrangements, and opportunity to progress. Our hybrid work environment provides a balance of in office and remote work.\nMost importantly, in all we do we live our values:\nAct as One Team by fostering inclusion, collaboration, and respect\nDrive for Excellence by being agile, innovative and efficient\nDo What's Right by acting safely, ethically, and sustainably\nOverview:\nWe are looking for an experienced leader to join the Data & Analytics team in the Business Technology (BT) organization. The COE lead will be responsible for overseeing the development of data competency within BT. This leader is responsible for providing people leadership to COE members and developing their skillsets. They will partner with product squads to understand resource needs and how COE members can be allocated across teams accordingly.\nEssential Functions:\nEstablish and articulate a clear vision across the COE and lead COE members in efforts to support application teams and the business; build new analytics capabilities; and establish new data processes and tooling\nRegularly review resource allocation in the COE, work with digital leaders to ensure that COE members are being utilized effectively, and oversee the COE forecast and budget\nDefine professional standards\/work methodology within the COE\nLead day to day management, coaching, guidance, and support of the CoE team\nSet up interaction and knowledge sharing processes among COE members assigned to distinct product squads\nSet and continuously evolve the mission and vision for the COE, in line with industry and organization standards\nIdentify, hire, develop, inspire, and retain the best talent\nRequirements:\nAdvanced degree (MS or PhD) in Computer Science, Data Science, or a related field\n10+ years of experience leading a Center of Excellence (or equivalent org), responsible for building out best practices and capabilities in data science and\/or data engineering\nRecognized broadly as an expert in data science and\/or data engineering\nDemonstrated ability to manage, interview, hire, and assess data science and\/or data engineering talent\nDemonstrated expertise in the Industrial Ops and\/or Safety domain is preferred\nProven skills in coaching team members in the areas of performance, standards and work methods\nClear passion for driving innovation, high quality and outcome-based value delivery\nBunge (NYSE: BG) is a world leader in sourcing, processing and supplying oilseed and grain products and ingredients. Founded in 1818, Bunge\u201a\u00c4\u00f4s expansive network feeds and fuels a growing world, creating sustainable products and opportunities for more than 70,000 farmers and the consumers they serve across the globe. The company is headquartered in St. Louis, Missouri and has 25,000 employees worldwide who stand behind more than 350 port terminals, oilseed processing plants, grain facilities, and food and ingredient production and packaging facilities around the world.\nBunge is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, transgender status, national origin, citizenship, age, disability or military or veteran status, or any other legally protected status. Bunge is an Equal Opportunity Employer. Minorities\/Women\/Veterans\/Disabled\nShow more\nShow less",
      "job_skills":"Data engineering, Data science, Agile methodology, Product squads, SQL, Python, Industrial Ops, Safety, Data pipelines, Data warehouse, Machine learning, AWS, Azure, Hadoop, Spark, Kafka, Git, Jenkins",
      "Category":"Backend Development"
  },
  {
      "job_title":"Azure Data Engineer",
      "company":"TriCom Technical Services",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/azure-data-engineer-at-tricom-technical-services-3768735555",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Azure Data Analyst\/Engineer\nSummary\nOur client is seeking a technically well-versed individual to build and enhance PMI systems and applications. This individual must be comfortable communicating and working directly with clients to find optimal solutions.\nRequirements\nAt least 5 years of experience with ETL tools including Azure Data Factory, FME, or similar.\nExperience integrating multiple data sources using ETL technology or APIs.\nKnowledge of Python libraries including Pandas, NumPy, or C#.NET.\nAt least 5-years of experience with relational or NoSQL databases (SQL Server is highly preferred).\nKnowledge and experience implementing RESTful Web services.\nExperience working in an Agile\/Scrum environment.\nSkill and experience with the following technologies and processes:\nETL;\nPMIS, program\/project management tools, integration, and data management;\nAzure or AWS Cloud;\nCI\/CD and Docker.\nPreferred\nAt least 5-years of experience with SQL Server.\nThis is a 6-Month Contract opportunity with our Kansas City, MO client. Employee benefits include Medical\/Dental Benefits, Paid time off, Paid Holidays, and 401(k) (with immediately-vested company match) available with TriCom during the contract period. H1-B Visa sponsorship is not available for this position. No third-parties, please.\n#onsite\n#hybrid\nShow more\nShow less",
      "job_skills":"Azure Data Factory, FME, ETL, Python, Pandas, NumPy, C#.NET, SQL Server, RESTful Web services, Agile, Scrum, CI\/CD, Docker, AWS Cloud, PMIS, program\/project management tools, data management",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Oracle Database Engineer (Requires ACTIVE Secret Security Clearance)",
      "company":"Dice",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-oracle-database-engineer-requires-active-secret-security-clearance-at-dice-3783005090",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Dice is the leading career destination for tech experts at every stage of their careers. Our client, TEKsystems c\/o Allegis Group, is seeking the following. Apply via Dice today!\nDescription:\nTEKsystems is seeking an experienced Oracle Database Administrator for a long-term contract supporting a data center local to the Kansas City area. As a Senior Oracle Database Administrator you will be responsible for planning, engineering, operating, maintaining, and problem resolution of the Oracle Database Platform as a Service capabilities. You will also work with associated hybrid cloud datacenter infrastructure and teams: virtualization; backup\/storage; operating systems management; networking; and management, monitoring and automation tools. You will support system operations, hardening, migration capabilities, customer interaction and support, and patching. You will also be involved in planning and executing cloud migration and operations activities.\nThe program operates and provides cybersecurity services to support the client application hosting environment. The team also provides engineering and implementation services to deploy and operate the on-prem, hybrid-cloud and cloud datacenter environments. This is an opportunity to shape the way the client achieves its goals to provide enterprise application hosting while ensuring daily support and secure operations for a world-wide warfighter community.\nResponsibilities\nAs aSeniorOracle Database Administrator you will be responsible for planning, engineering, operating, maintaining, and problem resolution of the Oracle Database Platform as a Service capabilities\nYou will also work with associated hybrid cloud datacenter infrastructure and teams: virtualization; backup\/storage; operating systems management; networking; and management, monitoring and automation tools\nYou will support system operations, hardening, migration capabilities, customer interaction and support, and patching\nYou will also be involved in planning and executing cloud migration and operations activities\nAdminister Oracle Platform as a Service hosting environment (Oracle 19c on RHEL operating as virtualized databases)\nMonitor, triage, respond to events, incidents, tasks, changes including working ticket queues and executing approved Data Center projects and activities across the Oracle service area\nMonitor, execute and troubleshoot RMAN backup\/restore\nImplement and manage oracle networking with SSL\/TLS\nDevelop, update, and troubleshoot scripts used to manage the Oracle environment\nCurrent scripts include bash, python, and ansible\nProvides cluster and datacenter database administration, operational support, and problem resolution\nCollaborates with other datacenter engineers on incident, event, and problem resolution; expertise in Red Hat Enterprise Linux 7 and 8 desired; experience with VMWare virtualization and cloud platforms desired\nWorks with various vendors to install, upgrade, configure, administer, automate, and optimize Oracle virtualization architecture and associated software, providing a secure, reliable, and highly available data base platform to Data Center customers and services\nPerforms software installation and upgrade automation including scripting in bash and python as well as automation of data center efforts using VMWare tools (VMWare Ops Manager, vRealize Automation\/Orchestrator)\nDevelops and maintains a comprehensive system event, performance, and capacity monitoring plan\nTroubleshoots problems, takes appropriate corrective action and\/or interacts with IT staff or vendors in performing complex testing, support and troubleshooting functions\nCoordinates troubleshooting and collaborates with customers to resolve customer database operation incidents\nProvides 24x7x365 on-call support in rotation with Technical Lead nights\/weekends with after hours response required in support of some incidents\nSupports monthly and quarterly security\/application patching process\nQualifications:\nBS+ 8-10 MS + 5-7 years experience, will consider HS+12 years experience\nExperiencing implementing DISA STIGs and security controls\nExperience implementing\/configuring and troubleshooting RMAN backup\/restore\nExperience with Oracle networking with SSL\/TLS\nExperience with Data Guard implementations\nSeniorlevel experience in VMWare vRealize Operations Suite (Operations Manager), HP Blade System (or similar hardware platform), Log Management tool (SysLog\/Log Insight), NetBackup, Red Hat Enterprise Linux; 7.x\/8.x, DISA STIGs\/SRG\nIAT Level II Certification (DOD 8570\/8140), e.g. CompTIA Security+, CASP, CISSP, CISM, CIS,\nOracle Certification required: Oracle Database Certified Master\nActive DoD SECRET Security Clearance\nMust be legally eligible for employment in the US.\nSkills:\nDatabase administrator, Oracle database, Oracle\nTop Skills Details:\nDatabase administrator, Oracle database, Oracle\nExperience Level:\nExpert Level\n#CJ\nAbout TEKsystems:\nWe're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.\nThe company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law. Senior Oracle Database Engineer (Requires ACTIVE Secret Security Clearance)\nShow more\nShow less",
      "job_skills":"SQL, Oracle Database, Oracle Platform as a Service, Data Guard, RHEL, VMWare virtualization, VMWare Ops Manager, vRealize Automation\/Orchestrator, Bash, Python, Ansible, DISA STIGs, SRG, syslog, Red Hat Enterprise Linux, Oracle Certification, Oracle Database Certified Master, DoD SECRET Security Clearance",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst",
      "company":"Rezilient Health",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-rezilient-health-3781946727",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"We're not telehealth and we're not a traditional doctor's office: we're the best parts of both.\nOur mission at Rezilient is simple: to make access to primary care convenient, timely and seamless. Because we virtually beam our doctors into our CloudClinics, our members can choose their doctor based on their preferences, not their location, for a completely different primary care experience.\nOur doctors can be anywhere, while our CloudClinics are conveniently placed close to where people live, work and shop. Each CloudClinic is staffed by an experienced clinic specialist who becomes the doctor\u201a\u00c4\u00f4s hands. Our members can also interact with their Rezilient doctors through chat and video, providing a continuous relationship with their doctor no matter where they are.\nAbove all, our tech-forward approach streamlines the primary care experience so our doctors have the time to treat our members as a whole person, not just a collection of symptoms. And we\u201a\u00c4\u00f4re continuing to add specialty services and breakthrough technology to offer the most comprehensive, convenient care possible.\nWe are looking for a Data Analyst to come in to support our growing multi-disciplinary operations and set the foundation for intelligent service delivery and rapid scaling. The ideal candidate excels in the analysis and manipulation of large data sets with the ability to create meaningful insights from the data. This candidate should have a passion for doing high-quality work, continuously learning and improving, effectively analyzing healthcare data, consistently developing and improving data and analytics methodologies, and regularly exceeding customer and internal stakeholder expectations. You will work closely with the product, data engineering, clinical, finance, and go-to-market teams in a cross-functional work environment to identify and implement process improvements, develop and maintain timely and accurate reporting and analytics, and support business planning and forecasting.\nThe selected candidate will have ample opportunity to refine sophisticated analytical skills, hone project management skills, and grow their career, skill sets, and expertise within the healthcare industry. This position is located at our St. Louis HQ in the beautiful DeBaliviere neighborhood, steps from Forest Park.\nKey Responsibilities:\nWork closely with the CTO, CMO, and CoS on all new data and analytics initiatives. You\u201a\u00c4\u00f4ll have a seat at the table and the ability to learn on the fly\nCollaborate with cross-functional team to understand business needs and identify areas for process improvement\nDevelop and maintain reporting and analytics to track key performance indicators and provide insights across the business\nAssist with planning and forecasting by analyzing data and providing recommendations\nCollaborate with cross-functional teams to identify and implement solutions to improve efficiency and effectiveness through a data-driven approach\nContinuously learn, build, and improve across all things \u201a\u00c4\u00fadata\u201a\u00c4\u00f9 at Rezilient, including:\nData Engineering \u201a\u00c4\u00ec perform Extract, Transform, Load (ETL) processes to ensure accurate and timely movement of data from diverse sources into a centralized data repository, employing data cleansing and transformation techniques to maintain data quality and integrity\nData Analysis \u201a\u00c4\u00ec conduct comprehensive and innovative analysis from claims and clinical data to extract and interpret relevant data, while extracting unique insights or trends from insurance claims and clinical data, such as comorbidities and common healthcare services utilized, and investigate discrepancies between clinical concepts and how they manifest in the data sets\nGenerating Insights \u201a\u00c4\u00ec collaborate with the Product, Marketing, and Clinical teams to translate data insights into actionable strategies for engaging identified members through analysis of clinical data of engaged and enrolled members (e.g., identify correlations with prior healthcare utilization)\nClinical Operations Insight \u201a\u00c4\u00ec analyze the performance of treatment protocols, achievement of milestones, and variance at different levels; work with cross-functional teams to generate and validate hypotheses regarding clinical operations\nClient Reporting and Material Preparation \u201a\u00c4\u00ec prepare and maintain dashboards that translate data insights into internal and external facing materials; develop predictive models for future results and forecasts of early indicators into long-term value; prepare performance year retrospective summaries\nRequirements\nDegree in Data Science, Computer Science, Statistics, Biostatistics, or related field\n2-3 years in a similar role is preferred \u201a\u00c4\u00ec with experience working with healthcare data and taxonomies (e.g. claims, eligibility, etc.)\nDetail-oriented with a commitment to accuracy\nStrong analytical and problem-solving skills \u201a\u00c4\u00ec with an ability to translate complex data into understandable insights\nSelf-starter that is intellectually curious, able to work independently in a team environment, and excited to build from the ground-up without a predefined playbook\nProficiency in Excel, as well as SQL, Python, and other relevant programming languages\nFamiliarity with modern data stack technologies and cloud-based platforms (e.g., AWS, Snowflake, Dbt, ETL, etc.)\nProficiency in visualization preferably with PowerBI, Looker, etc\nFamiliarity with Github\/Notebook documentation\nExceptional communication and organizational skills\nBenefits\nUnlimited Vacation & PTO\nMedical, Dental, Vision and Life Insurance\nErgonomic Desk Setup\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Engineering, Data Manipulation, Data Mining, Data Visualization, Forecasting, Healthcare Data, Programming Languages (Python SQL), Data Cleansing, Data Transformation, Data Quality, Data Integrity, DataDriven Approach, Claims Data, Clinical Data, Statistical Analysis, Data Modeling, Predictive Analytics, Tableau, PowerBI, Looker, Github, Notebook Documentation, AWS, Snowflake, Dbt, ETL",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer (Onsite - St. Louis)",
      "company":"Barry-Wehmiller Design Group",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-onsite-st-louis-at-barry-wehmiller-design-group-3786849642",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Who You\u201a\u00c4\u00f4ll Work With\nYou will join one of our 45 offices in the US, be part of a committed team of over 1500 professionals, and work in teams and directly with our clients doing work that is shaping the world around us. You will be welcomed into a rapidly growing business and team and empowered to make an impact. You will be valued, cared for, and challenged on your path to becoming a world-class professional consultant and surrounded by leaders who are committed to creating an environment that enables you to realize your own success and fulfillment.\nWhen you join Design Group as a Data Engineer, you are joining a team that will challenge you and position you for growth. In this role, you will work with a team of industry experts to help the world\u201a\u00c4\u00f4s leading companies solve their most difficult problems. You will partner with seasoned leaders, technical specialists, and subject matter experts to deliver the highest quality solutions to our clients with consistency and accuracy.\nWhat You\u201a\u00c4\u00f4ll Do\nDesign, develop, and maintain cloud data infrastructure leveraging technologies like Azure SQL Database, Azure Data Lakes, and Azure Synapse Analytics to enable advanced analytics (AWS experience is acceptable)\nBuild scalable cloud data solutions and pipelines for big data sources and large datasets using services like Azure Synapse Spark Pools, Azure Data Pipelines, Azure Data Lakes, and Spark Notebooks.\nCreate optimized data models, efficient ETL\/ELT logic, transformations, and metadata to structure and relate data for business insights.\nAutomate and schedule regular data integrations from transactional systems, on-prem data warehouses, enterprise databases and SaaS applications into high performance cloud data platforms.\nImplement data quality checks, validation processes, error handling, partitioning, security, and resilience capabilities into data solutions based on requirements.\nSupport migration initiatives to move on-premises data and BI systems into cloud data lakehouses, data lakes and other cloud analytics services.\nWhat You\u201a\u00c4\u00f4ll Bring\n0-2 years\u201a\u00c4\u00f4 experience as a data engineer, ETL developer, or similar role (internships experience included).\nExperience with cloud data technologies (Azure preferred) such as Azure Synapse Analytics and Spark Pools.\nStrong expertise with SQL and Python. Exposure to DAX and M preferred.\nFamiliarity with PowerBI or Tableau is a plus.\nExperience utilizing structured and unstructured data.\nKnowledge of data modeling, warehousing principles, ETL\/ELT, and metadata standards.\nUnderstanding of CI\/CD pipelines and DevOps processes is a plus.\nAbility to relate data opportunities to business needs.\nStrong communication, collaboration, curiosity, and perseverance skills.\nAnalytical mindset with problem solving and troubleshooting skills.\nBachelor\u201a\u00c4\u00f4s degree in Computer Science, Analytics, Information Systems or similar field required.\nOur culture and commitment to our people is what sets us apart. We foster an environment of mutual respect, integrity, and unconditional interest in the individual and collective success of our professionals. Our model and entrepreneurial mindset offer a rewarding, challenging, and highly flexible path. As an Application Support Analyst, you will build a meaningful and fulfilling career with the support of professional development resources and mentorships including our First Year Experience program, Individual Development Plans, and Career Path resources and tools. You will be surrounded by exceptional talent who will support your development as both a world-class professional and a highly effective leader.\nShow more\nShow less",
      "job_skills":"Azure SQL Database, Azure Data Lakes, Azure Synapse Analytics, Azure Synapse Spark Pools, Azure Data Pipelines, Spark Notebooks, ETL\/ELT, CI\/CD pipelines, DevOps, PowerBI, Tableau, DAX, M, SQL, Python, Structured data, Unstructured data, Data modeling, Warehousing principles, Metadata standards, Cloud data technologies",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"TekWissen \u00ac\u00c6",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-tekwissen-%C2%AE-3782890075",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Overview:\nTekwissen Group, is a workforce management provider throughout the USA and many other countries in the world. This client is a German multinational Pharmaceutical and biotechnology company and one of the largest pharmaceutical companies in the world, headquartered in Leverkusen, and areas of business include pharmaceuticals; consumer healthcare products, agricultural chemicals, seeds and biotechnology products.\nJob Title: Senior Data Engineer\nLocation: St Louis, MO, 63146\nDuration: 12 Months\nJob Type: Contract\nWork Type: Remote\nJob Description:\nWhat you will do is why you should join us:\nBe a critical senior member of a data engineering team focused on creating distributed analysis capabilities around a large variety of datasets\nTake pride in software craftsmanship, apply a deep knowledge of algorithms and data structures to continuously improve and innovate\nWork with other top-level talent solving a wide range of complex and unique challenges that have real world impact\nExplore relevant technology stacks to find the best fit for each dataset\nPursue opportunities to present our work at relevant technical conferences\nProject your talent into relevant projects. Strength of ideas trumps position on an org chart\nIf you share our values, you should have:\nAt least 7 years' experience in software engineering\nAt least 2 years' experience with Go\nProven experience (2 years) building and maintaining data-intensive APIs using a RESTful approach\nExperience with stream processing using Apache Kafka\nA level of comfort with Unit Testing and Test Driven Development methodologies\nFamiliarity with creating and maintaining containerized application deployments with a platform like Docker\nA proven ability to build and maintain cloud-based infrastructure on a major cloud provider like AWS, Azure or Google Cloud Platform\nExperience data modelling for large scale databases, either relational or NoSQL\nBonus points for:\nExperience with protocol buffers and gRPC\nExperience with: Google Cloud Platform, Apache Beam and or Google Cloud Dataflow, Google Kubernetes Engine or Kubernetes\nExperience working with scientific datasets, or a background in the application of quantitative science to business problems\nBioinformatics experience, especially large-scale storage and data mining of variant data, variant annotation, and genotype to phenotype correlation\nTekWissen Group is an equal opportunity employer supporting workforce diversity.\nShow more\nShow less",
      "job_skills":"Apache Kafka, Google Kubernetes Engine, Apache Beam, Google Cloud Dataflow, Kubernetes, Java, Go, Protocol buffers, Unit Testing, Test Driven Development, Cloudbased infrastructure, Docker, MySQL, NoSQL, REST, AWS, Azure, Google Cloud Platform",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"ASK Consulting",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-ask-consulting-3774796501",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"\"All candidates must be directly contracted by ASK Consulting on their payroll and cannot be subcontracted. We are unable to provide sponsorship at this moment\".\nJob Title: Data Scientist\nLocation: St. Louis, MO \/ Morris plains, NJ\nDuration: Long Term Contract with possibilities of extension\nPay Range : $63-65\/hour\njob Description:\nAbout the Opportunity:\nAre you passionate about data and its potential to drive innovation in the healthcare industry? We're seeking a talented and innovative Data Scientist to join our team in St. Louis, MO. As a Data Scientist in Healthcare Analytics, you'll play a crucial role in developing cutting-edge Machine Learning models and using data to unlock valuable insights.\nJob Description:\nMachine Learning Expertise: Be at the forefront of predicting cost trends and customer behaviors by leveraging advanced analytical methods, including regression, decision trees, and support vector machines.\nData Mining Pro: Dive deep into data mining using machine learning and supervised learning algorithms to unearth valuable insights.\nAnalytics Wizard: Support advanced analytical efforts, which may involve clustering, segmentation, logistic, and multivariate regression to drive informed decision-making.\nData Visualization Guru: Visualize, interpret, and creatively communicate data findings using tools like Excel, ggplot, and Tableau to various audiences.\nSkills You Bring:\nProven experience in developing and deploying production ML models.\nExpertise in analytical methods, including regression, decision trees, and support vector machines.\nHands-on experience with Teradata and Cloud computing platforms like AWS and Databricks.\nProficiency in Python, R, Spark, and SQL for data analysis and modeling.\n2-4 years of relevant work experience, with a preference for healthcare expertise.\nEducation:\nA Bachelor's or Master's degree in Data Science, Computer Science, Statistics, Mathematics, or another quantitative discipline.\nWhy Join Us:\nBe part of a dynamic team at the forefront of healthcare analytics.\nWork on exciting and innovative projects that make a real impact.\nCollaborate with top talent and expand your skill set.\nThis is a contract position to begin with, offering an opportunity to prove your capabilities.\nNote:\nThis is a position that requires candidates to be on the company's payroll, and subcontracting is not permitted.\nIf you're ready to drive innovation in healthcare analytics and have the skills and passion for data, we want to hear from you. Apply today and be part of our mission to revolutionize healthcare through data insights!\nAbout ASK:\nASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With 5 nationwide offices, two global delivery centers, and employees in 42 states-ASK Consulting connects people with amazing opportunities\nASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.\nShow more\nShow less",
      "job_skills":"Machine Learning, Data Mining, Analytics, Data Visualization, Regression, Decision Trees, Support Vector Machines, Teradata, Cloud Computing, AWS, Databricks, Python, R, Spark, SQL, Healthcare Expertise, Data Science, Computer Science, Statistics, Mathematics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Editech Staffing",
      "job_location":"St. Louis City County, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-editech-staffing-3781447436",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Editech Staffing does not partner with external agencies, no C2C, no sponsorship\nIn compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.\n*Completion of I-9, verifying US Citizenship\nOnsite - Springfield, Virginia or St. Louis, Missouri\nTS\/SCI Required\nOur client is seeking a Data Scientist to join their team! This position supports the Geospatial Services & Solutions business area to provide high-quality, cost-effective solutions to the customer. As part of the GSS Team the Data Scientist's expertise is needed to support a sophisticated enterprise environment. The Scientist is an active participant in SAFe and Scrum development teams and meetings.\nJob Summary:\nIdentify data sources and automate collection processes.\nPerform preprocessing of structured and unstructured data\nAnalyze large, complex data sets to identify trends and patterns.\nBuild predictive models and machine learning algorithms.\nCombine models through ensemble modeling.\nPresent information using data visualization techniques.\nPropose solutions and strategies to address Key Intelligence Questions\nCollaborate with engineering and product development teams.\nRequired Skills:\n2+ years of experience as a Data Scientist, Data Engineer, ML Engineer, or Data Analysts and bachelor\u201a\u00c4\u00f4s degree in computer Programming, Science, Engineering or a related technical discipline, or the equivalent combination of education, technical training, or work\/military experience\n3+ years of experience in a Linux environment\nDirect experience and demonstrated proficiency with Python programming to build containerized microservices that use message queues such as activemq or rabbitmq.\nExperienced in ML Model performance testing and hyperparameter tuning (Tensorboard, wandb, mlflow)\nExperience training ML models with GPU acceleration in a containerized environment using common AI frameworks such as Tensorflow or Torch.\nExperience with workload managers (SLURM, Argo Workflow, Airflow)\nStrong problem solving and troubleshooting skills.\nStrong communication and interpersonal skills\nMust possess excellent time management skills and the drive to work unsupervised.\nActive TS\/SCI clearance required and eligibility to obtain a CI poly.\nDesired Skills:\nPrior experience working with or within the Intelligence Community or a military intelligence unit.\nUnderstanding of access management and security groups (i.e., IAM, S3 bucket, SSH, VPN, etc.)\nComputer vision related experience with torchvision or tensorflow object detection APIs.\nAdditional languages on top of Python preferred (C++, Julia, Go, R)\nFamiliarity with Cloud Platform AI-ML toolsets (e.g., AWS Sagemaker, GCP Vertex)\nExperience building data pipelines with spark, kafka, or nifi.\nShow more\nShow less",
      "job_skills":"Python, Linux, ActiveMQ, RabbitMQ, Tensorboard, Wandb, Mlflow, TensorFlow, Torch, SLURM, Argo Workflow, Airflow, IAM, S3, SSH, VPN, TorchVision, Tensorflow Object Detection APIs, C++, Julia, Go, R, AWS Sagemaker, GCP Vertex, Spark, Kafka, Nifi",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist, Senior",
      "company":"ECS",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-senior-at-ecs-3726078746",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"ECS is seeking a\nData Scientist, Senior\nto work in our\nSt. Louis, MO\noffice.\nJob Description:\nThe purpose of this requirement is to provide the customer with data management and automation support. Any data management solutions created by the contractor should take into consideration any modernization objectives including the modernized database applications as well as other enterprise activities (e.g., GEOINT Workbench Foundation).\nDevelop a modernized data management workflow for all customer's programs\nCoordinate utilization and sustainment of the new database management processes and workflows with database developers and analysts\nResearch and understand current data management workflows\nPlan new workflows ensuring automation is built in\nEnsure new workflows have ability to be integrated seamlessly with our modernized database applications and enterprise-level APIs\nAssist in other data management tasks related to modernization activities\nConverting MapInfo (MapBasic) scripts to Python\nImplementing enterprise database management processes\nAutomating repetitive data management tasks\nRequired Skills:\nMust have an existing active TS\/SCI security clearance\nA Bachelor's degree and 10yrs of relevant work experience\nProficiency with the following tools:\nPython\nArcGIS, ArcSDE, ArcPro\nQuantum GIS (QGIS)\nPostgreSQL, Postgis, PgAdmin\nApplication programming interfaces (APIs)\nUnderstanding and familiarity with the following tools\nMapInfo\nMapBasic\nDesired Skills:\nExperience with workflow management systems, such as Flowable\nECS is an equal opportunity employer and does not discriminate or allow discrimination on the basis of race, color, religion, gender, age, national origin, citizenship, disability, veteran status or any other classification protected by federal, state, or local law. ECS promotes affirmative action for minorities, women, disabled persons, and veterans.\nECS is a leading mid-sized provider of technology services to the United States Federal Government. We are focused on people, values and purpose. Every day, our 3800+ employees focus on providing their technical talent to support the Federal Agencies and Departments of the US Government to serve, protect and defend the American People.\nShow more\nShow less",
      "job_skills":"Data Management, Automation, Python, ArcGIS, ArcSDE, ArcPro, Quantum GIS (QGIS), PostgreSQL, Postgis, PgAdmin, Application programming interfaces (APIs), MapInfo, MapBasic, TS\/SCI security clearance, Workflow Management Systems, Flowable, Database Development, Database Analysis, Data Integration",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Workforce Connections",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-workforce-connections-3784263959",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Location: Onsite, St. Louis MO 63146\nJob Responsibilities\nPerform analysis using data science techniques on structured and unstructured data sets, and develop algorithms for targeted business needs. Design and develop data models to predict business outcomes or future impact of decisions. Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation, and model implementation.\nDesign and construct analysis tools that extract, and analyze data and store analytical results in an appropriate format for business needs. Conduct exploratory data analysis from complex data sources and build key data sets to support SMI's mission. Use deep learning, machine learning and analytical techniques to create scalable solutions for business problems.\nEvaluate and design experiments to monitor key metrics and identify improvement opportunities. Develop mathematical and statistical models to distinguish relevant content or events and recognize patterns. Participate in presentations and communicate results of analysis and findings. Collaborate with information technology or external vendors in the deployment of insights through company applications.\nCo-lead development, deployment and maintenance of SMI's evergreen Data Science training program. Evaluate and utilize appropriate BI\/data visualization tools available in the toolkit to streamline insights deployment.\nStay up-to-date to most current evolvement in the Analytics and Data Science arena, with focus on personal development applied towards on the job experiences.\nActively assist and collaborate with others in the department in the continuous learning and knowledge sharing process across the Analytics & Science continuum\nSupport SMI's data science governance maturity, by contributing to development of analytics governance, best practices, and methodologies.\nTrack general business activity and providing clear, compelling management reporting on a regular basis.\nRequired Knowledge, Skills, And Abilities\n4+ years of experience in modeling and statistical analysis of large data sets in data science roles, involving data extraction, analysis, statistical modeling, and communication. Leverage of G Suite with solid storytelling skills.\nKnowledge of SQL and RDBMS. Strong domain knowledge in query languages, programming languages and statistical computing. Prior experience leveraging cloud computing solutions and Alteryx preferred.\nStrong attention to detail. Strong project management skills\nPast and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format. Track record of diving into data to discover hidden patterns.\nPrevious experience working in the areas of inferential statistics, machine learning, and artificial intelligence preferred.\nGraduate degree in Statistics, Mathematics, Computer Science, Informatics, Econometrics, Engineering, Experimental Science, or equivalent experience\n4+ years of experience in data science capabilities including data mining, predictive modeling, machine learning, statistical modeling, large scale data acquisition, transformation, and structured and unstructured data analysis.\nExperience with database technologies, query language, as well as fluency in managing and analyzing large data sets of data with advanced tools, such as R and Python etc.\nAbility to handle large amounts of data, identify key information and provide insightful recommendations to all levels within the organization.\nRequirements\nRequired Education: Graduate level education\nYears of Experience: 3 to 5 years\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Deep Learning, Statistical Modeling, R, Python, SQL, Data Mining, Predictive Modeling, Business Intelligence, Data Visualization, Cloud Computing, Data Governance, Data Warehousing, Data Analytics, Data Analysis, Data Management, Data Processing, Data Extraction, Data Transformation, Data Integration, Big Data, Experimental Science",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Software Engineer (Python\/Data Pipelines)",
      "company":"Diversity Resource Staffing Inc.",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-software-engineer-python-data-pipelines-at-diversity-resource-staffing-inc-3548643839",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"As Senior Software Engineer specializing in Python, you will be responsible for designing, developing, maintaining, and operationalizing quantitative models and analytic environments supporting NISA\u201a\u00c4\u00f4s core line of business. You will work closely with business counterparts and our quantitative research groups to understand their needs, formulate requirements, design creative and extensible solutions for data distribution, analysis, and modeling for consumption by internal business groups.\nAs a senior member of the IT Solutions team, you will also participate in design and code reviews, will collaborate with other team members, and mentor junior teammate.\nRequired Qualifications\nBachelor's degree or equivalent experience in a field requiring strong analytical and quantitative skills, such as Computer Science, Engineering, Mathematics, Finance, or Information Systems\nSignificant experience developing using Python (expertise in other high-level languages considered)\nExtensive experience designing queries and data structures in SQL Server or another relational database platform\nExperience in data science and data analysis\nPreferred Qualifications\nExperience building solutions using public cloud platforms (AWS, Azure, GCP)\nExperience designing & implementing data pipelines to support quantitative research\nFamiliarity with MATLAB or R\nExperience with unit testing frameworks\nWorking knowledge of modern application frameworks\nPrevious professional experience in financial services sector is a plus\nShow more\nShow less",
      "job_skills":"Python, SQL Server, Data science, Data analysis, AWS, Azure, GCP, MATLAB, R, Unit testing frameworks, Modern application frameworks, Financial services",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist- Journeyman",
      "company":"ECS",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-journeyman-at-ecs-3784918694",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"ECS is seeking a\nData Scientist- Journeyman\nto work in our\nSt Louis, MO\noffice .\nJob Description:\nECS is seeking a Data Scientist- Journeyman to work in our St Louis, MO office. This offer is contingent upon acceptance by the government customer, validation of appropriate clearances and approval from a cognizant government contracting officer. Candidate will be submitted for Counterintelligence Polygraph after customer indoctrination. The primary role for these data analysts are to provide support to data management and automation activities as part of SFP\u201a\u00c4\u00f4s technical operations team. The scope of work aligns to SFP\u201a\u00c4\u00f4s efforts to modernize and advance requirements management and production feedback capabilities. The contractor shall support the office in modernizing the Community\u201a\u00c4\u00f4s requirements management process, to include automation, data management, statistical analysis, data visualization, training, and process documentation. The primary result of this effort will be the implementation of enhanced requirements management capabilities in order to support Community stakeholders and SF leadership.\nThe contractor shall:\nWork in a team environment and interact with production offices, analysts, and data owners as required.\nAdvise and consult SF stakeholders on data management best practices.\nAssist SF analysts and external partners on data management procedures and best practices.\nImplement enterprise database management processes.\nPerform data management tasks, to include data manipulation.\nPerform data analysis to assess integrity, identify patterns, and determine and correct shortfalls.\nDevelop and document data management workflows.\nTransfer data between multiple formats.\nAutomate processes through the use of Python scripting and model building.\nPerform statistical analysis of data to identify trends and patterns and to build reports for SF leadership and IC community (or NSG).\nProvide advanced data visualization to convey findings and communicate insights utilizing capabilities such as IC Portal and other dynamic viewers.\nIndependently identify, document, and address technical challenges.\nDeliver schema mapping and entity resolution across disparate geospatial data sources through data scientist applied expertise in the subject.\nUnderstand and communicate the interrelationships across many disparate datasets.\nDocument and visualize data both temporally and spatially to assist in data integrity checks, ask the next question, and display analytical assessments.\nDevelop and apply methods to identify, collect, process, and analyze large volumes of data to build and enhance GEOINT processes, and systems.\nProvide support to produce GEOINT web services publication to develop application-ready content, support GEOINT content metadata-tagging to enable content discovery; and publish GEOINT web services.\nImplement ESRI Story Maps in a classified environment.\nWork with ESRI Portal technology to develop and maintain map services.\nSupport and manage geodatabase versioning workflows.\nSupport, manage, and automate geodatabase synchronization workflows.\nRequired Skills:\nActive TS\/SCI CI-Poly Clearance.\nMinimum of a Bachelor\u201a\u00c4\u00f4s Degree or 4+ years of experience.\nDemonstrated advanced proficiency with the following programs:\nPython o ArcGIS, ArcSDE, ArcPro, ArcGIS Online.\nPostgreSQL, Postgis, PgAdmin.\nApplication programming interfaces (APIs).\nDemonstrated advanced proficiency of database principles and technology.\nDemonstrated advanced data transformation skills.\nDemonstrated advanced data processing and analytic skills.\nDemonstrated advanced experience with enterprise geodatabase management.\nDemonstrated advanced experience geodatabase versioning workflows.\nDemonstrated advanced experience with geodatabase synchronization and integration.\nDemonstrated advanced experience with Python (i.e. numpy, pandas, matplotlib libraries).\nDemonstrated advanced experience in SQL and NoSQL technologies.\nDemonstrated advanced experience text parsing.\nDemonstrated advanced experience in metadata tagging (data storage, processing, and & analyzing).\nDemonstrated advanced experience in work with a variety of geospatial data formats.\nDesired Skills:\nDemonstrated experience with JAVA programming language.\nDemonstrated experience with cloud-based database solutions.\nECS is an equal opportunity employer and does not discriminate or allow discrimination on the basis of race, color, religion, gender, age, national origin, citizenship, disability, veteran status or any other classification protected by federal, state, or local law. ECS promotes affirmative action for minorities, women, disabled persons, and veterans.\nECS is a leading mid-sized provider of technology services to the United States Federal Government. We are focused on people, values and purpose. Every day, our 3800+ employees focus on providing their technical talent to support the Federal Agencies and Departments of the US Government to serve, protect and defend the American People.\nShow more\nShow less",
      "job_skills":"Python, ArcGIS, ArcSDE, ArcPro, ArcGIS Online, PostgreSQL, Postgis, PgAdmin, Application programming interfaces (APIs), NoSQL, SQL, Matplotlib, NumPy, Pandas, JAVA, Cloudbased database solutions, Geospatial data formats, Data management, Data analysis, Data visualization, Data processing, Geodatabase management, Geodatabase versioning, Geodatabase synchronization, Metadata tagging, Text parsing",
      "Category":"Backend Development"
  },
  {
      "job_title":"Big Data Developer",
      "company":"NR Consulting",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-developer-at-nr-consulting-3768030057",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\n4+ Years of experience with Scala is must\n4+ Years of experience with Spark is must.\nExtensive hands on experience on SQL and PL\/SQL\n3 + Years of Experience with Big Data and NoSQL platforms and technologies, specifically hands-on experience with one or more major Hadoop distributions and various ecosystem components (e.g. MapReduce, MLLib, Impala, HBase, Spark etc.).\nShould have experience either in Cloudera or Hortonworks\nGood Knowledge on Unix Schell Scripting and Java\nShow more\nShow less",
      "job_skills":"Scala, Spark, SQL, PL\/SQL, Big Data, NoSQL, Hadoop, MapReduce, MLLib, Impala, HBase, Cloudera, Hortonworks, Unix, Shell Scripting, Java",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist MACS007 with Security Clearance",
      "company":"ClearanceJobs",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-macs007-with-security-clearance-at-clearancejobs-3753467813",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Senior Data Scientist: Candidates must possess the following:\n10 + Years experience with data exploration, data cleaning, data analysis, data visualization, or data mining\n10 + Years experience with statistical and general-purpose programming languages for data analysis\nExperience analyzing structured and unstructured data sources\nExperience developing predictive data models, quantitative analyses and visualization of targeted data sources\nKnowledge of Machine Learning, Artificial Intelligence, or Natural Language Processing\nKnowledge of text mining or machine learning techniques\nActive TS\/SCI clearance; willingness to take a polygraph exam\nBachelor's degree in DS or related can qualify as 4 years' experience, Masters can qualify as 2 years' experience Candidates with the following qualifications in addition to the above will receive elevated consideration:\nExperience in the development of algorithms leveraging Visual Basic, R, Python, or SQL\/NoSQL Experience with Distributed data and computing tools and visualization tools, including ArcGIS, SPSS, SAS, MATLAB, Tableau.\nExperience with manipulating data using PostgreSQL, ORACLE, SQL or ACCESS database management system.\nBachelor's degree in Data Science or related field preferred; Master's degree in Data Science or related field a plus Security Clearance:\nTOP SECRET security clearance with active SCI access.\nShow more\nShow less",
      "job_skills":"Data Exploration, Data Cleaning, Data Analysis, Data Visualization, Data Mining, Statistical Programming, GeneralPurpose Programming, Predictive Data Modeling, Quantitative Analyses, Machine Learning, Artificial Intelligence, Natural Language Processing, Text Mining, TS\/SCI Clearance, Polygraph Exam, Visual Basic, R, Python, SQL\/NoSQL, Distributed Data, Computing Tools, Visualization Tools, ArcGIS, SPSS, SAS, MATLAB, Tableau, PostgreSQL, ORACLE, SQL, ACCESS, Data Science, TOP SECRET Security Clearance, SCI Access",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist | TS\/SCI",
      "company":"Blackspoke",
      "job_location":"Arnold, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-ts-sci-at-blackspoke-3760567609",
      "search_city":"Saint Louis",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Own your opportunity to serve as a critical component of our nation's safety and security. Make an impact by using your expertise to protect our country from threats.\nBe part of an exciting opportunity to contribute to one of the nation's most critical intelligence organizations. Your work directly impacts national security and global issues, you will have the chance to contribute to missions that are of paramount importance to the United States and its allies, know that that the environments and programs you support are making a difference on a global scale. Our customers operate at the forefront of technology, dealing with some of the most advanced defense, geospatial, and intelligence systems in the world.\nAs the Data Scientist, you'll be exposed and contribute to the development and application of innovative technologies such as machine learning, artificial intelligence, and advanced data analytics. Our work depends on a Data Engineer joining our team to support our intelligence customer in Springfield, VA or St. Louis, MO. This position supports the Geospatial IC to provide high-quality, cost-effective solutions to the customer. The Data Scientist's expertise is needed to support a sophisticated enterprise environment. The Scientist is an active participant in SAFe and Scrum development teams and meetings.\nWhat you will be working on:\nIdentify data sources and automate collection processes\nPerform preprocessing of structured and unstructured data\nAnalyze large, complex data sets to identify trends and patterns\nBuild predictive models and machine learning algorithms\nCombine models through ensemble modeling\nPresent information using data visualization techniques\nPropose solutions and strategies to address Key Intelligence Questions\nCollaborate with engineering and product development teams\nWhat you will bring to us:\n2+ years of experience as a Data Scientist, Data Engineer, ML Engineer, or Data Analysts and Bachelor's Degree in Computer Programming, Science, Engineering or a related technical discipline, or the equivalent combination of education, technical training, or work\/military experience\n3+ years of experience in a Linux environment\nDirect experience and demonstrated proficiency with Python programming to build containerized microservices that use message queues such as activemq or rabbitmq.\nExperienced in ML Model performance testing and hyperparameter tuning (Tensorboard, wandb, mlflow)\nExperience training ML models with GPU acceleration in a containerized environment using common AI frameworks such as Tensorflow or Torch.\nExperience with workload managers (SLURM, Argo Workflow, Airflow)\nStrong problem solving and troubleshooting skills\nStrong communication and interpersonal skills\nMust possess excellent time management skills and the drive to work unsupervised\nActive TS\/SCI clearance required and eligibility to obtain a CI poly\nWould be nice if you bring the following:\nPrior experience working with or within the Intelligence Community or a military intelligence unit\nUnderstanding of access management and security groups (i.e. IAM, S3 bucket, SSH, VPN, etc.)\ncomputer vision related experience with torchvision or tensorflow object detection APIs.\nAdditional languages on top of Python preferred (C++, Julia, Go, R)\nFamiliarity with Cloud Platform AI-ML toolsets (e.g. AWS Sagemaker, GCP Vertex)\nExperience building data pipelines with spark, kafka, or nifi\nEqual Opportunity Employer\/Veterans\/Disabled. Individuals with disabilities, including disabled veterans or veterans with service-connected disabilities, are encouraged to apply. If you need assistance applying outside of the online application, please contact recruiting@blackspoke.com for more information.\nThis Organization Participates in E-Verify\nThis employer participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.\nIf E-Verify cannot confirm that you are authorized to work, this employer is required to give you written instructions and an opportunity to contact Department of Homeland Security (DHS) or Social Security Administration (SSA) so you can begin to resolve the issue before the employer can take any action against you, including terminating your employment.\nEmployers can only use E-Verify once you have accepted a job offer and completed the Form I-9. E-Verify Works for Everyone For more information on E-Verify, or if you believe that your employer has violated its E-Verify responsibilities, please contact DHS.\nDepartment of Homeland Security: 888-897-7781and E-Verify.gov\nShow more\nShow less",
      "job_skills":"Data Science, Artificial Intelligence, Machine Learning, Predictive Modeling, Data Visualization, Data Analysis, Data Engineering, Python, Linux, Microservices, Message Queues, Model Performance Testing, Hyperparameter Tuning, Containerization, Tensorflow, Torch, Workload Managers, GPU Acceleration, Problem Solving, Troubleshooting, Communication, Interpersonal Skills, Time Management, TS\/SCI Clearance, Computer Vision, Object Detection, AWS Sagemaker, GCP Vertex, Spark, Kafka, Nifi",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"PREDICTif Solutions",
      "job_location":"Texas, United States",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-predictif-solutions-3778853630",
      "search_city":"Zion",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Data Scientist\nPREDICTif is growing quickly and there is high demand for the services we provide. We have been consulting leaders in the analytics space for nearly two decades supporting the needs of some of the largest companies in North America. Enterprise, SMB, and Start-up clients come to us for our deep experience with Big Data, Advanced Analytics, Machine Learning, Artificial Intelligence and more. As an AWS consulting partner, we build solutions on AWS that help our customers solve challenging business needs and deliver amazing results.\nThe Role:\nThe Data Scientist will be responsible for building large-scale data mining and ML\/AI solutions. You will be part of a fast-paced, entrepreneurial team focused on leveraging AWS services like Amazon SageMaker to build innovative solutions.\nPrincipal Accountabilities:\nWork alongside machine learning experts, technologists, product managers and other analysts to solve complex business problems. Identify what data to collect, devise methods to extract it, and develop processes to transform raw data into insights.\nHelp build a foundation for state-of-the-art technical capabilities to support ongoing and planned data analytics projects. Stay on top of AWS technological advancements to provide forward-thinking recommendations to clients.\nInvestigate data visualization and summarization techniques for conveying key findings related to applied analytics.\nEstablish strong working relationships with business analysts to understand requirements and determine optimal technologies.\nAnalyze technical needs and infrastructure design to determine integration with AWS cloud architecture.\nFollow AWS best practices, internal standards, budgets, and processes. Plan how code will integrate with AWS services like S3, Lambda, DynamoDB and RDS.\nCollaborate with project managers to estimate costs of AWS services needed for proposed solutions.\nDevelop overall implementation plans leveraging AWS.\nCommunicate proposed AWS solutions to clients with detailed documents.\nProvide support installing, customizing, and integrating AWS cloud services.\nSupport development teams to review code integrating with AWS services and assist QA testing of functionalities.\nProvide support for AWS-related issues in development or implementation.\nCapture AWS architecture details for traceability.\nRequired:\nStrong communication skills are a must. Ability to articulate solutions in both business and technological terms.\nAdvanced degree in quantitative discipline like math, statistics, or computer science.\nExpertise in machine learning, natural language processing, and using AWS AI services like SageMaker.\nStrong programming skills and experience with tools like Python, R, PySpark, etc.\nKnowledge of AWS big data services like EMR, Redshift, Kinesis, and Athena.\nAbility to build partnerships, drive consensus, and communicate solutions.\nProduce high quality work using AWS tools and services.\nAbility to manage multiple tasks and quickly switch between them.\nConstruct plans to execute priorities utilizing AWS cloud architecture.\nBenefits Highlights\nWe provide our employees with the benefits they need. From top-tier medical coverage and generous 401(k) contributions to flexible paid time off, PREDICTif promotes a healthy balance between work and life.\nMedical, dental and vision insurance\nPTO and paid holidays\nRetirement benefits\nBonus opportunities\nCasual dress\nPersonal development\nAbundant refreshments\nEquity opportunities\nCulture\nWe are customer-obsessed innovators at the forefront of innovation. We consistently exceed expectations and live by the highest value.\n\u00ac\u2211\nCustomer Obsession\nEverything we do starts with our customers. We listen to them, understand their needs, culture, and current state, and then work backwards to find the best-fit solutions. We work vigorously to become your trusted partner. Our clients 100% satisfaction is our top priority.\n\u00ac\u2211\nIntegrity\nWe earn trust by ensuring everything we do is with the highest level of integrity. We believe in transparency and strive to leave our clients better for having worked with us. We take your ethics to heart and together, become better corporate citizens.\n\u00ac\u2211\nPeople First\nOur purpose is to matter to our clients and our people. Advancing our team members\u201a\u00c4\u00f4 skillset is critical to our success. Every team member is given the respect and space to grow, allowing them to thrive. We seek out and reward excellence and find it frequently in our crew of thinkers and innovators, who will always deliver their best to our clients.\n\u00ac\u2211\nTake Pride\nWe take pride in the work that we perform for our customers. We strive to achieve the highest standard of quality in all our deliverables, ensuring our customers receive maximum return on their investments. We stand behind our products and services. We take our responsibility to our customers, their success, and our industry seriously.\nShow more\nShow less",
      "job_skills":"AWS, Amazon SageMaker, Machine Learning, Artificial Intelligence, S3, Lambda, DynamoDB, RDS, Python, R, PySpark, EMR, Redshift, Kinesis, Athena, Customer Obsession, People First, Take Pride",
      "Category":"Backend Development"
  },
  {
      "job_title":"Contract: Database Automation Engineer \/ DBA-DevOps",
      "company":"Upwork",
      "job_location":"Texas, United States",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/contract-database-automation-engineer-dba-devops-at-upwork-3739298808",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Upwork ($UPWK) is the world\u201a\u00c4\u00f4s work marketplace. We serve everyone from one-person startups to large, Fortune 100 enterprises with a powerful, trust-driven platform that enables companies and talent to work together in new ways that unlock their potential.\nLast year, more than $3.8 billion of work was done through Upwork by skilled professionals who are gaining more control by finding work they are passionate about and innovating their careers.\nThis is an engagement through Upwork\u201a\u00c4\u00f4s Hybrid Workforce Solutions (HWS) Team. Our Hybrid Workforce Solutions Team is a global group of professionals that support Upwork\u201a\u00c4\u00f4s business. Our HWS team members are located all over the world.\nWork\/Project Scope:\nProvisioning\nMaintenance\nRight-scaling\nCost-effective use\nCreate and maintain vulnerability management policies, procedures, and training\nMust Haves (Required Skills):\nRelational database management experience (Postgres\/MySQL\/Oracle)\nProficiency with database languages: SQL, PL\/SQL or pgPL\/SQL.\nScripting: Strong experience with Python (preferred), shell (secondary)\nOn-call assistance with DB-related incidents.\nAutomation mindset: Desire and ability to automate repetitive tasks.\nNice to Haves:\nCloud management: Experience with Terraform (CloudFormation, Hashicorp Packer, Chef\/Ansible).\nTechnologies: Kafka \/ Kinesis (on-prem or managed), ElasticSearch\/OpenSearch\/Mongo, Redis\/Memcache\nDatabases: Analytical databases like Snowflake\/Clickhouse\/Greenplum, data federation engines like Presto\/Trino\/Dremio\/Athena.\nUpwork is proudly committed to fostering a diverse and inclusive workforce. We never discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical condition), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.\nTo learn more about how Upwork processes and protects your personal information as part of the application process, please review our Global Job Applicant Privacy Notice\nShow more\nShow less",
      "job_skills":"Postgres, MySQL, Oracle, SQL, PL\/SQL, pgPL\/SQL, Python, Shell, Terraform, CloudFormation, Hashicorp Packer, Chef, Ansible, Kafka, Kinesis, ElasticSearch, OpenSearch, Mongo, Redis, Memcache, Snowflake, Clickhouse, Greenplum, Presto, Trino, Dremio, Athena",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Analyst",
      "company":"ClickJobs.io",
      "job_location":"Creve Coeur, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-at-clickjobs-io-3788843900",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job no: 492867 Work type: Full-time Location: Remote Categories: Information Technology, Project Management Posting Details Job Summary\/Basic Function The Senior Data Analyst will lead and manage all external reporting and survey completion activities. This position will develop processes and queries to streamline and automate all external surveys and reporting requirements. This position will help ensure the institution is in compliance with all federal, state, and local reporting requirements and all national reports and surveys. The position will assist the school and colleges in academic accreditation reporting. The position will develop institutional strategic reports and provide support to subject matter experts (SMEs) in building out data models, reports and dashboards. This position will be key in training and upskilling SMEs in dashboard creation and report writing. The position will partner with data engineering in ensuring the data infrastructure is well architected for current and historic analysis and will aid in data slice prioritization for reporting and compliance. This position will partner with data stewards across the institution to define, catalog, validate, and audit the data within the customer data platform (CDP), and master data management (MDM) system for more efficient reporting, analysis, and to continually expand the institution\u201a\u00c4\u00f4s single source of truth and underlying documentation. The position will partner with SMEs in data quality initiatives to help ensure data integrity in the CDP and MDM and in operational systems as well. This position will collaborate with SMEs and appropriate departments to identify potential areas to grow data collection efforts, eliminate data silos, and provide recommendations for changes to better respond to survey and reporting requirements when appropriate. Essential Responsibilities:\nLead all institutional external reporting activities, including preparation of required federal, state, and national reports\/surveys, census, and university fact book. Partner with schools and colleges for accreditation reporting. Ensure accuracy, timeliness, and compliance with reporting requirements.\nPartner with data stewards in academic and institutional departments to systematically collect, catalog, and warehouse data in the master data management system. This position will train and upskill data stewards in dashboards and reporting.\nCreate new data modeling and querying processes from the data lake \/ warehouse to automate the completion of external surveys for more efficient and accurate reporting. Collaborate with data engineering to help ensure the data architecture is built for current and historical analysis and reporting.\nThis position will collaborate with data stewards and appropriate departments to identify potential areas to grow data collection efforts, eliminate data silos, and provide recommendations for changes in order to better respond to survey and reporting requirements when appropriate.\nWorking with a team of people to ensure data integrity and quality, develop and maintain a dictionary of common data definitions, and ensure institutional data collection and reporting processes are reliable, valid, and ethical. Please note, due to the nature of this work, the successful candidate will need to possess experience in higher education institutional research data and\/or higher education data. See below qualifications for additional details. Minimum Qualifications\n5+ years previous experience in higher education institutional research including experience with federal, state, and national reporting and surveys for higher education, such as IPEDS, Common Data Set, US News, Petersons, etc.\nDemonstrated experience in creating automation scripts and queries to streamline survey and reporting completion\n10+ years demonstrated proficiency with Excel, including creating complex equations, pivot tables, and advanced visualizations\n5+ years with data querying in SQL Server or similar relational database\n3+ years dashboarding and visualization experience with Tableau or other dashboarding tool\nAbility to generate the most appropriate visualizations, dashboards, and KPIs for data storytelling and to solve strategic business questions\nAbility to create data models using MDX\nAbility to understand complex processes, anticipate how changes impact other areas, and make appropriate suggestions and create changes for process improvements where appropriate\nStrong interpersonal skills and ability to collaborate effectively with stakeholders and colleagues\nStrong experience in data storytelling and clearly articulating findings and results to decision makers\nAbility to document and validate data catalog definitions and collaborate with various constituents on change management Preferred Qualifications\n3+ years experience with Python or R programming languages (or similar programming language) and their associated visualization and data wrangling libraries (e.g. dplyr, ggplot2, tidyverse, matplotlib, pandas, numpy, seaborn, etc)\nExperience with data lake and data warehouse applications in Amazon Web Services in particular: Amazon RedShift, S3, and AWS Glue\nExperience with Mulesoft or other data integration tools\nExperience writing quality assurance rules with Drools (or other Business Rules Management System (BRMS))\nExperience migrating \/ converting dashboards from Power BI to Tableau\nExperience with master data management \/ data catalog applications (e.g. Informatica MDM, EBX, etc)\nKnowledge of statistical and descriptive analysis methods Physical Demands Open Until Filled Yes Special Instructions to Applicants An offer of employment is contingent upon successful completion of a background screening. Applicants requiring University sponsorship to obtain employment authorization will not be considered for this position. Maryville University is committed to a policy of equal opportunity and prohibits discrimination on the basis of age, disability, gender, genetic information, marital status, national origin, race\/color, religion, sex, sexual orientation, veteran status, or any other status protected by law. This extends to all aspects of the employment relationship, including recruiting, hiring, training, on-the-job treatment, promotion, layoff, and termination. Advertised: November 29, 2023 Applications close: Open until filled\nShow more\nShow less",
      "job_skills":"Data Analysis, Reporting, Survey Design, Data Integration, Data Warehousing, Data Quality, Data Visualization, SQL, Tableau, Python, R, AWS, Amazon RedShift, S3, AWS Glue, Drools, Power BI, Informatica MDM, Data Governance, Data Dictionary, Dashboarding, Data Modeling, Data Migration, Master Data Management, Data Catalog, Data Wrangling, Data storytelling, Statistical Analysis",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Oracle Database Engineer (Requires ACTIVE Secret Security Clearance)",
      "company":"TEKsystems",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-oracle-database-engineer-requires-active-secret-security-clearance-at-teksystems-3780295870",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description\nTEKsystems is seeking an experienced Oracle Database Administrator for a long-term contract supporting a data center local to the Kansas City area. As a Senior Oracle Database Administrator you will be responsible for planning, engineering, operating, maintaining, and problem resolution of the Oracle Database Platform as a Service capabilities. You will also work with associated hybrid cloud datacenter infrastructure and teams: virtualization; backup\/storage; operating systems management; networking; and management, monitoring and automation tools. You will support system operations, hardening, migration capabilities, customer interaction and support, and patching. You will also be involved in planning and executing cloud migration and operations activities.\nThe program operates and provides cybersecurity services to support the client application hosting environment. The team also provides engineering and implementation services to deploy and operate the on-prem, hybrid-cloud and cloud datacenter environments. This is an opportunity to shape the way the client achieves its goals to provide enterprise application hosting while ensuring daily support and secure operations for a world-wide warfighter community.\nResponsibilities\nAs a Senior Oracle Database Administrator you will be responsible for planning, engineering, operating, maintaining, and problem resolution of the Oracle Database Platform as a Service capabilities\nYou will also work with associated hybrid cloud datacenter infrastructure and teams: virtualization; backup\/storage; operating systems management; networking; and management, monitoring and automation tools\nYou will support system operations, hardening, migration capabilities, customer interaction and support, and patching\nYou will also be involved in planning and executing cloud migration and operations activities\nAdminister Oracle Platform as a Service hosting environment (Oracle 19c on RHEL operating as virtualized databases)\nMonitor, triage, respond to events, incidents, tasks, changes including working ticket queues and executing approved Data Center projects and activities across the Oracle service area\nMonitor, execute and troubleshoot RMAN backup\/restore\nImplement and manage oracle networking with SSL\/TLS\nDevelop, update, and troubleshoot scripts used to manage the Oracle environment\nCurrent scripts include bash, python, and ansible\nProvides cluster and datacenter database administration, operational support, and problem resolution\nCollaborates with other datacenter engineers on incident, event, and problem resolution; expertise in Red Hat Enterprise Linux 7 and 8 desired; experience with VMWare virtualization and cloud platforms desired\nWorks with various vendors to install, upgrade, configure, administer, automate, and optimize Oracle virtualization architecture and associated software, providing a secure, reliable, and highly available data base platform to Data Center customers and services\nPerforms software installation and upgrade automation including scripting in bash and python as well as automation of data center efforts using VMWare tools (VMWare Ops Manager, vRealize Automation\/Orchestrator)\nDevelops and maintains a comprehensive system event, performance, and capacity monitoring plan\nTroubleshoots problems, takes appropriate corrective action and\/or interacts with IT staff or vendors in performing complex testing, support and troubleshooting functions\nCoordinates troubleshooting and collaborates with customers to resolve customer database operation incidents\nProvides 24x7x365 on-call support in rotation with Technical Lead nights\/weekends with after hours response required in support of some incidents\nSupports monthly and quarterly security\/application patching process\nQualifications\nBS+ 8-10 MS + 5-7 years experience, will consider HS+12 years experience\nExperiencing implementing DISA STIGs and security controls\nExperience implementing\/configuring and troubleshooting RMAN backup\/restore\nExperience with Oracle networking with SSL\/TLS\nExperience with Data Guard implementations\nSenior level experience in VMWare vRealize Operations Suite (Operations Manager), HP Blade System (or similar hardware platform), Log Management tool (SysLog\/Log Insight), NetBackup, Red Hat Enterprise Linux; 7.x\/8.x, DISA STIGs\/SRG\nIAT Level II Certification (DOD 8570\/8140), e.g. CompTIA Security+, CASP, CISSP, CISM, CIS,\nOracle Certification required: Oracle Database Certified Master\nActive DoD SECRET Security Clearance\nMust be legally eligible for employment in the US.\nSkills\nDatabase administrator, Oracle database, Oracle\nTop Skills Details\nDatabase administrator, Oracle database, Oracle\nExperience Level\nExpert Level\n#CJ\nAbout TEKsystems\nWe're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.\nThe company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.\nShow more\nShow less",
      "job_skills":"Oracle Database Administration, Oracle Database Platform as a Service, Hybrid cloud datacenter infrastructure, Virtualization, Backup\/storage, Operating systems management, Networking, Management monitoring and automation tools, System operations, Hardening, Migration capabilities, Patching, Cloud migration, Cloud operations, Cybersecurity services, Application hosting, Data Center projects and activities, RMAN backup\/restore, Oracle networking with SSL\/TLS, Bash scripting, Python scripting, Ansible scripting, Cluster and datacenter database administration, Red Hat Enterprise Linux 7 and 8, VMWare virtualization, Cloud platforms, Oracle virtualization architecture, VMWare Ops Manager, vRealize Automation\/Orchestrator, System event performance and capacity monitoring, Troubleshooting, IT staff or vendors, Data Guard implementations, VMWare vRealize Operations Suite (Operations Manager), HP Blade System, Log Management tool (SysLog\/Log Insight), NetBackup, IAT Level II Certification (DOD 8570\/8140), CompTIA Security+, CASP, CISSP, CISM, CIS, Oracle Certification required: Oracle Database Certified Master, DoD SECRET Security Clearance",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Oracle Database Engineer (Requires ACTIVE Secret Security Clearance)",
      "company":"Dice",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-oracle-database-engineer-requires-active-secret-security-clearance-at-dice-3783005090",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Dice is the leading career destination for tech experts at every stage of their careers. Our client, TEKsystems c\/o Allegis Group, is seeking the following. Apply via Dice today!\nDescription:\nTEKsystems is seeking an experienced Oracle Database Administrator for a long-term contract supporting a data center local to the Kansas City area. As a Senior Oracle Database Administrator you will be responsible for planning, engineering, operating, maintaining, and problem resolution of the Oracle Database Platform as a Service capabilities. You will also work with associated hybrid cloud datacenter infrastructure and teams: virtualization; backup\/storage; operating systems management; networking; and management, monitoring and automation tools. You will support system operations, hardening, migration capabilities, customer interaction and support, and patching. You will also be involved in planning and executing cloud migration and operations activities.\nThe program operates and provides cybersecurity services to support the client application hosting environment. The team also provides engineering and implementation services to deploy and operate the on-prem, hybrid-cloud and cloud datacenter environments. This is an opportunity to shape the way the client achieves its goals to provide enterprise application hosting while ensuring daily support and secure operations for a world-wide warfighter community.\nResponsibilities\nAs aSeniorOracle Database Administrator you will be responsible for planning, engineering, operating, maintaining, and problem resolution of the Oracle Database Platform as a Service capabilities\nYou will also work with associated hybrid cloud datacenter infrastructure and teams: virtualization; backup\/storage; operating systems management; networking; and management, monitoring and automation tools\nYou will support system operations, hardening, migration capabilities, customer interaction and support, and patching\nYou will also be involved in planning and executing cloud migration and operations activities\nAdminister Oracle Platform as a Service hosting environment (Oracle 19c on RHEL operating as virtualized databases)\nMonitor, triage, respond to events, incidents, tasks, changes including working ticket queues and executing approved Data Center projects and activities across the Oracle service area\nMonitor, execute and troubleshoot RMAN backup\/restore\nImplement and manage oracle networking with SSL\/TLS\nDevelop, update, and troubleshoot scripts used to manage the Oracle environment\nCurrent scripts include bash, python, and ansible\nProvides cluster and datacenter database administration, operational support, and problem resolution\nCollaborates with other datacenter engineers on incident, event, and problem resolution; expertise in Red Hat Enterprise Linux 7 and 8 desired; experience with VMWare virtualization and cloud platforms desired\nWorks with various vendors to install, upgrade, configure, administer, automate, and optimize Oracle virtualization architecture and associated software, providing a secure, reliable, and highly available data base platform to Data Center customers and services\nPerforms software installation and upgrade automation including scripting in bash and python as well as automation of data center efforts using VMWare tools (VMWare Ops Manager, vRealize Automation\/Orchestrator)\nDevelops and maintains a comprehensive system event, performance, and capacity monitoring plan\nTroubleshoots problems, takes appropriate corrective action and\/or interacts with IT staff or vendors in performing complex testing, support and troubleshooting functions\nCoordinates troubleshooting and collaborates with customers to resolve customer database operation incidents\nProvides 24x7x365 on-call support in rotation with Technical Lead nights\/weekends with after hours response required in support of some incidents\nSupports monthly and quarterly security\/application patching process\nQualifications:\nBS+ 8-10 MS + 5-7 years experience, will consider HS+12 years experience\nExperiencing implementing DISA STIGs and security controls\nExperience implementing\/configuring and troubleshooting RMAN backup\/restore\nExperience with Oracle networking with SSL\/TLS\nExperience with Data Guard implementations\nSeniorlevel experience in VMWare vRealize Operations Suite (Operations Manager), HP Blade System (or similar hardware platform), Log Management tool (SysLog\/Log Insight), NetBackup, Red Hat Enterprise Linux; 7.x\/8.x, DISA STIGs\/SRG\nIAT Level II Certification (DOD 8570\/8140), e.g. CompTIA Security+, CASP, CISSP, CISM, CIS,\nOracle Certification required: Oracle Database Certified Master\nActive DoD SECRET Security Clearance\nMust be legally eligible for employment in the US.\nSkills:\nDatabase administrator, Oracle database, Oracle\nTop Skills Details:\nDatabase administrator, Oracle database, Oracle\nExperience Level:\nExpert Level\n#CJ\nAbout TEKsystems:\nWe're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.\nThe company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law. Senior Oracle Database Engineer (Requires ACTIVE Secret Security Clearance)\nShow more\nShow less",
      "job_skills":"Oracle, SQL, RMAN, SSL\/TLS, Data Guard, Virtualization, Red Hat Enterprise Linux, Bash, Python, Ansible, VMWare Ops Manager, VMWare vRealize Automation\/Orchestrator, NetBackup, Log Management tool, SysLog\/Log Insight, Oracle Database Certified Master, DISA STIGs, SRG, IAT Level II Certification, DOD 8570\/8140, CompTIA Security+, CASP, CISSP, CISM, CIS",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Software Engineer (Python\/Data Pipelines)",
      "company":"Diversity Resource Staffing Inc.",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-software-engineer-python-data-pipelines-at-diversity-resource-staffing-inc-3548643839",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"As Senior Software Engineer specializing in Python, you will be responsible for designing, developing, maintaining, and operationalizing quantitative models and analytic environments supporting NISA\u201a\u00c4\u00f4s core line of business. You will work closely with business counterparts and our quantitative research groups to understand their needs, formulate requirements, design creative and extensible solutions for data distribution, analysis, and modeling for consumption by internal business groups.\nAs a senior member of the IT Solutions team, you will also participate in design and code reviews, will collaborate with other team members, and mentor junior teammate.\nRequired Qualifications\nBachelor's degree or equivalent experience in a field requiring strong analytical and quantitative skills, such as Computer Science, Engineering, Mathematics, Finance, or Information Systems\nSignificant experience developing using Python (expertise in other high-level languages considered)\nExtensive experience designing queries and data structures in SQL Server or another relational database platform\nExperience in data science and data analysis\nPreferred Qualifications\nExperience building solutions using public cloud platforms (AWS, Azure, GCP)\nExperience designing & implementing data pipelines to support quantitative research\nFamiliarity with MATLAB or R\nExperience with unit testing frameworks\nWorking knowledge of modern application frameworks\nPrevious professional experience in financial services sector is a plus\nShow more\nShow less",
      "job_skills":"Python, SQL, Data Science, Data Analysis, Cloud Platforms (AWS Azure GCP), MATLAB, R, Unit Testing Frameworks, Application Frameworks",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer - Scala(U.S. remote)",
      "company":"Railroad19",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-scala-u-s-remote-at-railroad19-3782294502",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Railroad19, Inc.\nis hiring\nremote\nSenior Data Engineers\nto be a solid technical resource on a dynamic and growing team of accomplished engineers.\nOur ideal candidate is passionate about creating well-architected solutions containing thoroughly tested code. The ability to communicate effectively and develop relationships by empathizing with client goals is a highly valued skill within our company culture.\nCore Responsibilities:\nDevelop new and enhance existing application services\nWriting tests to maintain code quality\nUnderstand and adapt to our client's evolving business requirements within the television advertising domain.\nParticipate in detailed technical design sessions to understand client needs and provide productive feedback\nIdentify new opportunities, tools, and services to enhance the software platform\nSupport and troubleshoot issues, identify the root cause, and proactively recommend corrective actions\nSkills & Experience:\nScala 2.12 + development experience\nPassionate about developing clean and maintainable code with little or no side-effects\nExperience building Restful APIs in Scala using Spark 2.4\nStrong hands-on experience with AWS running spark jobs on ephemeral EMR clusters on AWS and S3.\nExperience with relational and non-relational databases\nWillingness to learn new technologies and takes pride in keeping up with the latest technologies and practices within the Scala and Spark development community\nExcellent oral and written communication skills\nStrong analytical and problem-solving skills\nSelf-directed and can effectively deliver solutions with little oversight\nA bachelor's or master's degree in computer science, computer engineering, or other technical disciplines or equivalent work experience is preferred but not required.\n$120,000 - $160,000 a year\nSalary is commensurate with experience.\nWe are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal-opportunity workplace.\n#Hiringnow\nWe are actively hiring (Data Engineers)\n#remote #Scala #DataEngineering #ApacheSpark\nShow more\nShow less",
      "job_skills":"Scala 2.12, Spark 2.4, RESTful APIs, AWS, EMR clusters, S3, Relational databases, Nonrelational databases, Hadoop, Java",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Power BI \/ Data Engineer-expert",
      "company":"neteffects",
      "job_location":"St. Louis City County, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-power-bi-data-engineer-expert-at-neteffects-3779391637",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"At neteffects, we are looking for a\nSr. Power BI\/ Data Engineer-expert\nfor our direct client in\nSt. Louis MO.\nContract -No c2c.\nHybrid in St. Louis MO\nEducation: Bachelor's degree or Master's degree with six years of experience\nTop Technical Skills\/Tools\/Experience Needed for the Role:\nTechnical Skills:\n\u201a\u00c4\u00a2\nProgramming Languages:\nPython, Scala, Go, SQL (required), R (preferred)\nBusiness Intelligence: Power BI, Power Apps\nPower BI and Data Visualizations\nPower Apps\n\u201a\u00c4\u00a2\nCloud Platforms\n: AWS, GCP\n\u201a\u00c4\u00a2\nData Warehousing\n: BigQuery, Redshift, Snowflake-\nexpertise on any one\n\u201a\u00c4\u00a2\nStreaming Technologies\n: Kafka\n\u201a\u00c4\u00a2\nData Pipelines\n: Spark, AWS SQS, Lambda, Step Functions, ECS, Fargate, Athena, BigQuery, GCP PubSub, Cloud Functions, Cloud Run, Kubernetes\n\u201a\u00c4\u00a2 I\nnfrastructure as Code\n: Terraform, AWS CloudFormation\n\u201a\u00c4\u00a2\nDevOps:\nContinuous Integration\/Continuous Delivery (CI\/CD)\n\u201a\u00c4\u00a2\nVersion Control:\nGit\n\u201a\u00c4\u00a2\nDocumentation:\nHaystack, SharePoint\n\u201a\u00c4\u00a2\n\u201a\u00c4\u00a2 Other:\nStatistical and\/or mathematical programming packages, machine learning (ML) (optional)\nExperience:\n\u201a\u00c4\u00a2 Building data models\n\u201a\u00c4\u00a2 Engineering data-intensive software\n\u201a\u00c4\u00a2 Implementing data pipelines\n\u201a\u00c4\u00a2 Working with cloud platforms\n\u201a\u00c4\u00a2 Collaborating with cross-functional teams\n\u201a\u00c4\u00a2 Leading and participating in design sessions\n\u201a\u00c4\u00a2 Providing technical recommendations\n\u201a\u00c4\u00a2 Estimating project timelines\n\u201a\u00c4\u00a2 Communicating technical information effectively\nAdditional Desired Skills:\n\u201a\u00c4\u00a2 Business Acumen: Understanding of business processes and needs\n\u201a\u00c4\u00a2 Leadership: Leading and motivating teams\n\u201a\u00c4\u00a2 Communication: Excellent written and oral communication skills\n\u201a\u00c4\u00a2 Project Management: Successfully managing projects from start to finish\n\u201a\u00c4\u00a2 Organizational Skills: Prioritizing tasks and meeting deadlines\n\u201a\u00c4\u00a2 Interpersonal Skills: Building and maintaining positive relationships\n\u201a\u00c4\u00a2 Global Experience: Working with culturally diverse teams\n\u201a\u00c4\u00a2 Learning: Continuously learning and staying up-to-date with new technologies\nAll qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\nShow more\nShow less",
      "job_skills":"Python, Scala, Go, SQL, R, Power BI, Power Apps, AWS, GCP, BigQuery, Redshift, Snowflake, Kafka, Spark, AWS SQS, Lambda, Step Functions, ECS, Fargate, Athena, GCP PubSub, Cloud Functions, Cloud Run, Kubernetes, Terraform, AWS CloudFormation, Git, Haystack, SharePoint, Machine Learning, Statistical Programming, Mathematical Programming Packages, Data Modeling, DataIntensive Software Engineering, Data Pipeline Implementation, Cloud Platform Experience, CrossFunctional Team Collaboration, Design Session Participation, Technical Recommendation, Project Timeline Estimation, Technical Information Communication, Business Acumen, Leadership, Communication, Project Management, Organizational Skills, Interpersonal Skills, Global Experience, Learning",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Cloud Data Engineer",
      "company":"BDO USA",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-cloud-data-engineer-at-bdo-usa-3765467837",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nJob Summary:\nThis position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.\nJob Duties\nDesigns and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS\nListens to client needs to align solution with business requirements and delivery schedule\nCreates written functional and technical designs\nParticipates in project status and stand meetings, and assists with providing aggregated project status for project and program managers\nAssists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions\nWrites code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles\nDelivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)\nAssists with implementation of data governance programs and best practices\nPerforms the cleaning and transforming of data from source systems into analytics models\nImplements models to support data visualizations and integrations\nAssists with implementing DevOps, DataOps and MLOps methodologies on projects\nWrites custom integration logic in applicable programming languages\nAssists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle\nAssists clients with licensing, security, and cost estimation of solutions\nPerforms code reviews to ensure adherence to standards\nWorks directly with clients and team members to establish secure data analytics platforms and infrastructure\nContributes to successful deployments of developed solutions and integration of DevOps tools\nMaintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools\nBuilds client relationships during project execution, effectively becoming a trusted advisor of the client\nParticipates in support activities for existing software solutions\nOther duties as assigned\nSupervisory Responsibilities\nSupervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product\nEducation\nQualifications, Knowledge, Skills and Abilities:\nHigh School Diploma or GED equivalent, required\nBachelor\u201a\u00c4\u00f4s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred\nExperience\nFive (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required\nOne (1) or more years of experience technically leading development projects, preferred\nOne (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred\nSoftware\nStrong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required\nExperience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required\nHands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred\nExperience with one (1) or more of the following computer languages, preferred:\nC#\nPython\nJava\nScala\nExperience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred\nExperience with Git and DevOps deployment technologies, preferred\nExperience with Linux, preferred\nExperience with one (1) or more of the following, preferred:\nData Lake Medallion Architecture\nBatch and\/or streaming data ingestion into a data lake\nAI Algorithms\/Machine Learning\nAutomation tools such as UiPath, Alteryx, etc.\nComputer Vision based AI technologies\nOther Knowledge, Skills & Abilities\nAbility to work with a high degree of professionalism and autonomy\nExcellent verbal and written communication skills\nSolid organizational skills, especially the ability to meet project deadlines with a focus on details\nAbility to successfully multi-task while working independently or within a group environment\nAbility to work in a deadline-driven environment, and handle multiple projects simultaneously\nAbility to interact effectively with people at all organizational levels of the Firm\nAbility to effectively interact with a team of professionals and delegating work assignments, as needed\nAbility to build and maintain strong relationships with internal and client personnel\nAbility to encourage a team environment on engagements, and contribute to the professional development of assigned personnel\nKeywords:\nData Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL\nIndividual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate\u201a\u00c4\u00f4s qualifications, experience, skills, and geography.\nCalifornia Range: $111,000 - $152,000\nColorado Range: $111,000 - $152,000\nNew York City\/ Valhalla Range: $111,000 - $152,000\nWashington Range: $111,000 - $152,000\nAbout Us\nBDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients\u201a\u00c4\u00f4 needs. We currently serve more than 400 publicly traded domestic and international clients.\nUnparalleled partner-involvement\nDeep industry knowledge and participation\nGeographic coverage across the U.S.\nCohesive global network\nFocused capabilities across disciplines\nBDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world\u201a\u00c4\u00f4s fifth largest accounting network.\nBDO offers a competitive Total Rewards package that encompass so much more than \u201a\u00c4\u00ec \u201a\u00c4\u00fatraditional benefits\u201a\u00c4\u00f9. Our wide range of rewards and our employees\u201a\u00c4\u00f4 ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.\nSome Examples Of Our Total Rewards Offerings Include\nCompetitive pay and eligibility for an annual performance bonus.\nA 401k plan plus an employer match\nComprehensive, medical, dental, vision, FSA, and prescription insurance from day one\nCompetitive Paid Time Off with daily accrual from day one of employment, plus paid holidays\nPaid Parental Leave\nAdoption Assistance\nFirm paid life insurance\nWellness programs\nAdditional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance\nAbove offerings may be subject to eligibility requirements.\nClick here to find out more!\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.\n\"BDO USA, P.A. is an EO employer M\/F\/Veteran\/Disability\"\nShow more\nShow less",
      "job_skills":"Data Analytics, Business Intelligence, Artificial Intelligence, SQL, Data Warehousing, Data Modeling, Azure, AWS, C#, Python, Java, Scala, Microsoft Fabric, Power BI, Azure Analysis Services, Git, DevOps, Linux, Data Lake Medallion Architecture, Batch, Streaming, AI Algorithms, Machine Learning, Automation, Computer Vision, UiPath, Alteryx, Tableau, Qlik, PySpark, Terraform, Bicep, Data Ops, Purview, Delta, Pandas, Spark SQL, SSIS, SSAS, SSRS, Snowflake, Athena, Glue, RedShift, QuickSight, SageMaker, S3, Databricks",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Analyst",
      "company":"Equifax",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-at-equifax-3781960084",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Equifax is where you can power your possible. If you want to achieve your true potential, chart new paths, develop new skills, collaborate with bright minds, and make a meaningful impact, we want to hear from you.\nEquifax Workforce Solutions (EWS), headquartered in St. Louis, MO\nis EFX\u201a\u00c4\u00f4s fastest growing and most profitable business unit. Learn more about EWS and our workforce solutions here: https:\/\/workforce.equifax.com\/\nEquifax (EFX)\n,\nHQ Atlanta, GA is a global data, analytics, and technology company. We believe knowledge drives progress. We blend unique data, analytics, and technology with a passion for serving customers globally, to create insights that power decisions to move people forward.\nThe senior data analyst will understand the needs of different audiences, deliver content both technically and non-technically, and have a knack for visually telling the story with data.\nWhat You\u201a\u00c4\u00f4ll Do\nThis role will be responsible for driving analytics that support sales enablement, marketing, and product development in a state of the art analytics cloud environment. Must be self motivated, collaborative, and results oriented.\nDevelop innovative analytical solutions that drive actionable insights to enrich a variety of revenue driving functions such as sales enablement, customer lifetime value, and market penetration\nConsultative approach to data projects, with the ability to artfully articulate the analysis to non-technical audiences\nTake ownership of delivering quality projects to the business, applying rigor to business requirements, design, and aftercare of the solution when deployed\nUtilizes Equifax\u201a\u00c4\u00f4s diverse data sources to craft solutions using various modeling techniques through the most appropriate open source and\/or proprietary tooling\nWhat Experience You'll Need\nBachelor\u201a\u00c4\u00f4s degree in Computer Science, Information Systems, Economics, Engineering, or a comparable discipline\n5+ years of work experience in identifying, gathering, transforming and analyzing data within and across database platforms (SQL, Python)\nStrong development skills in visualization software such as Tableau, Data Studio, or other business intelligence tools\nStrong analytical skills including the ability to rapidly learn new business, data assets and how to apply them to drive business impacts\nYou possess excellent written and verbal communication skills with the ability to communicate with team members at various levels, including business leaders\nWhat Could Set You Apart\nAdvanced degree in Statistics, Engineering, Business Analytics or a comparable discipline or experience\nWork experience in the SaaS industry driving sales or marketing functions\nWork experience building, loading, transforming, and analyzing data within Google Cloud Platform (GCP) or other similar cloud environment\nWork experience with regulated data\nWe offer comprehensive compensation and healthcare packages, 401k matching, paid time off, and organizational growth potential through our online learning platform with guided career tracks.\nAre you ready to power your possible? Apply today, and get started on a path toward an exciting new career at Equifax, where you can make a difference!\nEquifax is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\nShow more\nShow less",
      "job_skills":"SQL, Python, Tableau, Data Studio, Statistics, Engineering, Business Analytics, Google Cloud Platform, GCP",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist-Deep Learning-Bioinformatics",
      "company":"neteffects",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-deep-learning-bioinformatics-at-neteffects-3775479912",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Our direct client in St. Louis MO is looking for a DataScientist with Deep Learning & Bioinformatics\/ Biomolecular focus.\nContract\nHybrid \/ Remote for exceptional candidates\nNo c2c\nBasic requirements:\nThe candidate will join a cross divisional, global team to generate innovative machine learning solutions to better understand biomolecules.\nThe successful candidate will be responsible for\nimplementing machine learning models and work collaboratively with data scientists and research scientists leveraging available datasets and influencing new dataset generation.\nMust Haves:\n\u00ac\u2211\nPhD degree (or M.Sc. with 4 years of working experience) in computer sciences, computational chemistry, computational biology, physics\nor related fields.\n\u00ac\u2211 Profound experience with state-of-the-art\nadvanced mathematical models, machine learning methods and model selection concepts; previous experience with deep learning\nwould be of advantage.\n\u00ac\u2211 Real interest in\nbiology and the life sciences with knowledge of proteins\n. Proficient in applying deep learning algorithms to solve biomolecular problems.\n\u00ac\u2211 E\nxcellent programmin\ng and software engineering skills in\nPython are essential.\n\u00ac\u2211 Expertise in Python libraries like\nBiopython and NumPy\nwould be beneficial.\n\u00ac\u2211 The ability to write clean, efficient, and well-documented Python code is crucial.\n\u00ac\u2211 Proficiency in writing code and experience in cloud computing.\n\u00ac\u2211 Highly creative, independent, fast-learning person with outstanding problem-solving ability and the willingness to undertake challenging analysis tasks autonomously and in a timely fashion.\n\u00ac\u2211 Strong interpersonal skills, excellent written and verbal communication, and the ability to work effectively both independently and in cross-functional teams.\n\u00ac\u2211 Willingness to travel between research sites domestically and globally.\n\u00ac\u2211 Fluency in English, both written and spoken.\nAll qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\nShow more\nShow less",
      "job_skills":"Deep Learning, Bioinformatics, Biomolecular, Machine Learning, Python, Biopython, NumPy, Cloud Computing",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Staff AI Data Engineer",
      "company":"Recruiting from Scratch",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3773087762",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who is Recruiting from Scratch :\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nhttps:\/\/www.recruitingfromscratch.com\/\nThis is a hybrid role based in our\nPalo Alto\nor\nSan\nFrancisco\noffices and will require you to be in office Tuesdays and Thursdays.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nWe believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth\/notifications, trust and safety.\nWhat\u201a\u00c4\u00f4s the job?\nWe\u201a\u00c4\u00f4re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.\nIn this position, you will be responsible for establishing and executing the strategy for our organization\u201a\u00c4\u00f4s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.\nResponsibilities:\nDive into our dataset and design, implement and scale data pre\/post processing pipelines of ML models\nWork on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling\nBe self-motivated in seeking solutions when the correct path isn\u201a\u00c4\u00f4t always known\nCollaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders\nDesign and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams\nBuild data processing streams for cleaning and modeling text data for LLMs\nResearch and evaluate new technologies in the big data space to guide our continuous improvement\nCollaborate with multi-functional teams to help tune the performance of large data applications\nWork with Privacy and Security team on data governance, risk and compliance initiatives\nWork on initiatives to ensure stability, performance and reliability of our data infrastructure\nWhat We\u201a\u00c4\u00f4ll Love About You\nBachelors in Computer Science, Mathematics, Physics, or a related fields\n5+ years of experience as a data engineer building production-level pre\/post-processing data pipelines for ML\/DL models, including 2+ years of technical leadership experience\nExperience in statistical analysis & visualization on datasets using Pandas or R\nExperience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools\nDemonstrated prior experience in creating data pipelines for text data sets NLP\/ large language models\nAbility to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy\nExcellent coding skills in Python, Java, bash, SQL, and expertise with Git version control\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)\nExperience with any public cloud environment - AWS, GCP or Azure\nSignificant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc\nExperience building and maintaining ETL (managing high-quality reliable ETL pipelines)\nWe\u201a\u00c4\u00f4ll really swoon if you have\n2+ years of experience of technical leadership in building data engineering pipelines for AI\nPrevious experience in building data pipeline for conversational AI APIs and recommender systems\nExperience with distributed systems and microservices\nExperience with Kubernetes and building Docker images\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nStrong understanding of applied machine learning topics\nBe familiar with legal compliance (with data management tools) data classification, and retention\nConsistent track record of managing and implementing complex data projects\nWhat You'll Love About Us\nMission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world\nMultiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto\nFamily Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents\nRetirement Savings: Generous 401K plan with 6% match and immediate vest in the US\nCompensation: Industry-competitive compensation and eligibility for company bonus and equity programs\nQueer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more\nAdditional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events\nBase Pay Range\n$160,000\u201a\u00c4\u00ee$280,000 USD\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Python, Java, Bash, SQL, Git, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, PySpark, AWS, GCP, Azure, DynamoDB, ETL, Kafka, Storm, SparkStreaming, ML, NLP, LLM, Data engineering, Data mining, Data cleaning, Data normalizing, Data modeling, Data platforms, Data frameworks, Data processing, Data pipelines, Data governance, Data risk, Data compliance, Data infrastructure, Statistical analysis, Data visualization, Pandas, R, Conversational AI, Recommender systems, Distributed systems, Microservices, Docker images, Streamprocessing systems",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Staff AI Data Engineer",
      "company":"Recruiting from Scratch",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3759709551",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who is Recruiting from Scratch :\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nhttps:\/\/www.recruitingfromscratch.com\/\nThis is a hybrid role based in our\nPalo Alto,\nSan\nFrancisco or Chicago\noffices and will require you to be in office Tuesdays and Thursdays.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nWe believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth\/notifications, trust and safety.\nWhat\u201a\u00c4\u00f4s the job?\nWe\u201a\u00c4\u00f4re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.\nIn this position, you will be responsible for establishing and executing the strategy for our organization\u201a\u00c4\u00f4s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.\nResponsibilities:\nDive into our dataset and design, implement and scale data pre\/post processing pipelines of ML models\nWork on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling\nBe self-motivated in seeking solutions when the correct path isn\u201a\u00c4\u00f4t always known\nCollaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders\nDesign and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams\nBuild data processing streams for cleaning and modeling text data for LLMs\nResearch and evaluate new technologies in the big data space to guide our continuous improvement\nCollaborate with multi-functional teams to help tune the performance of large data applications\nWork with Privacy and Security team on data governance, risk and compliance initiatives\nWork on initiatives to ensure stability, performance and reliability of our data infrastructure\nWhat We\u201a\u00c4\u00f4ll Love About You\nBachelors in Computer Science, Mathematics, Physics, or a related fields\n5+ years of experience as a data engineer building production-level pre\/post-processing data pipelines for ML\/DL models, including 2+ years of technical leadership experience\nExperience in statistical analysis & visualization on datasets using Pandas or R\nExperience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools\nDemonstrated prior experience in creating data pipelines for text data sets NLP\/ large language models\nAbility to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy\nExcellent coding skills in Python, Java, bash, SQL, and expertise with Git version control\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)\nExperience with any public cloud environment - AWS, GCP or Azure\nSignificant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc\nExperience building and maintaining ETL (managing high-quality reliable ETL pipelines)\nWe\u201a\u00c4\u00f4ll really swoon if you have\n2+ years of experience of technical leadership in building data engineering pipelines for AI\nPrevious experience in building data pipeline for conversational AI APIs and recommender systems\nExperience with distributed systems and microservices\nExperience with Kubernetes and building Docker images\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nStrong understanding of applied machine learning topics\nBe familiar with legal compliance (with data management tools) data classification, and retention\nConsistent track record of managing and implementing complex data projects\nWhat You'll Love About Us\nMission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world\nMultiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto\nFamily Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents\nRetirement Savings: Generous 401K plan with 6% match and immediate vest in the US\nCompensation: Industry-competitive compensation and eligibility for company bonus and equity programs\nQueer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more\nAdditional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events\nBase Pay Range\n$160,000\u201a\u00c4\u00ee$280,000 USD\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Data engineering, ML Data Engine, ML Data Ops, Data pre\/post processing, ML models, Data mining, Data cleaning, Data normalizing, Data modeling, Data platforms, Data frameworks, Big data, Data governance, Data risk, Data compliance, Data infrastructure, Python, Java, bash, SQL, Git, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, AWS, GCP, Azure, SQL, DynamoDB, ETL, Kafka, Storm, SparkStreaming, Machine learning, Data management, Data classification, Data retention",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist- Journeyman",
      "company":"ECS",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-journeyman-at-ecs-3784918694",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"ECS is seeking a\nData Scientist- Journeyman\nto work in our\nSt Louis, MO\noffice .\nJob Description:\nECS is seeking a Data Scientist- Journeyman to work in our St Louis, MO office. This offer is contingent upon acceptance by the government customer, validation of appropriate clearances and approval from a cognizant government contracting officer. Candidate will be submitted for Counterintelligence Polygraph after customer indoctrination. The primary role for these data analysts are to provide support to data management and automation activities as part of SFP\u201a\u00c4\u00f4s technical operations team. The scope of work aligns to SFP\u201a\u00c4\u00f4s efforts to modernize and advance requirements management and production feedback capabilities. The contractor shall support the office in modernizing the Community\u201a\u00c4\u00f4s requirements management process, to include automation, data management, statistical analysis, data visualization, training, and process documentation. The primary result of this effort will be the implementation of enhanced requirements management capabilities in order to support Community stakeholders and SF leadership.\nThe contractor shall:\nWork in a team environment and interact with production offices, analysts, and data owners as required.\nAdvise and consult SF stakeholders on data management best practices.\nAssist SF analysts and external partners on data management procedures and best practices.\nImplement enterprise database management processes.\nPerform data management tasks, to include data manipulation.\nPerform data analysis to assess integrity, identify patterns, and determine and correct shortfalls.\nDevelop and document data management workflows.\nTransfer data between multiple formats.\nAutomate processes through the use of Python scripting and model building.\nPerform statistical analysis of data to identify trends and patterns and to build reports for SF leadership and IC community (or NSG).\nProvide advanced data visualization to convey findings and communicate insights utilizing capabilities such as IC Portal and other dynamic viewers.\nIndependently identify, document, and address technical challenges.\nDeliver schema mapping and entity resolution across disparate geospatial data sources through data scientist applied expertise in the subject.\nUnderstand and communicate the interrelationships across many disparate datasets.\nDocument and visualize data both temporally and spatially to assist in data integrity checks, ask the next question, and display analytical assessments.\nDevelop and apply methods to identify, collect, process, and analyze large volumes of data to build and enhance GEOINT processes, and systems.\nProvide support to produce GEOINT web services publication to develop application-ready content, support GEOINT content metadata-tagging to enable content discovery; and publish GEOINT web services.\nImplement ESRI Story Maps in a classified environment.\nWork with ESRI Portal technology to develop and maintain map services.\nSupport and manage geodatabase versioning workflows.\nSupport, manage, and automate geodatabase synchronization workflows.\nRequired Skills:\nActive TS\/SCI CI-Poly Clearance.\nMinimum of a Bachelor\u201a\u00c4\u00f4s Degree or 4+ years of experience.\nDemonstrated advanced proficiency with the following programs:\nPython o ArcGIS, ArcSDE, ArcPro, ArcGIS Online.\nPostgreSQL, Postgis, PgAdmin.\nApplication programming interfaces (APIs).\nDemonstrated advanced proficiency of database principles and technology.\nDemonstrated advanced data transformation skills.\nDemonstrated advanced data processing and analytic skills.\nDemonstrated advanced experience with enterprise geodatabase management.\nDemonstrated advanced experience geodatabase versioning workflows.\nDemonstrated advanced experience with geodatabase synchronization and integration.\nDemonstrated advanced experience with Python (i.e. numpy, pandas, matplotlib libraries).\nDemonstrated advanced experience in SQL and NoSQL technologies.\nDemonstrated advanced experience text parsing.\nDemonstrated advanced experience in metadata tagging (data storage, processing, and & analyzing).\nDemonstrated advanced experience in work with a variety of geospatial data formats.\nDesired Skills:\nDemonstrated experience with JAVA programming language.\nDemonstrated experience with cloud-based database solutions.\nECS is an equal opportunity employer and does not discriminate or allow discrimination on the basis of race, color, religion, gender, age, national origin, citizenship, disability, veteran status or any other classification protected by federal, state, or local law. ECS promotes affirmative action for minorities, women, disabled persons, and veterans.\nECS is a leading mid-sized provider of technology services to the United States Federal Government. We are focused on people, values and purpose. Every day, our 3800+ employees focus on providing their technical talent to support the Federal Agencies and Departments of the US Government to serve, protect and defend the American People.\nShow more\nShow less",
      "job_skills":"Python, ArcGIS, ArcSDE, ArcPro, ArcGIS Online, PostgreSQL, PostGIS, PgAdmin, Application programming interfaces (APIs), SQL, NoSQL, Geodatabase, Geospatial data formats, JAVA, Cloudbased database solutions, Data management, Data analysis, Data visualization, Data manipulation, Statistical analysis, Data integration, Data transformation, Metadata tagging, Geospatial data",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"Zelis",
      "job_location":"Jackson County, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-zelis-3767525941",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Summary\nBuild High level technical design both for Streaming and batch processing systems\nDesign and build reusable components, frameworks and libraries at scale to support analytics data products\nPerform POCs on new technology, architecture patterns\nDesign and implement product features in collaboration with business and Technology stakeholders\nAnticipate, identify, and solve issues concerning data management to improve data quality\nClean, prepare and optimize data at scale for ingestion and consumption\nDrive the implementation of new data management projects and re-structure of the current data architecture\nImplement complex automated workflows and routines using workflow scheduling tools\nBuild continuous integration, test-driven development and production deployment frameworks\nDrive collaborative reviews of design, code, test plans and dataset implementation performed by other data engineers in support of maintaining data engineering standards\nAnalyze and profile data for the purpose of designing scalable solutions\nTroubleshoot complex data issues and perform root cause analysis to proactively resolve product and operational issues\nLead, Mentor and develop offshore Data Engineers in adopting best practices and deliver data products.\nPartner closely with product management to understand business requirements, breakdown Epics,\nPartner with Engineering Managers to define technology roadmaps, align on design, architecture, and enterprise strategy\nRequirements\nMinimum of 8+ years experience with the following:\nSnowflake (Columnar MPP Cloud data warehouse)\nDBT (ETL tool)\nPython\nExperience designing and implementing Data Warehouse\nPreferred Skills\nAzure\/AWS cloud technology\nSQL objects (procedures, triggers, views, functions) in SQL Server. SQL query optimizations\nUnderstanding of T-SQL, indexes, stored procedures, triggers, functions, views, etc.\nDesign and development of Azure\/AWS Data Factory Pipelines preferred.\nDesign and development of data marts in Snowflake preferred\nWorking knowledge of Azure\/AWS Architecture, Data Lake, Data Factory\nBusiness analysis experience to analyze data to write code and drive solutions\nKnowledge of: Git, Azure DevOps, Agile, Jira and Confluence\nIndependence\/ Accountability\nRequires minimal daily supervision\nReceives detailed instruction on new assignments and determines next steps with guidance\nRegularly reviews goals and objectives with supervisor\nDemonstrates competence in relevant job responsibilities which allows for increasing level of independence\nAbility to manage and prioritize multiple tasks\nAbility to work under pressure and meet deadlines\nProblem Solving\nMakes logical suggestions of likely causes of problems and independently suggests solutions\nExcellent organizational skills are required to prioritize responsibilities, thus completing work in a timely fashion\nOutstanding ability to multiplex tasks as required\nExcellent project management and\/or business analysis skills.\nAttention to detail and concern for impact is essential\nAs a leading payments company in healthcare, we guide, price, explain, and pay for care on behalf of insurers and their members. We\u201a\u00c4\u00f4re Zelis in our pursuit to align the interests of payers, providers, and consumers to deliver a better financial experience and more affordable, transparent care for all. We partner with more than 700 payers, including the top-5 national health plans, BCBS insurers, regional health plans, TPAs and self-insured employers, over 4 million providers, and 100 million members, enabling the healthcare industry to pay for care, with care. Zelis brings adaptive technology, a deeply ingrained service culture, and a comprehensive navigation through adjudication and payment platform to manage the complete payment process.\nCommitment to Diversity, Equity,\u201a\u00c4\u00d8Inclusion, and Belonging\nAt Zelis, we champion diversity, equity, inclusion, and belonging in all aspects of our operations. We embrace the power of diversity and create an environment where people can bring their authentic and best selves to work. We know that a sense of belonging is key not only to your success at Zelis, but also to your ability to bring your best each day.\nEqual Employment Opportunity\nZelis is proud to be an equal opportunity employer. All applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\nWe encourage members of traditionally underrepresented communities to apply, even if you do not believe you 100% fit the qualifications of the position, including women, LGBTQIA people, people of color, and people with disabilities.\nAccessibility Support\nWe are dedicated to ensuring our application process is accessible to all candidates. If you are a qualified individual with a disability or a disabled veteran and require a reasonable accommodation with any part of the application and\/or interview process, please email TalentAcquisition@zelis.com\nSCAM ALERT: There is an active nationwide employment scam which is now using Zelis to garner personal information or financial scams. This site is secure, and any applications made here are with our legitimate partner. If you\u201a\u00c4\u00f4re contacted by a Zelis Recruiter, please ensure whomever is contacting you truly represents Zelis Healthcare. We will never asked for the exchange of any money or credit card details during the recruitment process. Please be aware of any suspicious email activity from people who could be pretending to be recruiters or senior professionals at Zelis.\nShow more\nShow less",
      "job_skills":"High level technical design, Streaming systems, Batch processing systems, Reusable components, Frameworks, Libraries, POCs, Technology, Architecture patterns, Product features, Data management, Data quality, Data cleaning, Data preparation, Data optimization, Data ingestion, Data consumption, Data architecture, Automated workflows, Routines, Workflow scheduling tools, Continuous integration, Testdriven development, Production deployment frameworks, Collaborative reviews, Design, Code, Test plans, Dataset implementation, Data engineering standards, Data analysis, Profiling, Scalable solutions, Troubleshooting, Root cause analysis, Product issues, Operational issues, Data engineering, Best practices, Product management, Business requirements, Epics, Technology roadmaps, Design alignment, Architecture alignment, Enterprise strategy, Snowflake, DBT, Python, Data Warehouse, Azure, AWS, SQL objects, SQL query optimization, TSQL, Stored procedures, Triggers, Functions, Views, Data Factory Pipelines, Data marts, Azure Architecture, Data Lake, Business analysis, Git, Azure DevOps, Agile, Jira, Confluence",
      "Category":"Backend Development"
  },
  {
      "job_title":"Azure Data Engineer",
      "company":"TriCom Technical Services",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/azure-data-engineer-at-tricom-technical-services-3768735555",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Azure Data Analyst\/Engineer\nSummary\nOur client is seeking a technically well-versed individual to build and enhance PMI systems and applications. This individual must be comfortable communicating and working directly with clients to find optimal solutions.\nRequirements\nAt least 5 years of experience with ETL tools including Azure Data Factory, FME, or similar.\nExperience integrating multiple data sources using ETL technology or APIs.\nKnowledge of Python libraries including Pandas, NumPy, or C#.NET.\nAt least 5-years of experience with relational or NoSQL databases (SQL Server is highly preferred).\nKnowledge and experience implementing RESTful Web services.\nExperience working in an Agile\/Scrum environment.\nSkill and experience with the following technologies and processes:\nETL;\nPMIS, program\/project management tools, integration, and data management;\nAzure or AWS Cloud;\nCI\/CD and Docker.\nPreferred\nAt least 5-years of experience with SQL Server.\nThis is a 6-Month Contract opportunity with our Kansas City, MO client. Employee benefits include Medical\/Dental Benefits, Paid time off, Paid Holidays, and 401(k) (with immediately-vested company match) available with TriCom during the contract period. H1-B Visa sponsorship is not available for this position. No third-parties, please.\n#onsite\n#hybrid\nShow more\nShow less",
      "job_skills":"Azure Data Factory, FME, ETL, Python, Pandas, NumPy, C#.NET, SQL Server, NoSQL databases, RESTful Web services, Agile, Scrum, PMIS, Program\/project management tools, Integration, Data management, Azure Cloud, AWS Cloud, CI\/CD, Docker",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Engineer",
      "company":"Lockton",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-at-lockton-3754704943",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Your Responsibilities\nWhat\u201a\u00c4\u00f4s the role and Key responsibilities:\nAs a Sr. Data Engineer, you will create and maintain optimal data pipeline architecture, Infrastructure automation (IAC) and also will assemble large, complex data sets that meet functional\/non-functional business requirements across Data Solutions.\nYou will also identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.\nImplement foundational and advanced analytics methodologies to address key metrics to improve customer experience, network performance, quality of service, profitability of products, and personalized offerings\nDelivering technical functionality developed against the Global Lockton Cloud Data Platform's with a Product Mindset.\nUse data, analysis, and automation to generate value within the company through advanced data modeling and other advanced analytics principles\nBuilding the infrastructure required for optimal ETL\/ELT of data from a wide variety of data sources using Cloud Technologies and OnPrem.\nResponsible for helping an organization deliver high data availability and quality throughout the entire data life cycle from ingestion to end products: dashboards, machine learning models, and production datasets.\nThe Successful Applicant\nTechnical Knowledge, Key skills and experience required for the successful candidate:\nHands-on experience with Azure services such as Azure Data Factory, Azure Databricks, ADLS-Delta lake, Azure functions, Logic aps, Synapse, Azure Logic Apps, Azure Storage, Azure Search, Purview, Azure SQL server, Scala\/Spark\/SQL\/PYTHON etc.\nAzure Database development experience with Infra as a Code, Azure CI\/CD, Azure Classic Pipelines, Azure YAML, ARM\/Terraforms\/Ansible, AKS\nMaintenance, Azure ML, Pipeline integrations, Azure PaaS and IaaS, Azure Infra Experience (Spinning VM's, Databases and Cosmos)\nExpertise in Data warehousing - data modelling, relational and Dimension modelling, Data quality, data catalog and Data Governance\nDesign and build highly scalable data pipelines using new generation tools and technologies like Spark, Kafka to induct data from various systems\nExperience with data security and data access controls and design across digital transformation\/cloud migration programs.\nDeep understanding of relational as well as NoSQL data stores, methods and approaches (star and snowflake, dimensional modelling)\nEnsure proper requirement traceability and Quality delivery during development and integration testing\nA strong background in the Microsoft SQL Server stack (including SSIS, SSRS, Power BI, and SSAS)\nAbility to build processes supporting data transformation, data structures, metadata, dependency, and workload management.\nStrong analytic skills related to working with structured and unstructured datasets\nShould support the Production live application by maintaining 100% Data accuracy and data availability in all 24*7.\nQualifications\nRequired Experience:\nMinimum of 7+ years of increasingly responsible experience in Data Platforms, Data Engineering, Software Engineering at high impactful and changing environments\n4+ years of working experience in Azure or cloud platforms as Solution\/Data Architect\/Data Engineer\n4+ years of hands-on experience with one or more cloud technologies such as Azure, AWS, Google.\nExperience in collaborating with a high-profile team of Data Engineers, data scientists, Business Analytics and Data Analysts\nKnowledge of Software development agile methodologies and worked in Scrum teams\nExcellent communication & presentation skills with a track record of engaging with senior business leaders\nExperience in Finance\/Insurance would be a distinct advantage\nShould have worked in a dynamic and fast-changing environment\nHigh affinity with AI-powered insight tools and engines and application of real-time solutions to analytics problems\nExperience with GEN AI and LLM's will be added advantage\nExposure to COGS\/KTLO, Operations and Command Center activity\nSoft Skills Required\nGood communication and presentation skills\nHighly driven, energetic, flexible, resourceful & ability to multitask\nClarity of thoughts and vision\nAbility to ideate and bring solutions to the table\nAdherence to timelines, without sacrificing the quality of output\nHands-on and detail-oriented, with a strong ability to coordinate across different Geographies and with different stakeholders\nAcademics\nGraduate degree in Engineering, Computer Science, Management Information Systems, or related\nStrong exposure to Databases and data structures of cloud-based technologies\nAzure\/GCP\/AWS Solution Architect certification or Data Engineer certification is plus\nCareer progression:\nReceive ongoing support and funding towards your personal learning and development, including coverage for relevant courses and certifications in data related fields. Lockton prides itself on offering outstanding career progression programs for those who wish to progress in their field of interest, be it in a Technical or Leadership capacity.\nShow more\nShow less",
      "job_skills":"Azure Data Factory, Azure Databricks, ADLSDelta lake, Azure functions, Logic aps, Synapse, Azure Logic Apps, Azure Storage, Azure Search, Purview, Azure SQL server, Scala\/Spark\/SQL\/PYTHON, Infra as a Code, Azure CI\/CD, Azure Classic Pipelines, Azure YAML, ARM\/Terraforms\/Ansible, Maintenance, Azure ML, Pipeline integrations, Azure PaaS, Azure IaaS, Data warehousing, Data modelling, Relational modelling, Dimension modelling, Data quality, Data catalog, Data Governance, Spark, Kafka, Data security, Data access controls, NoSQL data stores, Star and snowflake, Dimensional modelling, SSIS, SSRS, Power BI, SSAS, Data transformation, Data structures, Metadata, Dependency management, Workload management, Data accuracy, Data availability, Agile methodologies, Scrum teams, AIpowered insight tools, Realtime solutions, GEN AI, LLM's, COGS\/KTLO, Operations, Command Center",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Conversion Developer, Senior Associate",
      "company":"PwC",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-conversion-developer-senior-associate-at-pwc-3749937532",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nFunctional & Industry Technologies\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 80%\nA career within Functional and Industry Technologies services will provide you with the opportunity to build secure and new digital experiences for customers, employees, and suppliers. We focus on improving apps or developing new apps for traditional and mobile devices as well as conducting usability testing to find ways to improve our clients\u201a\u00c4\u00f4 user experience. Our team helps clients transform their business through enabling technologies across marketing, finance and operations in the functional areas such as Maximo and PowerPlant.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nBasic Qualifications\nMinimum Degree Required:\nBachelor Degree\nMinimum Years Of Experience\n4 years\nPreferred Qualifications\nDegree Preferred:\nMaster Degree\nCertification(s) Preferred\nAzure Data Engineer Associate\nDatabricks Certified Data Engineer Associate\nPreferred Fields Of Study\nComputer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology\nPreferred Knowledge\/Skills\nDemonstrates a thorough level of abilities with, and\/or a proven record of success as both an individual contributor and team member, identifying and addressing client needs:\nSupports in data analysis techniques to assess source data structures, identify mapping requirements, and define transformation rules for data conversion into Maximo;\nLeads Maximo's modules and functionalities related to Asset Management and Work Order Management and IBM Maximo, including its data structures, configuration settings, and integration capabilities;\nIdentifies relational databases, preferably experience in working with databases commonly used in Maximo, such as IBM DB2, Oracle, Microsoft SQL Server, along with familiarity with Maximo's Integration Framework (MIF) and its capabilities for data integration and conversion;\nSupports in designing and implementing data extraction, transformation, and loading processes for Maximo data conversion;\nShowcases understanding in SQL and database querying languages to extract and manipulate data from source systems along with understanding ETL tools and methodologies commonly used in Maximo data conversion;\nIdentifies technologies commonly used with Maximo, including web services (SOAP, RESTful APIs), XML, JSON, and other relevant data exchange formats;\nSupports in pipeline architecture and development using one of the tools such as Azure ADF, AWS Glue, SSIS, DataBricks (multiple preferred);\nUtilizes data cleansing techniques and methodologies to ensure the integrity and accuracy of converted data in Maximo;\nDevelopes data cleansing functional business rules as per Maximo Business Object (MBO) definitions for source to Maximo conversion requirements;and comprehensive testing plans and executing validation processes to verify the accuracy and integrity of converted data in Maximo;\nCustomizes Maximo options, such as Automation Scripts, Java Customizations, Database Configuration, or Application Designer, to support data conversion requirements;\nIdentifies integrations within Maximo with other enterprise systems, such as ERP systems, GIS systems, or asset management systems. Knowledge of integration patterns, data synchronization, and data exchange protocols; and,\nShowcases work experience as a Data Engineer, Data Architect or similar role, along with experience in programming languages including Python, PySpark, Scala, SQL.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-advisoryseniorassociate\nShow more\nShow less",
      "job_skills":"IBM Maximo, Azure Data Engineer Associate, PowerPlant, SQL, Oracle, AWS Glue, Python, PySpark, Scala, XML, JSON, ERP, GIS, Salesforce, Data Analysis, ETL, Data Conversion, Data Integration, Data Extraction, Data Transformation, Database querying, Database Configuration, Application Designer, Data Cleansing, Java, Maximo Business Object (MBO), SOAP, RESTful APIs",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Conversion Developer, Senior Associate",
      "company":"PwC",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-conversion-developer-senior-associate-at-pwc-3749936650",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nFunctional & Industry Technologies\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 80%\nA career within Functional and Industry Technologies services will provide you with the opportunity to build secure and new digital experiences for customers, employees, and suppliers. We focus on improving apps or developing new apps for traditional and mobile devices as well as conducting usability testing to find ways to improve our clients\u201a\u00c4\u00f4 user experience. Our team helps clients transform their business through enabling technologies across marketing, finance and operations in the functional areas such as Maximo and PowerPlant.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nBasic Qualifications\nMinimum Degree Required:\nBachelor Degree\nMinimum Years Of Experience\n4 years\nPreferred Qualifications\nDegree Preferred:\nMaster Degree\nCertification(s) Preferred\nAzure Data Engineer Associate\nDatabricks Certified Data Engineer Associate\nPreferred Fields Of Study\nComputer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology\nPreferred Knowledge\/Skills\nDemonstrates a thorough level of abilities with, and\/or a proven record of success as both an individual contributor and team member, identifying and addressing client needs:\nSupports in data analysis techniques to assess source data structures, identify mapping requirements, and define transformation rules for data conversion into Maximo;\nLeads Maximo's modules and functionalities related to Asset Management and Work Order Management and IBM Maximo, including its data structures, configuration settings, and integration capabilities;\nIdentifies relational databases, preferably experience in working with databases commonly used in Maximo, such as IBM DB2, Oracle, Microsoft SQL Server, along with familiarity with Maximo's Integration Framework (MIF) and its capabilities for data integration and conversion;\nSupports in designing and implementing data extraction, transformation, and loading processes for Maximo data conversion;\nShowcases understanding in SQL and database querying languages to extract and manipulate data from source systems along with understanding ETL tools and methodologies commonly used in Maximo data conversion;\nIdentifies technologies commonly used with Maximo, including web services (SOAP, RESTful APIs), XML, JSON, and other relevant data exchange formats;\nSupports in pipeline architecture and development using one of the tools such as Azure ADF, AWS Glue, SSIS, DataBricks (multiple preferred);\nUtilizes data cleansing techniques and methodologies to ensure the integrity and accuracy of converted data in Maximo;\nDevelopes data cleansing functional business rules as per Maximo Business Object (MBO) definitions for source to Maximo conversion requirements;and comprehensive testing plans and executing validation processes to verify the accuracy and integrity of converted data in Maximo;\nCustomizes Maximo options, such as Automation Scripts, Java Customizations, Database Configuration, or Application Designer, to support data conversion requirements;\nIdentifies integrations within Maximo with other enterprise systems, such as ERP systems, GIS systems, or asset management systems. Knowledge of integration patterns, data synchronization, and data exchange protocols; and,\nShowcases work experience as a Data Engineer, Data Architect or similar role, along with experience in programming languages including Python, PySpark, Scala, SQL.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-advisoryseniorassociate\nShow more\nShow less",
      "job_skills":"Azure Data Engineer Associate, Databricks Certified Data Engineer Associate, Maximo, PowerPlant, Python, PySpark, Scala, SQL, Azure ADF, AWS Glue, SSIS, DataBricks, SOAP, RESTful APIs, XML, JSON, Automation Scripts, Java Customizations, Database Configuration, Application Designer, ERP, GIS, Data Engineer, Data Architect",
      "Category":"Backend Development"
  },
  {
      "job_title":"Big Data Engineer",
      "company":"ICONMA",
      "job_location":"O'Fallon, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-engineer-at-iconma-3762690948",
      "search_city":"Missouri",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Big Data Engineer\nLocation: OFallon, MO\nDuration: 12 months with Possible Extension\/ with Possible Contract to hire\nDescription:\nAs a Senior Software Engineer in Data Platform & Engineering Services team, youll hold a valued role within a rapidly growing team inside one of the worlds most successful organizations, working closely with experienced and passionate engineers to solve problems customer problem.\nYou will be partnering with the data engineering teams, so the ability to influence and provide operational guidance is key.\nInitially, the Developer focus will be contributing to the development of operational tools and practices that help maintain service availability across hosted and cloud-based infrastructure.\nYou must understand the full stack and how systems are built as well as a grasp of operational best practices.\nRole:\nAs a member of the Unified Data Acquisition and Processing (UDAP) platform team, you will be responsible for building tools and systems that deploy and scale our applications and data in hybrid cloud and physical environments.\nWe enable the platform that helps teams across multiple programs to build, test, deploy and host hundreds of data pipelines across several global datacenters along with enterprise logging, monitoring and vulnerability detection.\nAll about You\/Experience:\nExperience in Data Warehouse related projects in product or service based organization\nExperience solving for Scalability, Performance and Stability\nExperience in a programming language in Java, Scala or Python\nExperience working in SQL and relational databases\nOperational experience in Big Data Stacks (Spark and Hadoop ecosystem)\nExpert knowledge of Linux operating systems and environment and Scripting\nA deep expertise in your field of Software Engineering\nExpert at troubleshooting complex system and application stacks\nOperational experience in Elastic Search (ELK stack) would be a plus\nOperational experience troubleshooting network\/server communication is a plus\nMotivation, creativity, selfdirection, and desire to thrive on small project teams\nStrong written and verbal English communication skills\nWhat is the name of your group? How does that fit into the overall Client organization :\nData Enablement team, UDAPP Unified Data Acquisition and Processing Platform\nWhat program will this person be supporting? Will this person be a part of a Guild If so, which one and how will they be contributing:\nYes, SDE\nWhat is your teams main responsibility:\nOur team is responsible for building out data pipelines and processes for data movement from sources to their new warehouse.\nHow would you describe the culture of your team:\nWhat we look for is the person should be able to self research and can be autonomous in this position.\nCannot depend on others to perform their work.\nNeed the ability to research by oneself.\nThey would work with product owners (data scientist) and enterprise architecture team, and data engineers.\nWould you please describe your management style:\nHands on because was in a technical position previously, has thorough understanding.\nIt's a small team but we all have great knowledge and experience.\nI'm open for all suggestions and changes to streamline\/reorganize our approach to grow the business.\nWe are building this platform and scaling it, but now we have lots of demand to use our platform.\nWe are trying to take it to the next phase, and produce an additional platform to process cloud processing.\nWhat will a typical work day look like for this contractor:\nWe do an alternating standup schedule, and their daily work will depend on their story.\nWhat are your top 3 required technical skills :\nJava\nHadoop\nSpark\nWhat are a couple of desired\/nice to have skills:\nCloud Applications such as Azure and\/or AWS\nWhat soft skills would you like to see in a candidate:\nAbility to research\nWork autonomous\nWilling to learn\nWhat level of competency is required :\nIntermediate to Advanced\nShow more\nShow less",
      "job_skills":"Java, Hadoop, Spark, SQL, Linux, Scripting, Software Engineering, Troubleshooting, Elastic Search (ELK stack), Cloud Applications, Azure, AWS",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer",
      "company":"TDK Technologies, LLC",
      "job_location":"O'Fallon, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-at-tdk-technologies-llc-3775478936",
      "search_city":"Missouri",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description:\nExperience dealing with large volumes of data, from various sources, both structured and unstructured.\nAbility to triage and talk through performance \/ scaling issues of dealing with data at scale.\nGood understanding of how data will be read (file formats, partitioning, bucketing).\nExtensive experience writing testable jobs using Spark (or equivalent) framework.\nProgramming & Scripting Languages: Java EE, Scala, Spark, SQL, Bash.\nWeb services & API standards: REST, OAuth, JSON.\nSoftware Architectures (micro-services, event driven, peer-to-peer).\nApplication Security.\nAsynchronous Pub-Sub and Point to Point Messaging Systems.\nAdvantage, if you have experience working in ETL and Hadoop Ecosystem: HBase, Solr, Spark Streaming, Kudu, Spring Boot, Spring Context, Spring Data Rest, General Cloudera experience.\nStreaming within the Hadoop ecosystem is a plus.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Processing, Data Warehousing, ETL, Hadoop, HBase, Kudu, Apache Spark, Solr, Spark Streaming, Java EE, Scala, SQL, Bash, REST, OAuth, JSON, Microservices, Eventdriven Architecture, PeertoPeer, Application Security, PubSub, PointtoPoint Messaging, Spring Boot, Spring Context, Spring Data Rest, Cloudera",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Bayer",
      "job_location":"Chesterfield, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-bayer-3785832331",
      "search_city":"Cahokia",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Senior Data Engineer for Chesterfield, MO to lead design & implementation of data processing, storage and delivery solutions; define strategies & engineering guidelines for major data platforms; identify data solutions to meet business capability needs & processes; participate in code reviews, testing & retrospectives; create & maintain design and code documentation; develop project estimates; collaborate with cross-functional IT stakeholders to align roadmaps, delivery dates & integration activities; ensure internal standards are met & drive improvements to internal processes; evaluate new technologies & languages for company use; lead conversations with product management stakeholders; mentor & coach junior team members. Requires Master\u201a\u00c4\u00f4s in C.S., I.T., M.I.S., Computer or Software Engineering or closely-related field & 3 yrs experiencein IT-related position(s): engineering data-intensive software using streaming & resource-based design principles; working with NoSQL databases, including Google BigQuery; using object-oriented and\/or functional programming languages, including Java, Python, Scala and\/or Go; modeling & developing data architecture; designing logical & physical models for datasets; working with relational databases, including Postgres, MySQL and\/or Oracle; modeling large datasets in distributed databases; working with Platform-as-a-Service software, including Cloud Foundry and\/or Kubernetes; using Spark and\/or Kafka for stream processing; applying machine learning methodologies to develop data solutions; using Cloud technologies, including AWS & Google Cloud Platform; and modeling orchestration using Apache AirFlow. Will also accept Bachelor\u201a\u00c4\u00f4s in said fields & 5 yrs progressive post-Bachelor\u201a\u00c4\u00f4s stated experience. Telecommuting permitted from home office location within reasonable commuting distance of Chesterfield, MO up to 2 days per week. Mail resume to Cascinda Fischbeck, Bayer Research and Development Services LLC, 800 N. Lindbergh Blvd. E2NE, St. Louis, MO 63167 or email resume to careers_us@bayer.com. Include reference code below with resume.\nBayer Research & Development Services LLC is an Equal Opportunity Employer\/Disabled\/Veterans\nBayer Research & Development Services LLC is committed to providing access and reasonable accommodations in its application process for individuals with disabilities and encourages applicants with disabilities to request any needed accommodation(s) using the contact information below.\nIf you meet the requirements of this unique opportunity, and want to impact our mission Science for a better life, we encourage you to apply now. Job postings will remain open for a minimum of ten business days and are subject to immediate closure thereafter without additional notice.\nDivision:\nCrop Science\nReference Code\n806556\nFunctional Area:\nAPD\nLocation:\nChesterfield, MO\nEmployment Type:\nRegular\nPosition Grade:\nContact Us\nAddress Telephone E-Mail\nCreve Coeur, MO\ncareers_us@bayer.com\n63167\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Processing, Data Storage, Data Delivery, Data Platforms, Data Architecture, Data Solutions, Business Capability Needs, Code Reviews, Testing, Retrospectives, Design Documentation, Project Estimates, CrossFunctional Collaboration, Roadmaps, Delivery Dates, Integration Activities, Internal Standards, Process Improvement, Technology Evaluation, Product Management, Mentoring, Coaching, Java, Python, Scala, Go, NoSQL Databases, Google BigQuery, ObjectOriented Programming, Functional Programming, Logical Models, Physical Models, Datasets, Relational Databases, Postgres, MySQL, Oracle, Distributed Databases, PlatformasaService Software, Cloud Foundry, Kubernetes, Spark, Kafka, Stream Processing, Machine Learning, Cloud Technologies, AWS, Google Cloud Platform, Apache AirFlow",
      "Category":"Backend Development"
  },
  {
      "job_title":"Cloud Data Engineer",
      "company":"Kelly",
      "job_location":"Bridgeton, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/cloud-data-engineer-at-kelly-3778866801",
      "search_city":"East Saint Louis",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Kelly Technology is seeking a Cloud Data Engineer to work with our premier client in the St. Louis. MO area.\nCloud Data Engineer\nBridgeton, Missouri\nFull Time\/Direct Hire\nsorry no C2C or relocation.\nOur premier client is the global industry leader in wheel alignment, wheel balancing, and vehicle inspection systems, as a Cloud Data Engineer based at our headquarters in St. Louis, Missouri. We are seeking a candidate with a passion for creating robust and scalable cloud data architectures.\nQualifications:\n\u00ac\u2211 Strong knowledge of SQL and data modeling techniques.\n\u00ac\u2211 Proven experience with cloud data services such as Azure SQL Databases\/Amazon RDS, Azure Data Factory\/AWS Glue, Azure or AWS Data Lake, or Google Cloud equivalents.\n\u00ac\u2211 Familiarity with Airflow and Python.\n\u00ac\u2211 Proficiency in Linux systems.\n\u00ac\u2211 Excellent problem-solving skills and attention to detail.\n\u00ac\u2211 Good communication skills and the ability to work collaboratively.\nResponsibilities:\nAs a Cloud Data Engineer, you will:\n\u00ac\u2211 Design, develop, and maintain reliable, scalable data infrastructure solutions using cloud services.\n\u00ac\u2211 Monitor, troubleshoot, and resolve issues within data operations infrastructure.\n\u00ac\u2211 Collaborate with the data engineering team, data scientists, and application developers to build maintainable solutions that meet business requirements.\n\u00ac\u2211 Ensure data privacy and compliance standards are met.\n\u00ac\u2211 Stay updated on the latest Microsoft data technologies and best practices.\n\u00ac\u2211 Drive technology direction by making recommendations based on experience and research.\n\u00ac\u2211 Create test plans and validation controls.\nAdditional Qualifications:\n\u00ac\u2211 Bachelor\u201a\u00c4\u00f4s degree in a computer-related field strongly preferred; equivalent combination of education and experience considered.\n\u00ac\u2211 5+ years of relevant experience required.\n\u00ac\u2211 Relevant Cloud or Data Engineering certifications.\n\u00ac\u2211 Experience with Software Development Life Cycle and DevOps.\n\u00ac\u2211 Familiarity with monitoring tools like Datadog.\n\u00ac\u2211 Experience with data and computing tools, including Airflow, dbt, and messaging queues like Kafka.\n\u00ac\u2211 Experience working on real-time data and streaming applications.\n#TJP2023-SPEC\nShow more\nShow less",
      "job_skills":"SQL, Data modeling, Cloud data services, Azure SQL Databases, Amazon RDS, Azure Data Factory, AWS Glue, Azure Data Lake, AWS Data Lake, Google Cloud, Airflow, Python, Linux, Problemsolving skills, Attention to detail, Communication skills, Collaboration skills, Data infrastructure solutions, Data operations infrastructure, Data engineering, Data science, Application development, Data privacy, Compliance standards, Microsoft data technologies, Best practices, Technology direction, Software Development Life Cycle, DevOps, Monitoring tools, Datadog, Data and computing tools, Messaging queues, Kafka, Realtime data, Streaming applications",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist - National Defense\/Python\/SQL\/AWS\/MLOps\/Clearances",
      "company":"Motion Recruitment",
      "job_location":"Laughlin AFB, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-national-defense-python-sql-aws-mlops-clearances-at-motion-recruitment-3732144864",
      "search_city":"Del Rio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"An Artificial Intelligence\/National Defense start-up is searching for Data Scientists to join their team. You would be solving complex problems by being a systems-level thinker, all the while transforming the nation\u201a\u00c4\u00f4s defense and national security. This team handles abstract problems regarding the public policy surrounding climate change, energy, and national security, among other pressing issues.\nSome of your responsibilities would include discovering datasets that could help in solution development; curating data, analyzing, and performing quantitative modeling; validating the quality of data, models, and results; deploying and implementing solutions in collaboration with product team; and interacting with the product team on current and upcoming user requirements.\nRequired Skills & Experience\nMasters or Ph.D. in Sciences, Mathematics or Engineering, especially numerical methods and simulations\nAt least 4 years of professional experience in a Data Scientist position\nPython (pandas, numpy, scipy, sci-kit learn, etc)\nSQL \/ MySQL\nCloud computing, preferably in an AWS environment\nLarge-scale data processing and implementing batch processing pipelines in HPC or cloud architecture\nActive government clearance (secret, top secret, ts\/sci - no Poly required)\nWhat You Will Be Doing\nDaily Responsibilities\n70% Hands On\n30% Team Collaboration\nThe Offer\nBonus eligible\nYou Will Receive The Following Benefits\nFull medical, dental, vision coverage for employee and dependents\n401k matching program\nPTO and Holidays\nBonus and other incentive programs\nAccess to mental health program\nAccess to Flexible Spending Accounts for Health Care, Dependent and Commuter\nApplicants must be currently authorized to work in the US on a full-time basis now and in the future. Possession of at minimum a Secret Clearance is required.**\nPosted By:\nLindsay Troyer\nShow more\nShow less",
      "job_skills":"Data Science, Numerical Methods, Simulations, Python, Pandas, Numpy, Scipy, Scikit Learn, SQL, MySQL, Cloud Computing, AWS, LargeScale Data Processing, Batch Processing Pipelines, HPC, Government Clearance, HandsOn Work, Team Collaboration, Bonus Eligibility, Full Medical Dental Vision Coverage, 401k Matching Program, PTO, Holidays, Bonus and Incentive Programs, Mental Health Program, Flexible Spending Accounts",
      "Category":"Backend Development"
  },
  {
      "job_title":"Staff Data Engineer",
      "company":"Fig - Food Is Good",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/staff-data-engineer-at-fig-food-is-good-3734114597",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Fig is building a digital food-as-medicine platform to help anyone with complex dietary needs live an easier, healthier life around food. We're a fast-growing, early-stage startup supporting over 800,000 users and backed by top VCs including Sequoia, Artis Ventures, Goodwater Capital, and Correlation Ventures. Our users love us (4.8 stars on app stores) as Fig changes their lives: \"THANK YOU!! It is sometimes such a struggle to find PCOS-compliant snacks, ingredients, etc. This app has truly changed my life in the 2 weeks I\u201a\u00c4\u00f4ve had it!\u201a\u00c4\u00f9\nFig\u201a\u00c4\u00f4s mission is to help millions of people with dietary restrictions more easily find food. Our core product, the Fig phone app, already helps hundreds of thousands of people navigate food at grocery stores and restaurants each month.\nOur company is seeking a highly skilled Data Engineer with extensive experience in building data ingestion, processing, and instrumentation systems at scale.\nWhat You Will Do\nAs a Data Engineer at Fig, you will:\nDesign, develop, and maintain our data architecture, data models, ETL pipelines, and data warehouse.\nCollaborate with cross-functional teams to identify business needs and translate them into data solutions.\nImplement and optimize data ingestion processes from multiple data sources for real-time analytics and business intelligence.\nSet up orchestration engines to run data ingestion processes in the cloud.\nMonitor, troubleshoot, and optimize the performance of data pipelines and database systems.\nAssist in developing data governance and data quality processes and ensure compliance with data privacy and security policies.\nStay up-to-date with the latest technologies and trends in the data engineering field.\nQualifications\nWho you are:\nAt least 3-5 years of professional experience in data engineering or related roles.\nProficiency in SQL and Python and experience with ETL tools.\nExperience with cloud platforms (AWS, GCP, Azure)\nSolid understanding of database design, data warehousing concepts, and data modeling.\nProven ability to build and maintain data pipelines and deliver high-quality data solutions.\nStrong problem-solving skills, analytical capabilities, and attention to detail.\nExcellent communication skills to collaborate with diverse teams.\nEXTREME attention-to-detail, efficiency, competence and a desire to get things right the first time (our users are counting on you!)\nStellar references\nNice To Haves\nExperience with web scraping at scale\nPersonal experience with dietary restrictions (either yourself or a loved one); navigating tricky dietary needs is a daunting task, and prior understanding of these challenges will be helpful.\nHow We Work\nFig is a fully remote team. We generally work US hours, with most of our meetings happening between 12-5 PM EST. We speak and write in English and generally expect employees to be proficient in communicating in English. That said, we don\u201a\u00c4\u00f4t have a strict geographic requirement if you are willing to work within those constraints. We expect this role to integrate into our software development lifecycle and join team meetings for sprint planning, retrospectives, and review.\nWhat We Offer\nCompetitive salary\nBe part of building company culture\nFor full-time employees:\nMeaningful equity in the form of stock options\n401(k) plan\nMedical, Dental, and Vision Insurance\nFlexible time off and paid holidays\nHow To Apply\nPlease reach out to\nrecruiting@foodisgood.com\nwith a resume or any questions. If we are interested, we will schedule an introductory call to get to know you more!\nShow more\nShow less",
      "job_skills":"Data engineering, ETL pipelines, Data architecture, Data models, SQL, Python, Data ingestion, Realtime analytics, Business intelligence, Cloud platforms, Database design, Data warehousing, Data quality, Data privacy, Data security, Data governance, Problemsolving, Analytical capabilities, Attention to detail, Communication, Teamwork, Web scraping",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Engineer",
      "company":"Inceed",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-at-inceed-3786531568",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Compensation:\n$140000\nLocation:\nHouston, TX\nSr. Data Engineer\nInceed has partnered with a great company to help find a skilled\nSr. Data Engineer\nto join their team!\nWe are looking for a talented and motivated Data Engineer to join our team. As a Data Engineer, you will be responsible for designing, developing, and maintaining the data architecture, infrastructure, and tools necessary for optimal extraction, transformation, and loading (ETL) of data from various sources to support our organization's data-driven initiatives.\nResponsibilities:\nData Pipeline Development:\nDesign, implement, and maintain scalable and efficient data pipelines for the extraction, transformation, and loading of data from diverse sources.\nCollaborate with cross-functional teams to understand data requirements and ensure the smooth flow of data between systems.\nData Modeling and Schema Design:\nDevelop and implement data models and schemas to support efficient storage and retrieval of structured and unstructured data.\nOptimize database performance and ensure data integrity.\nETL Process Optimization:\nContinuously improve and optimize ETL processes for better efficiency and reliability.\nImplement monitoring and logging mechanisms to identify and address issues in a timely manner.\nData Integration:\nIntegrate data from various sources to create a unified and comprehensive view of enterprise data.\nWork with data architects to ensure data integration solutions align with overall data architecture goals.\nDatabase Management:\nAdminister and maintain databases, ensuring high availability, security, and performance.\nCollaborate with database administrators to implement best practices for data storage and retrieval.\nData Quality Assurance:\nImplement data quality checks and validation processes to ensure accuracy and consistency of data.\nCollaborate with data stewards and business users to resolve data quality issues.\nCollaboration:\nCollaborate with data scientists, analysts, and other stakeholders to understand their data needs and provide timely and accurate data solutions.\nParticipate in cross-functional teams to contribute technical expertise to overall data strategy.\nDocumentation:\nCreate and maintain documentation for ETL processes, data models, and database architecture.\nDevelop and share best practices for data engineering within the organization.\nRequired Qualifications & Experience:\nBachelor's or Master's degree in Computer Science, Information Technology, or a related field.\nProven experience as a Data Engineer or in a similar role.\nProficiency in programming languages such as Python, Java, or Scala.\nExperience with ETL tools and frameworks (e.g., Apache NiFi, Apache Beam, Talend).\nStrong SQL skills and expertise in working with relational and NoSQL databases.\nFamiliarity with cloud platforms and services (e.g., AWS, Azure, Google Cloud).\nKnowledge of data warehousing concepts and technologies.\nExcellent problem-solving and analytical skills.\nPerks & Benefits:\nHealth, Dental, Vision and Life Insurance\n401k matching\nBonus\nOther Information:\nHybrid work schedule\nIf you are interested in learning more about the Sr. Data Engineer opportunity, please submit your resume for consideration. Our client is unable to provide sponsorship at this time.\nWe are Inceed, a staffing and direct placement firm who believes in the possibility of something better. Our mission is simple: We\u201a\u00c4\u00f4re here to help every person, whether client, candidate, or employee, find and secure what\u201a\u00c4\u00f4s better for them.\nInceed is an equal opportunity employer. Inceed prohibits discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.\nShow more\nShow less",
      "job_skills":"Python, Java, Scala, Apache NiFi, Apache Beam, Talend, SQL, Relational databases, NoSQL databases, AWS, Azure, Google Cloud, Data warehousing, ETL, Data modeling, Data integration, Database management, Data quality assurance, Collaboration, Documentation",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Engineer",
      "company":"MHK TECH INC",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-at-mhk-tech-inc-3769086257",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Sr. Data Engineer\nLocation: REMOTE\nPosition Type: Contract( Only W2)\nResponsibilities\nDesigning and implementing large-scale, distributed data processing systems using technologies such as Apache Hadoop, Apache Spark, or Apache Flink.\nDeveloping and optimizing data pipelines and workflows for ingesting, storing, processing, and analyzing large volumes of structured and unstructured data.\nCollaborating with data scientists, data analysts, and other stakeholders to understand data requirements and translate them into technical solutions.\nBuilding and maintaining data infrastructure, including data lakes, data warehouses, and real-time streaming platforms.\nDesigning and implementing data models and schemas for efficient data storage and retrieval.\nEnsuring the scalability, availability, and fault-tolerance of big data systems through proper configuration, monitoring, and performance tuning.\nIdentifying and evaluating new technologies, tools, and frameworks to improve the efficiency and effectiveness of big data processing.\nImplementing data security and privacy measures to protect sensitive information throughout the data lifecycle.\nCollaborating with cross-functional teams to integrate data from various sources, including structured databases, unstructured files, APIs, and streaming data.\nDeveloping and maintaining documentation, including data flow diagrams, system architecture, and technical specifications.\nRequirements\nBachelor's or higher degree in Computer Science, Engineering, or a related field.\nProven experience as a big data engineer or a similar role, with a deep understanding of big data technologies, frameworks, and best practices.\nStrong programming skills in languages such as Java, Scala, or Python for developing big data solutions.\nExperience with big data processing frameworks like Apache Hadoop, Apache Spark, Apache Flink, or similar.\nProficiency in SQL and NoSQL databases, as well as data modeling and database design principles.\nFamiliarity with cloud platforms and services, such as Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP).\nKnowledge of distributed computing principles and technologies, such as HDFS, YARN, and containerization (e.g., Docker, Kubernetes).\nUnderstanding of real-time streaming technologies and frameworks, such as Apache Kafka or Apache Pulsar.\nStrong problem-solving skills and ability to optimize and tune big data processing systems for performance and scalability.\nExcellent communication and teamwork skills to collaborate with cross-functional teams and stakeholders.\nShow more\nShow less",
      "job_skills":"Apache Hadoop, Apache Spark, Apache Flink, Data pipelines, Data infrastructure, Data warehouses, Data security, Data privacy, Java, Scala, Python, SQL, NoSQL, Cloud platforms, Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), HDFS, YARN, Docker, Kubernetes, Apache Kafka, Apache Pulsar, Realtime streaming, Distributed computing, Problemsolving skills, Communication skills, Teamwork skills",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Engineer (1000983)",
      "company":"The Judge Group",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-1000983-at-the-judge-group-3717698301",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Location:\nDallas, TX\nSalary:\n$140,000.00 USD Annually - $160,000.00 USD Annually\nDescription:\nOur client is currently seeking local Sr. Data Engineers in Plano, TX. Please apply!\nJava\/Python developer on Hadoop\/Spark\/Big Data platform with AWS experience preferably on EMR, EKS, Glue, Lake Formation. (6+ years of experience)\nW2 ONLY-No sponsorship or 3rd parties\nHYBRID- 3 Days on-site in Houston, TX or in Plano, TX\nContact:\njfahs@judge.com\nThis job and many more are available through The Judge Group. Find us on the web at www.judge.com\nShow more\nShow less",
      "job_skills":"Java, Python, Hadoop, Spark, Big Data, AWS, EMR, EKS, Glue, Lake Formation",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Analyst",
      "company":"Spruce Power",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-spruce-power-3787722493",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"THE POSITION: Sr. Data Analyst\nResponsible for performing analysis and generating actionable recommendations for improving performance in a leading residential solar energy services company.\nReports to the Business Intelligence Manager and conducts advanced analysis of data to arrive at insights that drive tactical and strategic efforts. The analyst is expected to work closely with the solar asset operations team and the external data service provider to proactively monitor and detect\/diagnosis underperforming solar systems. He\/she is also expected to create\/automate weekly, monthly and ad hoc reports as well as perform analysis to guide data-driven business decisions.\nThe ability to dive deep into data to arrive at insights that inform tactical and strategic efforts is required. The role also requires an attention to detail and the aptitude to tell a complete, compelling and actionable story through data and analysis.\nKey responsibilities include:\nGenerate and maintain reports to track solar system performance on a weekly, monthly, and quarterly basis\nExtract, parse and translate large production data sets into meaningful reports\nWork closely with various data service providers, maintain data quality and maintain\/improve automated dispatch system\nEscalate technical support issues to internal and external resources\nUtilize advanced analytics to drive new insights from various data sets and help generate actionable steps for improving solar system performance\nDefine, document and calculate Key Performance Indicators (KPIs) and methods for tracking these KPIs for internal and external stakeholders\nGenerate and publish reports and visualizations with Power BI and\/or other applications to be used by management for informed decision making and tracking performance\nCreate and present analysis to upper management and other key internal and external stakeholders\nAssist in identifying and advancing Business Intelligence and Analytical capabilities and functionality thought out the organization\nPerforms other duties as assigned\nQualifications\nDeep experience with Power BI software\nProven focus on and experience with generating actionable recommendations through data-driven analysis\nAbility to understand how data maps to business processes and to make recommendations on how to adjust procedures to gain efficiencies, increase quality or improve service\nAbility to communicate clearly and succinctly\nProven experience with a combination of SQL, SSRS, SSAS, Power BI, Excel\nAbility to write complex SQL queries and work with Sql Server relational databases\nStrong Power Point presentation skills\nExperience with programming languages including Python and R are preferred, but not required\nExperience in data management and data quality concepts, practices and services\nExperience with various file formats (XML, CSV, etc.)\nOutstanding organizational, analytical and facilitation skills.\nExperience with Microsoft Office Suite\u201a\u00c4\u00b6Excel, Word and PowerPoint\nFamiliarity with Azure Cloud is preferred, but not required\nExperienced with Data Warehouse concepts and practices\nFamiliar with ETL and data transfer concepts and capabilities\nAuthorized to work in the United States\nExperience in solar industries a plus\nEDUCATION\nMinimum of a Bachelor's degree or equivalent in computer science or STEM field\nEQUAL OPPORTUNITY EMPLOYER\nWe value a diverse work environment. Spruce Power is an equal opportunity employer and hires without consideration to race, religion, national origin, age, gender, sexual orientation, marital status, veteran status or disability.\nPowered by JazzHR\nFVGbTPWjIT\nShow more\nShow less",
      "job_skills":"Power BI, SQL, SSRS, SSAS, Python, R, Azure Cloud, Data Warehouse, ETL, XML, CSV, Data management, Data quality, Microsoft Office Suite, Data visualization",
      "Category":"Backend Development"
  },
  {
      "job_title":"Principal Data Engineer",
      "company":"MD Anderson Cancer Center",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-data-engineer-at-md-anderson-cancer-center-3766419805",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"The Principal Data Engineer in the area of Data Analytics & Delivery is a pivotal role in the Enterprise Data Engineering & Analytics Department in operationalizing critical data and analytics for MD Anderson's digital business initiatives. The Principal Data Engineer manages business requirements gathering, end-to-end solution planning and optimizes data analytics delivery within the Context Engine. The Principal Data Engineer partners with other Enterprise Data Engineering & Analytics teams to manage & build analytics deliverables for production use by our key data and analytics consumers.\nThe Principal Data Engineer also manages and coordinates data analytics delivery activities in compliance with data governance processes and data security requirements. This results in enabling faster data delivery, integrated data reuse and vastly improved time-to-solution for MD Anderson data and analytics initiatives.\nThe Principal Data Engineer role requires working creatively and collaboratively with IS and Institutional leaders across the enterprise. It involves evangelizing effective data accessibility practices and promoting better understanding of data and analytics. The Principal Data Engineer partners closely with teams across MD Anderson, including Enterprise Development & Integration and Enterprise Data Science departments in the build out and delivery of end-to-end analytic solutions through the Context Engine Framework.\nData Engineering - End-to-End Solution Delivery\nLead\/Communicate\/Participate End-to-end solution delivery that increases information capabilities and realizes data value across the institution. End-to-End solutions include build out of data sources and tools across the Context Engine framework by integrating data governance processes through data ingestion, ingress, egress, curation, pipeline build, data transformation and modeling steps. Incorporating highly integrated data governance processes that consistently tracking data provenance, security, data quality and ontology as well as through to data visualization and insights.\nLead\/Communicate\/Participate in existing end-to-end data pipelines consisting of a series of stages through which data flows (for example, from data sources or endpoints of acquisition to integration to consumption for specific use cases).\nLead\/Communicate\/Participate and incorporate data governance and metadata management processes into the data ingestion, curation and pipeline building efforts.\nLead\/Promote Data Analytics & Delivery efforts and manage relationships with stakeholders across the organization. This includes proactively communicating with stakeholders and prioritizing work for the team.\nDrive and lead data requirements for various end-to-end analytics deliverables to ensure we are delivering what is needed, not only what is requested.\nLead\/Communicate\/Participate and implement complex data analytics deliverables, including data analysis, report requests, metrics, extracts, visualizations, projects or dashboards in a timely manner by leveraging tools and methodologies in line with the Context Engine Strategy.\nLead\/Communicate\/Perform complex problem solving and formulation and testing and analysis of data. Designs queries using structure query language and NoSQL.\nCollaborate with other data engineers on integration efforts. Promote and ensure institutional data management strategies.\nStandards, Testing and Maintenance\nManage, coordinate and adhere to standard operating procedures set by IS division as well as all MDA policies and maintain build standards (data steward \/ governance oversight sign off) for support of MDA Institutional data strategy including Context Engine.\nManage Documentation preparation as needed for the implementation of enhancements or new technology\nManage & follow documented change control processes and may perform change control audits\nManage & perform quality control and testing and review the build of other analysts to ensure that solutions are technically sound\nOversee analytics system updates\/new releases for assigned modules\nManage and execute the adherence to regulatory requirements, quality standards and best practices for systems and processes, and collaborate with internal and external stakeholders\nLead and\/or participate in after-hours application support and downtime procedures\nEducate and Train\nLead, promote & train counterparts, such as data scientists, data analysts, LOB users or any data consumers, in data pipelining and preparation techniques, which make it easier for them to integrate and consume the data they need for their own use cases.\nLead, plan & establish training plans for various systems in the Context Engine Tools suite and develop curricula in partnership with the MDA Training team and EDEA system experts.\nProvide institutional, department and one-on-one training on EDEA deliverables.\nCoach and provide advice, guidance, encouragement, constructive feedback and transfer knowledge to less experienced team members across OneIS and the institution.\nManage liaison relationships with customers and OneIS to provide effective technical solutions and customer service.\nOneIS\nTo provide innovative, quality, and sustainable IT solutions and services. Our success is driven by our people through Integrity and Trust, Partnership, and Quality.\nPromotes trust, respect, support, and honestly with customers and each other.\nCommits to being a good partner focused on building productive, collaborative, and trusting relationships with our customers and each other.\nModels a commitment to excellence and strives to continually improve. Achieves desired outcomes, usability, and value that exceed expectations of others and our own.\nOther duties as assigned\nEducation Required: Bachelor's degree.\nPreferred Education: Master's Level Degree\nCertification Required: Must obtain at least one Epic Data Model certification (Clinical, Access, or Revenue) issued by Epic within 180 days of date of entry into job.\nPreferred Certification: the Access Data Model or the Clinical Data Model.\nExperience Required: Seven years of relevant information technology experience. May substitute required education with years of related experience on a one to one basis. With preferred degree, five years of experience required.\nPreferred Experience: Epic Cogito Analytics Experience\nPrior data warehouse and business intelligence solutions experience.\nHealthcare industry experience.\nWeb intelligence experience\nPrior experience in building Foundry data pipelines\nIt is the policy of The University of Texas MD Anderson Cancer Center to provide equal employment opportunity without regard to race, color, religion, age, national origin, sex, gender, sexual orientation, gender identity\/expression, disability, protected veteran status, genetic information, or any other basis protected by institutional policy or by federal, state or local laws unless such distinction is required by law. http:\/\/www.mdanderson.org\/about-us\/legal-and-policy\/legal-statements\/eeo-affirmative-action.html\nAdditional Information\nRequisition ID: 163593\nEmployment Status: Full-Time\nEmployee Status: Regular\nWork Week: Days\nMinimum Salary: US Dollar (USD) 119,500\nMidpoint Salary: US Dollar (USD) 149,500\nMaximum Salary : US Dollar (USD) 179,500\nFLSA: exempt and not eligible for overtime pay\nFund Type: Hard\nWork Location: Remote\nPivotal Position: No\nReferral Bonus Available?: Yes\nRelocation Assistance Available?: Yes\nScience Jobs: No\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Analytics, Data Management, Big Data, Data Governance, Data Security, Data Visualization, Data Warehousing, Business Intelligence, ETL, Data Integration, Data Quality, Data Modeling, Data Pipelining, Data Analysis, Reporting, Metrics, Dashboards, SQL, NoSQL, Hadoop, Hive, Spark, Informatica, Tableau, Power BI, GIS, Cloud Computing, AWS, Azure, GCP, Machine Learning, Artificial Intelligence, Data Science, Python, R, Java, C++, Unix, Linux, Windows",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Conversion Developer, Senior Associate",
      "company":"PwC",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-conversion-developer-senior-associate-at-pwc-3749939440",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nFunctional & Industry Technologies\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 80%\nA career within Functional and Industry Technologies services will provide you with the opportunity to build secure and new digital experiences for customers, employees, and suppliers. We focus on improving apps or developing new apps for traditional and mobile devices as well as conducting usability testing to find ways to improve our clients\u201a\u00c4\u00f4 user experience. Our team helps clients transform their business through enabling technologies across marketing, finance and operations in the functional areas such as Maximo and PowerPlant.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nBasic Qualifications\nMinimum Degree Required:\nBachelor Degree\nMinimum Years Of Experience\n4 years\nPreferred Qualifications\nDegree Preferred:\nMaster Degree\nCertification(s) Preferred\nAzure Data Engineer Associate\nDatabricks Certified Data Engineer Associate\nPreferred Fields Of Study\nComputer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology\nPreferred Knowledge\/Skills\nDemonstrates a thorough level of abilities with, and\/or a proven record of success as both an individual contributor and team member, identifying and addressing client needs:\nSupports in data analysis techniques to assess source data structures, identify mapping requirements, and define transformation rules for data conversion into Maximo;\nLeads Maximo's modules and functionalities related to Asset Management and Work Order Management and IBM Maximo, including its data structures, configuration settings, and integration capabilities;\nIdentifies relational databases, preferably experience in working with databases commonly used in Maximo, such as IBM DB2, Oracle, Microsoft SQL Server, along with familiarity with Maximo's Integration Framework (MIF) and its capabilities for data integration and conversion;\nSupports in designing and implementing data extraction, transformation, and loading processes for Maximo data conversion;\nShowcases understanding in SQL and database querying languages to extract and manipulate data from source systems along with understanding ETL tools and methodologies commonly used in Maximo data conversion;\nIdentifies technologies commonly used with Maximo, including web services (SOAP, RESTful APIs), XML, JSON, and other relevant data exchange formats;\nSupports in pipeline architecture and development using one of the tools such as Azure ADF, AWS Glue, SSIS, DataBricks (multiple preferred);\nUtilizes data cleansing techniques and methodologies to ensure the integrity and accuracy of converted data in Maximo;\nDevelopes data cleansing functional business rules as per Maximo Business Object (MBO) definitions for source to Maximo conversion requirements;and comprehensive testing plans and executing validation processes to verify the accuracy and integrity of converted data in Maximo;\nCustomizes Maximo options, such as Automation Scripts, Java Customizations, Database Configuration, or Application Designer, to support data conversion requirements;\nIdentifies integrations within Maximo with other enterprise systems, such as ERP systems, GIS systems, or asset management systems. Knowledge of integration patterns, data synchronization, and data exchange protocols; and,\nShowcases work experience as a Data Engineer, Data Architect or similar role, along with experience in programming languages including Python, PySpark, Scala, SQL.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-advisoryseniorassociate\nShow more\nShow less",
      "job_skills":"Maximo, IBM DB2, Oracle, Microsoft SQL Server, Maximo's Integration Framework (MIF), Azure ADF, AWS Glue, SSIS, DataBricks, Python, PySpark, Scala, SQL",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Cloud Data Engineer",
      "company":"BDO USA",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-cloud-data-engineer-at-bdo-usa-3765469453",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nJob Summary:\nThis position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.\nJob Duties\nDesigns and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS\nListens to client needs to align solution with business requirements and delivery schedule\nCreates written functional and technical designs\nParticipates in project status and stand meetings, and assists with providing aggregated project status for project and program managers\nAssists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions\nWrites code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles\nDelivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)\nAssists with implementation of data governance programs and best practices\nPerforms the cleaning and transforming of data from source systems into analytics models\nImplements models to support data visualizations and integrations\nAssists with implementing DevOps, DataOps and MLOps methodologies on projects\nWrites custom integration logic in applicable programming languages\nAssists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle\nAssists clients with licensing, security, and cost estimation of solutions\nPerforms code reviews to ensure adherence to standards\nWorks directly with clients and team members to establish secure data analytics platforms and infrastructure\nContributes to successful deployments of developed solutions and integration of DevOps tools\nMaintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools\nBuilds client relationships during project execution, effectively becoming a trusted advisor of the client\nParticipates in support activities for existing software solutions\nOther duties as assigned\nSupervisory Responsibilities\nSupervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product\nEducation\nQualifications, Knowledge, Skills and Abilities:\nHigh School Diploma or GED equivalent, required\nBachelor\u201a\u00c4\u00f4s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred\nExperience\nFive (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required\nOne (1) or more years of experience technically leading development projects, preferred\nOne (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred\nSoftware\nStrong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required\nExperience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required\nHands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred\nExperience with one (1) or more of the following computer languages, preferred:\nC#\nPython\nJava\nScala\nExperience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred\nExperience with Git and DevOps deployment technologies, preferred\nExperience with Linux, preferred\nExperience with one (1) or more of the following, preferred:\nData Lake Medallion Architecture\nBatch and\/or streaming data ingestion into a data lake\nAI Algorithms\/Machine Learning\nAutomation tools such as UiPath, Alteryx, etc.\nComputer Vision based AI technologies\nOther Knowledge, Skills & Abilities\nAbility to work with a high degree of professionalism and autonomy\nExcellent verbal and written communication skills\nSolid organizational skills, especially the ability to meet project deadlines with a focus on details\nAbility to successfully multi-task while working independently or within a group environment\nAbility to work in a deadline-driven environment, and handle multiple projects simultaneously\nAbility to interact effectively with people at all organizational levels of the Firm\nAbility to effectively interact with a team of professionals and delegating work assignments, as needed\nAbility to build and maintain strong relationships with internal and client personnel\nAbility to encourage a team environment on engagements, and contribute to the professional development of assigned personnel\nKeywords:\nData Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL\nIndividual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate\u201a\u00c4\u00f4s qualifications, experience, skills, and geography.\nCalifornia Range: $111,000 - $152,000\nColorado Range: $111,000 - $152,000\nNew York City\/ Valhalla Range: $111,000 - $152,000\nWashington Range: $111,000 - $152,000\nAbout Us\nBDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients\u201a\u00c4\u00f4 needs. We currently serve more than 400 publicly traded domestic and international clients.\nUnparalleled partner-involvement\nDeep industry knowledge and participation\nGeographic coverage across the U.S.\nCohesive global network\nFocused capabilities across disciplines\nBDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world\u201a\u00c4\u00f4s fifth largest accounting network.\nBDO offers a competitive Total Rewards package that encompass so much more than \u201a\u00c4\u00ec \u201a\u00c4\u00fatraditional benefits\u201a\u00c4\u00f9. Our wide range of rewards and our employees\u201a\u00c4\u00f4 ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.\nSome Examples Of Our Total Rewards Offerings Include\nCompetitive pay and eligibility for an annual performance bonus.\nA 401k plan plus an employer match\nComprehensive, medical, dental, vision, FSA, and prescription insurance from day one\nCompetitive Paid Time Off with daily accrual from day one of employment, plus paid holidays\nPaid Parental Leave\nAdoption Assistance\nFirm paid life insurance\nWellness programs\nAdditional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance\nAbove offerings may be subject to eligibility requirements.\nClick here to find out more!\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.\n\"BDO USA, P.A. is an EO employer M\/F\/Veteran\/Disability\"\nShow more\nShow less",
      "job_skills":"Data Analytics, Business Intelligence, Artificial Intelligence, Application Development, SQL, Data Warehousing, Data Modeling, Semantic Model Definition, Star Schema Construction, Cloud Data Analytics, Azure, AWS, C#, Python, Java, Scala, Tabular Modeling, Microsoft Fabric, Power BI, Azure Analysis Services, Git, DevOps, Linux, Data Lake Medallion Architecture, Batch Data Ingestion, Streaming Data Ingestion, AI Algorithms, Machine Learning, Automation Tools, UiPath, Alteryx, Computer Vision, .Net, Qlik, Tableau, Synapse, IoT, Data Lake, Stream, Cube, Microsoft, SQL Server, RedShift, UiPath, Cloud, RPA, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Athena, Data Pipeline, Glue, Star Schema, SSIS, SSAS, SSRS, PySpark, Delta, Pandas, Spark SQL, dbt, Terraform, Bicep, Data Ops, Purview, Hadoop",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist - Up to $150,000 + Huge Bonus + Package",
      "company":"Hunter Bond",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-up-to-%24150-000-%2B-huge-bonus-%2B-package-at-hunter-bond-3784570993",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job title: Data Scientist- Up to $140,000 + Huge Bonus + Package\nClient: Scaling fintech\nExperience Level: 1+ years'\nSalary: Up to $140,000 + Huge Bonus + Package\nLocation: Houston (Hybrid)\nSells: Cutting-edge tech, ownership of multiple greenfield projects, no red tape, gold medal Olympiads, highest regarded technologists around, a welcoming\/ collaborative environment, fantastic office spaces\nAn elite scaling fintech are searching for Data Scientists to join a group of the highest-regarded talent around!\nThis team has an unlimited tech budget, promotes a great culture, and is made up of incredible like-minded individuals.\nRole:\nDevelop a deep understanding of North American Energy Markets and build cutting edge analytics tools for ML models.\nWorking as part of a high performing team solving complex data issues and making deductions which you'll see directly impact the business.\nSkills\/Experience:\n3+ years Experience as a Data Scientist\nDegree in Computer Science\/ Engineering or Mathematics (or related field)\nGood skills in Python\nStrong SQL proficiency and understanding of database technologies, such as AWS RDS and Snowflake\nStrong proficiency in Python, with knowledge of common ML and statistical packages such as Scikit-Learn, SciPy, Prophet, etc\nExcellent exposure to Generalized Linear and Non-Linear Models, Time Series Analysis, Random Forest.\nShow more\nShow less",
      "job_skills":"Data Science, Python, SQL, AWS RDS, Snowflake, ScikitLearn, SciPy, Prophet, Generalized Linear Models, NonLinear Models, Time Series Analysis, Random Forest, Statistics, Machine Learning, ETL, Data Visualization, Business Intelligence, Data Mining, Data Analysis, Advanced Analytics, Hypothesis Testing, Causal Inference, Experimental Design, Ensemble Methods, Natural Language Processing, Cloud Computing, Big Data, Hadoop, Spark, Hive, Pig, Greenplum, Redshift, Teradata",
      "Category":"Backend Development"
  },
  {
      "job_title":"Spatiotemporal Data Scientist - 4669",
      "company":"Delphi-US, LLC",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/spatiotemporal-data-scientist-4669-at-delphi-us-llc-3766684694",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Title: Senior Data Scientist (Contract) - Job#4669\nLocation:\nRemote or Hybrid (Houston TX)\nJob Description:\nOur Machine Learning team tackles major opportunities for operational efficiency and revenue generation and deploys these models across environments where they re-shape the way we work. We are seeking a curious, proactive, and innovative Data Scientist to join our team. The ideal candidate has a strong scientific background, experience blending various datasets, building statistical\/machine learning models, and communicating the results back to business partners.\nCandidates Must Have the following background to be considered:\nDomain expertise with methane, air quality measurement, or atmospheric modeling would be very valuable since gas concentrations and movements are a lot of the modeling work. Modeling and studying other related scientific phenomena could be a good backup too.\nSpatiotemporal statistical modeling expertise. Time series expertise alone would also be a good backup even if we don\u201a\u00c4\u00f4t have the spatial statistics component. Bonus points for someone with Bayesian time series\/spatial experience.\nPython \/ R programming to model and analyze the data.\nSQL \u201a\u00c4\u00ec we\u201a\u00c4\u00f4re working with a variety of disparate datasets as we build out sensors at our environmental sites, so it\u201a\u00c4\u00f4s important that candidates can navigate uncharted datasets and quickly figure out how to link these accurately. SQL Expertise is a Must: to collect, aggregate new data sources & stage for modelling & analysis\nmethane measurement and atmospheric sciences\ndispersion models\nstatistical modeling\ndata management (SQL) experience\nResponsibilities:\nApply machine learning, advanced analytical techniques, and critical thinking to solve complex business problems\nSeek, build, and consolidate data inputs proactively to create and improve models\nTranslate business partners\u201a\u00c4\u00f4 needs into data science projects and make technical decisions based on the tradeoff between complexity and value\nDrive projects, individually and collaboratively, through the data science lifecycle including data collection, exploration\/analysis, model development, validation, and deployment\nDevelop presentations to communicate key messages to senior sponsors, non-technical partners, fellow data scientists, and other stakeholders\nWork with technical partners to deploy models and streamline the process to scale our work\nRequired Qualifications:\nBuilding statistical or machine learning models for prediction and inference\nAbility to code within Python (R also considered)\nAdvanced SQL knowledge to pull and transform data\nEducation and Experience\nQuantitative Foundation: B.S. degree in a quantitative field (e.g., Statistics, Engineering, Computer Science, Meteorology, Physics, Mathematics, Economics, Operations Research).\nExperience: 3+ years\u201a\u00c4\u00f4 experience in data science building and deploying models into production\nTechnical Skills\nProgramming: compose clean, efficient, and reusable code in Python and\/or R.\nMachine Learning \/ Modeling: understand what types of algorithms to use, their benefits and drawbacks, and how to implement them.\nData Wrangling: write efficient SQL queries from scratch that blend data from a variety of sources in the right form for modeling, analysis, and scoring.\nStatistical Analysis: investigate trends, patterns, and relationships using statistical methods and tests to reach actionable conclusions and understand causal relationships.\nData Visualization: grasp data-ink ratios and bring data-driven stories to life through visuals.\nScientific Research: experience using adjacent scientific literature to advance our thinking and modeling in novel areas where existing research is thin\nSoft Skills\nCurious: bring intellectual curiosity, an inquisitive nature, and a desire to deepen your knowledge and continue learning.\nOwnership: take responsibility to proactively advance projects, contribute to the team\/organization, and improve existing processes.\nBusiness acumen: understand the bigger picture for customers and the business while connecting your work to key objectives for both.\nStorytelling: write and present messages and insights clearly to persuade non-technical partners that they can confidently use our models and solutions.\nPreferred Qualifications\nA graduate degree (Masters or PhD) in a quantitative field\nExperience with spatial modeling, greenhouse gas emissions, atmospheric modeling, or remote sensing data\nProficiency using git for version control, collaboration, and releases\nExpertise with cloud services like AWS (SageMaker, S3, Redshift, etc.) and Snowflake\nBuilt dashboards for visualizing model outputs and performance monitoring using Microsoft PowerBI, Python dash, or similar tools\nAbout Delphi-US\nDelphi-US is a national recruiting firm based in Newport, Rhode Island. We specialize in IT, Engineering and Professional Staffing services for organizations from Main Street to Wall Street. Our mission is simple: To connect great people to great companies. We accomplish this with a proprietary skill-based and cultural matching process that results in higher qualified submissions along with increased interviews and offer rates. You\u201a\u00c4\u00f4ll find our team is friendly, professional and ready to advocate on your behalf, armed with industry trends, and an understanding of employer expectations.\nShow more\nShow less",
      "job_skills":"Python, R, SQL, Machine Learning, Modeling, Statistical Analysis, Data Wrangling, Data Visualization, Scientific Research, Spatial Modeling, Greenhouse Gas Emissions, Atmospheric Modeling, Remote Sensing Data, Git, AWS, Snowflake, Microsoft PowerBI, Python Dash, Data Science, Data Management, Data Analysis, Model Deployment, Model Validation, Presenting, Statistics, Meteorology, Physics, Mathematics, Economics, Operations Research, Causal Relationships",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data engineer - Python",
      "company":"MANDO TECHNOLOGIES INC",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-python-at-mando-technologies-inc-3767594146",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Mando Technologies is specializes in helping organizations make the most of their information assets. From acquiring, organizing, analyzing, and delivering data to closing the loop by integrating intelligence into the operations of the enterprise, Mando Technologies covers the full spectrum of Business Intelligence.\nOur data engineers are powering the capability to make decisions using data to improve operations and our customer and employee experience.\nThis role is a part of the Data Engineering and Analytics team with our Client Technology group. You'll bring your data engineering, collaboration and analytics skills to help cultivate a data driven culture by designing and delivering analytics solutions and making data analytics easier and more effective.\nWhat you'll do:\nBe a part of the data governance team. Work closely with data application teams and product owners to design, implement and support data governance and analytics solutions that provide insights to make better decisions.\nImplement data engineering solutions using Cloud services: (Snowflake, GitLab, CI\/CD, Airflow, etc.) and traditional data warehouse tools.\nImplement batch and streaming data pipelines using cloud technologies.\nLeads development of coding standards, best practices and privacy and security guidelines.\nMentors' others on technical and domain skills to create multi-functional teams.\nDevelop and support data privacy and governance related frameworks and help other team implement them for compliance\nExperience working in an Agile environment and with Agile teams\nPreferred Qualifications:\nMinimum Qualifications- Bachelor's degree in Computer Science, Computer Engineering, Technology or related technical discipline\n2-3 years software solution development using agile, DevOps, operating in a product model that includes designing, developing, and implementing large-scale applications or data engineering solutions\n7 years data analytics experience using SQL\nTools\/platforms required:\nProgramming\/Scripting: Python, Spark, Unix, SQL, APIs, Java\nData Platforms: Cassandra, Netezza, SQL Server, Snowflake\nCloud Technologies: AWS\nCI\/CD: GitLab, Jenkins, Kubernetis, Terraform\nBI Analytics Tool Stack - Tableau, and Grafana\nTools: DataStage, Control-M\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Analytics, Business Intelligence, Cloud Services, Data Governance, Data Warehousing, Batch and Streaming Data Pipelines, Coding Standards, Best Practices, Privacy and Security Guidelines, Agile Development, DevOps, Software Solution Development, SQL, Python, Spark, Unix, APIs, Java, Cassandra, Netezza, SQL Server, Snowflake, AWS, GitLab, Jenkins, Kubernetes, Terraform, Tableau, Grafana, DataStage, ControlM",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer with AWS",
      "company":"IQuest Solutions Corporation",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-with-aws-at-iquest-solutions-corporation-3700281134",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Data Engineer\nPlano TX\nCTS\/JPMC\n3 Positions: Developer\/Sr Developer \/ Lead Developer.\nResponsibilities\nDesign, develop, and maintain Python-based applications, tools, and scripts to support database migration processes.\nCollaborate with cross-functional teams to analyze existing systems, databases, and applications to identify migration needs and opportunities.\nPlan, execute, and oversee database migration projects, ensuring minimal downtime and data integrity throughout the process.\nImplement effective data mapping, transformation, and validation techniques during migration to ensure accurate and complete transfer of data.\nDevelop and maintain scripts and automation workflows for seamless integration of migration tasks into the deployment pipeline.\nOptimize application performance and scalability using appropriate AWS services, considering factors such as compute, storage, security, and networking.\nWork closely with DevOps teams to deploy and manage applications within AWS cloud infrastructure.\nMonitor, troubleshoot, and resolve database migration issues, performance bottlenecks, and system failures.\nImplement security best practices in accordance with AWS standards to safeguard sensitive data and ensure compliance.\nCollaborate with QA teams to conduct thorough testing of migrated databases and applications to validate their functionality and performance.\nStay up to date with the latest advancements in AWS services, Python development, and database migration techniques.\nQualifications\nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent work experience).\nProven experience as a Python Developer, with a strong portfolio showcasing Python-based projects and tools.\nIn-depth understanding of database migration strategies, data mapping, and transformation techniques.\nSolid experience with AWS services such as EC2, RDS, S3, Lambda, DynamoDB, and others for application deployment, data storage, and scaling.\nFamiliarity with AWS migration services like Database Migration Service (DMS) and Server Migration Service (SMS).\nAWS certification (e.g., AWS Certified Developer, AWS Certified Solutions Architect) is a significant plus.\nProficiency in SQL and experience with both relational and NoSQL databases.\nStrong problem-solving skills and the ability to troubleshoot complex migration and application issues.\nExcellent teamwork and communication skills, with the ability to collaborate effectively across different teams and stakeholders.\nKnowledge of DevOps practices and tools for continuous integration and deployment.\nExperience with version control systems like Git and agile development methodologies.\nStrong attention to detail and a commitment to delivering high-quality solutions.\nThanks & Regards\nSonali Singh\nSr. Technical Recruiter\nDesk:\n+1(940)-536-0395\nEmail:\ns.singh@iquestsols.com\nVisit:\nwww.iquestsols.com\nShow more\nShow less",
      "job_skills":"Python, SQL, AWS, EC2, RDS, S3, Lambda, DynamoDB, Database Migration Service (DMS), Server Migration Service (SMS), DevOps, Git, NoSQL, Relational databases, Version control systems, Agile development methodologies",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer, Data Engineering",
      "company":"PepsiCo",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-data-engineering-at-pepsico-3701097237",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Overview\nPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo\u201a\u00c4\u00f4s global business scale to enable business insights, advanced analytics and new product development. PepsiCo\u201a\u00c4\u00f4s Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\nWhat PepsiCo Data Management and Operations does:\nMaintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company\nResponsible for day-to-day data collection, transportation, maintenance\/curation and access to the PepsiCo corporate data asset\nWork cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders\nIncrease awareness about available data and democratize access to it across the company\nAs a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.\nResponsibilities\nActive contributor to code development in projects and services.\nManage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.\nBuild and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.\nResponsible for implementing best practices around systems integration, security, performance and data management.\nEmpower the business by creating value through the increased adoption of data, data science and business intelligence landscape.\nCollaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.\nEvolve the architectural capabilities and maturity of the data platform by engaging with enterprise architects and strategic internal and external partners.\nDevelop and optimize procedures to \u201a\u00c4\u00faproductionalize\u201a\u00c4\u00f9 data science models.\nDefine and manage SLA\u201a\u00c4\u00f4s for data products and processes running in production.\nSupport large-scale experimentation done by data scientists.\nPrototype new approaches and build solutions at scale.\nResearch in state-of-the-art methodologies.\nCreate documentation for learnings and knowledge transfer.\nCreate and audit reusable packages or libraries\nQualifications\n6+ years of overall technology experience that includes at least 4+ years of hands-on software development, data engineering, and systems architecture.\n4+ years of experience with Salesforce Cloud Technologies is must.\n4+ years of experience with Sales force Customer data modeling, data warehousing, and building high-volume ETL\/ELT pipelines.\n4+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.\n4+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).\n2+ years in cloud data engineering experience in Azure.\nFluent with Azure cloud services. Azure Certification is a plus.\nExperience with integration of multi cloud services with on-premises technologies.\nExperience with data modeling, data warehousing, and building high-volume ETL\/ELT pipelines.\nExperience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.\nExperience building\/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.\nExperience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.\nExperience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.\nExperience with version control systems like Github and deployment & CI tools.\nExperience with Azure Data Factory, Azure Databricks and Azure Machine learning tools.\nExperience with Statistical\/ML techniques is a plus.\nExperience with building solutions in the retail or in the supply chain space is a plus\nUnderstanding of metadata management, data lineage, and data glossaries is a plus.\nWorking knowledge of agile development, including DevOps and DataOps concepts.\nFamiliarity with business intelligence tools (such as PowerBI).\nBA\/BS in Computer Science, Math, Physics, or other technical fields.\nSkills, Abilities, Knowledge:\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nProven track record of leading, mentoring data teams.\nStrong change manager. Comfortable with change, especially that which arises through company growth.\nAbility to understand and translate business requirements into data and technical requirements.\nHigh degree of organization and ability to manage multiple, competing projects and priorities simultaneously.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong leadership, organizational and interpersonal skills; comfortable managing trade-offs.\nFoster a team culture of accountability, communication, and self-management.\nProactively drives impact and engagement while bringing others along.\nConsistently attain\/exceed individual and team goals\nAbility to lead others without direct authority in a matrixed environment.\nSalesforce Data Cloud Accreditation\nRelevant Salesforce certifications and consulting experience are strongly recommended\nFamiliarity with Data Regulation\nEEO Statement\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.\nPepsiCo is an Equal Opportunity Employer: Female \/ Minority \/ Disability \/ Protected Veteran \/ Sexual Orientation \/ Gender Identity\nIf you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.\nPlease view our Pay Transparency Statement\nShow more\nShow less",
      "job_skills":"Data engineering, Salesforce Cloud Technologies, Data modeling, Data warehousing, ETL\/ELT pipelines, Data Lake Infrastructure, Data Analytics, SQL optimization, Python, PySpark, Scala, Azure cloud services, Azure Certification, Kubernetes, Github, Azure Data Factory, Azure Databricks, Azure Machine learning tools, Statistical\/ML techniques, Retail, Supply chain, Metadata management, Data lineage, Data glossaries, DevOps, DataOps, PowerBI, Communication skills, Leadership, Teamwork, Problemsolving, Analytical skills, Attention to detail, Multitasking, Time management, Stress management, Salesforce Data Cloud Accreditation, Data Regulation",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Engineer",
      "company":"MANDO TECHNOLOGIES INC",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-at-mando-technologies-inc-3767598096",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Mando Technologies is specializes in helping organizations make the most of their information assets. From acquiring, organizing, analyzing, and delivering data to closing the loop by integrating intelligence into the operations of the enterprise, Mando Technologies covers the full spectrum of Business Intelligence.\nJob Description\nOnly W2 Candidates*********\nLooking for experienced Data Engineer with strong Pyspark and SQL skills with exposure to AWS services for one of our Direct client in Dallas, TX.\nAt least 3-5 years\u201a\u00c4\u00f4 experience with Big Data \/ Hadoop architecture and related technologies\nHands-on experience with Spark RDDs, Datasets, Dataframes, etc with Python or Java\nHands-on experience using SQL, Spark SQL, HiveQL and performance tuning for big data operations\nHands-on experience using technologies such as Hive, Pig, Sqoop, UNIX environment etc\nExperience using CI\/CD processes for application software integration and deployment using Git, Jenkins\nExperience with AWS (S3. EMR, EC2 & Lambda) or similar technologies\nExperience using SDLC and Agile software development practices\nExposure to Snowflake or relational databases experience with SQL optimization skills\nSoft-skills\nGood written, verbal, presentation, and interpersonal communication skills, given an opportunity willing to work in a challenging and cross platform environment.\nStrong Analytical and problem-solving skills. Ability to quickly master new concepts and applications\nPreferable knowledge in Business Intelligence and Visualization\nShow more\nShow less",
      "job_skills":"Pyspark, SQL, AWS, Big Data, Hadoop, Spark RDDs, Datasets, Dataframes, Python, Java, Spark SQL, HiveQL, Hive, Pig, Sqoop, UNIX, CI\/CD, Git, Jenkins, SDLC, Agile, Snowflake, Relational databases, Business Intelligence, Visualization",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer Assoc Manager",
      "company":"PepsiCo",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-assoc-manager-at-pepsico-3767172909",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Overview\nPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo\u201a\u00c4\u00f4s global business scale to enable business insights, advanced analytics and new product development. PepsiCo\u201a\u00c4\u00f4s Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\nWhat PepsiCo Data Management and Operations does:\nMaintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company\nResponsible for day-to-day data collection, transportation, maintenance\/curation and access to the PepsiCo corporate data asset\nWork cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders\nIncrease awareness about available data and democratize access to it across the company\nAs a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.\nResponsibilities\nActive contributor to code development in projects and services.\nManage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.\nBuild and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.\nResponsible for implementing best practices around systems integration, security, performance and data management.\nEmpower the business by creating value through the increased adoption of data, data science and business intelligence landscape.\nCollaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.\nEvolve the architectural capabilities and maturity of the data platform by engaging with enterprise architects and strategic internal and external partners.\nDevelop and optimize procedures to \u201a\u00c4\u00faproductionalize\u201a\u00c4\u00f9 data science models.\nDefine and manage SLA\u201a\u00c4\u00f4s for data products and processes running in production.\nSupport large-scale experimentation done by data scientists.\nPrototype new approaches and build solutions at scale.\nResearch in state-of-the-art methodologies.\nCreate documentation for learnings and knowledge transfer.\nCreate and audit reusable packages or libraries.\nQualifications\nBA\/BS in Computer Science, Math, Physics, or other technical fields.\n6+ years of overall technology experience that includes at least 4+ years of hands-on software development, data engineering, and systems architecture.\n4+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.\n4+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).\n2+ years in cloud data engineering experience in Azure.\nFluent with Azure cloud services. Azure Certification is a plus.\nExperience with integration of multi cloud services with on-premises technologies.\nExperience with data modeling, data warehousing, and building high-volume ETL\/ELT pipelines.\nExperience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.\nExperience building\/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.\nExperience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.\nExperience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.\nExperience with version control systems like Github and deployment & CI tools.\nExperience with Azure Data Factory, Azure Databricks and Azure Machine learning tools.\nExperience with Statistical\/ML techniques is a plus.\nExperience with building solutions in the retail or in the supply chain space is a plus\nUnderstanding of metadata management, data lineage, and data glossaries is a plus.\nWorking knowledge of agile development, including DevOps and DataOps concepts.\nFamiliarity with business intelligence tools (such as PowerBI).\nSkills, Abilities And Knowledge\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nProven track record of leading, mentoring data teams.\nStrong change manager. Comfortable with change, especially that which arises through company growth.\nAbility to understand and translate business requirements into data and technical requirements.\nHigh degree of organization and ability to manage multiple, competing projects and priorities simultaneously.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong leadership, organizational and interpersonal skills; comfortable managing trade-offs.\nFoster a team culture of accountability, communication, and self-management.\nProactively drives impact and engagement while bringing others along.\nConsistently attain\/exceed individual and team goals\nAbility to lead others without direct authority in a matrixed environment.\nCompetencies\nHighly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business.\nUnderstands both the engineering and business side of the Data Products released.\nPlaces the user in the center of decision making.\nTeams up and collaborates for speed, agility, and innovation.\nExperience with and embraces agile methodologies.\nStrong negotiation and decision-making skill.\nExperience managing and working with globally distributed teams.\nEEO Statement\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.\nPepsiCo is an Equal Opportunity Employer: Female \/ Minority \/ Disability \/ Protected Veteran \/ Sexual Orientation \/ Gender Identity\nIf you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.\nPlease view our Pay Transparency Statement.\nShow more\nShow less",
      "job_skills":"Data engineering, Data pipelines, Data quality, Cloud data engineering, Azure cloud services, Data modeling, Data warehousing, ETL\/ELT pipelines, Data profiling, Data quality tools, MPP database technology, Redshift, Synapse, SnowFlake, Cloud infrastructure, Kubernetes, DevOps, DataOps, Business intelligence tools, PowerBI, Python, PySpark, Scala, SQL, Azure Data Factory, Azure Databricks, Azure Machine learning tools, Statistical\/ML techniques, Metadata management, Data lineage, Data glossaries, Agile development",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Tata Consultancy Services",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-tata-consultancy-services-3778777265",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title\nSenior Data Engineer\nTechnical\/Functional Skills\nPrimary \u201a\u00c4\u00ec Cloud Based ETL Tool, DBT, Snowflake (Cloud DB), Strong SQL, Unix\/Python, Control-M, Service Now, RPA\nExperience Required\n8-10 yrs\nRoles & Responsibilities\nRole Description\nAnalyze requirements and existing resources to Propose, create ETL designs and database objects\nWork with project and business analyst leads in order to develop and clarify in-dep th technical requirements including logical and physical data modeling activities\nDesign and implement ETL processes for data transactions related to Enterprise Data Warehouse, Operational Data Store (ODS), and other data structures to support our Business Intelligence operations\nDevelops, enhances, debugs, supports, maintains and tests software applications that support business units or supporting functions using IBM Infosphere Data Stage ETL or any other cloud based ETL tool both ETL and ELT approaches. These application program solutions may involve diverse development platforms, software, hardware, technologies and tools.\nMust have hands-on on Snowflake development environment with all SQL operations. Must be aware of ELT approach as well.\nParticipates in the design, development and implementation of complex applications, often using IBM Infosphere Information Server (IIS) products like Data Stage, Quality Stage on a Linux Grid environment. Control-M\/Scheduling tools.\nRequired Skills:10+ Yrs Relevant IT software experience (Technical) in ETL Datastage or any other cloud based ETL Tool development Experience with databases like Snowflake (Cloud DB), Oracle, Netezza, MS SQL Server 2012+, DB2 and MS Access\nExperience with job automation & scheduling software (Control-M) Strong ability to write SQL queries\nDesired Skills:\nFamiliar with Snowflake (Cloud DB), DBT,\nPython, UNIX, Windows, File transfer utilities, process flow creation, ETL technologies, Hadoop, ServiceNow, RPA\nGood to have Skills: Snow-Pro Certified. Service Now Certified,.Strong SQL, Strong conceptual understanding of core DW Concepts including different approaches\/methodologies. dbt (data build tool) experience is an added advantage\nShow more\nShow less",
      "job_skills":"Cloud Based ETL Tool, DBT, Snowflake, SQL, Unix, Python, ControlM, Service Now, RPA, Data Warehousing, Data Modeling, Data Migration, Data Integration, Data Quality, Hadoop, UNIX, Windows, File transfer utilities, ETL technologies, dbt",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Engineer",
      "company":"Professional Diversity Network",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-at-professional-diversity-network-3777672007",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"PepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo's global business scale to enable business insights, advanced analytics and new product development. PepsiCo's Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\nWhat PepsiCo Data Management And Operations Does\nMaintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company\nResponsible for day-to-day data collection, transportation, maintenance\/curation and access to the PepsiCo corporate data asset\nWork cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders\nIncrease awareness about available data and democratize access to it across the company\nAs a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.\nResponsibilities\nActive contributor to code development in projects and services.\nManage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.\nBuild and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.\nResponsible for implementing best practices around systems integration, security, performance and data management.\nEmpower the business by creating value through the increased adoption of data, data science and business intelligence landscape.\nCollaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.\nEvolve the architectural capabilities and maturity of the data platform by engaging with enterprise architects and strategic internal and external partners.\nDevelop and optimize procedures to \"productionalize\" data science models.\nDefine and manage SLA's for data products and processes running in production.\nSupport large-scale experimentation done by data scientists.\nPrototype new approaches and build solutions at scale.\nResearch in state-of-the-art methodologies.\nCreate documentation for learnings and knowledge transfer.\nCreate and audit reusable packages or libraries.\nQualifications\nBA\/BS in Computer Science, Math, Physics, or other technical fields.\n6+ years of overall technology experience that includes at least 4+ years of hands-on software development, data engineering, and systems architecture.\n4+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.\n4+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).\n2+ years in cloud data engineering experience in Azure.\nFluent with Azure cloud services. Azure Certification is a plus.\nExperience with integration of multi cloud services with on-premises technologies.\nExperience with data modeling, data warehousing, and building high-volume ETL\/ELT pipelines.\nExperience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.\nExperience building\/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.\nExperience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.\nExperience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.\nExperience with version control systems like Github and deployment & CI tools.\nExperience with Azure Data Factory, Azure Databricks and Azure Machine learning tools.\nExperience with Statistical\/ML techniques is a plus.\nExperience with building solutions in the retail or in the supply chain space is a plus\nUnderstanding of metadata management, data lineage, and data glossaries is a plus.\nWorking knowledge of agile development, including DevOps and DataOps concepts.\nFamiliarity with business intelligence tools (such as PowerBI).\nSkills, Abilities And Knowledge\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nProven track record of leading, mentoring data teams.\nStrong change manager. Comfortable with change, especially that which arises through company growth.\nAbility to understand and translate business requirements into data and technical requirements.\nHigh degree of organization and ability to manage multiple, competing projects and priorities simultaneously.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong leadership, organizational and interpersonal skills; comfortable managing trade-offs.\nFoster a team culture of accountability, communication, and self-management.\nProactively drives impact and engagement while bringing others along.\nConsistently attain\/exceed individual and team goals\nAbility to lead others without direct authority in a matrixed environment.\nCompetencies\nHighly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business.\nUnderstands both the engineering and business side of the Data Products released.\nPlaces the user in the center of decision making.\nTeams up and collaborates for speed, agility, and innovation.\nExperience with and embraces agile methodologies.\nStrong negotiation and decision-making skill.\nExperience managing and working with globally distributed teams.\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.\nPepsiCo is an Equal Opportunity Employer: Female \/ Minority \/ Disability \/ Protected Veteran \/ Sexual Orientation \/ Gender Identity\nIf you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.\nPlease view our Pay Transparency Statement\nShow more\nShow less",
      "job_skills":"Data engineering, Data architecture, Cloud data engineering, Data management, Data warehousing, Data lakes, Data analytics, Data science, Data quality, Data integration, DevOps, DataOps, Agile development, Machine learning, Statistical techniques, Python, PySpark, Scala, SQL, MPP databases, Redshift, Synapse, Snowflake, Kubernetes, GitHub, Azure Data Factory, Azure Databricks, Azure Machine Learning, PowerBI, Apache Griffin, Deequ, Great Expectations",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Engineer - Clinical Data Repository",
      "company":"CVS Health",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-clinical-data-repository-at-cvs-health-3777364967",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand \u201a\u00c4\u00ee with heart at its center \u201a\u00c4\u00ee our purpose sends a personal message that how we deliver our services is just as important as what we deliver.\nOur Heart At Work Behaviors\u201a\u00d1\u00a2 support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.\nPosition Summary\nA Brief Overview:\nAs a member of the Data and Analytics organization, you will be responsible fordesigning, building, and maintaining best-in-class data pipelines aimed at driving best-in-class solutions. You will collaborate with cross-functional teams, including data scientists, analysts, and software engineers, to ensure the efficient and reliable processing, storage, and retrieval of data.\nWhat you will do:\nBuild high-performing clinical data processing frameworks leveraging Google Cloud Platform and utilizing GCP Services like Dataflow, Pub-Sub, Composer, Healthcare API and Big Query.\nDesign and develop clinical data pipelines for ingestion, enrichment, and consumption frameworks for onboarding clinical data from various data sources formatted in various industry standards (FHIR, C-CDA, HL7 V2, JSON, XML, etc.).\nPerform Health care Data Analysis, Data profiling of source data to derive meaningful insights, and document data requirements to support the new data source onboarding.\nBuild state-of-the-art data pipelines supporting both batch and real-time streams to enable Clinical data collection, storage, processing, transformation, aggregation, and dissemination through heterogeneous channels. .\nDevelop proof of concepts for batch\/real-time data engineering solutions that leverage emerging technologies.\nRequired Qualifications\n6+years of hands-on experience in design, and development of enterprise data processing applications (ETL\/ELT)\n5+years of hands-on and robust experience in Python, Unix Shell scripting, SQL and handling of JSON, XML data.\n3+years of experience in building batch and streaming data pipelines using cloud data engineering technologies ( in GCP\/AWS\/Azure etc)\n2+years of experience working with tools to automate CI\/CD pipelines (e.g., Jenkins, GIT)\nMust have great articulation and communication skills.\nWorking in a fluid environment, defining, and owning priorities that adapt to our larger goals. You can bring clarity to ambiguity while remaining open-minded to new information.\nPreferred Qualifications\nGCP data engineering technologies such as Cloud Dataflow, Cloud Storage, Pub\/sub, Cloud Composer, Big Query, and Health care API (FHIR store)\nKnowledge and Experience in Big Query is strongly preferable.\nExperience working with health care data and understanding of analytics and how it is leveraged within the healthcare industries.\nExperience in working cross functional initiatives communicating effectively and confidently with business partners, project team members and senior management.\nKnowledge and experience HL7 FHIR, HL7V2 and C-CDA standards is a strong plus.\nEducation\nBachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline. Master's degree preferred.\nPay Range\nThe typical pay range for this role is:\n$90,000.00 - $180,000.00\nThis pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.\nIn addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company\u201a\u00c4\u00f4s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (\u201a\u00c4\u00faPTO\u201a\u00c4\u00f9) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Companypolicies.\nFor more detailed information on available benefits, please visitjobs.CVSHealth.com\/benefits\nCVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.\nYou are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.\nCVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services throughColleagueRelations@CVSHealth.comIf you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Pipelines, ETL\/ELT, Python, Unix Shell Scripting, SQL, JSON, XML, Cloud Data Engineering Technologies, Cloud Dataflow, Cloud Storage, Pub\/Sub, Cloud Composer, Big Query, Health Care API (FHIR Store), Big Query, Healthcare Data, Analytics, HL7 FHIR, HL7 V2, CCDA Standards, Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst",
      "company":"MANDO TECHNOLOGIES INC",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-mando-technologies-inc-3768770013",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Mando Technologies is specializes in helping organizations make the most of their information assets. From acquiring, organizing, analyzing, and delivering data to closing the loop by integrating intelligence into the operations of the enterprise, Mando Technologies covers the full spectrum of Business Intelligence.\nNeed talented Data Analyst for a long-term contract based in Plano, TX (Hybrid) On W2\nNote - No H1b\nKey Skills And Experience\nDevelop and maintain SQL queries and scripts for data extraction and reporting.\nHandle and customize APIs to integrate external data sources into our analysis.\nWork with PySpark for big data processing and analysis.\nExperience in Python and SQL for data manipulation and analysis.\nExperience in data patterns, data filling, and data extension techniques.\nExperience with PySpark, is a plus.\nPreferred\nSQL (strong)\nAWS S3, CI\/CD, etc. (intermediate)\nNice To Have\nPython programming\nFamiliarity with BI tools like Tableau or Power BI\nShow more\nShow less",
      "job_skills":"SQL, Python, PySpark, API Integration, Data Extraction, Data Reporting, Data Manipulation, Data Analysis, Data Patterns, Data Filling, Data Extension, AWS S3, CI\/CD, Tableau, Power BI",
      "Category":"Backend Development"
  },
  {
      "job_title":"SENIOR DATA ENGINEER @Irving - TX",
      "company":"Diverse Lynx",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-%40irving-tx-at-diverse-lynx-3764420980",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job title SENIOR DATA ENGINEER 2.Job summary Perform the Data Engineer activities 3.Experience 8to12Yrs 4.Required Skills ,BigQuery,Cloud Dataflow,Airflow 5.Nice to have skills ,PySpark,GCP Services,Python 6.Technology -Not Applicable 7.Shift Day 8.Roles & Responsibilities Analyzes complex data structures from disparate data sources and design large scale data engineering pipeline Develops large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs Collaborates with product business and data science team to collect user stories and translate into technical specifications Uses knowledge in Cloud & Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines Uses strong programming skills in PySpark, Python, Java or any of the major languages to build robust data pipelines and dynamic systems Builds highly scalable and extensible data marts and data models to support Data Science and other internal customers on Cloud. Integrates data from a variety of sources, assuring that they adhere to data quality and accessibility standards. Analyzes current information technology environments to identify and assess critical capabilities and recommend solutions Experiments with available tools and advice on new tools to determine optimal solution given the requirements dictated by the model\/use case Required Qualifications 3+ years of progressively complex related experience in cloud data engineering and data analysis Knowledge in programing languages such as PySpark, Java, Python, Hive, SQL Knowledge in Cloud Technology, Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment Strong knowledge of large-scale search applications and building high volume data pipelines, preferably using Dataproc, composer services on GCP or other Cloud Platforms 2+ years of development experience in GCP and native tools & services such as DataProc, Composer, BigQuery, Airflow 2 to 3+ years of PySpark or Scala or Python programing proficient in SQL 3&plus; years\nDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\nShow more\nShow less",
      "job_skills":"BigQuery, Cloud Dataflow, Airflow, PySpark, GCP Services, Python, Hadoop, HDFS, Apache Hive, SQL, Dataproc, Composer, Composer, Scala",
      "Category":"Backend Development"
  },
  {
      "job_title":"Principal DATA Engineer   Data Analytics Platform",
      "company":"Verdant Infotech Solutions",
      "job_location":"Copper Canyon, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-data-engineer-data-analytics-platform-at-verdant-infotech-solutions-3785514142",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Title: Principal DATA Engineer \u201a\u00c4\u00ec Data Analytics Platform\nDuration: Direct Hire\nVisa: USC and GC only ( No Fake , Need Genuine Only)\nLocation: Hybrid available in the following cities: Phoenix, AZ \/ Chicago, IL \/ New York, NY \/ San Francisco, CA ( Need local of these cities only)\nInterview: 2 Videos\nNeed: Updated LinkedIn with profile pic.\nJob Description\nThis position is a hands-on, individual contributor and technical leader involved in setting the standards and ensuring excellence in quality of outputs across multiple teams to create an Analytics Data Platform. This initiative consists of creating an appropriate replica of various bespoke operational data stores and customer contribution data into a data platform that is fit for analytics and data science workloads. Scale and velocity should excite you, not scare you. We are looking for someone who has successfully built and delivered an Analytics Data Platform from the ground up.\nThis is a principal level, individual contributor role responsible for architecting a Data Analytics Platform based on AWS technologies. They will also be responsible for acting as a player\/coach with our existing analytics technical platform team consisting of senior and junior data engineers. They will have the support of our Sr. Director, Analytics Technical Platform. It is critical to have actual, hands-on experience architecting and building a data analytics platform for medium to large enterprise based on AWS technologies. Theoretical knowledge is not enough.\nKey Responsibilities\nMinimum 15 or more years of experience in designing and developing complex software projects.\nExperience in influencing cross-functional teams to create high throughput, high velocity data pipelines using both streaming and batch processing paradigms.\nEffective communicator with exceptional public speaking skills. Comfortable presenting to all levels within the company.\nExperience designing, implementing and operationalizing an analytics data platform in AWS.\nNetworking experience relevant to moving data between on-prem and cloud environments.\nExperience with data handling processes such as retention policies, masking and encryption for compliance and visibility purposes.\nCurrent development skills using python, java or Scala.\nExperience with multiple data stores such as Oracle, MS-SQL Server, Postgres and noSql variety.\nExperience running a vendor selection process for relevant analytics platform needs.\nExpertise in terraform, k8s and\/or other cloud orchestration technologies.\nExperience creating AWS observability and monitoring systems.\nExperience with several of the following AWS technologies: Glue\/Glue Catalog\/Glue Crawler, Kinesis\/Firehose, RedShift, DynamoDB, Athena.\nExperience with ETL tools.\nExperience with data processing orchestration tools.\nExperience with data cataloging tools.\nEssential Functions\nPartners with product management to craft product strategy, create product descriptions and ensure alignment to technology roadmaps.\nBe a thought leader: a senior point of expertise on Data Engineering, Data Science, Business Intelligence, software engineering issues, industry trends and developing technologies. Be a role model to others on the team; coach and mentor team members.\nTakes ownership for creating technical product design and architecture \u201a\u00c4\u00ec evaluating buy vs. build decisions and bought product maturity and fit for purpose.\nWorks closely with customers to understand their needs and create a partnership for making products better.\nDocuments SDLC artifacts so that other team members can understand and \"follow the leader\u201a\u00c4\u00f9 \u201a\u00c4\u00ec such as Confluence documentation, jira artifacts and associated MS-office documents (Excel, Word, PPT).\nDesigns, implements and operationalizes a data analytics platform using AWS tools such as:\nS3 storage\nGlue and related tools\nRedshift, DynamoDB\nAthena\nCrawlers\nObservability matters using CloudWatch and CloudTrail\nCoach and develop others to use the above tools by creating small technical demonstrators or POCs.\nCreates and conducts presentations for small-to-medium size groups.\nSupport the company's commitment to risk management and protecting the integrity and confidentiality of systems and data.\nThe above job description is not intended to be an all-inclusive list of duties and standards of the position. Incumbents will follow instructions and perform other related duties as assigned by their supervisor.\nMinimum Qualifications\nEducation and\/or experience typically obtained through a bachelor's degree in computer science, or related technical field.\nMinimum 15 or more years of experience in designing and developing complex software projects.\nExperience in influencing cross-functional teams to create high throughput, high velocity data pipelines using both streaming and batch processing paradigms.\nEffective communicator with exceptional public speaking skills. Comfortable presenting to all levels within the company.\nKnowledge of Software Development Lifecycle (SDLC) best practices, software development methodologies (Agile, Scrum, LEAN etc) and DevOps practices.\nExperience designing, implementing and operationalizing an analytics data platform in AWS.\nNetworking experience relevant to moving data between on-prem and cloud environments.\nExperience with data handling processes such as retention policies, masking and encryption for compliance and visibility purposes.\nCurrent development skills using python, java or Scala.\nExperience with multiple data stores such as Oracle, MS-SQL Server, Postgres and noSql variety.\nExperience running a vendor selection process for relevant analytics platform needs.\nExpertise in terraform, k8s and\/or other cloud orchestration technologies.\nExperience creating AWS observability and monitoring systems.\nExperience with several of the following AWS technologies: Glue\/Glue Catalog\/Glue Crawler, Kinesis\/Firehose, RedShift, DynamoDB, Athena.\nExperience with ETL tools.\nExperience with data processing orchestration tools.\nExperience with data cataloging tools.\nBackground and drug screen.\nPreferred Qualifications\nMaster's degree in computer science or related field.\n|\n,\n5208 Windsor Ln, Copper Canyon, Texas, 75077\nShow more\nShow less",
      "job_skills":"AWS, Data Analytics Platform, Data Engineering, Data Science, Business Intelligence, Software Engineering, Cloud Orchestration, Terraform, K8s, Python, Java, Scala, Oracle, MSSQL Server, Postgres, NoSQL, ETL Tools, Data Processing Orchestration Tools, Data Cataloging Tools, Confluence, Jira, CloudWatch, CloudTrail, Glue, Glue Catalog, Glue Crawler, Kinesis, Firehose, RedShift, DynamoDB, Athena, Crawlers",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-capital-one-3781379615",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Plano 1 (31061), United States of America, Plano, TexasSenior Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking\nData Engineers\nwho are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do:\nCollaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\nWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems\nUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake\nShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community\nCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\nPerform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply)\nAt least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java\n2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)\n2+ year experience working on real-time data and streaming applications\n2+ years of experience with NoSQL implementation (Mongo, Cassandra)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Data Engineering, Scala, Python, Java, Linux, Agile, RDBMS, NoSQL, Cloud Computing, AWS, Azure, Google Cloud, Hadoop, Hive, Kafka, Spark, Mongo, Cassandra, Redshift, Snowflake, Unit Testing, SQL, MapReduce, EMR, Gurobi, MySQL",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-capital-one-3774778159",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Plano 5 (31065), United States of America, Plano, TexasSenior Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking a\nSenior Data Engineer\nwho is passionate about marrying data with emerging technologies. As a Capital One Senior Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do\nProactively seeks out opportunities to address customer needs and influences stakeholders so that we are building the best solutions for the most important problems\nSupport the design and development of scalable data architectures and systems that extract, store, and process large amounts of data\nBuild and optimize data pipelines for efficient data ingestion, transformation, and loading from various sources while ensuring data quality and integrity\nCollaborate with Data Scientists, Machine Learning Engineers, Business Analysts and\/or Product Owners to understand their requirements and provide efficient solutions for data exploration, analysis, and modeling\nImplement testing, validation and pipeline observability to ensure data pipelines are meeting customer SLAs\nUse cutting edge technologies to develop modern data pipelines supporting Machine Learning and Artificial Intelligence\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply)\nAt least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java\n2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka or Spark)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Python, SQL, Scala, Java, AWS, Microsoft Azure, Google Cloud, MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Redshift, Snowflake, UNIX\/Linux, Agile",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-capital-one-3780755514",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Plano 1 (31061), United States of America, Plano, TexasSenior Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do:\nCollaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\nWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems\nUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake\nShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community\nCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\nPerform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply)\nAt least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java\n2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)\n2+ year experience working on real-time data and streaming applications\n2+ years of experience with NoSQL implementation (Mongo, Cassandra)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nThe minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\nNew York City (Hybrid On-Site): $161,900 - $184,800 for Senior Data EngineerSan Francisco, California (Hybrid On-Site): $171,500 - $195,800 for Senior Data Engineer\nCandidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u201a\u00c4\u00f4s offer letter.\nThis role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and\/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Java, Scala, Python, Open Source RDBMS, NoSQL databases, Redshift, Snowflake, Cloud based data warehousing, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL, Mongo, Cassandra, UNIX\/Linux, Agile engineering, MapReduce, AWS, Microsoft Azure, Google Cloud",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-capital-one-3774777399",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Plano 6 (31066), United States of America, Plano, TexasSenior Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking a\nSenior Data Engineer\nwho is passionate about marrying data with emerging technologies. As a Capital One Senior Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do\nProactively seeks out opportunities to address customer needs and influences stakeholders so that we are building the best solutions for the most important problems\nSupport the design and development of scalable data architectures and systems that extract, store, and process large amounts of data\nBuild and optimize data pipelines for efficient data ingestion, transformation, and loading from various sources while ensuring data quality and integrity\nCollaborate with Data Scientists, Machine Learning Engineers, Business Analysts and\/or Product Owners to understand their requirements and provide efficient solutions for data exploration, analysis, and modeling\nImplement testing, validation and pipeline observability to ensure data pipelines are meeting customer SLAs\nUse cutting edge technologies to develop modern data pipelines supporting Machine Learning and Artificial Intelligence\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply)\nAt least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java\n2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka or Spark)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Data engineering, Agile development, Python, SQL, Scala, Java, TensorFlow, Linux, Hadoop, Hive, EMR, Kafka, Spark, Redshift, Snowflake, AWS, Azure, Google Cloud",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-capital-one-3786336016",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Plano 5 (31065), United States of America, Plano, TexasSenior Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do:\nCollaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\nWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems\nUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake\nShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community\nCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\nPerform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply)\nAt least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java\n2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)\n2+ year experience working on real-time data and streaming applications\n2+ years of experience with NoSQL implementation (Mongo, Cassandra)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Java, Scala, Python, RDBMS, NoSQL, Redshift, Snowflake, Machine learning, Distributed microservices, Full stack systems, Cloudbased data warehousing, Unit testing, Agile engineering, UNIX\/Linux, Shell scripting, MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL, Mongo, Cassandra",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-capital-one-3779612006",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Plano 6 (31066), United States of America, Plano, TexasSenior Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do:\nCollaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\nWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems\nUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake\nShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community\nCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\nPerform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply)\nAt least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java\n2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)\n2+ year experience working on real-time data and streaming applications\n2+ years of experience with NoSQL implementation (Mongo, Cassandra)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Agile, AWS, Cassandra, Cloud, EMR, Gurobi, Hadoop, Hive, Java, Kafka, MapReduce, Microsoft Azure, Mongo, MySQL, NoSQL, Open Source RDBMS, Python, Redshift, Scala, Snowflake, Spark, SQL, UNIX\/Linux",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-capital-one-3774775763",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Plano 3 (31063), United States of America, Plano, TexasSenior Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do:\nCollaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\nWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems\nUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake\nShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community\nCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\nPerform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply)\nAt least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java\n2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)\n2+ year experience working on real-time data and streaming applications\n2+ years of experience with NoSQL implementation (Mongo, Cassandra)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Agile, AWS, Cassandra, Cloud Computing, EMR, Gurobi, Hadoop, Hive, Java, Kafka, Linux, MapReduce, Mongo, MySQL, Open Source RDBMS, Python, Redshift, Scala, Snowflake, Spark, SQL, UNIX",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-capital-one-3774772993",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Plano 1 (31061), United States of America, Plano, TexasSenior Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Senior Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do:\nCollaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\nWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems\nUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake\nShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community\nCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\nPerform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply)\nAt least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java\n2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)\n2+ year experience working on real-time data and streaming applications\n2+ years of experience with NoSQL implementation (Mongo, Cassandra)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Java, Scala, Python, RDBMS, NoSQL, Redshift, Snowflake, Machine Learning, Microservices, Agile, Unit Testing, Git, UNIX\/Linux, Shell Scripting, AWS, Azure, Google Cloud, MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL",
      "Category":"Backend Development"
  },
  {
      "job_title":"Python Data Engineer (W2 Employees Only, No Corp-to-Corp)",
      "company":"Ccube",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/python-data-engineer-w2-employees-only-no-corp-to-corp-at-ccube-3787928953",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Location: Plano, TX (Onsite - Hybrid, absolutely not remote)\nRequirements:\n5+ years of professional work experience designing and implementing data pipelines in a cloud environment is required.\n2+ years of experience migrating\/developing data solutions in the AWS cloud is required.\n1+ years of experience building\/implementing data pipelines using Databricks or similar cloud database.\nExpert level knowledge of using SQL to write complex, highly-optimized queries across large volumes of data.\nHands-on object-oriented programming experience using Python is required.\nProfessional work experience building real-time data streams using Spark and Experience in Spark.\nKnowledge or experience in architectural best practices in building data lakes\nQualifications:\nBachelor\u201a\u00c4\u00f4s or master's degree in Computer Science or a related field (a must)\n5+ years of experience building scalable enterprise data pipelines in the cloud\nW2 Employees Only, No Corp-to-Corp\nPowered by JazzHR\nIZ0PrT3m57\nShow more\nShow less",
      "job_skills":"Data Pipelines, AWS Cloud, Databricks, SQL, Python, Spark, Data Lakes, Cloud Computing, ObjectOriented Programming",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"Dynatron Software, Inc.",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-dynatron-software-inc-3768749551",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Lead Data Engineer\n100% Remote | Full Time\nWe are seeking a dynamic and experienced Lead Data Engineer to join our newly formed Data Platform Team. As a Lead Data Engineer, you will have the opportunity to collaborate with a team of data scientists, engineers, and analysts to create and maintain scalable data pipelines. You will be responsible for writing big data pipelines in Python and DBT transformations in SQL. The ideal candidate will have a strong technical background, a passion for data processing, and the ability to think creatively and strategically to solve complex challenges.\nKey Responsibilities:\nWrite, test, and maintain robust, high-quality code in Python and DBT data models on Snowflake.\nWork with data and analytics experts to strive for greater functionality in our data systems.\nCollaborate with cross-functional teams to gather requirements and develop software solutions.\nDesign, construct, install, test, and maintain highly scalable data management systems.\nProvide debugging and troubleshooting support for existing systems.\nParticipate in code reviews to ensure software quality and adherence to standards.\nAssist in database design and the development of our Snowflake data warehouse.\nLeverage AWS and other cloud technologies for efficient software deployment and scalability.\nUse Python to process and clean data, manage ETL pipelines, and create automated workflows.\nMinimum Qualifications:\nBachelor's degree in Computer Science, Engineering, or a related field.\n5+ years of experience in designing, implementing, and maintaining relational\/data warehousing environments.\nStrong proficiency in programming languages commonly used in data engineering, such as Python, SQL, and big data technologies like Snowflake, Spark, Kafka, and distributed computing frameworks.\nExperience working with data warehouses and relational databases.\nFamiliarity with AWS and\/or other cloud-based technologies.\nExperience with Big Data technologies such as Hadoop, Spark, Beam, Flink, or similar technologies is a plus.\nExcellent problem-solving skills with a strong attention to detail.\nAbility to work both independently and as part of a team.\nExcellent verbal and written communication skills.\nPreferred Qualifications:\nExperience working on a project that involved multi-classification\nExperience with hybrid cloud workflows\nIn Return for Your Expertise, You Will Receive:\nExcellent benefits including health, dental, and vision insurance, stock options, work from home and flexible scheduling depending on job requirements, professional development opportunities, 9 paid holidays, and 15 days PTO.\nHome office setup support for remote employees.\nA welcome \u201a\u00c4\u00faswag bag\u201a\u00c4\u00f9 with branded clothing as an official welcome to the team.\nThe chance to work for an organization that puts people first and fosters a culture of teamwork, integrity, communication, accountability, and positive attitude!\nDynatron Software is an Equal Opportunity Employer and encourages all qualified individuals to apply.\nCompensation:\n$130,000 - $160,000\nShow more\nShow less",
      "job_skills":"Python, DBT, SQL, Snowflake, Data pipelines, AWS, Apache Spark, Data cleaning, ETL, Hadoop, Kafka, Beam, Flink, Distributed computing, Data warehouses, Relational databases, Multiclassification, Hybrid cloud, Software design, Software implementation, Software maintenance, Data processing, Debugging, Troubleshooting, Code review, Requirements gathering",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Big Data\/ Hadoop Engineer (Plano)",
      "company":"Experis",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-big-data-hadoop-engineer-plano-at-experis-3779917482",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Experis is a part of the Manpower Group family of brands. ManpowerGroup has partnered with a leading Financial Services organization in the\nPlano, TX\narea for a\nSr. Big Data\/ Hadoop Engineer\ncontract position to assist their team.\nJob\nTitle\n:\nSr. Big Data\/ Hadoop Engineer\nLocation\n:\nPlano, TX\nContract\n: 12 to 18 Months\nPay Rate Range\n: $63 to $65\nClient\n: Financial Client\nPosition Summary\nThe data solution delivery team is looking for an experienced Senior Hadoop Developer. Candidate should have in-depth knowledge of Hadoop technologies, SQL, and ETL processes. Candidate should possess excellent analytical capabilities, get a deep understanding of the data, and build co-relation between various data elements\/objects. The data solution delivery team is also responsible for ingesting the data from multiple sources, The candidate should be able to support the ingestion process using big data tools and frameworks.\nPrimary Skills\nHadoop\nSecondary Skills\nPython\nTertiary Skills\nUNIX\/SHELL SCRIPTS\nRequired Skills\nBachelor's degree in a technical or business-related field or equivalent working experience.\n4+ years of experience in data warehousing architectural approaches.\nMinimum of 4 years in big data.\n(Cloudera) Sound understanding and experience with the Hadoop ecosystem (Cloudera). Able to understand and explore the constantly evolving tools within the Hadoop ecosystem and apply them appropriately to the relevant problems at hand.\nExperience in working with Big Data implementation in a production environment.\nMust have experience with Big Data technologies like Hadoop, Hive, Spark, Python, Scala, etc. Experience in Python and Unix shell scripting. Experience in scheduling tools like Autosys Understanding of Agile methodologies and technologies Sound knowledge of relational databases (SQL) and experience with large SQL-based systems. Exposure to and strong working knowledge of distributed systems.\nExcellent understanding of client-service models and customer orientation in service delivery. Ability to grasp the 'big picture' for a solution by considering all potential options in the impacted area. Aptitude to understand and adapt to newer technologies. The ability to work with teammates in a collaborative manner to achieve a mission. Experience in query optimization, and performance tuning of complex SQL queries. Benchmark and debug critical issues with algorithms and software as they arise.\nFrequently Asked Questions\nBenefits? Yes, you can enroll in our corporate discount benefits package.\nRemote Workers? Hybrid with 3 days onsite and 2 days remote in a week.\nVisa Sponsorship? Not offered\nCorp-to-Corp? Not eligible\nHow To Apply\nFor immediate attention please apply online and send an email\nAbout Experis\nhttps:\/\/www.experis.com\/\nExperis is part of the ManpowerGroup family of brands. ManpowerGroup is the world leader in innovative workforce solutions, connecting human potential to the power of business. ManpowerGroup serves both large and small organizations across all industry sectors through our brands and offerings: Manpower, Experis, Talent Solutions, and Jefferson Wells.\nShow more\nShow less",
      "job_skills":"Hadoop, SQL, ETL, Python, UNIX\/SHELL SCRIPTS, Cloudera, Spark, Scala, Autosys, Agile, Distributed systems, SQL, Performance tuning, Data warehousing, Data processing, Data ingestion, Big data tools and frameworks, Data analytics, Data solution delivery",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Engineer",
      "company":"Diverse Lynx",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-at-diverse-lynx-3764419990",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Technical\/Functional Skills\nPrimary \u201a\u00c4\u00ec Cloud Based ETL Tool, Snowflake (Cloud DB), Snaplogic , DBT, Strong SQL, Unix\/Python, Control-M\nExperience Required\n10&plus; Years\nRoles & Responsibilities\nRole Description\nAnalyze requirements and existing resources to Propose, create ETL designs and database objects\nWork with project and business analyst leads in order to develop and clarify in-depth technical requirements including logical and physical data modeling activities\nDesign and implement ETL processes for data transactions related to Enterprise Data Warehouse, Operational Data Store (ODS), and other data structures to support our Business Intelligence operations\nDevelops, enhances, debugs, supports, maintains and tests software applications that support business units or supporting functions using IBM Infosphere Data Stage ETL or any other cloud based ETL tool both ETL and ELT approaches. These application program solutions may involve diverse development platforms, software, hardware, technologies and tools.\nMust have hands-on on Snowflake development environment with all SQL operations. Must be aware of ELT approach as well.\nParticipates in the design, development and implementation of complex applications, often using IBM Infosphere Information Server (IIS) products like Data Stage, Quality Stage on a Linux Grid environment. Control-M\/Scheduling tools.\nRequired Skills:10&plus; Yrs Relevant IT software experience (Technical) in ETL Datastage or any other cloud based ETL Tool development Experience with databases like Snowflake (Cloud DB), Oracle, Netezza, MS SQL Server 2012&plus;, DB2 and MS Access\nExperience with job automation & scheduling software (Control-M) Strong ability to write SQL queries\nDesired Skills:\nFamiliar with Java API\u201a\u00c4\u00f4s, Snowflake (Cloud DB), Snaplogic,\nPython, UNIX, Windows, File transfer utilities, process flow creation, ETL technologies, Hadoop\nGood to have Skills: Java Springboot, Snow-Pro Certified, Snaplogic, Strong SQL, Strong conceptual understanding of core DW Concepts including different approaches\/methodologies. dbt (data build tool) experience is an added advantage\nDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\nShow more\nShow less",
      "job_skills":"CloudBased ETL Tool, Snowflake, Snaplogic, DBT, SQL, Unix, Python, ControlM, Data Stage, Linux Grid, Java API's, Hadoop, Java Springboot, SnowPro Certified, dbt",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Architect \/ BI Developer",
      "company":"Stellent IT",
      "job_location":"Coppell, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-architect-bi-developer-at-stellent-it-3692571731",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Title -Data Architect\/ PowerBI Developer\nLocation - Coppell, TX (4 days a week onsite, 1 day remote)\nPhone + Skype\nVisa - Green Card Holder or US Citizen\nJob Description\nManager Notes:\nArchitect for data enterprise operations\nNeed experience with SQL Server database (SSAS, SSIS) and Power BI\nMust understand how system consumes data and put in cubes and schedule it to run and then reporting on the data environment\nVery hands on technically with data architecture and analytics\nJob Summary\nThe Director of Enterprise Systems\nwill be responsible for leading the\nEnterprise Applications\nteam overseeing Smoothie King's enterprise solutions and data management environment across the organization. The Director of Enterprise Systems will assist in planning, implementing, and managing the data warehouse, analytics and reporting platforms as well as related support activities.\nEssential Functions \/ Major Responsibilities\nProvide leadership and expertise in managing Information systems across the enterprise, including but not limited to: Data Warehouse, Corporate Systems, and custom applications.\nSet The Strategy, Roadmap, And Key Milestones To Operationalize a Vision Which Delivers Business Value By Innovative Use Of Data, Including\nData architecture.\nData integration and analytics solutions and services.\nAnalytics platforms, tools, architecture, and engineering.\nManagement of data and analytics products.\nData stewardship, data analytics and enablement, data science, and data\/AI operations.\nOwn strategic decisions for our data analytics infrastructure such as analytics tool selection and design.\nManage the overall management and upkeep of a Company's Enterprise systems, including installing and configuring software, applying security patches, and monitoring system performance.\nOversee the end-to-end integration of software components and systems to support the effective and efficient delivery of data services across the organization.\nEstablish and maintain standards for analysis, design, coding, testing, and documentation of the Data Warehouse and Enterprise Applications.\nParticipate in projects to integrate new technologies and upgrades of existing technologies including installing, configuring, and testing new hardware and software. Monitor and report on the status of projects.\nRecommend processes for requesting and prioritizing requests for data requests and application development projects.\nParticipates in cross-functional, cross-discipline project teams to better leverage the existing systems.\nCoordinates information and data changes that occur as part of system lifecycle to ensure consistency.\nRecognizes and identifies potential areas where existing policies and procedures that require change, or where new ones need to be developed.\nSupervise, lead, hire, coach, and evaluate performance of staff has one direct report\nRequired Skills \/ Abilities \/ Competencies\nAbility to work independently on multiple assignments and to work collaboratively within internal and cross-functional teams.\nAbility to adapt to new technology platforms and services.\nDemonstrates experience in delivering successful outcomes.\nDemonstrates experience in setting priorities and performance management measures.\nDemonstrates Experience With The Following\nInfrastructure as a Service (Azure\/AWS).\nData as a Service.\nStorage as a Service.\nContainerization.\nStrong experience with Microsoft SQL and database architecture, database administration principles, best practices, and the uses of information technology to support organizational requirements.\nManaging Enterprise Infrastructure Systems in a Hybrid Cloud environment between on-premises data centers, AWS, and Azure.\nExperience developing custom, Python, R, and Microsoft PowerShell scripts.\nKnowledge of IT operation processes including asset management, project management, configuration management, incident management and change management.\nA working knowledge of TCP\/IP, Network layers and routing, DNS, DHCP, Active Directory, LDAP, information security; including system hardening, log analysis, intrusion detection, and vulnerability scanning.\nPromote the culture, values, and mission of Smoothie King.\nEducation And Experience\nBachelor's degree in Computer Science, or related field.\nTen (10) + years IT Experience; or equivalent combination of education and experience.\nSeven (7) + years of demonstrated hands-on experience with the planning, delivery and management of enterprise information systems including Data Warehouse.\nFive (5)+ years of supervisor experience leading internal and external teams.\nFive (5)+ years of experience planning and managing systems in a high availability, fast-paced environment.\nWorking knowledge of the design, installation, and support of Data Warehouse models, tools, and analytics platforms.\nCloud experience with AWS, Azure, O365 and other Microsoft stack tools.\nShow more\nShow less",
      "job_skills":"Data Architecture, Power BI, SQL Server, SSAS, SSIS, Data Management, Analytics, Data Warehousing, Data Integration, Data Science, Data Analytics, Data Stewardship, Data Enablement, Data\/AI Operations, Python, R, Microsoft PowerShell, Azure, AWS, Microsoft SQL, Database Administration, Information Technology, Hybrid Cloud, Active Directory, LDAP, Information Security, System Hardening, Log Analysis, Intrusion Detection, Vulnerability Scanning, TCP\/IP, Network Layers, Routing, DNS, DHCP",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer",
      "company":"Brooksource",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-at-brooksource-3757803281",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Data Engineer\nPlano, TX\nHybrid (onsite Monday - Wednesday)\nAs the Data Engineer for a Fortune 50 company, you will be responsible for day-to-day data collection, transportation, maintenance and access to enterprise data. You will be a member of a team of data engineers who build data pipelines into various source systems, rest data on the data lake and enable exploration and access for analytics, visualization, machine learning and product development efforts across the company.\nMINIMUM QUALIFICATIONS\nQUALIFICATIONS:\nBA\/BS in Computer Science, Math, Physics, or other technical fields.\n6+ years of overall technology experience that includes at least 4+ years of hands-on software development, data engineering, and systems architecture.\n4+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.\n4+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).\n2+ years in cloud data engineering experience in Azure.\nFluent with Azure cloud services. Azure Certification is a plus. (AWS will work)\nExperience with integration of multi cloud services with on-premises technologies.\nExperience with data modeling, data warehousing, and building high-volume ETL\/ELT pipelines.\nExperience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.\nExperience building\/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.\nExperience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.\nExperience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.\nExperience with version control systems like Github and deployment & CI tools.\nExperience with Azure Data Factory, Azure Databricks and Azure Machine learning tools.\nExperience with Statistical\/ML techniques is a plus.\nUnderstanding of metadata management, data lineage, and data glossaries is a plus.\nWorking knowledge of agile development, including DevOps and DataOps concepts.\nFamiliarity with business intelligence tools (such as PowerBI).\nRESPONSIBILITES:\nActive contributor to code development in projects and services\nManage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products\nBuild and own the automation and monitoring frameworks that capture metrics and operational KPIs for data pipeline quality and performance\nWork cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders\nResponsible for implementing best practices around systems integration, security, performance and data management\nEmpower the business by creating value through the increased adoption of data, data science and business intelligence landscape\nWHAT\u201a\u00c4\u00f4S IN IT FOR YOU\u201a\u00c4\u00b6?\nHealth benefits, 401K Plan, Weekly Pay Checks, Onsite cafeteria\nOpportunity to work with a Fortune 400, international retail brand\nOpportunity to diversify skillset and learn new technologies support several different retail applications\nBrooksource provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws.\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Collection, Data Transportation, Data Maintenance, Data Access, Data Warehousing, Data Analytics, Data Modeling, Data Quality, ETL\/ELT Pipelines, Data Profiling, MPP Databases, Redshift, Synapse, SnowFlake, Cloud Infrastructure, Kubernetes, Version Control Systems, Azure Data Factory, Azure Databricks, Azure Machine Learning, Statistical\/ML Techniques, Metadata Management, Data Lineage, Data Glossaries, Agile Development, DevOps, DataOps, Business Intelligence Tools, PowerBI, Python, PySpark, Scala, SQL, Azure, AWS, Apache Griffin, Deequ, Great Expectations",
      "Category":"Backend Development"
  },
  {
      "job_title":"Distinguished Data Engineer",
      "company":"Verizon",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/distinguished-data-engineer-at-verizon-3786568411",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"When you join Verizon\nVerizon is one of the world's leading providers of technology and communications services, transforming the way we connect around the world. We're a human network that reaches across the globe and works behind the scenes. We anticipate, lead, and believe that listening is where learning begins. In crisis and in celebration, we come together-lifting up our communities and striving to make an impact to move the world forward. If you're fueled by purpose, and powered by persistence, explore a career with us. Here, you'll discover the rigor it takes to make a difference and the fulfillment that comes with living the #NetworkLife.\nAs a Distinguished Engineer- Cloud within the Artificial Intelligence and Data Organization (AI&D), you will be strategizing, identifying and driving state-of-the-art technologies for Platform Rationalization and Work with leadership and help align on strategies across the enterprise. You will be defining a blueprint for GCP's adoption and GCP's services and come up with high-level design to implement solutions and Partner with stakeholders to identify real business opportunities and build a roadmap. You will be a good thought leader with innovation in every thought. You are a good team player and have a go-getter kind of attitude with good interpersonal skills. Understanding the Latest happening in Cloud technologies, Generative AI, Datascience, ML and Model Operations area and building good work culture with stakeholders including, Business, Enterprise architects, Data Engineers, Data Scientists. Adhering to the organization priorities and policies. Building external stakeholder communication with Business user and Data ScientistsThe work you'll be doing will be Architecting, Build & support at AI&D platforms, which is going to enhance the experience for Data scientists and ML engineers to build world class solutions at scale.\nWhat you'll be doing...\nPerforming the Proof of Concepts (POCs) & Proof of Technologies (POTs) with new services\/technologies in cloud, on-prem & open source technologies\/\nDeveloping hybrid solutions to effectively utilize the GPUs across on-prem & cloud by lowering the operational costs.\nWorking closely with the Enterprise architects, AI&D Leaders, network & security teams and application teams to build the scalable platforms that meets both business and technical requirements within the budget.\nInfluencing the stakeholders to get the desired outcome.\nPerformance GCP Bigquery administration, workload management & BQ tuning.\nProviding support for the engineering team on Kubernetes Clusters, Dataproc, Kafka, HDP and CDP cluster related issues.\nIdentifying the opportunities to automate the platform engineering activities including but not limited to Security compliance, platform remediation & governance.\nCreating tools and assets for managing data products, Creating and maintaining documentation for platform configurations, changes, and issues.\nDesigning and recommending solution frameworks for teams to develop self-serve \/ auto-heal solutions in GCP & On Prem Hadoop Platform.\nDeveloping and deploying Python based custom solutions using Cloud Functions, Pubsub, BQ etc services in GCP.\nCreating GCP infrastructure using Terraform and optimize the custom terraform modules.\nDeveloping ansible scripts and integrate with Terraform as part of application environment provisioning in GCP \/ On Pem.\nCollecting, integrating and Developing platform observability dashboards .\nAnalyzing and designing SRE solutions on top of existing GCP networks spanning across different GCP projects and on Prem Hadoop.\nResolving user issues for data services in Hadoop, Spark and GCP like dataproc, dataflow, composer, GKE, storage, Compute, BQ, cloud functions to name a few.\nHandling production support activities and following the incident management process.\nWhere you'll be working:\nIn this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.\nWhat we're looking for...\nYou'll need to have:\nBachelor's degree or four or more years of work experience.\nSix or more years of relevant work experience.\nEven better if you have one or more of the following:\n4 or more years of experience as Platform\/solution\/Enterprise architect.\nDeep hands-on experience with Spark, Hive, big data & open source technologies .\nDevOps \/ SRE \/ Hadoop experience.\n2 or more years experience in GCP cloud technologies\nExperience in a modern scripting language (preferably Python \/ shell scripting ) for automation of build tasks. Two or more years Experience with Big Data on GCP - Dataproc, dataflow, Cloud Function, BigQuery, Composer, GKE, IA, etc.\nExperience in working with REST APIs and event based Architecture\nExperience in distributed processing (Hadoop \/ Spark ) Framework , resource management and optimization techniques.\nStrong analytical and troubleshooting skills.\nGenerative AI certification & implementation experience.\nExperience in optimizing the complex SQLs .\nExperience in Git , Jenkins CI\/CD, Python and GCP client libraries.\nGCP Cloud Architect certification(s) or equivalent public cloud certifications.\nIf Verizon and this role sound like a fit for you, we encourage you to apply even if you don't meet every \"even better\" qualification listed above.\nWhere you'll be working\nIn this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.\nScheduled Weekly Hours\n40\nEqual Employment Opportunity\nWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.\nShow more\nShow less",
      "job_skills":"Cloud Technologies, Big Data, Data Science, Machine Learning, Data Engineering, Kubernetes, Dataproc, Apache Kafka, Hortonworks Data Platform, Cloudera Data Platform, Data Observability, Site Reliability Engineering, DevOps, Apache Spark, Apache Hive, SQL, Git, Jenkins, Python, GCP Client Libraries, Cloud Function, Compute Engine, Terraform",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer - Senior",
      "company":"HTC Global Services",
      "job_location":"Addison, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-senior-at-htc-global-services-3779397961",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"HTC \u201a\u00c4\u00ec A brief profile\nEstablished in 1990, HTC Inc., a CMM Level 5 company with headquarters in Troy, Michigan, is a leading global Information Technology solution and BPO provider. HTC assists clients across multiple industry verticals, offering turnkey project lifecycle in, e-business, data warehousing, embedded systems, ECM, SCM, CRM, and ERP solutions. HTC Inc offers Connect IT, our Global Delivery Methodology that enables seamlessly delivery of outsourced IT services. HTC has global delivery centers across the globe.\nResponsibilities:\nDesign, develop and support data pipelines in a hybrid cloud environment to enable advanced analytics. Design, develop and support CI\/CD of data pipelines and micro-services.\nDevelop new services in AWS using server-less and container-based services. Work with Spark clusters and Bigdata ecosystem tools on-prem and in the cloud.\nMinimum Qualifications:\nProficient in Python and Spark\nHands-on experience with Azure\/AWS\/GCP\nHands-on experience with Data Lake or Data Warehouse\nIntermediate to advanced SQL skills\nExperience in using Serverless Development\nShould have the ability to work and contribute beyond defined responsibilities\nExcellent communication\/inter-personal skills a must\nAttitude and aptitude to learn new technologies in a fast-paced environment\nEffective problem-solving skills\nAbility to work in a fast-paced environment with a \"can do\" attitude\nPreferred Qualifications:\n8+ Years of working experience in relevant technologies.\nBesides Minimum Qualification below will be considered added advantages\nWorking experience on Python, Airflow, Apache Spark , Apache Beam, Apache Flink, Kubernetes etc.\nExperience with CI\/CD and DevOps is added advantage\nWorking Knowledge of OpenShift\nFamiliarity in using AIOPS platforms like mlFlow, AutoML\nKnowledge on Kafka is added advantage\nBachelors in Computer Engineering and\/or Computer Science and\/or Information Technology.\nBenefits:\nAt HTC Global Services our associates have access to a comprehensive benefits package that includes Health, Dental, Vision, Paid-Time-Off, Paid Holidays, 401K matching, Life and Accidental Death Insurance, Short- & Long-Term Disability Insurance, and a variety of other offerings.\nDiversity & Inclusion\nOur success as a company is built on practicing inclusion and embracing diversity. HTC Global Services is committed to providing a work environment free from discrimination and harassment, where all employees are treated with respect and dignity. Together we work to create and maintain an environment where everyone feels valued, included, and respected. At HTC Global Services, our differences are embraced and celebrated. HTC is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills, and experiences within our workforce. HTC is proud to be recognized as a National Minority Supplier\nEEO\/M\/F\/V\/H\nShow more\nShow less",
      "job_skills":"Python, Spark, Azure, AWS, GCP, Data Lake, Data Warehouse, SQL, Serverless Development, Airflow, Apache Spark, Apache Beam, Apache Flink, Kubernetes, CI\/CD, DevOps, OpenShift, AIOPS platforms, mlFlow, AutoML, Kafka",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Services Engineer",
      "company":"Mr. Cooper",
      "job_location":"Lewisville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-services-engineer-at-mr-cooper-3786376138",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Who We Are\nWe are Xome, a real estate services company headquartered in the Dallas, Texas area. As a subsidiary of Mr. Cooper Group, we employ over 1,200 team members nationwide. The nation\u201a\u00c4\u00f4s largest financial services companies look to us for integrated and scalable business solutions that help simplify the mortgage and real estate process.\nAt the heart of everything we do is our purpose: To keep the dream of home ownership alive. If that sounds like a big, lofty goal, that\u201a\u00c4\u00f4s because it really is. And we can\u201a\u00c4\u00f4t do it alone. Our entire team is focused on helping create a stable and healthy housing industry. And, making sure the process of buying\/selling a home doesn\u201a\u00c4\u00f4t undermine the excitement of home ownership. That\u201a\u00c4\u00f4s why we battle every day against the mediocrity of the status quo to simplify the complex world of mortgage servicing, lending and banking. We see ourselves as the experts who make doing business easier. While others bring complexity and a lack of transparency, we offer simplicity, trust, and visibility across the entire property lifecycle. And we deliver radical customer service.\nNow, you might be wondering; how exactly do you pronounce Xome? Simple. ZOM (like home, if it started with a z)!\nThe Senior Data Services Engineer is responsible for designing and developing data repositories for enterprise business operations to be used for providing business reporting and analysis. The Senior Data Services Engineer will support the analytics team by providing accurate, timely and relevant data to meet their diverse requirements. The Senior Data Services Engineer will also work closely with internal teams to support and build business insight tools.\nEssential Job Functions\nDesigns data architectures and builds relational\/dimensional databases and establish methods to improve functional reporting data content and completeness of data.\nDesign and develop robust, re-usable and scalable data driven solutions and data pipeline frameworks to automate the ingestion, processing and delivery of both structured and unstructured batch and real-time streaming.\nProvide technical skills in designing and developing BI\/Data projects in the areas of optimal design patterns, models, standards and code to ensure consistency and realize benefits of a high-performing, secure, reliable and scalable architecture\nCollaborate with IT architecture\/data team\/ data scientists to develop a practical end state and reference architectures for BI\/Data with considerations for distributed data, in-memory computing, cloud computing, visualization tools\/platforms\nProvide technical leadership in areas such as master data management and reference data management to reduce duplication and redundancy for core data objects\nWork with the data governance team to ensure alignment of data definition, quality specifications, models and meta data management to technical implementations.\nDevelops relationships with the larger development teams that promote trust and increase efficiency and effectiveness\nParticipate in application validation and QA efforts as they pertain to reporting, data, metrics, and report creation and execution.\nOther duties as assigned.\nEducation \/ Experience Requirements\nBachelor's Degree or Foreign equivalent in Information Technology, Computer Science, Computer Information Systems, Engineering or related field and 5 years of progressively responsible experience OR a Master\u201a\u00c4\u00f4s Degree in Information Technology, Computer Science, Computer Information Systems, Engineering or related field (foreign equivalent acceptable) and 3 years of progressively responsible experience.\n5+ progressive years of experience in Data Warehouse, SQL scripting, SQL Tuning and Business Intelligence technologies.\n5+ progressive years of experience in Python programming language for scripting and ETL development.\n5+ progressive years of strong data engineering, SQL scripting and tuning experience.\nYears of progressive experience should include strong knowledge of any of the ETL tools like SSIS, Azure Data Factory, Informatica; any of the Data Modeling tools like Erwin, ER\/Studio, Toad Data Modeler; any of the BI tools like SSRS, Tableau, Microsoft Power BI.\nMust be experienced in designing and implementing high performance data pipelines using Databricks for data analytics with any major cloud platform like AWS or Azure.\nMust be experienced in developing and implementing data quality and data governance standards.\nMust be experienced implementing high performing technical solutions related to ETL with large source environments and patterns related to ODS, MDM, Landing\/Staging areas and EDW\/Data Mart.\nExperience in managing data and analytics programs (people, process, tools) through the full lifecycle: strategic recommendation; design of experiments, testing, communication, pilot, implementation, etc.\nKnowledge of developing and maintaining formal documentation that describes the data and data structures including data modeling.\nAbility to work with senior technical and business resources providing technical guidance related to data architecture and governance.\nIn-depth knowledge of IT concepts, strategies and methodologies and their application to business opportunities.\nAbility to mentor junior Data Engineers.\nMortgage or Finance industry experience is a big plus.\nXome is committed to nurturing a diverse and inclusive environment where every employee is empowered to be their authentic self. We know that a large part of our success as a business is directly tied to our ongoing efforts to attract and retain diverse talent and maintain an inclusive environment where each employee can thrive. Embracing and leveraging diversity through an inclusive work environment fosters new ideas, new insights, and constant innovation. We strive to weave the principles of diversity and inclusion throughout the fabric of how we work, how we interact, and how we engage with our customers and the community.\nJob Requisition ID\n021044\nJob Category\nInformation Technology\nPrimary Location City:\nLewisville\nPrimary Location Region:\nTexas\nPrimary Location Postal Code:\n75067\nPrimary Location Country:\nUnited States of America\nAdditional Posting Location(s):\nShow more\nShow less",
      "job_skills":"Data Structures, Business Intelligence, Data Architecture, Data Engineering, ETL Development, SQL Scripting, SQL Tuning, Python, Data Modeling, Data Warehousing, Cloud Computing, AWS, Azure, SSIS, Azure Data Factory, Informatica, Erwin, ER\/Studio, Toad Data Modeler, SSRS, Tableau, Microsoft Power BI, Databricks, ODS, MDM, Landing\/Staging Areas, EDW\/Data Mart, Data Governance, Data Quality",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Aditi Consulting",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-aditi-consulting-3762448756",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Collaborative team environment\nWants to be on the cutting edge, working with cutting edge technologies, open to new ideas and strategies\nTeam access and collaboration\nThe reason for hiring is they have expanded and restructured- taken the old BI team and moved into Data Engineering as well as brought on a director of engineering.\nThis candidate will report to the Director of Data Engineering and will be working on a team of 2 that has been approved to grow into a team of 6.\nDesigns and implements self-service data product deployment strategies\nPromotes BorrowWorks\u201a\u00c4\u00f4 cloud strategy and design cloud-native data engineering workflows\nDevelops tooling to facilitate data product development, deployment, and monitoring\nDevelops automated workflows for data engineering pipelines\nCollaborates with data engineers, software engineers, business analysts, and data scientists to develop data pipelines and automation solutions\nCreates and promotes best practices in data operations\nHelps contribute to a collaborative, open developer environment\nLeads improvements in methodology or initiatives to address capability gaps or increase efficiency\nOffers advice and guidance to junior associates for sake of continuous improvement.\nRequired\nFive (5) years of experience related to Data Engineering\nDemonstrated experience with data and software engineering best practices and implementing data and software development lifecycles.\nDemonstrated experience with implementing data ingestion\/testing automation solutions.\nDemonstrated success in one or more of the following programming languages: SQL, Python, Java, Scala.\nExperience developing RESTful APIs\nExperience with Docker\/Kubernetes\nExperience delivering and scaling data products in production.\nCompensation:\nThe pay rate range above is the base hourly pay range that Aditi Consulting reasonably expects to pay someone for this position (compensation may vary outside of this range depending on a number of factors, including but not limited to, a candidate\u201a\u00c4\u00f4s qualifications, skills, competencies, experience, location and end client requirements).\nBenefits and Ancillaries:\nMedical, dental, vision, PTO benefits and ancillaries may be available for eligible Aditi Consulting employees and vary based on the plan options selected by the employee.\nShow more\nShow less",
      "job_skills":"Data Engineering, Cloudnative data engineering, Data product development, Data product deployment, Data pipeline automation, Data operations best practices, Collaborative developer environment, Data and software engineering best practices, Data and software development lifecycles, Data ingestion automation, Testing automation solutions, RESTful APIs, Docker, Kubernetes, Data products in production, SQL, Python, Java, Scala",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Services Engineer",
      "company":"Mr. Cooper",
      "job_location":"Lewisville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-services-engineer-at-mr-cooper-3786372704",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Who We Are\nWe are Xome, a real estate services company headquartered in the Dallas, Texas area. As a subsidiary of Mr. Cooper Group, we employ over 1,200 team members nationwide. The nation\u201a\u00c4\u00f4s largest financial services companies look to us for integrated and scalable business solutions that help simplify the mortgage and real estate process.\nAt the heart of everything we do is our purpose: To keep the dream of home ownership alive. If that sounds like a big, lofty goal, that\u201a\u00c4\u00f4s because it really is. And we can\u201a\u00c4\u00f4t do it alone. Our entire team is focused on helping create a stable and healthy housing industry. And, making sure the process of buying\/selling a home doesn\u201a\u00c4\u00f4t undermine the excitement of home ownership. That\u201a\u00c4\u00f4s why we battle every day against the mediocrity of the status quo to simplify the complex world of mortgage servicing, lending and banking. We see ourselves as the experts who make doing business easier. While others bring complexity and a lack of transparency, we offer simplicity, trust, and visibility across the entire property lifecycle. And we deliver radical customer service.\nNow, you might be wondering; how exactly do you pronounce Xome? Simple. ZOM (like home, if it started with a z)!\nThere\u201a\u00c4\u00f4s no place like XomeTM! At Xome, we believe the process of buying and selling a home shouldn\u201a\u00c4\u00f4t undermine the excitement of home ownership, so we\u201a\u00c4\u00f4ve reimagined the real estate experience to create a bridge\u00ac\u2260\u00ac\u2260\u00ac\u2260\u00ac\u2260\u00ac\u2260\u00ac\u2260 between the offline and online world. Xome is the only platform that digitally connects every major touch-point in the real estate process\u201a\u00c4\u00ee giving our customers unique visibility and access into all parts of the real estate transaction process.\nOur culture encourages collaboration, breakthrough thinking and work that makes a lasting difference. We reward initiative and informed decisions and empower you to act in the best interests of our customers and our company. Our decisions are guided by our key principles of: Putting Customers First, having a Bias for Action, Failing Fast, Innovating and Breaking Paradigms, and Creating Sustainable results.\nHere at Xome, we recognize that our past, present, and future success is driven by the passionate and talented people we employ, and we are always looking for smart, dedicated people to join our teams. We put a priority on not simply hiring incredible people, but retaining them with engaging, challenging jobs \u201a\u00c4\u00ec as well as a respect for the importance of balance and work-life integration.\nIf you are excited by the idea of building revolutionary products to simplify real estate nationwide and want to help us raise the bar \u201a\u00c4\u00ec we look forward to hearing from you.\nJob Summary\nThe Senior Data Services Engineer is responsible for designing and developing data repositories for enterprise business operations to be used for providing business reporting and analysis. The Senior Data Services Engineer will support the analytics team by providing accurate, timely and relevant data to meet their diverse requirements. The Senior Data Services Engineer will also work closely with internal teams to support and build business insight tools.\nEssential Job Functions\nDesigns data architectures and builds relational\/dimensional databases and establish methods to improve functional reporting data content and completeness of data.\nDesign and develop robust, re-usable and scalable data driven solutions and data pipeline frameworks to automate the ingestion, processing and delivery of both structured and unstructured batch and real-time streaming.\nProvide technical skills in designing and developing BI\/Data projects in the areas of optimal design patterns, models, standards and code to ensure consistency and realize benefits of a high-performing, secure, reliable and scalable architecture\nCollaborate with IT architecture\/data team\/data scientists to develop a practical end state and reference architectures for BI\/Data with considerations for distributed data, in-memory computing, cloud computing, visualization tools\/platforms\nProvide technical leadership in areas such as master data management and reference data management to reduce duplication and redundancy for core data objects\nWork with the data governance team to ensure alignment of data definition, quality specifications, models and meta data management to technical implementations.\nDevelops relationships with the larger development teams that promote trust and increase efficiency and effectiveness\nParticipate in application validation and QA efforts as they pertain to reporting, data, metrics, and report creation and execution.\nOther duties as assigned.\nEducation \/ Experience Requirements\nBachelor's Degree or Foreign equivalent in Information Technology, Computer Science, Computer Information Systems, Engineering or related field and 4 years of progressively responsible experience OR a Master\u201a\u00c4\u00f4s Degree in Information Technology, Computer Science, Computer Information Systems, Engineering or related field (foreign equivalent acceptable) and 2 years of progressively responsible experience.\n4+ progressive years of experience in Data Warehouse, SQL scripting, SQL Tuning and Business Intelligence technologies.\n4+ progressive years of experience in Python programming language for scripting and ETL development.\n4+ progressive years of strong data engineering, SQL scripting and tuning experience.\nYears of progressive experience should include strong knowledge of any of the ETL tools like SSIS, Databricks, Azure Data Factory, Informatica; any of the Data Modeling tools like Erwin, ER\/Studio, Toad Data Modeler; any of the BI tools like SSRS, Tableau, Microsoft Power BI.\nMust be experienced in designing and implementing high performance data pipelines using Databricks for data analytics with any major cloud platform like AWS or Azure.\nMust be experienced in developing and implementing data quality and data governance standards.\nMust be experienced implementing high performing technical solutions related to ETL with large source environments and patterns related to ODS, MDM, Landing\/Staging areas and EDW\/Data Mart.\nExperience in managing data and analytics programs (people, process, tools) through the full lifecycle: strategic recommendation; design of experiments, testing, communication, pilot, implementation, etc.\nKnowledge of developing and maintaining formal documentation that describes the data and data structures including data modeling.\nAbility to work with senior technical and business resources providing technical guidance related to data architecture and governance.\nIn-depth knowledge of IT concepts, strategies and methodologies and their application to business opportunities.\nFamiliarity with Real Estate terminology and standards.\nAbility to mentor junior Data Engineers.\nMortgage or Finance industry experience is a big plus.\nXome is committed to nurturing a diverse and inclusive environment where every employee is empowered to be their authentic self. We know that a large part of our success as a business is directly tied to our ongoing efforts to attract and retain diverse talent and maintain an inclusive environment where each employee can thrive. Embracing and leveraging diversity through an inclusive work environment fosters new ideas, new insights, and constant innovation. We strive to weave the principles of diversity and inclusion throughout the fabric of how we work, how we interact, and how we engage with our customers and the community.\nJob Requisition ID\n020964\nJob Category\nInformation Technology\nPrimary Location City:\nLewisville\nPrimary Location Region:\nTexas\nPrimary Location Postal Code:\n75067\nPrimary Location Country:\nUnited States of America\nAdditional Posting Location(s):\nHome - California\nPay Range: $110,000.00 - $138,000.00\nShow more\nShow less",
      "job_skills":"AWS, Azure, Azure Data Factory, BI, Business Intelligence, Cloud computing, Data architecture, Data Engineering, Data Factory, Data governance, Data Mart, Data Modeling, Data Pipeline, Data Quality, Data Science, Data Structures, Data Warehouse, Databricks, EDW, ETL, Informatica, IT, Landing Zones, Machine Learning, Master Data Management, MDM, Microsoft Power BI, Mortgage, ODS, Python, Real Estate, Reference Data Management, SSIS, SSRS, Staging Areas, SQL, SQL scripting, SQL Tuning, Tableau, Toad Data Modeler",
      "Category":"Backend Development"
  },
  {
      "job_title":"Principal Engineer \u201a\u00c4\u00ec Database, SRE, & Cloud Engineering",
      "company":"Genuine Parts Company",
      "job_location":"Coppell, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-engineer-%E2%80%93-database-sre-cloud-engineering-at-genuine-parts-company-3700370896",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Background:\nGenuine Parts Company (\u201a\u00c4\u00faGPC\u201a\u00c4\u00f9 or the \u201a\u00c4\u00faCompany\u201a\u00c4\u00f9), founded in 1928 and based in Atlanta, Georgia, is a leading distributor of automotive and industrial replacement parts and value-added services. The Company operates a global portfolio of businesses with more than 10,000 locations across the world. GPC has approximately 50,000 global employees. The Company has operations in the United States, Canada, Mexico, Australia, New Zealand, Indonesia, Singapore, France, the U.K., Germany, Poland, the Netherlands, Belgium, Spain and China.\nPosition Purpose:\nSeeking world-class talent to join the world\u201a\u00c4\u00f4s leading distributor of automotive and industrial replacement parts and value-added services operating 5,500+ locations and servicing more than 20,000 locations in the U.S and Canada.\nThis individual must be a network technologist & engineer at heart and be comfortable in defining the technology direction and being hands on with the execution of the strategy. She\/He must exhibit a deep understanding of modern technology stack and agile delivery models, demonstrated focus on emerging technologies, including cloud-based solutions, and must have a proven track record of modernizing complex networking infrastructures at scale.\nClose collaboration and alignment with a wide variety of both internal stakeholders and external vendors will be required. As such, exceptional abilities in building and maintaining strong working relationships will be required. High level communication, expert level technical acumen, and project oversight skills are ideal.\nThe Principal Engineer is ultimately responsible for shepherding a project team, contributing to the solution design, provide assistance with configuration development, and ensuring efficient and precise deployment within the complex GPC Enterprise Network environment.\nThe engineering process is highly collaborative. In addition to pairing, Principal Engineers field questions from other teams and organizations, encourage cross-team collaboration, and serve as the Subject Matter Expert for all Network related inquiries. They also play an active role working with 3rd party vendors as well as the open-source community.\nPrincipal Engineer\u201a\u00c4\u00f4s create foundational processes and technical focus that aligns with the forward-looking GPC communications and connectivity strategy. The Principal Engineer will also be responsible for the organization, presentation, and remediation of network architectural diagrams and other solution-related documentation. In addition, Principal Network Engineers will be involved in solution configuration, performance tuning and testing as well as production monitoring.\nAs Principal Engineer, you will be the technology Subject Matter Expert within the GPC Network Engineering Team and are expected to build and grow the skillsets of the more junior engineers and collaborate with Network Engineering Team management to devise and deliver unique and innovative networking solutions that optimize GPC\u201a\u00c4\u00f4s products, applications, and service offerings.\nMajor Tasks, Responsibilities And Key Accountabilities\n~40% Execution & 30% Engineering Leadership\nCollaborates and pairs with other network and product\/application team members to deliver secure, reliable, and scalable network solutions\nDevelops comprehensive processes and procedures geared to the sustainment of the GPC network\nDelivers technology solutions and recommendations providing high reliability and resiliency in the networking environment.\nPerforms as the GPC Network Team Subject Matter Expert with all solutions and architectures deployed within the network.\nCollaborates with the Network Team management group to efficiently delivery new and innovative solutions to GPC networking.\nProvides mentoring and technical oversight to the GPC Engineering Team during solution delivery and configuration.\nCreates meaningful architecture diagrams and other documentation essential to the operation and management of the GPC Network.\n~20% \u201a\u00c4\u00ec Support & Enablement:\nFields questions and inquiries concerning the GPC Network from other entities throughout the company.\nCollaborates with the Network Support team for the efficient and effective resolution of issues encountered within the network.\nOversees and implements architectural modifications and improvements to the network environment.\nWorks with vendors to help identify and implement solutions and capabilities essential to the GPC service offering.\nProactively reviews the Engineering Team skillsets, capabilities, and performance in the network and provides recommendations for improvements.\nTriages high priority issues and outages as they arise\n~10% \u201a\u00c4\u00ec Learning:\nModerates and manages Network Team development activities including cross-functionality training, mentoring, and general strategy discussions.\nLearns, through reading, tutorials, and videos, new technologies and best practices being used within other technology organizations\nAttends conferences and learns how to apply new technologies where appropriate\nDesired Qualifications & Experiences:\n7-10+ years continued experience with Network Engineering and Support\nConsistent track record of teamwork, and delivering high impact results\nExperience with public cloud (AWS, Azure, GCP)\nStrong communication skills\nNetwork Certifications (Cisco CCIE, AWS Solutions Architect, Azure, etc.)\nSpecific Experience with the following solutions and technologies:\nCisco Routing and Switching Solutions \u201a\u00c4\u00ec (WAN, LAN, ACI)\nCisco Security Solutions \u201a\u00c4\u00ec (ASA, Umbrella, FTD)\nCisco Meraki Wireless Solutions\nFortinet Firewall Solutions \u201a\u00c4\u00ec (VPN, Virtual Appliances, Firewalls)\nLoad Balancing Solutions and techniques \u201a\u00c4\u00ec (F5, VMWare Avi, I-Rules)\nAutomation and Scripting \u201a\u00c4\u00ec (Ansible, API, Python, JSON)\nNot the right fit? Let us know you're interested in a future opportunity by joining our Talent Community on jobs.genpt.com or create an account to set up email alerts as new job postings become available that meet your interest!\nGPC conducts its business without regard to sex, race, creed, color, religion, marital status, national origin, citizenship status, age, pregnancy, sexual orientation, gender identity or expression, genetic information, disability, military status, status as a veteran, or any other protected characteristic. GPC's policy is to recruit, hire, train, promote, assign, transfer and terminate employees based on their own ability, achievement, experience and conduct and other legitimate business reasons.\nShow more\nShow less",
      "job_skills":"Network engineering, Network architecture, Cloud computing, Agile methodology, Collaboration, Communication, Technical leadership, Problem solving, Troubleshooting, Continuous learning, Cisco Routing and Switching Solutions, Cisco Security Solutions, Cisco Meraki Wireless Solutions, Fortinet Firewall Solutions, Load Balancing, Automation, Scripting, Ansible, API, Python, JSON",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"Dice",
      "job_location":"Lewisville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-dice-3788098613",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Dice is the leading career destination for tech experts at every stage of their careers. Our client, Braintree Technology Solutions, is seeking the following. Apply via Dice today!\nLead Data Engineer\nLocation: Lewisville, TX USA, This is Onsite role\nJob Functions \/ Responsibilities\nBuild and document automated data pipelines from a wide range of data sources with an emphasis on automation and scale\nDevelop highly available applications and APIs to support near real time integrations using an AWS based technology stack Ensure product and technical features are delivered to spec and on time in a DevOps fashion Contribute to overall architecture, framework, and design patterns to store and process high data volumes\nDevelop solutions to measure, improve, and monitor data quality based on business requirements\nDesign and implement reporting and analytics feature in collaboration with product owners, reporting analysts \/ data analysts, and business partners within an Agile \/ Scrum methodology\nProactively support product health by building solutions that are automated, scalable, and sustainable \u00ac\u00f8 be relentlessly focused on minimizing defects and technical debt Provide post implementation production support for data pipelines\nQualifications\nBachelors' degree in Computer Science, Informatics, or a related field required Masters\u00ac\u00f8 degree in Computer Science preferred\n3+ years of experience in a data engineering role\n2+ years of experience with AWS and related services (e.g., EC2, S3, SNS, Lambda, IAM, Snowflake)\nHands on experience with ETL tools and techniques (Desirable) Basic proficiency with a dialect of ANSI SQL, APIs, and Python Knowledge of and experience with RDBMS platforms, such as MS SQL Server, MySQL, NoSQL, Postgres\nShow more\nShow less",
      "job_skills":"Data Engineering, AWS, EC2, S3, SNS, Lambda, IAM, Snowflake, ETL tools and techniques, SQL, Python, RDBMS, MS SQL Server, MySQL, NoSQL, Postgres, Agile, Scrum, DevOps",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"HTC Global Services",
      "job_location":"Addison, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-htc-global-services-3780003338",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Title: Senior Data Engineer\nLocation: Addison, TX\nLength: Fulltime\nAbout HTC Global Services:\nShaping careers since 1990 - our long tenured employees are a testimony of the work culture. Join our global employee base of 12,000 and help us bring human expertise to tech in order to deliver purposeful solutions that amplify value.\nRequirements:\nDesign, develop and support data pipelines in a hybrid cloud environment to enable advanced analytics. Design, develop and support CI\/CD of data pipelines and micro-services.\nDevelop new services in AWS using server-less and container-based services. Work with Spark clusters and Bigdata ecosystem tools on-prem and in the cloud.\nMinimum Qualifications:\nProficient in Python and Spark\nHands-on experience with Azure\/AWS\/GCP\nHands-on experience with Data Lake or Data Warehouse\nIntermediate to advanced SQL skills\nExperience in using Serverless Development\nShould have the ability to work and contribute beyond defined responsibilities\nExcellent communication\/inter-personal skills a must\nAttitude and aptitude to learn new technologies in a fast-paced environment\nEffective problem-solving skills\nAbility to work in a fast-paced environment with a \"can do\" attitude\nPreferred Qualifications:\n8+ Years of working experience in relevant technologies.\nBesides Minimum Qualification below will be considered added advantages\nWorking experience on Python, Airflow, Apache Spark , Apache Beam, Apache Flink, Kubernetes etc.\nExperience with CI\/CD and DevOps is added advantage\nWorking Knowledge of OpenShift\nFamiliarity in using AIOPS platforms like mlFlow, AutoML\nKnowledge on Kafka is added advantage\nBachelors in Computer Engineering and\/or Computer Science and\/or Information Technology.\nBenefits:\nAt HTC Global Services our associates have access to a comprehensive benefits package that includes Health, Dental, Vision, Paid-Time-Off, Paid Holidays, 401K matching, Life and Accidental Death Insurance, Short- & Long-Term Disability Insurance, and a variety of other offerings.\nMove ahead:\nOur success as a company is built on practicing inclusion and embracing diversity. HTC Global Services is committed to providing a work environment free from discrimination and harassment, where all employees are treated with respect and dignity. Together we work to create and maintain an environment where everyone feels valued, included, and respected. At HTC Global Services, our differences are embraced and celebrated. HTC is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills, and experiences within our workforce. HTC is proud to be recognized as a National Minority Supplier and an equal opportunity employer of protected veterans.\nShow more\nShow less",
      "job_skills":"Python, Spark, Azure, AWS, GCP, Data Lake, Data Warehouse, Serverless Development, Airflow, Apache Spark, Apache Beam, Apache Flink, Kubernetes, OpenShift, AIOPS, mlFlow, AutoML, Kafka, CI\/CD, DevOps",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Staff AI Data Engineer",
      "company":"Recruiting from Scratch",
      "job_location":"Carrollton, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3759706916",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who is Recruiting from Scratch :\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nhttps:\/\/www.recruitingfromscratch.com\/\nThis is a hybrid role based in our\nPalo Alto,\nSan\nFrancisco or Chicago\noffices and will require you to be in office Tuesdays and Thursdays.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nWe believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth\/notifications, trust and safety.\nWhat\u201a\u00c4\u00f4s the job?\nWe\u201a\u00c4\u00f4re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.\nIn this position, you will be responsible for establishing and executing the strategy for our organization\u201a\u00c4\u00f4s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.\nResponsibilities:\nDive into our dataset and design, implement and scale data pre\/post processing pipelines of ML models\nWork on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling\nBe self-motivated in seeking solutions when the correct path isn\u201a\u00c4\u00f4t always known\nCollaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders\nDesign and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams\nBuild data processing streams for cleaning and modeling text data for LLMs\nResearch and evaluate new technologies in the big data space to guide our continuous improvement\nCollaborate with multi-functional teams to help tune the performance of large data applications\nWork with Privacy and Security team on data governance, risk and compliance initiatives\nWork on initiatives to ensure stability, performance and reliability of our data infrastructure\nWhat We\u201a\u00c4\u00f4ll Love About You\nBachelors in Computer Science, Mathematics, Physics, or a related fields\n5+ years of experience as a data engineer building production-level pre\/post-processing data pipelines for ML\/DL models, including 2+ years of technical leadership experience\nExperience in statistical analysis & visualization on datasets using Pandas or R\nExperience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools\nDemonstrated prior experience in creating data pipelines for text data sets NLP\/ large language models\nAbility to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy\nExcellent coding skills in Python, Java, bash, SQL, and expertise with Git version control\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)\nExperience with any public cloud environment - AWS, GCP or Azure\nSignificant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc\nExperience building and maintaining ETL (managing high-quality reliable ETL pipelines)\nWe\u201a\u00c4\u00f4ll really swoon if you have\n2+ years of experience of technical leadership in building data engineering pipelines for AI\nPrevious experience in building data pipeline for conversational AI APIs and recommender systems\nExperience with distributed systems and microservices\nExperience with Kubernetes and building Docker images\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nStrong understanding of applied machine learning topics\nBe familiar with legal compliance (with data management tools) data classification, and retention\nConsistent track record of managing and implementing complex data projects\nWhat You'll Love About Us\nMission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world\nMultiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto\nFamily Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents\nRetirement Savings: Generous 401K plan with 6% match and immediate vest in the US\nCompensation: Industry-competitive compensation and eligibility for company bonus and equity programs\nQueer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more\nAdditional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events\nBase Pay Range\n$160,000\u201a\u00c4\u00ee$280,000 USD\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Data engineering, ML pipelines, Data mining, Data cleaning, Data normalizing, Data modeling, Data pre\/post processing, Pandas, R, Airflow, KubeFlow, NLP, Python, Java, SQL, Bash, Git, Snowflake, Kubernetes, Docker, Helm, Spark, PySpark, AWS, GCP, Azure, DynamoDB, ETL, Kafka, Storm, SparkStreaming, Machine learning",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Staff AI Data Engineer",
      "company":"Recruiting from Scratch",
      "job_location":"Watauga, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3759707765",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who is Recruiting from Scratch :\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nhttps:\/\/www.recruitingfromscratch.com\/\nThis is a hybrid role based in our\nPalo Alto,\nSan\nFrancisco or Chicago\noffices and will require you to be in office Tuesdays and Thursdays.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nWe believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth\/notifications, trust and safety.\nWhat\u201a\u00c4\u00f4s the job?\nWe\u201a\u00c4\u00f4re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.\nIn this position, you will be responsible for establishing and executing the strategy for our organization\u201a\u00c4\u00f4s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.\nResponsibilities:\nDive into our dataset and design, implement and scale data pre\/post processing pipelines of ML models\nWork on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling\nBe self-motivated in seeking solutions when the correct path isn\u201a\u00c4\u00f4t always known\nCollaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders\nDesign and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams\nBuild data processing streams for cleaning and modeling text data for LLMs\nResearch and evaluate new technologies in the big data space to guide our continuous improvement\nCollaborate with multi-functional teams to help tune the performance of large data applications\nWork with Privacy and Security team on data governance, risk and compliance initiatives\nWork on initiatives to ensure stability, performance and reliability of our data infrastructure\nWhat We\u201a\u00c4\u00f4ll Love About You\nBachelors in Computer Science, Mathematics, Physics, or a related fields\n5+ years of experience as a data engineer building production-level pre\/post-processing data pipelines for ML\/DL models, including 2+ years of technical leadership experience\nExperience in statistical analysis & visualization on datasets using Pandas or R\nExperience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools\nDemonstrated prior experience in creating data pipelines for text data sets NLP\/ large language models\nAbility to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy\nExcellent coding skills in Python, Java, bash, SQL, and expertise with Git version control\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)\nExperience with any public cloud environment - AWS, GCP or Azure\nSignificant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc\nExperience building and maintaining ETL (managing high-quality reliable ETL pipelines)\nWe\u201a\u00c4\u00f4ll really swoon if you have\n2+ years of experience of technical leadership in building data engineering pipelines for AI\nPrevious experience in building data pipeline for conversational AI APIs and recommender systems\nExperience with distributed systems and microservices\nExperience with Kubernetes and building Docker images\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nStrong understanding of applied machine learning topics\nBe familiar with legal compliance (with data management tools) data classification, and retention\nConsistent track record of managing and implementing complex data projects\nWhat You'll Love About Us\nMission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world\nMultiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto\nFamily Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents\nRetirement Savings: Generous 401K plan with 6% match and immediate vest in the US\nCompensation: Industry-competitive compensation and eligibility for company bonus and equity programs\nQueer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more\nAdditional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events\nBase Pay Range\n$160,000\u201a\u00c4\u00ee$280,000 USD\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"ML Data Engine, ML Data OPs, Data pre\/post processing pipelines, Data mining, Data cleaning, Data normalization, Data modeling, Data platforms, Data frameworks, Big data, Data governance, Data risk, Data compliance, Data infrastructure, Pandas, R, Airflow, KubeFlow, Python, Java, bash, SQL, Git, Snowflake, Kubernetes, Docker, Helm, Spark, pySpark, AWS, GCP, Azure, DynamoDB, ETL, Kafka, Storm, SparkStreaming, Applied machine learning, Data classification, Data retention, Data management tools",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Staff AI Data Engineer",
      "company":"Recruiting from Scratch",
      "job_location":"Watauga, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3773088699",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who is Recruiting from Scratch :\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nhttps:\/\/www.recruitingfromscratch.com\/\nThis is a hybrid role based in our\nPalo Alto\nor\nSan\nFrancisco\noffices and will require you to be in office Tuesdays and Thursdays.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nWe believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth\/notifications, trust and safety.\nWhat\u201a\u00c4\u00f4s the job?\nWe\u201a\u00c4\u00f4re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.\nIn this position, you will be responsible for establishing and executing the strategy for our organization\u201a\u00c4\u00f4s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.\nResponsibilities:\nDive into our dataset and design, implement and scale data pre\/post processing pipelines of ML models\nWork on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling\nBe self-motivated in seeking solutions when the correct path isn\u201a\u00c4\u00f4t always known\nCollaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders\nDesign and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams\nBuild data processing streams for cleaning and modeling text data for LLMs\nResearch and evaluate new technologies in the big data space to guide our continuous improvement\nCollaborate with multi-functional teams to help tune the performance of large data applications\nWork with Privacy and Security team on data governance, risk and compliance initiatives\nWork on initiatives to ensure stability, performance and reliability of our data infrastructure\nWhat We\u201a\u00c4\u00f4ll Love About You\nBachelors in Computer Science, Mathematics, Physics, or a related fields\n5+ years of experience as a data engineer building production-level pre\/post-processing data pipelines for ML\/DL models, including 2+ years of technical leadership experience\nExperience in statistical analysis & visualization on datasets using Pandas or R\nExperience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools\nDemonstrated prior experience in creating data pipelines for text data sets NLP\/ large language models\nAbility to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy\nExcellent coding skills in Python, Java, bash, SQL, and expertise with Git version control\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)\nExperience with any public cloud environment - AWS, GCP or Azure\nSignificant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc\nExperience building and maintaining ETL (managing high-quality reliable ETL pipelines)\nWe\u201a\u00c4\u00f4ll really swoon if you have\n2+ years of experience of technical leadership in building data engineering pipelines for AI\nPrevious experience in building data pipeline for conversational AI APIs and recommender systems\nExperience with distributed systems and microservices\nExperience with Kubernetes and building Docker images\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nStrong understanding of applied machine learning topics\nBe familiar with legal compliance (with data management tools) data classification, and retention\nConsistent track record of managing and implementing complex data projects\nWhat You'll Love About Us\nMission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world\nMultiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto\nFamily Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents\nRetirement Savings: Generous 401K plan with 6% match and immediate vest in the US\nCompensation: Industry-competitive compensation and eligibility for company bonus and equity programs\nQueer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more\nAdditional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events\nBase Pay Range\n$160,000\u201a\u00c4\u00ee$280,000 USD\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Airflow, AWS, Apache Spark, Azure, Bash, Data Mining, Data Modeling, Data Pipelines, Data Preprocessing, Data Processing, Docker, Git, Helm, Java, Kubernetes, KubeFlow, Kafka, LLM, ML Data OPs, Natural Language Processing, NoSQL, Pandas, Python, R, Relational Databases, Snowflake, SQL, Storm, SparkStreaming",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Tata Consultancy Services",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-tata-consultancy-services-3779622237",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title\nSenior Data Engineer\nTechnical\/Functional Skills\nPrimary \u201a\u00c4\u00ec Cloud Based ETL Tool, DBT, Snowflake (Cloud DB), Strong SQL, Unix\/Python, Control-M, Service Now, RPA\nExperience Required\n8-10 yrs\nRoles & Responsibilities\nRole Description\nAnalyze requirements and existing resources to Propose, create ETL designs and database objects\nWork with project and business analyst leads in order to develop and clari fy in-depth technical requirements including logical and physical data modeling activities\nDesign and implement ETL processes for data transactions related to Enterprise Data Warehouse, Operational Data Store (ODS), and other data structures to support our Business Intelligence operations\nDevelops, enhances, debugs, supports, maintains and tests software applications that support business units or supporting functions using IBM Infosphere Data Stage ETL or any other cloud based ETL tool both ETL and ELT approaches. These application program solutions may involve diverse development platforms, software, hardware, technologies and tools.\nMust have hands-on on Snowflake development environment with all SQL operations. Must be aware of ELT approach as well.\nParticipates in the design, development and implementation of complex applications, often using IBM Infosphere Information Server (IIS) products like Data Stage, Quality Stage on a Linux Grid environment. Control-M\/Scheduling tools.\nRequired Skills:10+ Yrs Relevant IT software experience (Technical) in ETL Datastage or any other cloud based ETL Tool development Experience with databases like Snowflake (Cloud DB), Oracle, Netezza, MS SQL Server 2012+, DB2 and MS Access\nExperience with job automation & scheduling software (Control-M) Strong ability to write SQL queries\nDesired Skills:\nFamiliar with Snowflake (Cloud DB), DBT,\nPython, UNIX, Windows, File transfer utilities, process flow creation, ETL technologies, Hadoop, ServiceNow, RPA\nGood to have Skills: Snow-Pro Certified. Service Now Certified,.Strong SQL, Strong conceptual understanding of core DW Concepts including different approaches\/methodologies. dbt (data build tool) experience is an added advantage\nShow more\nShow less",
      "job_skills":"CloudBased ETL Tool, DBT, Snowflake, SQL, Unix, Python, ControlM, Service Now, RPA, ETL Datastage, Oracle, Netezza, MS SQL Server, DB2, MS Access, Job automation & scheduling software, Hadoop, File transfer utilities, Process flow creation, ETL technologies, DW Concepts, dbt (data build tool)",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Archetype Permanent Solutions",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-archetype-permanent-solutions-3787919070",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are seeking a highly skilled and analytical Data Scientist to join our team. The ideal candidate will be adept at using large data sets to find opportunities for product and process optimization, and using models to test the effectiveness of different courses of action. This role will require both a strong technical background in data analysis and the ability to communicate findings to non-technical teams and stakeholders.\nKey Responsibilities:\nWork with stakeholders to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nQualifications:\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Statistics, Mathematics, Computer Science, or another quantitative field.\n2 years of experience in a Data Scientist or Data Analyst role.\nStrong problem-solving skills with an emphasis on product development.\nExperience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages\/drawbacks.\nExcellent written and verbal communication skills for coordinating across teams.\nPreferred Skills:\nExperience with distributed data\/computing tools: Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\nExperience with AWS, Azure, or another cloud service.\nExperience visualizing\/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.\nBenefits:\nCompetitive salary and benefits package.\nDynamic and innovative work environment.\nOpportunities for professional growth and development.\n[Other company-specific benefits like remote work options, flexible schedules, wellness programs, etc.]\nHow to Apply:\nPlease submit your resume, cover letter, and any relevant work samples\nPowered by JazzHR\n3tBUY1AUTb\nShow more\nShow less",
      "job_skills":"Data Science, Data Analysis, Statistics, Mathematics, Computer Science, R, Python, SQL, Data Modeling, Machine Learning, Clustering, Decision Tree Learning, Artificial Neural Networks, Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, AWS, Azure, Periscope, Business Objects, D3, ggplot",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Conversion Developer, Senior Associate",
      "company":"PwC",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-conversion-developer-senior-associate-at-pwc-3749937559",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nFunctional & Industry Technologies\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 80%\nA career within Functional and Industry Technologies services will provide you with the opportunity to build secure and new digital experiences for customers, employees, and suppliers. We focus on improving apps or developing new apps for traditional and mobile devices as well as conducting usability testing to find ways to improve our clients\u201a\u00c4\u00f4 user experience. Our team helps clients transform their business through enabling technologies across marketing, finance and operations in the functional areas such as Maximo and PowerPlant.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nBasic Qualifications\nMinimum Degree Required:\nBachelor Degree\nMinimum Years Of Experience\n4 years\nPreferred Qualifications\nDegree Preferred:\nMaster Degree\nCertification(s) Preferred\nAzure Data Engineer Associate\nDatabricks Certified Data Engineer Associate\nPreferred Fields Of Study\nComputer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology\nPreferred Knowledge\/Skills\nDemonstrates a thorough level of abilities with, and\/or a proven record of success as both an individual contributor and team member, identifying and addressing client needs:\nSupports in data analysis techniques to assess source data structures, identify mapping requirements, and define transformation rules for data conversion into Maximo;\nLeads Maximo's modules and functionalities related to Asset Management and Work Order Management and IBM Maximo, including its data structures, configuration settings, and integration capabilities;\nIdentifies relational databases, preferably experience in working with databases commonly used in Maximo, such as IBM DB2, Oracle, Microsoft SQL Server, along with familiarity with Maximo's Integration Framework (MIF) and its capabilities for data integration and conversion;\nSupports in designing and implementing data extraction, transformation, and loading processes for Maximo data conversion;\nShowcases understanding in SQL and database querying languages to extract and manipulate data from source systems along with understanding ETL tools and methodologies commonly used in Maximo data conversion;\nIdentifies technologies commonly used with Maximo, including web services (SOAP, RESTful APIs), XML, JSON, and other relevant data exchange formats;\nSupports in pipeline architecture and development using one of the tools such as Azure ADF, AWS Glue, SSIS, DataBricks (multiple preferred);\nUtilizes data cleansing techniques and methodologies to ensure the integrity and accuracy of converted data in Maximo;\nDevelopes data cleansing functional business rules as per Maximo Business Object (MBO) definitions for source to Maximo conversion requirements;and comprehensive testing plans and executing validation processes to verify the accuracy and integrity of converted data in Maximo;\nCustomizes Maximo options, such as Automation Scripts, Java Customizations, Database Configuration, or Application Designer, to support data conversion requirements;\nIdentifies integrations within Maximo with other enterprise systems, such as ERP systems, GIS systems, or asset management systems. Knowledge of integration patterns, data synchronization, and data exchange protocols; and,\nShowcases work experience as a Data Engineer, Data Architect or similar role, along with experience in programming languages including Python, PySpark, Scala, SQL.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-advisoryseniorassociate\nShow more\nShow less",
      "job_skills":"Maximo, PowerPlant, Azure Data Engineer Associate, Databricks Certified Data Engineer Associate, Computer Science, Information Technology, Data analysis, Data extraction, Data transformation, Data loading, SQL, ETL tools, Azure ADF, AWS Glue, SSIS, DataBricks, Data cleansing, Python, PySpark, Scala",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Staff AI Data Engineer",
      "company":"Recruiting from Scratch",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3773087720",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who is Recruiting from Scratch :\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nhttps:\/\/www.recruitingfromscratch.com\/\nThis is a hybrid role based in our\nPalo Alto\nor\nSan\nFrancisco\noffices and will require you to be in office Tuesdays and Thursdays.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nWe believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth\/notifications, trust and safety.\nWhat\u201a\u00c4\u00f4s the job?\nWe\u201a\u00c4\u00f4re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.\nIn this position, you will be responsible for establishing and executing the strategy for our organization\u201a\u00c4\u00f4s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.\nResponsibilities:\nDive into our dataset and design, implement and scale data pre\/post processing pipelines of ML models\nWork on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling\nBe self-motivated in seeking solutions when the correct path isn\u201a\u00c4\u00f4t always known\nCollaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders\nDesign and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams\nBuild data processing streams for cleaning and modeling text data for LLMs\nResearch and evaluate new technologies in the big data space to guide our continuous improvement\nCollaborate with multi-functional teams to help tune the performance of large data applications\nWork with Privacy and Security team on data governance, risk and compliance initiatives\nWork on initiatives to ensure stability, performance and reliability of our data infrastructure\nWhat We\u201a\u00c4\u00f4ll Love About You\nBachelors in Computer Science, Mathematics, Physics, or a related fields\n5+ years of experience as a data engineer building production-level pre\/post-processing data pipelines for ML\/DL models, including 2+ years of technical leadership experience\nExperience in statistical analysis & visualization on datasets using Pandas or R\nExperience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools\nDemonstrated prior experience in creating data pipelines for text data sets NLP\/ large language models\nAbility to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy\nExcellent coding skills in Python, Java, bash, SQL, and expertise with Git version control\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)\nExperience with any public cloud environment - AWS, GCP or Azure\nSignificant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc\nExperience building and maintaining ETL (managing high-quality reliable ETL pipelines)\nWe\u201a\u00c4\u00f4ll really swoon if you have\n2+ years of experience of technical leadership in building data engineering pipelines for AI\nPrevious experience in building data pipeline for conversational AI APIs and recommender systems\nExperience with distributed systems and microservices\nExperience with Kubernetes and building Docker images\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nStrong understanding of applied machine learning topics\nBe familiar with legal compliance (with data management tools) data classification, and retention\nConsistent track record of managing and implementing complex data projects\nWhat You'll Love About Us\nMission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world\nMultiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto\nFamily Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents\nRetirement Savings: Generous 401K plan with 6% match and immediate vest in the US\nCompensation: Industry-competitive compensation and eligibility for company bonus and equity programs\nQueer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more\nAdditional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events\nBase Pay Range\n$160,000\u201a\u00c4\u00ee$280,000 USD\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Data Engineering, ML\/DL, Data Mining, Data Cleaning, Data Normalization, Data Modeling, Statistical Analysis, Visualization, Big Data Technologies, Apache Airflow, Kubernetes, Apache Spark, Python, Java, SQL, Git, Data Pipelines, AWS, GCP, Azure, NLP, Conversational AI, Recommender Systems, Microservices, Kafka, Storm, Machine Learning",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Staff AI Data Engineer",
      "company":"Recruiting from Scratch",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-staff-ai-data-engineer-at-recruiting-from-scratch-3759708638",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who is Recruiting from Scratch :\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nhttps:\/\/www.recruitingfromscratch.com\/\nThis is a hybrid role based in our\nPalo Alto,\nSan\nFrancisco or Chicago\noffices and will require you to be in office Tuesdays and Thursdays.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nWe believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth\/notifications, trust and safety.\nWhat\u201a\u00c4\u00f4s the job?\nWe\u201a\u00c4\u00f4re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines.\nIn this position, you will be responsible for establishing and executing the strategy for our organization\u201a\u00c4\u00f4s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack.\nResponsibilities:\nDive into our dataset and design, implement and scale data pre\/post processing pipelines of ML models\nWork on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling\nBe self-motivated in seeking solutions when the correct path isn\u201a\u00c4\u00f4t always known\nCollaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders\nDesign and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams\nBuild data processing streams for cleaning and modeling text data for LLMs\nResearch and evaluate new technologies in the big data space to guide our continuous improvement\nCollaborate with multi-functional teams to help tune the performance of large data applications\nWork with Privacy and Security team on data governance, risk and compliance initiatives\nWork on initiatives to ensure stability, performance and reliability of our data infrastructure\nWhat We\u201a\u00c4\u00f4ll Love About You\nBachelors in Computer Science, Mathematics, Physics, or a related fields\n5+ years of experience as a data engineer building production-level pre\/post-processing data pipelines for ML\/DL models, including 2+ years of technical leadership experience\nExperience in statistical analysis & visualization on datasets using Pandas or R\nExperience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools\nDemonstrated prior experience in creating data pipelines for text data sets NLP\/ large language models\nAbility to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy\nExcellent coding skills in Python, Java, bash, SQL, and expertise with Git version control\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)\nExperience with any public cloud environment - AWS, GCP or Azure\nSignificant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc\nExperience building and maintaining ETL (managing high-quality reliable ETL pipelines)\nWe\u201a\u00c4\u00f4ll really swoon if you have\n2+ years of experience of technical leadership in building data engineering pipelines for AI\nPrevious experience in building data pipeline for conversational AI APIs and recommender systems\nExperience with distributed systems and microservices\nExperience with Kubernetes and building Docker images\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nStrong understanding of applied machine learning topics\nBe familiar with legal compliance (with data management tools) data classification, and retention\nConsistent track record of managing and implementing complex data projects\nWhat You'll Love About Us\nMission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world\nMultiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto\nFamily Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents\nRetirement Savings: Generous 401K plan with 6% match and immediate vest in the US\nCompensation: Industry-competitive compensation and eligibility for company bonus and equity programs\nQueer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more\nAdditional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events\nBase Pay Range\n$160,000\u201a\u00c4\u00ee$280,000 USD\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Airflow, Applied ML, AWS, Azure, Bash, Big data, Cloud environment, Computer Science, Data engineering, Data governance, Data pipelines, Data processing, Data science, Data visualization, Docker, DynamoDB, ETL, Git, GCP, Helm, Java, Kafka, Kubernetes, KubeFlow, LLMs, Machine learning, Mathematics, Microservices, NLP, NoSQL, Orchestration frameworks, Pandas, Physics, Python, R, Relational databases, Salesforce, Snowflake, SQL, Spark, SparkStreaming, Storm, Technology leadership, Text data, Version control",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Cloud Data Engineer",
      "company":"BDO USA",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-cloud-data-engineer-at-bdo-usa-3765469454",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nJob Summary:\nThis position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.\nJob Duties\nDesigns and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS\nListens to client needs to align solution with business requirements and delivery schedule\nCreates written functional and technical designs\nParticipates in project status and stand meetings, and assists with providing aggregated project status for project and program managers\nAssists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions\nWrites code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles\nDelivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)\nAssists with implementation of data governance programs and best practices\nPerforms the cleaning and transforming of data from source systems into analytics models\nImplements models to support data visualizations and integrations\nAssists with implementing DevOps, DataOps and MLOps methodologies on projects\nWrites custom integration logic in applicable programming languages\nAssists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle\nAssists clients with licensing, security, and cost estimation of solutions\nPerforms code reviews to ensure adherence to standards\nWorks directly with clients and team members to establish secure data analytics platforms and infrastructure\nContributes to successful deployments of developed solutions and integration of DevOps tools\nMaintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools\nBuilds client relationships during project execution, effectively becoming a trusted advisor of the client\nParticipates in support activities for existing software solutions\nOther duties as assigned\nSupervisory Responsibilities\nSupervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product\nEducation\nQualifications, Knowledge, Skills and Abilities:\nHigh School Diploma or GED equivalent, required\nBachelor\u201a\u00c4\u00f4s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred\nExperience\nFive (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required\nOne (1) or more years of experience technically leading development projects, preferred\nOne (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred\nSoftware\nStrong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required\nExperience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required\nHands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred\nExperience with one (1) or more of the following computer languages, preferred:\nC#\nPython\nJava\nScala\nExperience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred\nExperience with Git and DevOps deployment technologies, preferred\nExperience with Linux, preferred\nExperience with one (1) or more of the following, preferred:\nData Lake Medallion Architecture\nBatch and\/or streaming data ingestion into a data lake\nAI Algorithms\/Machine Learning\nAutomation tools such as UiPath, Alteryx, etc.\nComputer Vision based AI technologies\nOther Knowledge, Skills & Abilities\nAbility to work with a high degree of professionalism and autonomy\nExcellent verbal and written communication skills\nSolid organizational skills, especially the ability to meet project deadlines with a focus on details\nAbility to successfully multi-task while working independently or within a group environment\nAbility to work in a deadline-driven environment, and handle multiple projects simultaneously\nAbility to interact effectively with people at all organizational levels of the Firm\nAbility to effectively interact with a team of professionals and delegating work assignments, as needed\nAbility to build and maintain strong relationships with internal and client personnel\nAbility to encourage a team environment on engagements, and contribute to the professional development of assigned personnel\nKeywords:\nData Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL\nIndividual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate\u201a\u00c4\u00f4s qualifications, experience, skills, and geography.\nCalifornia Range: $111,000 - $152,000\nColorado Range: $111,000 - $152,000\nNew York City\/ Valhalla Range: $111,000 - $152,000\nWashington Range: $111,000 - $152,000\nAbout Us\nBDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients\u201a\u00c4\u00f4 needs. We currently serve more than 400 publicly traded domestic and international clients.\nUnparalleled partner-involvement\nDeep industry knowledge and participation\nGeographic coverage across the U.S.\nCohesive global network\nFocused capabilities across disciplines\nBDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world\u201a\u00c4\u00f4s fifth largest accounting network.\nBDO offers a competitive Total Rewards package that encompass so much more than \u201a\u00c4\u00ec \u201a\u00c4\u00fatraditional benefits\u201a\u00c4\u00f9. Our wide range of rewards and our employees\u201a\u00c4\u00f4 ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.\nSome Examples Of Our Total Rewards Offerings Include\nCompetitive pay and eligibility for an annual performance bonus.\nA 401k plan plus an employer match\nComprehensive, medical, dental, vision, FSA, and prescription insurance from day one\nCompetitive Paid Time Off with daily accrual from day one of employment, plus paid holidays\nPaid Parental Leave\nAdoption Assistance\nFirm paid life insurance\nWellness programs\nAdditional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance\nAbove offerings may be subject to eligibility requirements.\nClick here to find out more!\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.\n\"BDO USA, P.A. is an EO employer M\/F\/Veteran\/Disability\"\nShow more\nShow less",
      "job_skills":"Data Analytics, Business Intelligence, Artificial Intelligence, Application Development, SQL, Data Warehousing, Data Modeling, Semantic Model Definition, Star Schema Construction, Cloud Data Analytics Solutions, Azure, AWS, C#, Python, Java, Scala, Tabular Modeling, Microsoft Fabric, Power BI, Azure Analysis Services, Git, DevOps, Linux, Data Lake Medallion Architecture, Batch Data Ingestion, Streaming Data Ingestion, Data Lake, AI Algorithms, Machine Learning, Automation Tools, UiPath, Alteryx, Computer Vision based AI technologies",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer, Infrastructure-Dallas, Austin, or San Antonio, TX",
      "company":"H-E-B",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-infrastructure-dallas-austin-or-san-antonio-tx-at-h-e-b-3740525124",
      "search_city":"Union",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Since H-E-B Digital Technology's inception, we've been investing heavily in our customers' digital experience, reinventing how they find inspiration from food, how they make food decisions, and how they ultimately get food into their homes. This is an exciting time to join H-E-B Digital--we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience. If you enjoy taking on new challenges, working in a rapidly changing environment, learning new skills, and applying it all to solve large and impactful business problems, we want you as part of our team.\nOur Partners thrive The H-E-B Way. In the\nSenior Data Engineer, Infrastructure\njob, that means you have a...\nHEART FOR PEOPLE... you can organize multiple engineers, negotiate solutions, and provide upward communication\nHEAD FOR BUSINESS... you consistently demonstrate and uphold the standards of coding, infrastructure, and process\nPASSION FOR RESULTS... you're capable of high-velocity contributions in multiple technical domains\nWhat you will do:\nDesign and deploy batch and streaming data pipeline infrastructure using IaC and CI\/CD\nImplement features to ensure data platform performance, reliability, and security\nDevelop solutions to improve monitoring and observability for data pipelines and platform infrastructure\nBuild data platform components using hybrid cloud services (AWS, GCP, and Azure)\nUse configuration management tools to provision system images and install and configure Linux application servers\nHelp contain costs by delivering solutions to monitor data platform utilization and expenditure\nProject you will impact:\nBuild a world class data platform that can handle petabytes of data\nImprove the data quality and consumer experience for 100K+ enterprise data consumers\nWho you are:\nHands-on experience in DevOps for cloud infrastructure and data pipelines\nSolid background in Linux, networking, SSL\/TLS cert management, secrets management, IAM and security best practices\nExperienced programmer in one or more languages such as Bash\/Shell, Python, Java, Go, Ruby\nUnderstanding of Big Data and Hybrid Cloud infrastructure. Experienced in technologies such as Kafka, Kubernetes, Spark, Databricks, AWS EMR, S3, data warehouses (Snowflake, Teradata)\nSignificant experience with one or more cloud infrastructure providers (AWS, GCP, Azure)\nExperienced in cloud administration and Infrastructure as Code (Terraform, Cloud Formation, AWS CDK, Pulumi)\nComfortable with configuration management tools (Ansible, Puppet, Chef, Salt)\nHave worked with enterprise monitoring, APM, and log analysis tools like Datadog, Splunk, ELK Stack, New Relic\nExperienced with CI\/CD tools such as GitLab CI\/CD and Jenkins\nUp to date on the latest technology developments. Should be able to evaluate and propose new tooling\/solutions for data platform\nExcellent written, oral communication and presentation skills\nBonus:\nDevOps certifications\nCloud certifications\nDATA3232\nShow more\nShow less",
      "job_skills":"IaC, CI\/CD, Linux, Networking, SSL\/TLS cert management, Secrets management, IAM, Bash\/Shell, Python, Java, Go, Ruby, Kafka, Kubernetes, Spark, Databricks, AWS EMR, S3, Snowflake, Teradata, AWS, GCP, Azure, Terraform, Cloud Formation, AWS CDK, Pulumi, Ansible, Puppet, Chef, Salt, Datadog, Splunk, ELK Stack, New Relic, GitLab CI\/CD, Jenkins",
      "Category":"Backend Development"
  },
  {
      "job_title":"Database Administrator",
      "company":"Clayton Services",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/database-administrator-at-clayton-services-3783989397",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Clayton Services is searching for a\nDatabase Administrator\nto join a thriving company in Houston. The\nDatabase Administrator\nwill administer, maintain, and optimize company databases, utilizing Python, SQL, and Power BI expertise to support data management initiatives and collaborate with the data engineering team.\nPay Rate:\n$75,000 - $80,000\/annually\nBenefits:\nFully covered medical and dental benefits with excellent PTO available!\nLocation:\nSpring Branch Central\nWork Setting:\nonsite, 5 days per week\nDatabase Administrator Responsibilities:\nAssist in installing, configuring, and maintaining database software (e.g., MySQL, PostgreSQL, SQL Server).\nAid in data migration and transformation tasks using Python and SQL.\nCollaborates with the data engineer to ensure smooth data integration and reporting within Power BI.\nMonitor database systems, optimize SQL queries, and troubleshoot performance issues.\nPerform routine database backups, implement disaster recovery plans, and uphold data security.\nCreate and maintain comprehensive documentation for database configurations, processes, and procedures.\nStay updated on emerging trends in database technologies, Power BI advancements, and developments in data analytics.\nDatabase Administrator Skills and Abilities:\nExcellent problem-solving and troubleshooting skills.\nExcellent communication and teamwork abilities.\nFamiliarity with database management tools and utilities.\nBasic understanding of database management systems (DBMS).\nKnowledge of database security best practices.\nCertification in database administration (e.g., Oracle Certified Associate, Microsoft Certified: Azure Database Administrator Associate).\nStrong proficiency in Python and SQL for data manipulation and analysis.\nAbility to take on new challenges and adapt to evolving technologies.\nAbility to take and pass a technical assessment based on SQL and coding skills.\nDatabase Administrator Education and Experience:\nBachelor's degree in Computer Science, Information Technology, or related field.\n2+ years of hands-on experience.\nExperience with cloud-based databases (e.g., AWS RDS, Azure SQL Database).\nExperience with the SDLC (front-end and\/or back-end development).\nExperience with data visualization and reporting.\nShow more\nShow less",
      "job_skills":"Python, SQL, Power BI, MySQL, PostgreSQL, SQL Server, Data migration, Data transformation, Data integration, Data reporting, Database backups, Disaster recovery, Data security, Database documentation, Database management tools, Database management systems (DBMS), Database security best practices, Oracle Certified Associate, Microsoft Certified: Azure Database Administrator Associate, Cloudbased databases (AWS RDS Azure SQL Database), SDLC (frontend and\/or backend development), Data visualization, Data reporting",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Science Specialist",
      "company":"Hydrogen Group",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-science-specialist-at-hydrogen-group-3780021087",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Ob Description\nWe are currently seeking an experienced data scientist to join the Big Data and Advanced Analytics department. As part of the Data Analytics team, the Lead Data Scientist will work closely with the Data Engineering team and business functions to solve real-world oil and gas midstream problems using machine learning, data science algorithms and artificial intelligence.\nResponsibilities Include\nWork independently on optimization projects for multiple business functions\nIdentify and frame the optimization opportunity from understanding the business problem \/ opportunity\nGather, cleanse, and transform internal and external data\nAnalyze data and deliver insights via visualizations and dashboards\nCreate, productionize, and maintain models \/ solutions that address business problems\nPresent, explain and defend results from analysis and modeling, and approach taken\nParticipate in strategic planning discussions around optimizations, data science and big data analytics\nThe Successful Candidate Will Meet The Following Qualifications\n5+ years of practical experience framing and solving optimization problems in supply chain, logistics, or operations\n5+ years of hands on experience with applied statistics \/ math and optimization techniques\nProfessional experience with optimization tools such as linear programming, integer programming, or heuristic methods\nProfessional experience programming in Python\nExperience with AWS is a plus\nEducational background in Operations Research, Applied Mathematics, or Industrial Engineering is a plus\nAbility to adapt in a rapidly changing environment\nAbility to communicate insights and approaches in a simple, actionable manner\nAbility to work independently and with team members from different backgrounds\nExcellent attention to detail and problem-solving skills\nShow more\nShow less",
      "job_skills":"Data Science, Optimization, Machine Learning, Data Analytics, Python, AWS, Operations Research, Applied Mathematics, Industrial Engineering, Linear Programming, Integer Programming, Heuristic Methods, Data Engineering, Business Intelligence, Data Visualization, Dashboarding, Presentation Skills, Communication Skills, Teamwork Skills, Problem Solving Skills",
      "Category":"Backend Development"
  },
  {
      "job_title":"Expert Data Engineer",
      "company":"HP",
      "job_location":"Spring, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/expert-data-engineer-at-hp-3772976776",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"We are looking for an\nExpert Data Engineer\nto join our team and help us build and maintain scalable data pipelines and systems. You will be responsible for designing, developing, testing, and deploying data solutions that meet the needs of our clients and stakeholders. You will also collaborate with data analysts, data scientists, and other data engineers to ensure data quality, reliability, and performance.\nIf you are interested in working on petabytes of data from millions of devices. If solving complex data issues excites you this is the opportunity for you.\nResponsibilities\nLeads the team to write, deploy, and maintain software to build, integrate, manage, maintain, and quality-assure data.\nArchitects, designs, implements, and maintains reliable and scalable data solutions in the AWS cloud environment using Scrum\/Agile methodology.\nImplement data ingestion, transformation, and processing workflows using ETL tools and frameworks.\nResearches and promotes new tools and techniques to shape the future of the data engineering environment.\nEnsure data security, privacy, and compliance with relevant regulations and policies.\nMonitor, troubleshoot, and debug data issues and performance bottlenecks. Guides team to deploy secure and well-tested software that meets privacy and compliance requirements; develops, maintains, and improves CI \/ CD pipeline.\nDocument and communicate data engineering processes and solutions to stakeholders and users.\nRepresents the data engineering team for all phases of larger and more-complex development projects.\nWorks with following site-reliability engineering standard methodologies: on-call rotations for services they maintain, responsible for defining and maintaining SLAs. Design, build, deploy and maintain infrastructure as code. Containerizes server deployments.\nActively contributes to improve developer velocity.\nKnowledge & Skills\nDemonstrable coding expertise in one or more object-oriented programming languages (e.g., Python, Scala, Java, etc.)\nDeep and hands-on experience (7+ years) designing, planning, productionizing, maintaining, and documenting reliable and scalable data infrastructure and data products in complex environments.\nHands on experience with:\nExpert in AWS tools and services such as S3, Glue, Lambda, EMR, Redshift, Athena, etc.\nExperience with other cloud platforms and services such as Azure, GCP, etc. is a plus.\nExperience with data quality, testing, and validation tools and techniques\nExperience with data visualization and reporting tools such as QuickSight, Tableau, Power BI, etc.\nStrong analytical and problem-solving skills\nExcellent communication and collaboration skill\nUnderstanding Data Structures & Algorithms & their performance\nExperience designing and implementing large-scale distributed systems.\nDeep knowledge and hands-on experience in technologies across all data lifecycle stages\nInternal client management and ability to lead large organizations via influence .\nAbility to effectively communicate product architectures, design proposals and negotiate options at senior management levels.\nEducation & Experience\nBachelor's or Master's degree in Computer Science, Information Systems, Engineering, or equivalent.\nAbout HP\nYou\u201a\u00c4\u00f4re out to reimagine and reinvent what\u201a\u00c4\u00f4s possible\u201a\u00c4\u00eein your career as well as the world around you.\nSo are we. We love taking on tough challenges, disrupting the status quo, and creating what\u201a\u00c4\u00f4s next. We\u201a\u00c4\u00f4re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.\nHP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.\nOur history: HP\u201a\u00c4\u00f4s commitment to diversity, equity and inclusion \u201a\u00c4\u00ec it's just who we are.\nFrom the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you\u201a\u00c4\u00f4re more innovative and that helps grow our bottom line. Come to HP and thrive!\nShow more\nShow less",
      "job_skills":"Python, Scala, Java, AWS, S3, Glue, Lambda, EMR, Redshift, Athena, Azure, GCP, QuickSight, Tableau, Power BI, Data Structures, Algorithms, Distributed Systems, Data Lifecycle, Data Visualization, Communication, Collaboration",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer (FT)",
      "company":"Double Line, Inc.",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-ft-at-double-line-inc-3783141492",
      "search_city":"Dahlonega",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Please DO NOT send applications\/resume via email. Use the link below to APPLY ONLINE:\nhttps:\/\/doubleline.applytojob.com\/apply\/FcLpeWsMBJ\/Senior-Data-Engineer\n(This is a remote position open to candidates residing near Austin, TX, Raleigh, NC, or Nashville, TN. We have an office location in Austin, TX for use at our employees' convenience. We have no plans to return to the office on a mandatory basis.)\nFeeling underappreciated? Underutilized? Want to be a part of a specialized team with exposure to a wide variety of data puzzles to solve, while using your skills to improve education? Come join a team where you can\nFly the Airplane\n, not just be a passenger in the back. We're a growing company focused on expanding our Development team with an experienced and innovative Senior Data Engineer with impressive analytical skills. Sound interesting?\nIf so, we're looking for a motivated and driven person like you who has:\nSuccessfully completed multiple projects where you designed and executed ways to solve complex problems for clients around data integration, data quality, data warehousing, and analytics.\nDemonstrated proficiency in deciding which ETL and data streaming technologies to use in AWS, Google Cloud, and Azure-based solutions, and propensity to pick something new when you want to push yourself and the team to innovate.\nMastery of T-SQL and experience with postgreSQL or other forms of SQL.\nExperience in an Agile environment with Lean software development principles.\nDrive to amplify the skills of teammates through mentoring and training junior and mid-level data engineers.\nMindset of continuous improvement and setting best practices.\nDeadline-driven mentality.\nBonus points if you're bringing knowledge of or really want to learn the following:\nA wide variety of data processing tools and approaches, from Python to Google BigQuery to SSIS to AWS Lambda to Azure Data Factory and others.\nPerformance implications of memory and disk usage at different data volumes.\nBusiness intelligence tools and dashboard design theory.\nWe Do Not Want You To Make The Leap Without Knowing What We Need, So Here Is How We Define Success For This Position\nBring a new idea to our team of brilliant data engineers in the first 30 days.\nLead the collaborative design process of a data engineering solution in one of our projects in the first 2 months.\nBecome a mentor to a data engineer within your first 6 months.\nIn Return, We Offer\nA mission-driven company with a long-term focus on helping the world by untangling the technical knots that challenge state and local governments, particularly in education, healthcare, and similar fields.\nA home where your voice matters and you can affect real change.\nDirect connection to the Executive team where you can help drive the future of the company.\nAn employer who cares about you, makes sure you're engaged with exciting work, and offers robust benefits, 401k with employer match, and a great culture.\nWe need to know - can you make this happen? If so, we definitely need to talk to you.\nPlease DO NOT send applications\/resume via email. Use the link below to APPLY ONLINE:\nhttps:\/\/doubleline.applytojob.com\/apply\/FcLpeWsMBJ\/Senior-Data-Engineer\nDouble Line understands the importance of creating a safe and comfortable work environment and encourages individualism and authenticity in every member of our team. We provide equal employment opportunities to all employees and applicants for employment and prohibit discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment.\nDouble Line does not currently offer relocation assistance.\nAbout Double Line, Inc.\nWe are a technology consulting company providing customized data solutions for educational and other public organizations.\nShow more\nShow less",
      "job_skills":"Data Integration, Data Quality, Data Warehousing, Analytics, ETL, Data Streaming, AWS, Google Cloud, Azure, TSQL, postgreSQL, SQL, Agile, Lean Software Development, Mentoring, Training, Python, Google BigQuery, SSIS, AWS Lambda, Azure Data Factory, Business Intelligence, Dashboard Design, Memory Usage, Disk Usage, Data Volumes",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Engineer",
      "company":"Experfy",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-at-experfy-3633149722",
      "search_city":"Dahlonega",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"A Sr. Data Engineer is proficient in the development of all aspects of data processing including data warehouse architecture\/modeling and ETL processing. The position focuses research on development and delivery of analytical solutions using various tools including Confluent Kafka, Kinesis, Glue, Lambda, Snowflake and SQL Server. A Sr. Data Engineer must be able to work autonomously with little guidance or instruction to deliver business value.\nResponsibilities\nPosition Responsibiliti\nes\nPartner with business stakeholders to gather requirements and translate them into technical specifications and process documentation for IT counterparts (on-prem and offshore)\nHighly proficient in the architecture and development of an event driven data warehouse; streaming, batch, data modeling, and storage\nAdvanced database knowledge; creating\/optimizing SQL queries, stored procedures, functions, partitioning data, indexing, and reading execution plans\nSkilled experience in writing and troubleshooting Python\/PySpark scripts to generate extracts, cleanse, conform and deliver data for consumption\nExpert level of understanding and implementing ETL architecture; data profiling, process flow, metric logging and error handling\nSupport continuous improvement by investigating and presenting alternatives to processes and technologies to an architectural review board\nDevelop and ensure adherence to published system architectural decisions and development standards\nMulti-task across several ongoing projects and daily duties of varying priorities as required\nInteract with global technical teams to communicate business requirements and collaboratively build data solutions\nRequirements\nRequirements\n8+ years of development experience\nExpert level in data warehouse design\/architecture, dimensional data modeling and ETL process development\nAdvanced level development in SQL\/NoSQL scripting and complex stored procedures (Snowflake, SQL Server, DynomoDB, NEO4J a plus)\nExtremely proficient in Python, PySpark, and Java\nAWS Expertise - Kinesis, Glue (Spark), EMR, S3, Lambda, and Athena\nStreaming Services - Confluent Kafka and Kinesis (or equivalent)\nHands on experience in designing and developing applications using Java Spring Framework (Spring Boot, Spring Cloud, Spring Data etc)\nShow more\nShow less",
      "job_skills":"Data warehouse architecture\/modeling, ETL processing, Confluent Kafka, Kinesis, Glue, Lambda, Snowflake, SQL Server, Python, PySpark, SQL, Stored procedures, Data profiling, Process flow, Metric logging, Error handling, System architectural decisions, Java Spring Framework, Spring Boot, Spring Cloud, Spring Data",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Engineer",
      "company":"Experfy",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-at-experfy-3590332063",
      "search_city":"Vineland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"A Sr. Data Engineer is proficient in the development of all aspects of data processing including data warehouse architecture\/modeling and ETL processing. The position focuses research on development and delivery of analytical solutions using various tools including Confluent Kafka, Kinesis, Glue, Lambda, Snowflake and SQL Server. A Sr. Data Engineer must be able to work autonomously with little guidance or instruction to deliver business value.\nResponsibilities\nPosition Responsibilities\nPartner with business stakeholders to gather requirements and translate them into technical specifications and process documentation for IT counterparts (on-prem and offshore)\nHighly proficient in the architecture and development of an event driven data warehouse; streaming, batch, data modeling, and storage\nAdvanced database knowledge; creating\/optimizing SQL queries, stored procedures, functions, partitioning data, indexing, and reading execution plans\nSkilled experience in writing and troubleshooting Python\/PySpark scripts to generate extracts, cleanse, conform and deliver data for consumption\nExpert level of understanding and implementing ETL architecture; data profiling, process flow, metric logging and error handling\nSupport continuous improvement by investigating and presenting alternatives to processes and technologies to an architectural review board\nDevelop and ensure adherence to published system architectural decisions and development standards\nMulti-task across several ongoing projects and daily duties of varying priorities as required\nInteract with global technical teams to communicate business requirements and collaboratively build data solutions\nRequirements\nRequirements\n8+ years of development experience\nExpert level in data warehouse design\/architecture, dimensional data modeling and ETL process development\nAdvanced level development in SQL\/NoSQL scripting and complex stored procedures (Snowflake, SQL Server, DynomoDB, NEO4J a plus)\nExtremely proficient in Python, PySpark, and Java\nAWS Expertise - Kinesis, Glue (Spark), EMR, S3, Lambda, and Athena\nStreaming Services - Confluent Kafka and Kinesis (or equivalent)\nHands on experience in designing and developing applications using Java Spring Framework (Spring Boot, Spring Cloud, Spring Data etc)\nShow more\nShow less",
      "job_skills":"Data warehouse architecture, ETL processing, Confluent Kafka, Kinesis, Glue, Lambda, Snowflake, SQL Server, SQL, Python, PySpark, Java, Spring Framework, Spring Boot, Spring Cloud, Spring Data, AWS Expertise, EMR, S3, Athena, NoSQL, Hadoop, Spark, NEO4J",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Archetype Permanent Solutions",
      "job_location":"El Paso, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-archetype-permanent-solutions-3787916075",
      "search_city":"El Centro",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are seeking a highly skilled and analytical Data Scientist to join our team. The ideal candidate will be adept at using large data sets to find opportunities for product and process optimization, and using models to test the effectiveness of different courses of action. This role will require both a strong technical background in data analysis and the ability to communicate findings to non-technical teams and stakeholders.\nKey Responsibilities:\nWork with stakeholders to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nQualifications:\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Statistics, Mathematics, Computer Science, or another quantitative field.\n2 years of experience in a Data Scientist or Data Analyst role.\nStrong problem-solving skills with an emphasis on product development.\nExperience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages\/drawbacks.\nExcellent written and verbal communication skills for coordinating across teams.\nPreferred Skills:\nExperience with distributed data\/computing tools: Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\nExperience with AWS, Azure, or another cloud service.\nExperience visualizing\/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.\nBenefits:\nCompetitive salary and benefits package.\nDynamic and innovative work environment.\nOpportunities for professional growth and development.\n[Other company-specific benefits like remote work options, flexible schedules, wellness programs, etc.]\nHow to Apply:\nPlease submit your resume, cover letter, and any relevant work samples\nPowered by JazzHR\n2c7D8cKfPG\nShow more\nShow less",
      "job_skills":"Data Science, Data Analysis, Data Processing, Statistics, Mathematics, Computer Science, Predictive Modeling, Machine Learning, R, Python, SQL, Data Architectures, Clustering, Decision Tree Learning, Artificial Neural Networks, Distributed Data Tools, Hadoop, Hive, Spark, Gurobi, MySQL, AWS, Azure, Cloud Services, Data Visualization, Periscope, Business Objects, D3, ggplot",
      "Category":"Backend Development"
  },
  {
      "job_title":"W2 Contract- Long Term Hybrid Contract- Data Engineer Position at Dalla\/Fort Worth, TX.",
      "company":"Software Technology Inc.",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/w2-contract-long-term-hybrid-contract-data-engineer-position-at-dalla-fort-worth-tx-at-software-technology-inc-3659214344",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Hi All,\nMy name is Poornachandra Rao and I am a Technical Recruiter at STI Org. I am reaching out to you on an exciting job opportunity with one of our clients\nHybrid Role- 5 Days a Months\nPosition: Data Engineer\nLocation: Hybrid - Dalla\/Fort Worth, TX\nDuration: Long Term\nTop 4 Requirements\nDatabase SQL, Oracle or NoSQL\nETL Tools Informatica, DataStage etc.\nPython\/Spark\/PySpark\nAWS\nResponsibilities\nDeliver high performing scalable, flexible and cost-effective data solutions that conform to architectural designs and Fidelity technology strategy\nBuild and own a portfolio of policies, procedures and best practices to provide operational and engineering disciplines to evolving data protection & security technologies\nEvaluate emerging technologies and market trends through research and POCs to improve and innovate on data protection & security technologies offerings\nOwn and continuously optimize tools, process and capabilities to support operational activities\nQualification\nStrong technology background in two or more database technologies Relational (Oracle, SQL Server, MySQL), NoSQL (MongoDB, Cassandra, Graph DB) and Cloud Databases (Aurora, Dynamo, Elastic Cache etc)\nKnowledge of Data Modelling Principles and solid understanding of database internals\nStrong Python experience with building ETL workflows and data-driven solutions\nPossess the ability to employ design patterns and generalize code to address common use cases. Capable of authoring high quality & reusable code to contribute to broader repositories\nExpertise in one or more of cloud computing platform (AWS or Azure)\nExperience using tools for infrastructure as a code (e.g., Terraform, Docker, CloudFormation, etc.) and automation workflows (i.e. GitLab, Jenkins, Artifactory, CI\/CD)\n7+ years in Technology with 3 years in developing and deploying data solutions\nNote : Need genuine consultant who can give Code assessment and last 5 Years of w2 employment details once get selected\nWarm Regards,\nB. Poorna Chandra Rao,\nTechnical Recruiter,\nSoftware Technology Inc (STI).\nEmail:\npoornab@stiorg.com\nPhone no: 609 447 3342.\nwww.stiorg.com\nShow more\nShow less",
      "job_skills":"Data Engineer, SQL, Oracle, NoSQL, Informatica, DataStage, Python, Spark, PySpark, AWS, Data Modelling Principles, ETL workflows, Terraform, Docker, CloudFormation, GitLab, Jenkins, Artifactory, CI\/CD",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Cloud Data Engineer",
      "company":"BDO USA",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-cloud-data-engineer-at-bdo-usa-3765474001",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nJob Summary:\nThis position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.\nJob Duties\nDesigns and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS\nListens to client needs to align solution with business requirements and delivery schedule\nCreates written functional and technical designs\nParticipates in project status and stand meetings, and assists with providing aggregated project status for project and program managers\nAssists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions\nWrites code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles\nDelivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)\nAssists with implementation of data governance programs and best practices\nPerforms the cleaning and transforming of data from source systems into analytics models\nImplements models to support data visualizations and integrations\nAssists with implementing DevOps, DataOps and MLOps methodologies on projects\nWrites custom integration logic in applicable programming languages\nAssists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle\nAssists clients with licensing, security, and cost estimation of solutions\nPerforms code reviews to ensure adherence to standards\nWorks directly with clients and team members to establish secure data analytics platforms and infrastructure\nContributes to successful deployments of developed solutions and integration of DevOps tools\nMaintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools\nBuilds client relationships during project execution, effectively becoming a trusted advisor of the client\nParticipates in support activities for existing software solutions\nOther duties as assigned\nSupervisory Responsibilities\nSupervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product\nEducation\nQualifications, Knowledge, Skills and Abilities:\nHigh School Diploma or GED equivalent, required\nBachelor\u201a\u00c4\u00f4s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred\nExperience\nFive (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required\nOne (1) or more years of experience technically leading development projects, preferred\nOne (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred\nSoftware\nStrong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required\nExperience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required\nHands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred\nExperience with one (1) or more of the following computer languages, preferred:\nC#\nPython\nJava\nScala\nExperience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred\nExperience with Git and DevOps deployment technologies, preferred\nExperience with Linux, preferred\nExperience with one (1) or more of the following, preferred:\nData Lake Medallion Architecture\nBatch and\/or streaming data ingestion into a data lake\nAI Algorithms\/Machine Learning\nAutomation tools such as UiPath, Alteryx, etc.\nComputer Vision based AI technologies\nOther Knowledge, Skills & Abilities\nAbility to work with a high degree of professionalism and autonomy\nExcellent verbal and written communication skills\nSolid organizational skills, especially the ability to meet project deadlines with a focus on details\nAbility to successfully multi-task while working independently or within a group environment\nAbility to work in a deadline-driven environment, and handle multiple projects simultaneously\nAbility to interact effectively with people at all organizational levels of the Firm\nAbility to effectively interact with a team of professionals and delegating work assignments, as needed\nAbility to build and maintain strong relationships with internal and client personnel\nAbility to encourage a team environment on engagements, and contribute to the professional development of assigned personnel\nKeywords:\nData Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL\nIndividual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate\u201a\u00c4\u00f4s qualifications, experience, skills, and geography.\nCalifornia Range: $111,000 - $152,000\nColorado Range: $111,000 - $152,000\nNew York City\/ Valhalla Range: $111,000 - $152,000\nWashington Range: $111,000 - $152,000\nAbout Us\nBDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients\u201a\u00c4\u00f4 needs. We currently serve more than 400 publicly traded domestic and international clients.\nUnparalleled partner-involvement\nDeep industry knowledge and participation\nGeographic coverage across the U.S.\nCohesive global network\nFocused capabilities across disciplines\nBDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world\u201a\u00c4\u00f4s fifth largest accounting network.\nBDO offers a competitive Total Rewards package that encompass so much more than \u201a\u00c4\u00ec \u201a\u00c4\u00fatraditional benefits\u201a\u00c4\u00f9. Our wide range of rewards and our employees\u201a\u00c4\u00f4 ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.\nSome Examples Of Our Total Rewards Offerings Include\nCompetitive pay and eligibility for an annual performance bonus.\nA 401k plan plus an employer match\nComprehensive, medical, dental, vision, FSA, and prescription insurance from day one\nCompetitive Paid Time Off with daily accrual from day one of employment, plus paid holidays\nPaid Parental Leave\nAdoption Assistance\nFirm paid life insurance\nWellness programs\nAdditional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance\nAbove offerings may be subject to eligibility requirements.\nClick here to find out more!\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.\n\"BDO USA, P.A. is an EO employer M\/F\/Veteran\/Disability\"\nShow more\nShow less",
      "job_skills":"Data Analytics, Business Intelligence, Artificial Intelligence, Application Development, Data Warehousing, Data Modeling, Semantic Model Definition, Star Schema Construction, Cloud Data Analytics, SQL, Data Definition Language (DDL), Data Manipulation Language (DML), Views, Functions, Stored Procedures, Performance Tuning, Azure, AWS, C#, Python, Java, Scala, Tabular Modeling, Microsoft Fabric, Power BI, Azure Analysis Services, Git, DevOps, Linux, Data Lake Medallion Architecture, Batch Data Ingestion, Streaming Data Ingestion, Data Lake, AI Algorithms, Machine Learning, Automation Tools, UiPath, Alteryx, Computer Vision, Professionalism, Autonomy, Verbal Communication, Written Communication, Organizational Skills, Project Deadlines, MultiTasking, Teamwork, DeadlineDriven Environment, Multiple Projects, Interpersonal Skills, Team Environment, Professional Development, Relationship Building",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer Manager - Remote",
      "company":"NRG Energy",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-manager-remote-at-nrg-energy-3771060654",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"At NRG, we\u201a\u00c4\u00f4re bringing the power of energy to people and organizations by putting customers at the center of everything we do. We generate electricity and provide energy solutions and natural gas to millions of customers through our diverse portfolio of retail brands. A Fortune 500 company, operating in the United States and Canada, NRG delivers innovative solutions while advocating for competitive energy markets and customer choice, working towards a sustainable energy future. More information is available at www.nrg.com. Connect with NRG on Facebook, LinkedIn and follow us on Twitter @nrgenergy.\nWe are looking for a highly skilled Data Engineering Manager who has a passion for data and analytics. Data Engineering Manager will be responsible for managing the delivery of projects, encouraging the adoption and integration of data, working closely with partners and leading a team of Data engineers with various levels of experience and capability.\nRequirements\n8+ years of experience managing data\n5+ years of experience leading project or technical teams which includes experience providing technical direction, thought leadership, coaching and mentoring.\n5+ years of strong experience in SQL and Data Analysis\n3+ years in development of data pipelines\/ETL for data ingestion, data preparation, data integration and data aggregation areas.\n3+ years of solid experience in Python and Spark\n3+ years of hands-on experience with Amazon Web Services (AWS)\nDeep understanding of data warehouse, data cloud architecture, building data pipelines, and orchestration\nExperience managing vendor\/supplier relationships\nEssential Duties\/Responsibilities\nManage the design and development of data models and pipelines that capture and transform data from internal and external systems.\nCollaborate with team members for the purpose of collecting data and executing the company\u201a\u00c4\u00f4s data mission\nCommunicate effectively with technical and non-technical stakeholders\nYou will partner with cross functional teams to identify opportunities and continuously develop and improve processes for efficiency\nIdentify and document standard methodologies, standards, and architecture guidelines\nEnsure solutions are highly usable, scalable, and maintainable\nWhy NRG Is a Great Place To Work\nGreat company culture!! Voted as a BEST employer by Forbes\nA competitive total compensation package, including annual incentive and\/or commission\nStock Purchase Plan\nBenefits on the first day of employment - Medical, Dental, Vision, Life Insurance, and Short Term Disability, Wellness program, etc.\nCompany-paid life insurance and disability insurance\n401 (k) plan to help save for retirement\nGenerous PTO plan, plus 8 company holidays, and 3 floating holidays\nNumerous discounts, including electricity discounts on NRG brands\nIf you reside in or intend to work remotely from California, Colorado, New York or Washington State, you may contact Careers@nrg.com for compensation information related to this position and other information as required by applicable law. Please include the job title in your request.\nNRG Energy is committed to a drug and alcohol free workplace. To the extent permitted by law and any applicable collective bargaining agreement, employees are subject to periodic random drug testing, and post-accident and reasonable suspicion drug and alcohol testing. EOE AA M\/F\/Protected Veteran Status\/Disability\nEEO is the Law Poster (The poster can be found at http:\/\/www.eeoc.gov\/employers\/upload\/poster_screen_reader_optimized.pdf)\nLevel, Title and\/or Salary may be adjusted based on the applicant's experience or skills.\nOfficial description on file with Talent.\nShow more\nShow less",
      "job_skills":"Leadership, Data engineering, Data warehousing, Analysis, Data modeling, Pipelines, Oracle SQL, Python, Spark, AWS, Data aggregation, Data integration, ETL, Vendor management, Data governance, Cloud architecture, DataBricks, Informatica",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data engineer - Austin, TX",
      "company":"Diverse Lynx",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-austin-tx-at-diverse-lynx-3776527757",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nWe are looking for a Senior Data Engineer to join our team and help us build and maintain our data infrastructure and pipelines. As a Senior Data Engineer, you will be responsible for designing, developing, and implementing scalable and reliable data solutions to support our business needs. You will also work closely with other engineers and data scientists to ensure that our data is clean, accessible, and secure.\nResponsibilities\nDesign, develop, and implement scalable and reliable data pipelines and architectures\nWork with data scientists and analysts to understand their data needs and develop solutions to meet those needs\nBuild and maintain data warehouses and data marts\nOptimize data pipelines and architectures for performance and efficiency\nImplement data security and governance measures\nMonitor and troubleshoot data pipelines and architectures\nStay up-to-date on the latest data engineering technologies and trends\nQualifications\n8&plus; years of experience in a data engineering role\nStrong experience with SQL, Python, and other data engineering technologies\nExperience with cloud computing platforms such as AWS, Azure, or GCP\nExperience with big data technologies such as Hadoop, Spark, and Kafka\nExperience with data warehousing and data mart technologies such as Snowflake, Redshift, and BigQuery\nExperience with data security and governance best practices\nExcellent problem-solving and analytical skills\nStrong communication and collaboration skills\nBonus Points\nExperience with machine learning and deep learning\nExperience with data visualization tools such as Tableau and Power BI\nExperience with data streaming technologies such as Kafka and Flink\nDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\nShow more\nShow less",
      "job_skills":"SQL, Python, Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), Apache Hadoop, Apache Spark, Apache Kafka, Snowflake, Amazon Redshift, Google BigQuery, Machine learning, Deep learning, Tableau, Power BI, Data streaming, Kafka, Flink",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"HeartFlow, Inc",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-heartflow-inc-3780093387",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"HeartFlow, Inc. is a medical technology company transforming the diagnosis and management of coronary artery disease, the #1 cause of death worldwide, using cutting-edge technology. The flagship product\u201a\u00c4\u00eean AI-based, non-invasive cardiac test called the HeartFlow Analysis\u201a\u00c4\u00eeprovides a color-coded, 3D model of a patient\u201a\u00c4\u00f4s coronary arteries indicating the impact blockages have on blood flow to the heart. It offers physicians a completely novel way to diagnose and treat cardiac patients. Our pipeline of products is growing and so is our team; join us in helping to revolutionize precision heartcare.\nHeartFlow is a VC-backed, pre-IPO company that has received international recognition for exceptional strides in healthcare innovation, is supported by medical societies around the world, cleared for use in the US, UK, Europe, Japan and Canada, and has been used for more than 200,000 patients worldwide.\nThe Sr. Data Engineer brings DataOps, data engineering, DevOps and cloud computing expertise in expanding and optimizing our data lake processing pipeline and data analytics architecture. They bring technical expertise to design, architect, implement and support solutions to scale and optimize data flow into and out of cloud-based data lakes for cross functional teams to consume for Tableau reporting, Ad-hoc querying and Machine learning processing. ;\nIn addition, expertise in cross-team (NetOps, DevOps, InfoSec, SecOPs, etc.) collaboration via use of professional skills are utilized to perform stretch roles as Sr. Data Engineer.\nThe Sr. Data Engineer will be a mentor and SME to other members of the team, as well as consult to management and leadership.\nJob Responsibilities:\nDesign, build, and maintain a scalable and low-latency infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and targets using AWS data lake related services and analytics-related technologies.\nSupport and collaborate with down-stream consumers, i.e. Tableau, Ad-hoc and Machine Learning to ensure their success by assembling and delivering required data sets, security, and acceptable query times\nPerform exporting\/sync of data to third-party products, i.e. Salesforce, FTP Servers, etc. using AWS AppFlow, SFTP SSH, etc.\nBe SME from within the team to provide expertise to bring innovative ideas from concept to fruition via collaborative POCs, Spikes and \/or discussions with team members.\nIdentify, design, document and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nUnderstand and guide a comprehensive testing, continuous integration and development framework for schema, data, and functional processes\/pipelines, etc.\nBe SME for tools used by Data Engineering, i.e. GitHub, Jira, Confluence, etc.\nManage AWS accounts dedicated to DataOps team with root level access that have DevOps, NetOps, InfoSec and DataOps stretch-role responsibilities.\nSkills Needed:\nStrong experience with AWS cloud services: S3, DMS, RDS, Lambda, Redshift, Glue, AppFlow, EC2, in cross-region and cross-account implementations\nStrong experience with AWS security: IAM Roles\/Policies\/Users, Okta\/SSO\nStrong experience with AWS networking: VPC, Subnets, security groups, route tables, gateways, etc.\nStrong experience with technical writing to document processes, best practices, create architecture diagrams, etc. using Atlassian Confluence, Lucid Charts, etc.\nStrong experience with Agile Scrum: Managing, creating and maintaining Jira board, issues, sprint shutdown, grooming, status updates with management, supporting documentation and sprint demos. Perform stretch-role of Scrum Master.\nStrong experience with Infrastructure as Code via Terraform, AWS CDK for Python, AWS CloudFormation, etc.\nStrong experience with NoSQL databases, i.e. DynamoDB, DocumentDB and\/or MongoDB\nStrong experience with relational\/DW SQL databases such as MySQL, PostgreSQL, and Redshift\nStrong experience with programming in Python via python.org and Anaconda python using AWS Boto3, PyCharm IDE, etc. and data engineering related packages: pandas, numpy, scipy, sqlalchemy, pyarrow, redshift connector\nStrong experience building and optimizing data pipelines, architectures, data lakes, data sets, etc.\nStrong experience with reading and writing of multiple file formats, i.e. JSON, text\/CSV, and parquet\nStrong experience with transferring and receiving of files via SFTP SSH using ssh CLI, Python, Filezilla, etc.\nStrong experience with Code repo management - Git and GitHub, managing and overseeing repos, branches, pull requests, etc. using standalone CLI and GUI tools, and integrated with PyCharm.\nStrong experience with Salesforce: reading and writing of data to and from the data lake, Salesforce Query Language, and Salesforce objects and structures.\nStrong experience API usage and connectivity via Python and Postman REST API client tool.\nExperience with AWS CloudWatch alerting and notification integration with third-party tools: PagerDuty, Slack, etc.\nExperience with managing and overseeing dedicated AWS accounts: billing, tuning, security and access management, network and connectivity management, root level login\/access\/tasks, etc.\nExperience with containerization technologies, such as Docker, AWS ECR, AWS Lambda\nExperience with third-party Data and File management tools, i.e. DBeaver, FileZilla, etc.\nExperience with AWS and third-party ETL tools: AWS Glue, Hevo, Boomi, etc.\nExperience with master data, metadata, versioning, tagging, cataloging of data sources\nFamiliarity with data visualization and analytics tools like Tableau\nEducational Requirements & Work Experience:\n5+ years of experience in a Data Engineering role in a team setting\n5+ years of experience working with AWS cloud using data related services\n5+ years of experience working with RDS, Redshift and NoSQL\n2+ years of experience working with Data Lakes in AWS\nUndergraduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Graduate degree preferred.\nAWS certifications a plus\nExperience leading data analysts or managing teams a plus\nThe pay range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to experience and training; skill sets; licensure and certifications; and other business and organizational needs. A reasonable estimate of the base salary compensation range is $122,445 to $165,000 per year.\nWe also offer a range of benefits and programs to meet employee needs based on eligibility. These benefits include comprehensive health care coverage, a health savings account, disability, and life insurance, a Critical Illness and accident plan, a flex spending account (medical and dependent care), a 401k plan with a company match, mental health support TaskHuman, EAP, financial coaching, Rocket Lawyer, and more. HeartFlow offers 12 paid holidays, 15 vacation days, and 80 hours of sick leave.\nAbout HeartFlow, Inc.\nHeartFlow, Inc. is a medical technology company redefining the way heart disease is diagnosed and treated. Our non-invasive HeartFlow FFRct Analysis leverages deep learning to create a personalized 3D model of the heart. By using this model, clinicians can better evaluate the impact a blockage has on blood flow and determine the best treatment for patients. Our technology is reflective of our Silicon Valley roots and incorporates decades of scientific evidence with the latest advances in artificial intelligence. The HeartFlow FFRct Analysis is commercially available in the United States, Canada, Europe and Japan. For more information, visit www.heartflow.com .\nHeartFlow, Inc. is an Equal Opportunity Employer. We are committed to a work environment that supports, inspires, and respects all individuals and do not discriminate against any employee or applicant because of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. This policy applies to every aspect of employment at HeartFlow, including recruitment, hiring, training, relocation, promotion, and termination.\nPositions posted for HeartFlow are not intended for or open to third party recruiters \/ agencies. Submission of any unsolicited resumes for these positions will be considered to be free referrals.\nUS Locations Only: All employees and contingent workers (contractor, consultant, interns or temporary personnel) are required to be vaccinated against SARS-CoV-2 as recommended by CDC, unless a reasonable accommodation is approved. All prospective hires will be expected to provide proof of vaccination on their first day of employment.\nShow more\nShow less",
      "job_skills":"AI, Deep Learning, Machine Learning, Python, AWS, S3, DMS, RDS, Lambda, Redshift, Glue, AppFlow, EC2, IAM, VPC, Subnets, Route tables, Gateways, Lucid Charts, Confluence, Atlassian, Jira, Scrum, Terraform, AWS CDK, Python.org, Anaconda, PyCharm, Boto3, pandas, numpy, scipy, sqlalchemy, pyarrow, Redshift connector, JSON, CSV, Parquet, SFTP SSH, Git, GitHub, DBeaver, FileZilla, AWS Glue, Hevo, Boomi, Docker, AWS ECR, Salesforce, Tableau, Docker, AWS ECR, Salesforce Query Language",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer \u201a\u00c4\u00ec Houston",
      "company":"Soho Square Solutions",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-%E2%80%93-houston-at-soho-square-solutions-3654419833",
      "search_city":"Jasper",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description\nRole: Data Engineer\nRequired Skills: Java\/Spark\/Databricks\/Kubernetes (+ AWS Cloud Exp)\nIndustry : Financial Services; FS - Banking & Capital Markets\nOther Information: Intermediate (4-7 yrs exp)\nLocation: Houston, TX\nKey Responsibilities\nThe job function of a Java Spark Databricks AWS data engineer involves working with data engineering technologies and platforms to design, develop, and maintain data solutions on the AWS cloud platform.\nHere are some key responsibilities and tasks associated with this role:\nData Ingestion: Develop and implement processes to extract data from various sources, such as databases, APIs, and files, and load it into the data lake or data warehouse using Java, Spark, and AWS tools\nData Transformation: Perform data cleansing, validation, and transformation using Spark and Java programming, ensuring data quality and consistency. Apply business rules and data processing techniques to prepare the data for analysis and consumption\nData Pipeline Development: Design and build scalable data pipelines using AWS services like AWS Glue, AWS Data Pipeline, or Apache Airflow. Develop ETL (Extract, Transform, Load) processes to move and transform data between different systems and data stores\nData Modeling: Create and maintain data models and schemas, including dimensional and relational models, to support data storage and retrieval requirements. Optimize data structures for performance and efficiency.\nPerformance Optimization: Fine-tune Spark applications and data processing workflows to improve performance and reduce processing time. Optimize resource utilization, data partitioning, and data caching strategies.\nData Security and Governance: Implement data security and access controls to ensure data privacy and compliance with regulatory requirements. Apply data governance practices to manage metadata, data lineage, and data cataloging.\nMonitoring and Troubleshooting: Monitor data pipelines and Spark jobs for performance, errors, and issues. Troubleshoot and resolve data-related problems, such as data quality issues or performance bottlenecks.\nCollaboration and Documentation: Collaborate with cross-functional teams, including data scientists, analysts, and business stakeholders, to understand data requirements and deliver data solutions. Document data pipelines, processes, and system configurations.\nCloud Infrastructure Management: Configure and manage AWS services like Amazon EMR (Elastic MapReduce), Amazon S3 (Simple Storage Service), and AWS Glue for data processing, storage, and management. Monitor and optimize cloud resources for cost efficiency.\nContinuous Improvement: Stay updated with emerging technologies, industry trends, and best practices related to data engineering and cloud computing. Continuously enhance skills and knowledge to improve data engineering processes and solutions.\nShow more\nShow less",
      "job_skills":"Java, Apache Spark, Databricks, Kubernetes, AWS, Data Ingestion, Data Transformation, Data Pipeline Development, Data Modeling, Performance Optimization, Data Security, Data Governance, Monitoring, Troubleshooting, Collaboration, Documentation, Cloud Infrastructure Management, ETL (Extract Transform Load), Amazon EMR (Elastic MapReduce), Amazon S3 (Simple Storage Service), AWS Glue, AWS Data Pipeline, Apache Airflow",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Engineer java sparc sqlLocation: St Louis, MO (Onsite)",
      "company":"Executive Staff Recruiters \/ ESR Healthcare",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-java-sparc-sqllocation-st-louis-mo-onsite-at-executive-staff-recruiters-esr-healthcare-3645958534",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Company Profile\nesrhealthcare.com.mysmartjobboard.com\nLead Data Engineer\n>\n> Location: St Louis, MO (Onsite)\n>\n> Duration: 12 month with possible extension\n>\n> Required Work Experience:\n>\n>\n5+ years of experience in an engineering role using Python,\n> Java, Spark, and SQL.\n>\n>\nGCP Cloud Experience Required\n>\n>\nStrong working experience in HealthCare domain is a must\n>\n>\nStrong Linux\/Unix background and hands on knowledge.\n>\n>\nExperience with Shell scripting and bash.\n>\n>\nExperience with version control platform github\n>\n>\nExperience with development ecosystem including Jenkins,\n> Artifactory, CI\/CD, and Terraform.\n>\n>\nPipeline creation and automation for Data Acquisition\n>\n>\nMetadata extraction pipeline design and creation between\n> raw and finally transformed datasets\n>\n>\nPast experience with big data technologies including HDFS,\n> Spark, Impala, Hive\n>\n>\nAble to collaborate with scrum team including scrum master,\n> product owner, data analysts, Quality Assurance, business owners, and\n> data architecture to produce the best possible end products\n>\n>\nWorks on problems of diverse scope and complexity ranging\n> from moderate to substantial\n>\n>\nAssists senior professionals in determining methods and\n> procedures for new tasks\n>\n>\nLeads basic or moderately complex projects\/activities on\n> semi-regular basis\n>\n>\nMust possess excellent written and verbal communication\n> skills\n>\n>\nAbility to understand and analyze complex data sets\n>\n>\nExercises independent judgment on basic or moderately\n> complex issues regarding job and related tasks\n>\n>\nMakes recommendations to management on new processes, tools\n> and techniques, or development of new products and services\n>\n>\nWorks under minimal supervision, uses independent judgment\n> requiring analysis of variable factors\n>\n>\nCollaborates with senior professionals in the development\n> of methods, techniques and analytical approach\n>\n>\nAble to effectively communicate highly technical\n> information to numerous audiences, including management, the user\n> community, and less-experienced staff.\n>\n>\nConsistently communicate on status of project deliverables\n>\n>\nConsistently provide work effort estimates to management to\n> assist in setting priorities\n>\n>\nDeliver timely work in accordance with estimates\n>\n>\nSolve problems as they arise and communicate potential\n> roadblocks to manage expectations\n>\n>\nAdhere strictly to all security policies\n>\n> Regards...!!!!\n>\n> Aravind\nPowered by Webbtree\nShow more\nShow less",
      "job_skills":"Python, Java, Spark, SQL, GCP Cloud, Linux\/Unix, Shell scripting, Bash, GitHub, Jenkins, Artifactory, CI\/CD, Terraform, Data Acquisition Pipeline, Metadata extraction pipeline, HDFS, Impala, Hive, Scrum, Data analysis, Quality Assurance, Data Architecture, Communication, Data analysis, Independent judgment, Recommendations, Supervision, Collaboration, Technical communication, Status updates, Work effort estimates, problem solving, Security policies",
      "Category":"Backend Development"
  },
  {
      "job_title":"SENIOR MARKETING DATA ANALYST",
      "company":"Ameren",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-marketing-data-analyst-at-ameren-3778739779",
      "search_city":"Cahokia",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"About Us\nAmeren is a leader in the energy industry, and our transformation toward more clean, renewable energy is also transforming other industries and infrastructure in our communities. As a regional company serving local customers, we not only serve our communities, we're a part of them. This isn't just a job. At Ameren, we invest in you, so you can power the quality of life you want.\nDiversity, Equity & Inclusion is one of the core values that guides us in everything we do. We are committed to building a skilled and diverse workforce that brings diverse perspectives to every area of our business.\nOur benefits include:\nMedical coverage on date of hire\n100% employer paid cash balance pension plan\n401(k) with company match fully vested on date of hire\nMinimum of 15 days paid vacation and 12 paid holidays\nPaid parental leave and family caregiver leave\nAbout Ameren Services (B&CS)\nAmeren Services provides administrative support and services to Ameren Corporation and its operating companies, subsidiaries and affiliates. Ameren Services includes a wide range of skill sets and roles, from finance and legal experts to digital and cyber specialists, plus those charged with ensuring environmental compliance and operational safety. Together, we help execute a strategy that enables Ameren to deliver superior long-term value to customers, shareholders and the environment.\nAbout The Position\nThe Sr Marketing Data Analyst is:\nResponsible for integrating data from our various marketing campaigns, formatting the data into an easy-to-analyze visual format, working independently to uncover insights, and communicating those insights and recommendations to communications strategists, business partners and leaders.\nWorks independently to design and develop methods, processes, and systems to consolidate and analyze marketing automation and lead generation data to generate actionable insights.\nWorks independently to solve complex business problems using data analysis.\nKey responsibilities include:\nCollaborate with communications strategists and\/or other stakeholders to identify and document data requirements and measurement strategies based on campaign goals and objectives prior to the launch of marketing and\/or communications campaigns.\nPull marketing engagement data from various platforms to integrate, analyze and interpret results for marketing tactics or channels associated with a campaign, including web, email, paid advertising (e.g., digital display ads, CTV, streaming radio, and paid search), direct mail, energy statement messaging, YouTube and social media.\nAutomate and visualize the data, leveraging tools like Looker Studio or Power BI to provide a holistic picture of campaign performance and provide recommendations for optimizations.\nReview all the variables that impact our marketing and campaign results, including creative, copy, CTAs, targeting, timing and distribution channels, to identify and draw conclusions regarding performance, trends and insights.\nMake ongoing and real-time data-driven recommendations and identify opportunities for optimizations and A\/B or multivariate tests.\nCreate easy-to-understand reports and templates that effectively display key data points and tell a story in PowerPoint or via a visualization tool for working teams, marketing and leadership teams.\nIndependently and effectively work and communicate with communications strategists and leadership to deliver or present customer and campaign insights and optimizations.\nPartner effectively with other departments to fully define analytics requirements, provide engineering, data validations and modeling.\nDevelop innovative and efficient solutions for leveraging APIs for data integration, processing and automation and assist in the ongoing maintenance of reporting and analytics applications.\nMentor and provide ongoing support for less experienced team members.\nOther duties as assigned.\nQualifications\nBachelor\u201a\u00c4\u00f4s degree required, preferably in mathematics, statistics, computer science, marketing, or business.\n5+ years of relevant experience\nMaster\u201a\u00c4\u00f4s and\/or Ph.D. in a technical discipline e.g., engineering, mathematics, statistics, finance\/economics, etc.) may replace a maximum of 2 years of experience.\nCareer path level depends on applicant experience and credentials\nIn addition to the above qualifications, the successful candidate will demonstrate:\nStrong knowledge of data visualization and relational databases.\nStrong knowledge of marketing platforms including marketing automation software (e.g., Salesforce Marketing Cloud or HubSpot), website analytics and tagging systems (e.g., GA4, GTM and Big Query), digital marketing platforms (e.g., Google AdWords, Campaign Manager 360 and AWS Pinpoint), social media platforms (e.g., Sprinklr, Facebook, Twitter and LinkedIn) and visualization tools (e.g., Looker Studio, Power BI etc.).\nWriting queries (SQL), and programming (R, Python, VBA, or SAS) is not required but would be a plus.\nStrong analytical skills to address business problems.\nStrong knowledge with Microsoft Office Products \u201a\u00c4\u00ec specifically Microsoft Excel.\nAbility to manage multiple priorities and to clarify priorities, scope and requirement in ambiguous situations.\nAdditional Information\nAmeren\u201a\u00c4\u00f4s selection process includes a series of interviews and may include a leadership assessment process. Specific details will be provided to qualified candidates.\nIf end date is listed, the posting will come down at 12:00 am on that date:\nTuesday December 19, 2023\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, ethnicity, age, disability, genetic information, military service or status, pregnancy, marital status, sexual orientation, gender identity or expression, or any other class, trait, or status protected by law.\nShow more\nShow less",
      "job_skills":"Data visualization, Relational databases, Marketing automation software, Website analytics, Tagging systems, Digital marketing platforms, Social media platforms, Visualization tools, Data analysis, SQL, R, Python, VBA, SAS, Microsoft Office Products, Microsoft Excel, Statistics, Computer science, Marketing, Business, Engineering, Mathematics, Finance, Economics, Salesforce Marketing Cloud, HubSpot, GA4, GTM, Big Query, Google AdWords, Campaign Manager 360, AWS Pinpoint, Sprinklr, Facebook, Twitter, LinkedIn, Looker Studio, Power BI",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer (Remote First)",
      "company":"European Wax Center",
      "job_location":"Texas, United States",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-remote-first-at-european-wax-center-3757566437",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Perks & Benefits\nRemote-First Workplace\nFlexible Fridays\nDiversity, Equity & Inclusion Council\nMonthly Remote Stipend\nProfessional Development Stipend (up to $500 annually)\n1 Wellness\/Mental Health Paid Day Off\n1 Volunteer Paid Day Off\nHealth Benefits (Medical, Dental, Vision)\nHDHP with HSA plan (annual employer contribution to HSA)\nEmployer-Paid Basic Life Insurance and AD&D\nEmployer-Paid Short- and Long-term Disability\nEmployer-Paid Wellness Reward Program\nEmployer-Paid Mental Health Benefit\nEmployer-Paid Employee Assistance Program\nEmployer-Paid Out of State Medical Travel Benefit\n401(k) Safe-Harbor Matching\nAncillary Benefits (pet insurance, legal coverage, identity theft protection, accident, hospital, and critical illness coverages)\nPaid Time Off (increases with tenure)\nPaid Parental, Adoption, and Foster Leave\nOut of State Medical Travel Benefit\nAbout The Role\nEWC is looking for a motivated Senior Data Engineer to join our growing team of data experts. In this role, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and engineer who enjoys optimizing data systems and building them from the ground up. The Sr. Data Engineer will support our data analysts\/scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company\u201a\u00c4\u00f4s data architecture to support our next generation of products and data initiatives.\nA Day In The Life\nCollecting, organizing, managing, and converting raw data into a format that can be easily analyzed by Business Intelligence analysts and data scientists.\nBuilding and maintaining data pipelines that collect and transport data from various sources to EWC\u201a\u00c4\u00f4s data storage systems.\nUsing algorithms and programming languages such as SQL and Python to prepare data for analysis.\nWorking closely with the management and end-users to understand and address business requirements related to data storage, management, and analysis.\nCreating data analysis tools and developing new data validation methods to ensure data accuracy and completeness.\nIdentifying ways to make data more reliable, efficient, and accessible to relevant stakeholders.\nCreating and maintaining the organization\u201a\u00c4\u00f4s software and hardware architecture to support efficient and secure data storage and management.\nConducting research and troubleshooting to address potential problems that may arise in the data storage and management systems.\nPlay a key role in designing and crafting a modern Data and Information Delivery and Analytics platform in the cloud to support retail service and product distribution for the US market.\nCreate and maintain optimal data pipeline architecture.\nAssemble large, complex data sets that meet functional\/non-functional business requirements.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS \u201a\u00c4\u00f2big data\u201a\u00c4\u00f4 technologies.\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\nWork with stakeholders including the Executive, Operations, FP&A, and Supply Chain teams to assist with data-related technical issues and support their data infrastructure needs.\nKeep our data separated and secure during transmission and at rest.\nCreate data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\nWork with data and analytics experts to strive for greater functionality in our data systems.\nWhat Sets You Apart\nAdopts EWC values in personal work behaviors, decision making, contributions and interpersonal interactions.\nHelps shape a positive work environment by demonstrating and influencing others to reward performance and value \"can do\" people, accountability, diversity and inclusion, flexibility, continuous improvement, collaboration, creativity, and fun.\nExperience with commercial data engineering\/science solution initiatives.\nAbility to manage a broad range of deliverables with ambiguous task symptomatology while consistently achieving collaborative success with others to accomplish goals.\nWorks well in a team environment and takes pride in participating in projects that employ the skills of all team members.\nAbility to learn quickly in a dynamic environment and to troubleshoot issues.\nBusiness savvy communications skills and concise written communication skills.\nAbility to be self-sufficient and self-driven in a small team.\nUnderstanding of the current threat and vulnerability landscape.\nExcellent organization and presentation skills.\nEducation And Experience\nBS in Computer Science, Data Science, or equivalent.\n7+ years of professional software development or data engineering experience.\n5+ years of experience using and strategizing the use of DBT and Airflow.\nStrong working knowledge of SQL, of datastores and their tradeoffs (including relational, columnar, and document stores), data modeling, data structures, data manipulation.\nStrong knowledge of Extract, Transform, Load (ETL) pipeline design, tooling, and support.\nExperience designing, building and optimizing \u201a\u00c4\u00f2big data\u201a\u00c4\u00f4 data pipelines, architectures and data sets.\nExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\nStrong analytic skills related to working with unstructured datasets.\nBuild processes supporting data transformation, data structures, metadata, dependency and workload management.\nProven ability to architect, implement, and optimize high throughput data pipelines.\nExperience deploying production systems in the cloud (i.e., AWS, Azure).\nStrong communication skills in writing and conversation.\nExperience with tools we use every day:\nStorage: Snowflake, AWS Storage Services (e.g., S3, RDS, Glacier)\nETL\/BI: Astronomer, DBT, Domo, Tableau, PowerBI\nProven passion and talent for teaching fellow engineers and non-engineers.\nExperience with encryption at rest, including multiple approaches and tradeoffs.\nExperience in Retail operations.\nEuropean Wax Center is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, protected veteran status, or any other characteristic protected by law.\nThis job description is a general description of essential job functions. It is not intended to describe all duties someone in this position may perform. All employees of EWC and operating subsidiaries are expected to perform tasks as assigned by supervisory\/management personnel, regardless of job.\nShow more\nShow less",
      "job_skills":"SQL, Python, Big Data, Data Engineering, Data Pipelines, AWS, DBT, Airflow, Data Modeling, Data Structures, Data Manipulation, Extract Transform Load (ETL), Snowflake, AWS Storage Services, Astronomer, Domo, Tableau, PowerBI, Encryption, Data Analysis, Data Science",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Software Engineer (Data Engineering)",
      "company":"Harbor Health",
      "job_location":"Texas, United States",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-software-engineer-data-engineering-at-harbor-health-3787915497",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Harbor Health looking for a Senior Software Engineer to become a member of our team! Harbor Health is an entirely new multi-specialty clinic group in Austin, TX utilizing a modern approach to co-create health with those who get, give, and pay for it, allowing everyone to fully flourish. Join us as we build a fully integrated system that connects care to a better payment model that truly puts the human being at the center.\nAs a Senior Software Engineer with a focus on data engineering at Harbor Health, you will play a pivotal role in our data transformation initiatives. You will work with a team of dedicated professionals using AWS, Snowflake, and DBT Labs to create efficient data pipelines. Your expertise in Python, SQL, and SQL performance optimization, along with your ability to take a proactive and collaborative approach to your work, will be essential in shaping the future of healthcare data analytics.\nOur Sr. Software Engineer will be responsible for:\nCollaborate with cross-functional teams to design, develop, and maintain data engineering solutions.\nDevelop and optimize ETL processes using DBT Labs and other technologies.\nDesign and implement data models and data transformations for our Snowflake data warehouse.\nCreate robust, scalable, and maintainable code using Python.\nWrite efficient SQL queries and be an expert at SQL performance tuning.\nParticipate in daily standup meetings with the team to ensure alignment and effective collaboration.\nIndependently manage and execute projects while being adaptable and productive, whether working alone or in a team.\nSuccessful Sr. Software Engineer's will have:\nBachelor's degree in Computer Science, Software Engineering, or a related field (or equivalent work experience).\n5+ years in a Data Engineering role with proven experience as a software engineer\nDemonstrated strong proficiency in AWS, Snowflake, and DBT Labs.\nAdvanced skills in Python for data engineering and transformation.\nExpertise in SQL and SQL performance optimization.\nCurious and action-oriented mindset, self-motivated, and able to work effectively both independently and in a team.\nExcellent problem-solving skills and the ability to drive projects to completion.\nAdditional Skills & Experiences Preferred include:\nKimball data modeling experience\nInmon data modeling experience\nExperience working with healthcare data and healthcare quality metrics such as HEDIS measures.\nAbility to travel as needed, less than 10% of time.\nIf you are passionate about health care and you want to create something new together, we want you to be apart of our team!\nPowered by JazzHR\n8Lt6GnsYsF\nShow more\nShow less",
      "job_skills":"Python, SQL, AWS, Snowflake, DBT Labs, Data Engineering, ETL, Data Models, Data Transformations, Data Warehousing, Software Engineering, Kimball Data Modeling, Inmon Data Modeling, Healthcare Data, Healthcare Quality Metrics, HEDIS Measures",
      "Category":"Backend Development"
  },
  {
      "job_title":"Principal Data Engineer (Remote)",
      "company":"Collins Aerospace",
      "job_location":"Texas, United States",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-data-engineer-remote-at-collins-aerospace-3770133137",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Date Posted:\n2023-11-20\nCountry:\nUnited States of America\nLocation:\nHTX99: Field Office - TX Remote Location, Remote City, TX, 73301 USA\nPosition Role Type:\nRemote\nDo you want to be part of the team that builds the Data Platform at the center of Transforming the Aviation Industry?\nAs a\nPrincipal\nData Engineer\n, you will be on a mission to ensure that our Data Platform can leverage data from various sources to help transform the passenger journey as well as help our customers leverage data to improve their operations. This role is\nresponsible for the design, development and maintenance of data processes and pipelines\nsupporting critical Strategic Business Unit (SBU) Data initiatives in support of the Digital Transformation. The scope of the role encompasses many facets of the aviation industry. You will\nwork with Data Scientists and Application Developers\nto\nbuild data-based products\nthat benefit commercial airlines, airports and passengers.\nYour work will influence the next generation of connected aviation products.\nYou will work with a team where you will be able to\nshare your ideas and vulnerabilities and will be treated with care and empathy\n. You will work with a team that shows courage in doing the right thing, not because it is easy. This is a great opportunity with room to\ngrow and learn about new and interesting technology solutions.\nOur business unit, Connected Aviation Solutions (CAS), is leading the Connected Ecosystem strategic pillar for Collins Aerospace. The Data Management & Data Science (DM&DS) team has end-to-end responsibility to\nensure that CAS data assets are managed with integrity and quality prior to consumption by our critical customer facing applications\n- whether via API\u201a\u00c4\u00f4s, analytics and\/or data visualizations.\nWhat YOU will do:\nYOU will contribute to establishing Data Engineering best practices, building the DataOps model and enabling the ML and AI roadmap of the future.\nYOU will develop automation and monitoring processes that support the data pipelines.\nYOU will work closely with the architecture team to implement modern data repositories that support the CAS use cases (Pipelines, API\u201a\u00c4\u00f4s, Data Science, Applications and Visualizations).\nYOU will work with internal business customers and software development teams to gather and document requirements for data publishing and data consumption.\nYOU will work with the CAS and DT Enterprise Data Architects to automate cloud deployments, as well as build CI\/CD pipeline to support cloud-based workloads. This includes developing views, materialized views, and SQL scripts.\nYOU may travel domestically and internationally up to 15%.\nYOU will work on a distributed and diverse team that collaborates and communicates well.\nWhat YOU will learn:\nYOU will learn all about the datasets that are produced in the aerospace ecosystem; such as how the various components in an aircraft interact with each other.\nYOU will learn how to enable Data Scientists to perform ML and AI experiments.\nYOU will gain exposure to large scale data processing leveraging modern technology stacks including Databricks and AWS native services.\nYOU can take flight to becoming a subject matter expert and leader in Data Engineering with exposure to the variety of business and products in an ever-evolving aerospace industry. CAS is growing and so can you.\nEducation & Experience:\nTypically requires a degree in Science, Technology, Engineering or Mathematics (STEM) unless prohibited by local laws\/regulations and minimum 8 years prior relevant experience or an Advanced Degree in a related field and minimum 5 years of experience or in absence of a degree, 12 years of relevant experience.\nQualifications You Must Have:\nMust be authorized to work in the U.S. without sponsorship now or in the future. RTX will not offer sponsorship for this position.\nDemonstrated engineering experience in system integration and design, data pipeline development, or software\/service development and deployment.\nExperience building data pipelines leveraging tools like Spark, Python, PySpark & SQL as well as working with AWS\/Azure Cloud platforms and related services and Terraform, Gitlab and similar CI\/CD tools.\nExperience with Databricks Platform and leveraging that platform to build out a Data Lake.\nSkills We Value:\nProfessional background developing complex SQL queries and programming in Python with ability to transform raw data into valuable insights.\nExperience designing cloud-based data platforms that ensure cost optimization, scalability, performance and ease of use for end users of the platform.\nExperience with Micro Services Architectures.\nAWS\/Azure certifications.\nCollins Aerospace, an RTX company, is a leader in technologically advanced and intelligent solutions for the global aerospace and defense industry. Collins Aerospace has the capabilities, comprehensive portfolio, and expertise to solve customers\u201a\u00c4\u00f4 toughest challenges and to meet the demands of a rapidly evolving global market.\n#reempowerprogram\nThis role is also eligible for the Re-Empower Program. The Re-Empower Program helps support talented and committed professionals as they rebuild their capabilities, enhance leadership skills, and continue their professional journey. Over the course of the 14-week program, experienced professionals will gain paid, on-the-job experience, have an opportunity to participate in sessions with leadership, develop personalized plans for success and receive coaching to guide their return-to-work experience. Upon completion of the program, based on performance and contributions participants will be eligible for a career at RTX.\nMinimum Program Qualifications:\nBe on a career break of one or more year at time of application\nHave prior experience in functional area of interest\nHave interest in returning in either a full-time or part-time position\nConnected Aviation Solutions:\nOur Connected Aviation Solutions team provides advanced information management systems, products and services that enable the connected ecosystem by bringing together Collins\u201a\u00c4\u00f4 unique breadth of aviation products with our smart digital solutions to help us enhance every aspect of the end-to-end travel experience. We help airlines, airports and business aircraft turn data into value to streamline operations, increase efficiency and reduce cost, enhance the passenger experience and contribute to sustainable flight. By combining the best networks, connectivity and data\/analytics solutions, we\u201a\u00c4\u00f4re solving big problems for our customers and the world, while enhancing the security and connectivity of systems both on and off the aircraft, to help operators and passengers stay more connected and informed and create a more sustainable, efficient, reliable and enjoyable travel experience. Aviation connects the world. Our Connected Aviation Solutions team connects aviation. Sustainably. Seamlessly. Securely.\nDiversity drives innovation; inclusion drives success\n. We believe a multitude of approaches and ideas enable us to deliver the best results for our workforce, workplace, and customers. We are committed to fostering a culture where all employees can share their passions and ideas so we can tackle the toughest challenges in our industry and pave new paths to limitless possibility.\nWE ARE REDEFINING AEROSPACE.\nPlease ensure the role type (defined below) is appropriate for your needs before applying to this role.\nRemote:\nEmployees who are working in Remote roles will work primarily offsite (from home). An employee may be expected to travel to the site location as needed.\n*Position is remote; however, if you live within a reasonable commute of a Collins site with other colleagues you interact with, your manager will discuss whether there is a degree of onsite presence associated with this role.\nSome of our competitive benefits package includes:\nMedical, dental, and vision insurance\nThree weeks of vacation for newly hired employees\nGenerous 401(k) plan that includes employer matching funds and separate employer retirement contribution, including a Lifetime Income Strategy option\nTuition reimbursement program\nStudent Loan Repayment Program\nLife insurance and disability coverage\nOptional coverages you can buy: pet insurance, home and auto insurance, additional life and accident insurance,\u201a\u00c4\u00d8critical illness\u201a\u00c4\u00d8insurance, group legal, ID theft protection\nBirth, adoption, parental leave benefits\nOvia Health, fertility, and family planning\nAdoption Assistance\nAutism Benefit\nEmployee Assistance Plan, including up to 10 free counseling sessions\nHealthy You Incentives, wellness rewards program\nDoctor on Demand, virtual doctor visits\nBright Horizons, child and elder care services\nTeladoc Medical Experts, second opinion program\nAnd more!\nAt Collins, the paths we pave together lead to limitless possibility. And the bonds we form \u201a\u00c4\u00ec with our customers and with each other -- propel us all higher, again and again.\nApply now and be part of the team that\u201a\u00c4\u00f4s redefining aerospace, every day.\nThe salary range for this role is 94,000 USD - 196,000 USD; however, RTX considers several factors when extending an offer, including but not limited to, the role and associated responsibilities, a candidate\u201a\u00c4\u00f4s work experience, location, education\/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and\/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and\/or the company\u201a\u00c4\u00f4s performance.\nRTX is An Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.\nPrivacy Policy and Terms:\nClick on this link to read the Policy and Terms\n01663890\nShow more\nShow less",
      "job_skills":"Data Engineering, DataOps, Machine Learning, Cloud Computing, Python, Data Pipelines, Spark, PySpark, SQL, AWS, Azure, Terraform, Gitlab, Databricks, Data Lake, Cloudbased Data Platforms, Cost Optimization, Scalability, Performance, Micro Services Architectures, AWS\/Azure Certifications",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer III",
      "company":"Frost",
      "job_location":"Texas, United States",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-iii-at-frost-3767134629",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"The candidate for this exciting opportunity can work from their Texas home near a Frost Texas location or at a Frost Texas office location (the candidate must live in Texas). The candidate would have to travel to San Antonio, Texas a couple times per month. Frost will help reimburse relocation costs to move to Texas if one is not currently living in Texas.\nJob Description\nIt\u201a\u00c4\u00f4s about putting our best to the test.\nAre you described as someone with an inquisitive mind and an innovative personality? Are you never satisfied with good enough? Does solving complex problems and ensuring top-quality systems excite you? If so, being a Data Engineer III with Frost could be for you.\nAt Frost, it\u201a\u00c4\u00f4s about more than a job. It\u201a\u00c4\u00f4s about having a flourishing career where you can thrive, both in and out of work. At Frost, we\u201a\u00c4\u00f4re committed to fostering an environment that reflects our values and encourages team members to be the best they can be. In joining our adaptable, integrity-driven team, you\u201a\u00c4\u00f4ll become part of Frost\u201a\u00c4\u00f4s over 150-year legacy of providing unparalleled banking services.\nWho You Are\nAs a\nData Engineer III\n,\nyou\nwill lead the development and implementation of ETL processes and data pipelines. You\u201a\u00c4\u00f4ll play an important role in designing and building scalable and reliable data infrastructures. You\u201a\u00c4\u00f4ll use your strong problem-solving skills to ensure that the systems are performing optimally and meet our high standards. You believe in effective communication and will have the opportunity to address potential problems and solutions to complex issues.\nWhat You\u201a\u00c4\u00f4ll Do\nDevelop and maintain data pipelines to automate data ingestion and processing\nCollaborate with stakeholders to identify data requirements and ensure data infrastructure meets business needs\nDevelop and enforce data governance policies and standards\nMonitor data infrastructure and performance to identify and resolve issues\nDrive best practices via code and design reviews\nCoach, mentor, and provide technical assessments\nProvide guidance to other Data Engineers as needed\nStay up to date with industry trends and new technologies in data engineering\nAlways take action using integrity, caring, and excellence to achieve all-win outcomes\nWhat You\u201a\u00c4\u00f4ll Need\nBachelor's degree in Computer Science, Information Technology, or related field\n4+ Years of experience as a data engineer\n3+ Years of experience developing in either Python, Java , Scala or Spark\nAdvanced understanding of database technologies such as SQL and NoSQL\nExpertise in ETL tools and techniques\nKnowledge of data modeling and schema design\nStrong problem-solving and analytical skills\nFamiliarity with Big Data technologies such as Hadoop, Spark, Hive, and Cloud native data engineering technologies\nExperience leveraging cloud technologies to develop data pipelines\nMastery of data modeling concepts\nStrong understanding of ETL concepts and Data Warehousing concepts\nExperience with CI\/CD pipelines\nExperience with version control software\nStrong understanding of Agile Principles (Scrum)\nExcellent written and verbal communication skills\nAdditional Preferred Skills\nKnow how of Informatica Intelligent Cloud Services (IICS) will be a plus.\nOur Benefits\nAt Frost, we care about your health, your family, and your future and strive to have our benefits reflect that. This includes:\nMedical, dental, vision, long-term disability, and life insurance\n401(k) matching\nGenerous holiday and paid time off schedule\nTuition reimbursement\nExtensive health and wellness programs, including our Employee Assistance Program\nReferral bonus program + more!\nSince 1868, Frost has dedicated their expertise to provide exceptional banking, investment, and insurance services to businesses and individuals throughout Texas. Frost is one of the 50 largest U.S. banks by asset size and is a leader in banking customer satisfaction. At Frost, it\u201a\u00c4\u00f4s about being part of something bigger. If this sounds like you, we encourage you to apply and see what\u201a\u00c4\u00f4s possible at Frost.\nShow more\nShow less",
      "job_skills":"Python, Java, Scala, Spark, SQL, NoSQL, Hadoop, Hive, Informatica Intelligent Cloud Services (IICS), CI\/CD pipelines, Agile Principles, Scrum",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst",
      "company":"Ekodus INC.",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-ekodus-inc-3693761786",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"JOB TITLE: DATA ANALYST\nLocation: MUST CURRENTLY LIVE IN THE ALEDO, TX AREA FT. WORTH IS CLOSE, HOWEVER, DALLAS, TX IS TOO FAR, SO IF SOMEONE LIVES IN DALLAS, THEY WOULD HAVE TO RELOCATE\nMUST WORK ONSITE 4 DAYS A WEEK 10 HOURS A DAY YOU WILL HAVE A THREE-DAY WEEKEND, WHICH IS AWESOME\nThe Data Analyst position is responsible for the daily operation, maintenance, and support of the Enterprise Department's software solutions and assisting in developing, refining, and maintaining the coop's digital business processes and workflows.\nIntegration\nAutomation\nMDM\nServerless Move in and out of those worlds\nPython Scripting\nSQL Server\nSQL Database\nWindows technology\nPowerShell\nData Pipelining\nSnowflake\nAWS\nWorkflows\nPlease share resume at msharma@ekodsuinc.com or career@ekodusinc.com.\nShow more\nShow less",
      "job_skills":"Data Analysis, Software Maintenance, Software Development, Digital Business Processes, Workflows, Integration, Automation, MDM, Serverless, Python Scripting, SQL Server, SQL Database, Windows Technology, PowerShell, Data Pipelining, Snowflake, AWS, Workflows",
      "Category":"Backend Development"
  },
  {
      "job_title":"Tableau Reporting & Analytics Analyst\/Advisor",
      "company":"TechTammina LLC",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/tableau-reporting-analytics-analyst-advisor-at-techtammina-llc-3704076298",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Role: Tableau Reporting & Analytics Analyst\/Advisor\nDuration: 6-months contract to hire\nWorksite Location: hybrid remote, up to 3-days onsite and the candidates must be local to either of the following locations:\nPlano, TX\nReston, VA\nBethesda, MD\nRate: Market\nInterview Process: 1- video conference interview and then a hiring decision will be made\nNotes\nHere is what is required on the candidates:\nMust be local and willing to work hybrid, up to 3-days onsite from either of the following client locations:\nPlano, TX\nReston, VA\nBethesda, MD\nMust be a Green Card Holder, GC-EAD, H4-EAD, or a US Citizen\nMust be extremely strong in full-scale Tableau BI reports development and creating dashboards\nMust have hands-on experience with Python which they will use for scripting and ETL work for their cloud migration project\nMust have strong data modeling experience, dealing with Linear \/ Logical Regressions for Predictive Data\nMust have some form of cloud experience, preferably with AWS\nMust have some form of Mortgage or Financial Services Industry experience in which they may have dealt with mortgages and understand the mortgage business and terminology\nMUST HAVE STRONG COMMUNICATION SKILLS and experience presenting reports and presentations to senior leadership teams, and providing recommendations based on data evaluations\nJob Description\nTableau Reporting & Analytics Analyst\/Advisor\nBusiness Intelligence\nSkilled in presenting information and\/or ideas to an audience in a way that is engaging and easy to understand\nAbility to transform business processes using BPA, RPA, or other technology-enabled automation\nExperience gathering accurate information to explain concepts and answer critical questions\nAdept at managing project plans, resources, and people to ensure successful project completion\nExpertise in using statistical methods, including: developing and testing hypotheses, using experimental design, and running linear and logistic regressions\nExperience in the process of analyzing data to identify trends or relationships to inform conclusions about the data\nSkilled in the graphical representation of information in the form of a charts, diagrams, pictures, and dashboards with programs and tools such as Excel, Tableau, or Power BI\nRequired Skills\nSkilled in Excel\nExperience using JIRA\nExperience using SharePoint\nSkilled in SQL\nSkilled in Python hands on experience with ETL to cloud migrations\nSkilled in Tableau\nCloud experience, preferably with AWS\nMortgage Experience\nData Modeling: Logical and Physical Data Modeling (presenting to stakeholders)\nDesired Skills\nTOAD SQL database management tool\nAlteryx for data analytics applications\nAdditional Notes And Insight For Candidates\nWHAT TO EXPECT: STRONG hands-on Python Development will be critical for this role. The majority of their technical questions will surround Python in relation to migration to the Cloud. Most candidates that have been previously eliminated from consideration, have all been because their Python \/ ETL skills were not where they needed them to be for this particular role. BE PREPARED to answer technical questions surrounding Python.\nADDITIONAL INFO ABOUT THE PROJECT:\nThey will discuss the challenges they are facing currently, which is primarily surrounding their cloud migration and for other OPD projects. Fannie Mae deals with large amounts of data and their objective is to streamline and consolidate everything into one place, which comes with a lot of complexity. Data is located across multiple different systems, with some of those being legacy systems with a lot of legacy processes that are still being utilized. Just like the data sources, which haven't been updated, they also need to get them updated as well as a large number of inventory reports that they are trying to consolidate.\nShow more\nShow less",
      "job_skills":"Tableau, Python, ETL, AWS, Cloud, Linear \/ Logical Regressions, Predictive Data, Mortgage, Financial Services, Communication skills, Presentation skills, Data evaluations, BPA, RPA, Project management, Statistical methods, Experimental design, Data visualization, Excel, SharePoint, SQL, TOAD, Alteryx",
      "Category":"Backend Development"
  },
  {
      "job_title":"Tableau Reporting & Analytics Analyst\/Advisor || Hybrid Role",
      "company":"Steneral Consulting",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/tableau-reporting-analytics-analyst-advisor-hybrid-role-at-steneral-consulting-3706306685",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Need candidate salary expectations\nMust be local and willing to work hybrid, up to 3-days onsite from either of the following client locations (must be local to either of the 3 locations):\nPlano, TX\nReston, VA\nBethesda, MD\nMust be extremely strong in full-scale Tableau BI reports development and creating dashboards\nMust have hands-on experience with Python which they will use for scripting and ETL work for their cloud migration project\nMust have strong data modeling experience, dealing with Linear \/ Logical Regressions for Predictive Data\nMust have some form of cloud experience, preferably with AWS\nMust have some form of Mortgage experience in which they may have dealt with mortgages and understand the mortgage business and terminology\nMUST HAVE STRONG COMMUNICATION SKILLS and experience presenting reports and presentations to senior leadership teams, and providing recommendations based on data evaluations\nJob Description\nTableau Reporting & Analytics Analyst\/Advisor\nBusiness Intelligence\nSkilled in presenting information and\/or ideas to an audience in a way that is engaging and easy to understand\nAbility to transform business processes using BPA, RPA, or other technology-enabled automation\nExperience gathering accurate information to explain concepts and answer critical questions\nAdept at managing project plans, resources, and people to ensure successful project completion\nExpertise in using statistical methods, including: developing and testing hypotheses, using experimental design, and running linear and logistic regressions\nExperience in the process of analyzing data to identify trends or relationships to inform conclusions about the data\nSkilled in the graphical representation of information in the form of a charts, diagrams, pictures, and dashboards with programs and tools such as Excel, Tableau, or Power BI\nRequired Skills\nSkilled in Excel\nExperience using JIRA\nExperience using SharePoint\nSkilled in SQL\nSkilled in Python hands on experience with ETL to cloud migrations\nSkilled in Tableau\nCloud experience, preferably with AWS\nMortgage Experience\nData Modeling: Logical and Physical Data Modeling (presenting to stakeholders)\nDesired Skills\nTOAD SQL database management tool\nAlteryx for data analytics applications\nWHAT TO EXPECT\n: STRONG hands-on Python Development will be critical for this role. The majority of their technical questions will surround Python in relation to migration to the Cloud. Most candidates that have been previously eliminated from consideration, have all been because their Python \/ ETL skills were not where they needed them to be for this particular role. BE PREPARED to answer technical questions surrounding Python.\nShow more\nShow less",
      "job_skills":"Tableau, Python, ETL, AWS, Data Modeling, Linear Regression, Logical Regression, Predictive Data, Cloud Experience, Mortgage Experience, Excel, JIRA, SharePoint, SQL, TOAD SQL, Alteryx",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst",
      "company":"MANDO TECHNOLOGIES INC",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-mando-technologies-inc-3768770013",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Mando Technologies is specializes in helping organizations make the most of their information assets. From acquiring, organizing, analyzing, and delivering data to closing the loop by integrating intelligence into the operations of the enterprise, Mando Technologies covers the full spectrum of Business Intelligence.\nNeed talented Data Analyst for a long-term contract based in Plano, TX (Hybrid) On W2\nNote - No H1b\nKey Skills And Experience\nDevelop and maintain SQL queries and scripts for data extraction and reporting.\nHandle and customize APIs to integrate external data sources into our analysis.\nWork with PySpark for big data processing and analysis.\nExperience in Python and SQL for data manipulation and analysis.\nExperience in data patterns, data filling, and data extension techniques.\nExperience with PySpark, is a plus.\nPreferred\nSQL (strong)\nAWS S3, CI\/CD, etc. (intermediate)\nNice To Have\nPython programming\nFamiliarity with BI tools like Tableau or Power BI\nShow more\nShow less",
      "job_skills":"SQL, Python, PySpark, Data extraction, Data reporting, Data manipulation, Data analysis, API, Data integration, Big data processing, Data patterns, Data filling, Data extension, Tableau, Power BI, AWS S3, CI\/CD",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Transformation Analyst",
      "company":"CoreLogic",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-transformation-analyst-at-corelogic-3790402254",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"At CoreLogic, we are driven by a single mission\u201a\u00c4\u00eeto make the property industry faster, smarter, and more people-centric. CoreLogic is the trusted source for property intelligence, with unmatched precision, depth, breadth, and insights across the entire ecosystem. Our talented team of 5,000 employees globally uses our network, scale, connectivity and technology to drive the largest asset class in the world. Join us as we work toward our vision of fueling a thriving global property ecosystem and a more resilient society.\nCoreLogic is committed to cultivating a diverse and inclusive work culture that inspires innovation and bold thinking; it's a place where you can collaborate, feel valued, develop skills and directly impact the real estate economy. We know our people are our greatest asset. At CoreLogic, you can be yourself, lift people up and make an impact. By putting clients first and continuously innovating, we're working together to set the pace for unlocking new possibilities that better serve the property industry.\nJob Description\nWe are adding a Data Transformation Professional to the team. The analyst will utilize\nSQL Server, Google Cloud Platform, SSIS\nand proprietary tools while interacting with our onsite team of Developers and Analysts. The analyst maintains existing and develops new data curation logic and solutions to meet target Production SLAs for turn times and quality, monitors the data curation pipeline, and does troubleshooting of the data curation pipeline as required. The position supports a high volume, high risk, and tight turnaround time driven process so the specific role of oversight is key to ongoing success.\nTake advantage of an opportunity to join the\nhybrid-remote\ngroup responsible for building CoreLogic's Smart Data Platform!\nJob Responsibilities\nWorking largely independently, under general supervision, provides production support by querying and manipulating varying and complex data and file formats to ensure data quality before data goes into next production step.\nCompletes user requests utilizing existing programs. Formulates and defines system scope and objectives through research and fact-finding to modify internal business systems.\nTracks, discovers, and researches industry trends and devises ways to capture these trends into CoreLogic and incorporate them into our products to ensure accurate and timely content. Applies adjustments to systems and processes to solve problems or improve effectiveness. Develops a strong understanding of CoreLogic products to understand how data is to be used, needs to be analyzed and recognize changes in industry reporting.\nDevelops a robust knowledge of multiple data sets and their interaction with each other. Sets objectives for own work and contributes to completion of team milestones. Provides guidance and assistance to more junior team members.\nUses database development tools (e.g. ETL Tools, etc.), proprietary application, and data analysis techniques to prepare data for input into final product.\nProvides appropriate analysis, follow up, notification, and solutions to management related to abnormal job termination and resolution.\nProactively identifies more effective ways to resolve issues.\nSpecial projects include but are not limited to custom reports\/data development, process enhancement, product development, specialized product support for national and key accounts, providing training, or taking on a mentoring role.\nIndependently evaluates and documents results using reports and tools to ensure data quality.\nJob Qualifications\nBachelor\u201a\u00c4\u00f4s degree, preferably in Computer Science, Engineering, Math, or other related subject.\nStrong hands-on experience with SQL & T-SQL, ETL tools (SSIS), and Microsoft Suite.\n3-5 years of related experience, working with large datasets & Data Modeling.\n3-5 years of experience monitoring Data loads and Operational Dashboard KPIs to perform root cause analysis and resolution.\nIntermediate to advanced level experience with various file formats.\nStrong analytical skills and process thinking skills.\nStrong oral, written communication and presentation skills to interact regularly within team, within the larger heavily matrixed and geographically dispersed organization(s), and with internal and\/or external customers to ensure understanding of key issues.\nStrong working knowledge of database processing techniques and concepts including flow charting, data manipulation, relational database principles, database queries and database programming.\nDemonstrates an extensive understanding of our database, data, processes and product lines.\nThorough understanding of both in-house and third-party software to analyze and process the data.\nExperience Translating conceptual ideas into projects\/tasks and business needs to technical requirements.\nDriven to excel in areas of technical expertise and expand base of knowledge.\nPreferred Qualifications\n3-5 years of related experience in Real estate industry.\nExperience with MLS, Appraisal, and Building Permit Data.\nHands on experience with C#\nAnnual Pay Range\n62,100 - 78,000 USD\nCoreLogic benefits information can be found here: http:\/\/www.yourcorebenefits.com\/. Qualifications, locations and experience of the individual ultimately selected for the position may impact the final actual offered compensation, which may vary from any posted range.\nCoreLogic's Diversity Commitment\nCoreLogic is fully committed to employing a diverse workforce and creating an inclusive work environment that embraces everyone\u201a\u00c4\u00f4s unique contributions, experiences and values. We offer an empowered work environment that encourages creativity, initiative and professional growth and provides a competitive salary and benefits package. We are better together when we support and recognize our differences.\nEOE AA M\/F\/Veteran\/Disability\nCoreLogic is an Equal Opportunity\/Affirmative Action employer committed to attracting and retaining the best-qualified people available, without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, disability or status as a veteran of the Armed Forces, or any other basis protected by federal, state or local law. CoreLogic maintains a Drug-Free Workplace.\nPlease apply on our website for consideration.\nPrivacy Policy - http:\/\/www.corelogic.com\/privacy.aspx\nBy providing your telephone number, you agree to receive automated (SMS) text messages at that number from CoreLogic regarding all matters related to your application and, if you are hired, your employment and company business. Message & data rates may apply.\nYou can opt out at any time by responding STOP or UNSUBSCRIBING and will automatically be opted out company-wide.\nConnect with us on social media! Click on the quicklinks below to find out more about our company and associates.\nShow more\nShow less",
      "job_skills":"SQL Server, Google Cloud Platform, SSIS, ETL Tools, TSQL, Microsoft Suite, Data Modeling, Database Processing, Relational Database Principles, Data Manipulation, Flow Charting, C#, MLS, Appraisal, Building Permits",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Analyst, CRM & Loyalty",
      "company":"Yum! Brands",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-crm-loyalty-at-yum%21-brands-3790085494",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nAs a CRM \/ Customer Engagement and Retention (CER) Data Analyst, you\u201a\u00c4\u00f4ll closely support the CER team in making data-driven decisions about marketing campaign execution. This position will own critical analyses and integration projects from beginning to end, including opportunity identification, problem scoping, analysis framing \/ execution, and synthesizing results to project stakeholders as well as internal leadership.\nAnalyze CRM & Loyalty campaigns to provide actionable recommendations to the CER team\nIdentify areas of opportunity based on Loyalty\/CRM analytics, customer segmentations, deployment tactics and audience targeting\nAssist in creating test and learn plans to facilitate tactical optimization and strategic changes to our programs to increase customer annual value (CAV)\nPartner closely with data science and loyalty vendor partners to monitor critical KPI\u201a\u00c4\u00f4s\nEDUCATION\nBachelor\u201a\u00c4\u00f4s degree in computer science, marketing, databases, or a related field with 4+ years of experience working in analytics positions in performance-driven marketing, e-commerce, or consulting organizations.\nMinimum Requirements And Experience\nMaster Level of Experience using SQL; able to easily query complex data and construct data models as needed and experience working with relational databases (Snowflake), query authoring (SQL) as well as working familiarity with a variety of databases\nComfortable with multi-faceted analytics projects, integrating data from multiple sources, and synthesizing & presenting actionable insights from a variety of data-points\nWorking knowledge of a CDP (Treasure Data, Twilio, Bloomreach, Convertlab, Salesforce Data Cloud, etc.)\nWorking knowledge of at least one commonly applied BI tool (Tableau, Power BI, Domo, etc.) Digital Marketing -tools (e.g. Braze, Punchh, etc.) and Project Management tools (e.g. Atlassian, Jira, etc.)\nExperience with data management and manipulation tools (Python, Scala, or R) and a desire to learn more\nExcellent communication skills with a record of successfully advocating to turn insights into action, as well as the ability to synthesize quantitative results to determine implications and make actionable strategic recommendations\nSalary Range: $108,700\u00ac\u2260\u00ac\u2260 to $136,300 annually + bonus eligibility.\nThis is the expected salary range for this position. Ultimately, in determining pay, we'll consider the successful candidate\u201a\u00c4\u00f4s location, experience, and other job-related factors.\nBenefits: Employees (and their eligible family members) may enroll in the following types of insurance coverage: medical, dental, vision, legal, and accidental death and dismemberment, as well as FSA\/HSA (depending on enrolled medical plan). Yum! also provides short-term disability, long-term disability, and life insurance. Employees may enroll in our 401(k) plan. Yum! provides 4 weeks of vacation, paid sick leave, 10 paid holidays, a floating day off and 2 paid days for volunteer time each calendar year. To learn more about working at Yum! - Click here .\nAt Yum!, one of our core values is to Believe in ALL People. This means seeing the value in everyone and unlocking their full potential to be their best self. YUM! Brands, Inc. (including its subsidiaries Yum Restaurant Services Group, LLC (\u201a\u00c4\u00faYRSG\u201a\u00c4\u00f9) and Yum Connect, LLC (\u201a\u00c4\u00faYum Digital and Technology\u201a\u00c4\u00f9)(collectively, \u201a\u00c4\u00faYum\u201a\u00c4\u00f9) is proud to be an equal opportunity employer and is committed to equity, inclusion, and belonging for all dimensions of diversity. We do not discriminate based on race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other protected characteristic. Yum! is committed to working with and providing reasonable accommodation to applicants with disabilities or special needs.\nUS Job Seekers\/Employees -\nClick here\nto view the \u201a\u00c4\u00fa\nKnow Your Rights\n\u201a\u00c4\u00f9 poster and supplement and the Pay Transparency Policy Statement.\nAbout Us\nWho We Are\nFounded in 1958, Pizza Hut - a subsidiary of Yum! Brands, Inc. - now operates more than 18,000 restaurants in more than 100 countries. Pizza Hut is leading the way in providing customers with great experiences, innovating with technology and new products, as well as delivering exceptional service.\nOur People & Culture\nBenefits\nWe're looking for people who LOVE pizza and thrive in a fun, past paced, and customer-centric environment. At our corporate campuses, Pizza Hut has created the perfect place for you to grow your career. Every day, you\u201a\u00c4\u00f4ll work to support our franchisees and teams across the U.S., continuously challenging yourself to feed more possibilities. In return, we\u201a\u00c4\u00f4ll provide professional development and career growth opportunities so that you can become your best and achieve your goals. And we\u201a\u00c4\u00f4ll sweeten the deal by immersing you in our world-class recognition culture and providing a robust array of benefits, some highlights include:\n4 weeks PTO, plus standard holidays and time off to volunteer\nGenerous parental leave (16 weeks for moms, 6 weeks for dads)\n401(k) with 6% match, vested immediately\nOn-site daycare\n24\/7 fitness center with laundry services\nHalf-day Fridays, year round\nGiving Back\nAs a global company, Pizza Hut aims to make the world better by acting responsibly with respect to food, planet and people. Whether it\u201a\u00c4\u00f4s donating food through the Harvest Program or supporting literacy with the Pizza Hut BOOK IT! Program \u201a\u00c4\u00ec the company, our franchisees and our team members are committed to improving the communities we serve.\nPizza Hut is an equal opportunity workplace and committed to fostering an inclusive, diverse culture . All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, sexual orientation, or gender identity), national origin, age, disability and genetic information (including family medical history).\nShow more\nShow less",
      "job_skills":"SQL, Snowflake, Tableau, Power BI, Domo, Braze, Punchh, Atlassian, Jira, Python, Scala, R, CDP (Treasure Data Twilio Bloomreach Convertlab Salesforce Data Cloud), BI tool",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Analyst",
      "company":"Spruce Power",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-spruce-power-3787722493",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"THE POSITION: Sr. Data Analyst\nResponsible for performing analysis and generating actionable recommendations for improving performance in a leading residential solar energy services company.\nReports to the Business Intelligence Manager and conducts advanced analysis of data to arrive at insights that drive tactical and strategic efforts. The analyst is expected to work closely with the solar asset operations team and the external data service provider to proactively monitor and detect\/diagnosis underperforming solar systems. He\/she is also expected to create\/automate weekly, monthly and ad hoc reports as well as perform analysis to guide data-driven business decisions.\nThe ability to dive deep into data to arrive at insights that inform tactical and strategic efforts is required. The role also requires an attention to detail and the aptitude to tell a complete, compelling and actionable story through data and analysis.\nKey responsibilities include:\nGenerate and maintain reports to track solar system performance on a weekly, monthly, and quarterly basis\nExtract, parse and translate large production data sets into meaningful reports\nWork closely with various data service providers, maintain data quality and maintain\/improve automated dispatch system\nEscalate technical support issues to internal and external resources\nUtilize advanced analytics to drive new insights from various data sets and help generate actionable steps for improving solar system performance\nDefine, document and calculate Key Performance Indicators (KPIs) and methods for tracking these KPIs for internal and external stakeholders\nGenerate and publish reports and visualizations with Power BI and\/or other applications to be used by management for informed decision making and tracking performance\nCreate and present analysis to upper management and other key internal and external stakeholders\nAssist in identifying and advancing Business Intelligence and Analytical capabilities and functionality thought out the organization\nPerforms other duties as assigned\nQualifications\nDeep experience with Power BI software\nProven focus on and experience with generating actionable recommendations through data-driven analysis\nAbility to understand how data maps to business processes and to make recommendations on how to adjust procedures to gain efficiencies, increase quality or improve service\nAbility to communicate clearly and succinctly\nProven experience with a combination of SQL, SSRS, SSAS, Power BI, Excel\nAbility to write complex SQL queries and work with Sql Server relational databases\nStrong Power Point presentation skills\nExperience with programming languages including Python and R are preferred, but not required\nExperience in data management and data quality concepts, practices and services\nExperience with various file formats (XML, CSV, etc.)\nOutstanding organizational, analytical and facilitation skills.\nExperience with Microsoft Office Suite\u201a\u00c4\u00b6Excel, Word and PowerPoint\nFamiliarity with Azure Cloud is preferred, but not required\nExperienced with Data Warehouse concepts and practices\nFamiliar with ETL and data transfer concepts and capabilities\nAuthorized to work in the United States\nExperience in solar industries a plus\nEDUCATION\nMinimum of a Bachelor's degree or equivalent in computer science or STEM field\nEQUAL OPPORTUNITY EMPLOYER\nWe value a diverse work environment. Spruce Power is an equal opportunity employer and hires without consideration to race, religion, national origin, age, gender, sexual orientation, marital status, veteran status or disability.\nPowered by JazzHR\nFVGbTPWjIT\nShow more\nShow less",
      "job_skills":"Power BI, Solar PV systems, Data analysis and reporting, Data extraction and parsing, SQL, SSRS, SSAS, Python, R programming, XML, CSV, Data management, Data quality, Microsoft Office Suite, Azure Cloud, Data Warehouse, ETL, Data transfer",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Portfolio Management Analyst",
      "company":"Sunnova Energy",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-portfolio-management-analyst-at-sunnova-energy-3770338364",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Brief Description Of Sunnova\nSunnova (NYSE: NOVA) is revolutionizing the energy industry as a leading Energy as a Service (EaaS) provider of solar, battery storage, EV charging, and other energy solutions with customers spanning the U.S. and its territories. Founded in 2012, our goal is to provide homeowners, businesses, and communities with a better energy service at a better price \u201a\u00c4\u00ec making clean, renewable energy more accessible, reliable, and affordable.\nAt Sunnova, we believe that our success comes from the diversity and creativity of our people. Our team is made up of forward-thinkers who are passionate about changing the energy industry for the better, and we're looking for like-minded individuals to join us. We encourage our people to push beyond traditional limits and explore new horizons \u201a\u00c4\u00ec because only then can we truly transform the world for the better.\nIf you're excited about being a part of the fastest-growing segment of the energy industry, we want you on our team!\nThe Sr. Portfolio Management Analyst Position\nSunnova Energy is searching for Sr. Portfolio Management Analyst to be responsible for developing data processes, data flows and providing substantial analytical support for Sunnova\u201a\u00c4\u00f4s Sales & Marketing department. The role is responsible in delivering insightful metrics, reports, and analysis through various approaches, and presenting the results in a visual format through tools such as Tableau.\nSr. Portfolio Management Analyst Responsibilities\nDevelops analytical models and data visualizations to drive analytic insights\nBuilds an adaptable data architecture allowing to build and iterate on new data sets quickly\nDesigns and develops metrics, dashboards, and reports around Portfolio performance to drive key business decisions\nDevelops and maintain processes and standards to enable data access, reporting, quality and master data management\nDesigns, builds, and manages data sources to satisfy our growing data needs\nDevelops and manage data pipelines at enterprise scale\nBuilds data expertise and enable data quality for various data flows\nPerforms qualitative and quantitative assessments of all aspects of models including theoretical aspects, model design and implementation. As well as, assessing data quality, integrity and preparing recommendations on how to improve data quality\nInteracts with cross-functional teams to model current operations processes and evaluate potential solutions\nPrepares analysis and reporting for key activities and projects by collecting, analyzing, and summarizing information: documents detailed explanations for significant variances\nDesigns, maintains, and continuously improves dashboards\nBuilds documentation and ad hoc analyses, methodology, and data definitions for raw data\nProactively identifies key areas for process improvement through data analysis and strategic thinking\nProduces custom reports and analysis\nCompletes various additional tasks and projects as requested from management\nMinimum Requirements\nBachelor\u201a\u00c4\u00f4s degree in Finance, Data Analytics, Information Technology, Statistics, Economics, Mathematics or related field\n4-7 years relevant Data Analysis\/Engineering experience for large to BIG data\n4-7 years of SQL (Microsoft SQL Server, PostgreSQL, AWS Redshift, etc.) experience, as well as Python\n4-7 years of experience with schema design and dimensional data modeling\nAdvanced knowledge and experience with Tableau\nAdvanced knowledge of Excel\nPreferred Qualifications\nExperience creating dashboards and using analytics to measure business processes and performance in high-volume industry; Consumer Product, Banking\/Finance, Energy\/Utilities\nStrong statistical knowledge including regression analysis, correlation\/causal computations, or AI\/ML applications\nAdditional Knowledge, Skills And Abilities\nAbility to analyze and obtain insights from complex \/ large data sets\nExperience in analysis of IT applications that cross numerous operational and servicing disciplines\nStrong interpersonal and communication skills\nAbility to manage time effectively, set priorities and meet deadlines\nAbility to assess metric outcomes on a relative basis and create sound recommendations based on accurate data evaluation\nDemonstrated experience communicating business implications of complex data relationships\nWorking Conditions\nOpen office environment\nRemote office environment if outside of Houston\nSome travel may be required if working remote\nPhysical Requirements\nExtended periods of time working at computer workstation\nBenefits\nSunnova offers a generous employee reward package that includes:\nComprehensive benefits, including medical, dental, vision, life insurance, healthcare flexible spending account, and 401(k) with employer match\nCompetitive compensation & annual bonus\nPaid time off, including 10 holidays and Paid Parental Leave\nCell phone allowance for many roles\nFree access to onsite fitness center in Houston and\/or discounted fitness memberships through health provider\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.\nIf you are selected for a position, your employment will be contingent upon submission to and successful completion of a post-offer\/pre-placement drug test (and medical examination if required by the role) as well as pre-placement verification of the information and qualifications provided during the selection process.\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Engineering, Tableau, SQL, Microsoft SQL Server, PostgreSQL, AWS Redshift, Python, Schema Design, Dimensional Data Modeling, Statistics, Regression Analysis, Correlation\/Causal Computations, AI\/ML, Business Process Analysis, Performance Measurement, Communication, Time Management, Prioritization, Data Evaluation, Complex Data Relationships",
      "Category":"Backend Development"
  },
  {
      "job_title":"Azure Data Lead Analyst",
      "company":"Kubota Tractor Corporation",
      "job_location":"Grapevine, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/azure-data-lead-analyst-at-kubota-tractor-corporation-3784645147",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"For Earth For Life\nBASIC PURPOSE AND SCOPE OF POSITION\nThis position requires a collaboration with business users\/analysts\/scientists to identify the required data and bring them into Azure analytics platform.\nPRINCIPAL ACTIVITIES\n: This position does the following in accordance with all applicable Federal, State and local laws \/ regulations and the Company\u201a\u00c4\u00f4s policies, procedures and guidelines:\nDesign, build, and maintain datasets in Azure Data lake\/SQL DB\/Synapse by extracting data from various source systems\nDesign and develop data processing\nMonitor and optimize data storage and data processing\nWork with Security Engineers to implement data security\nActively involved with Production Support and troubleshoot the issues in live system by engaging appropriate internal and external stakeholders, being responsive, leading the root cause analysis and thoughtful on upstream and downstream impacts of the change. Provide quick resolution of the problems ensuring minimal downtime to the business and adhering to the change control process of the organization\nSPECIAL PROJECTS\nAs assigned.\nMinimum Qualifications\nEDUCATION, CERTIFICATIONS, AND TRAINING:\nBachelor's degree in Computer Science, Information systems, Engineering or a related discipline; or equivalent combination of education and experience\nCertification of Data Engineering on Microsoft Azure is preferred\nSkills And Background\nOverall 5+ years of experience in the Data and Analytics domain, performing Data Engineering on Business Intelligence, Digital and Data Warehouse projects.\nAt least 2 full life-cycle Azure implementations preferred\nMust be an expert in implementing data warehouse, data lakes, big data, data streaming and ingestion, data retention and archiving, ETL, etc.\nShould have experience with Azure Storage\/Data Lake, Azure Data Factory, Azure Databricks, Data processing languages SQL and Python or, Data Wrangling, Azure Synapse, and S\/4 data structure, preferred\nParticipates in multiple design activities with authority to make independent choices free from supervision\nRequires strong communication skills to work internally with end user departments, management and peers. Develops and provides written and verbal presentations to end users, peers, and support personnel\nLanguage Requirements\nMust be able to read, write and communicate in English.\nEQUIPMENT OPERATION\n(% of time, description, nature of service):\nOffice equipment including computer, copier, fax, phone, printer\nPhysical Requirements\nTypical office environment.\nAdditional Information\nDISCLAIMER:\nThe information provided in the description has been designed to indicate the general nature and level of work performed by incumbents within the classification. This description is not intended to be a comprehensive inventory of all duties, responsibilities, qualifications and working conditions required of employees assigned to this job\/classification. This job is intended to include the current essential functions of the job. Management reserves the right to add or modify the duties and responsibilities and to designate other functions as essential at any time.\nKubota is an equal opportunity at will employer and does not discriminate against any employee or applicant for employment because of age, race, religion, color, disability, sex, sexual orientation or national origin.\nApply Now\nShow more\nShow less",
      "job_skills":"Azure, Azure Data Lake, Azure SQL DB, Azure Synapse, Data Engineering, Data Processing, Data Security, Data Warehouse, Data Lake, Big Data, Data Streaming, Data Ingestion, Data Retention, Data Archiving, ETL, Azure Storage, Azure Data Factory, Azure Databricks, SQL, Python, Data Wrangling, Azure Synapse, S\/4 data structure, English, Office equipment, Computer, Copier, Fax, Phone, Printer",
      "Category":"Backend Development"
  },
  {
      "job_title":"Program Analyst II - DEA EPIC NLPRP (Onsite)",
      "company":"BluePath Labs (8(a) & SDVOSB)",
      "job_location":"El Paso, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/program-analyst-ii-dea-epic-nlprp-onsite-at-bluepath-labs-8-a-sdvosb-3776320890",
      "search_city":"Socorro",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Location: Bozeman, MT or El Paso, TX\nBluePath Labs is a fast-growing research and consulting company committed to solving complex problems for federal, state, and local government clients. We offer a range of professional, scientific, and technology services. Our specific areas of expertise include business consulting, research and data science, and technology integration.\nWe are actively seeking an experienced Program Analyst to provide analytical and technical support to the Drug Enforcement Administration and the El Paso Intelligence Center's (EPIC's) National License Plate Reader Program (NLPRP).\nThis position will be fully onsite in Bozeman, MT or El Paso, TX.\nWork Description\nThe El Paso Intelligence Center (EPIC) is the nation's singular multi-agency tactical intelligence center and supports U.S. federal, state, local, tribal, campus, and international law enforcement agencies (LEA), and interdiction agencies (IA). EPIC conducts investigations and interdiction operations through timely analysis and dissemination of intelligence, into illicit drugs and drug-related trafficking; illegal aliens, weapons and bulk currency smuggling, and trans-national crime \/ terrorism.\nThe successful candidate for the Program Analyst position will provide analytical program support. This will include providing EPIC Programs management with information for making decisions on administrative and programmatic aspects of EPIC programs. They will also support EPIC mission planning, maintain a weekly portfolio of EPIC projects, and perform other duties as the project requires.\nResponsibilities\nProvide collection, analytical, and information dissemination support for a classified program.\nProvide EPIC Programs management with objectively based information for making decisions on the administrative and programmatic aspects of EPIC Programs, operations and management.\nSupport EPIC mission planning, and schedule updates and maintenance which shall consist of tracking ongoing, backlogged and planned EPIC programs that supports the operation.\nUpdate a weekly portfolio as new requests for assistance are received from various projects that support EPIC's mission and track them until they are completed and closed out.\nConduct and process information requests that EPIC frequently receives from internal and external requestors.\nCoordinate with IT support staff and LPR support team on operation and management of the LPR SharePoint site.\nMinimum Requirements\nU.S. Citizenship\n5+ years of experience in the development and monitoring of policies and procedures, designed to provide management control over a large-scale support services function\nBachelor's Degree or an additional 2 years of equivalent experience\nStrong written and oral communication skills\nAbility to successfully pass a background check and obtain a security clearance\nBenefits\nBluePath Labs offers a comprehensive benefits package. Benefits include, but are not limited to: healthcare reimbursement, lifestyle & wellness reimbursement, Flexible Spending Account (FSA), tuition assistance, 401(k) with company match, and paid time off for vacation \/ sick leave, in addition to 12 holidays per calendar year.\nAbout BluePath\nBluePath Labs combines mission and business insights with advanced technologies to deliver measurable performance improvements for our clients. BluePath is dedicated to surpassing client expectations by always living by our core values of integrity, professionalism, and resilience. BluePath's extensive experience in Government, Military, Commercial, and Academic environments is unique among small businesses and a core differentiator of our solutions. Our multidisciplinary background allows us to solve diverse and complex problems. Most importantly, we work closely with our clients to frame problems correctly, optimize processes, leverage technologies, and implement enduring solutions. Labs are where ideas are born, experiments occur, and breakthroughs happen. It is the hallmark of BluePath's culture.\nhttps:\/\/www.bluepathlabs.com\/\nBluePath Labs is an equal opportunity employer.\nShow more\nShow less",
      "job_skills":"SharePoint, LPR, Data Science, Information Dissemination, Program Management, Background Check, Security Clearance, Flexible Spending Account, 401(k), Java, C++, Python, SQL, NoSQL, R, Tableau, Power BI, Excel, Git",
      "Category":"Backend Development"
  },
  {
      "job_title":"Information Management Analyst (Mid-Level, Data Quality Analyst)",
      "company":"USAA",
      "job_location":"Bulverde, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/information-management-analyst-mid-level-data-quality-analyst-at-usaa-3789028452",
      "search_city":"New Braunfels",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Why USAA?\nLet\u201a\u00c4\u00f4s do something that really matters.\nAt USAA, we have an important mission: facilitating the financial security of millions of U.S. military members and their families. Not all of our employees served in our nation\u201a\u00c4\u00f4s military, but we all share in the mission to give back to those who did. We\u201a\u00c4\u00f4re working as one to build a great experience and make a real impact for our members.\nWe believe in our core values of honesty, integrity, loyalty, and service. They\u201a\u00c4\u00f4re what guides everything we do \u201a\u00c4\u00ec from how we treat our members to how we treat each other. Come be a part of what makes us so special!\nThe Opportunity\nAs a dedicated Information Management Analyst (Mid-Level, Data Quality Analyst), you will support P&C Modernization.\nWe offer a flexible work environment that requires an individual to be in the office 4 days per week. This position will be based in the San Antonio, TX Home Office. Relocation assistance is not available for this position.\nJoin our team in P&C Data Modernization and be part of the exciting journey to deliver robust and high-quality P&C Data. On my team you will execute user acceptance testing with a business lens to ensure accuracy of data before it goes live into production. You will also help ensure ongoing quality with research and defect mitigation and ensure our user community has access to the most accurate data. Our data quality efforts are core to the modernization program, and you can be part of this Epic Journey.\nIn This Position You Will Manage And Analyze Information Using a Variety Of Techniques And Tools, Support Data Management Efforts With Business Owners And Technical Teams To Manage And Analyze Information And Data Including Master And Reference Data In Adherence To USAA Internal Policies, Standards, Procedures, And External Laws And Regulations. You Will Support One Or More Information Management Functions\nMetadata management to ensure information is understood.\nData Quality to ensure data is measured and trusted.\nRetention Management to ensure data is retained and purged appropriately.\nData Security to ensure data is properly secured and handled based on sensitivity and regulatory requirements.\nThis may include working with the Information Asset Stewards and technical Owners to log data sources, support the Authoritative Data Source certification, ingest metadata and data lineage into the Enterprise Data Repository, provide data quality oversight, monitor data SLAs and data quality index, remediation times, and monitor material modifications to ensure re-certification occurs if warranted.\nWhat You'll Do\nIdentify opportunities for process improvements across all IMA responsibilities and processes.\nParticipate in and possibly lead discussions with cross-functional teams to drive consistency, efficiency, and effectiveness of the information management.\nParticipate in development of best practices and tools based on business needs.\nMaintain Information Asset Inventories. Ensure data and assets are classified appropriately.\nSupport delivery of information in accordance with Information Governance standards and data management practices through documentation, collaboration, and execution of defined processes.\nMaintain metadata repository and proper metadata association.\nReview, validate, and record metadata and data quality information.\nDevelop process improvements and enhancements to mitigate data quality risks including data quality plan development, implementing data quality rule checks, monitoring data quality results, reports and dashboards, as appropriate.\nDocument and updates data quality corrective action plans.\nSupport compliance assessment process by reviewing and documenting failures from data quality compliance assessment checks.\nRecommend Master and Reference Data processes and procedures to align with Enterprise Policies and Standards.\nCreate and maintain reference data in accordance to defined processes and procedures.\nManage quality and maintenance of master data as it is created.\nHelp define and drive implementation of processes and enhancements to mitigate data quality risks.\nSupport compliance assessment process by identifying and escalating items that may be a risk to the corporation.\nSupport Privacy initiatives through classification, tagging, and analysis of sensitive data.\nEnsure compliance and remediation of sensitive data in accordance to defined policies and processes. Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled in accordance with risk and compliance policies and procedures.\nWhat You Have\nBachelor\u201a\u00c4\u00f4s degree in business or science discipline is required; OR 4 years of related data and analytics or technical experience (in addition to the minimum years of experience required) may be substituted in lieu of degree.\n4 years of experience in an information management practice, business application function, or data delivery; OR If Advanced degree in a Business or Science discipline, 2 years of experience in data and analytics, technical, or business relevant function\nBasic working experience following data management practices and theories and utilizing tools to implement data management to address data management risks and concerns.\nIntermediate Working SQL knowledge including SQL-based languages.\nAbility to build business knowledge through meaningful partnerships at the individual contributor and leadership levels.\nDemonstrates skills in understanding and correcting data discrepancies, identifying data anomalies, and root cause analysis.\nDemonstrated advanced communication skills with the ability to deliver presentations to all levels of management.\nWhat Sets You Apart\nKnowledge and experience with P&C operational and\/or analytical environments, applications accessed by the P&C community and how the data is used (Pricing, Underwriting, Product Management)\nDemonstrated experience conducting User Acceptance Testing to ensure data quality for new data assets.\nProficient in developing analytical queries (strong Python preferred).\nStrong analytical mindset and problem-solving skills needed in a fast-paced environment.\nThe above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.\nWhat We Offer\nCompensation: USAA has an effective process for assessing market data and establishing ranges to ensure we remain competitive. You are paid within the salary range based on your experience and market data of the position. The actual salary for this role may vary by location. The salary range for this position is: $71,490 - $136,690.\nEmployees may be eligible for pay incentives based on overall corporate and individual performance and at the discretion of the USAA Board of Directors.\nBenefits: At USAA, our employees enjoy best-in-class benefits to support their physical, financial, and emotional wellness. These benefits include comprehensive medical, dental and vision plans, 401(k), pension, life insurance, parental benefits, adoption assistance, paid time off program with paid holidays plus 16 paid volunteer hours, and various wellness programs. Additionally, our career path planning and continuing education assists employees with their professional goals.\nFor more details on our outstanding benefits, please visit our benefits page on USAAjobs.com.\nApplications for this position are accepted on an ongoing basis, this posting will remain open until the position is filled. Thus, interested candidates are encouraged to apply the same day they view this posting.\nUSAA is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\nShow more\nShow less",
      "job_skills":"Data Quality Management, Data Analysis, Metadata Management, Data Security, SQL, Python, User Acceptance Testing, Data Governance, Data Management, Data Mitigation, Data Quality Rule Checks, Master Data Management",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Catalog and Lineage Central Governance Analyst",
      "company":"PwC",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-catalog-and-lineage-central-governance-analyst-at-pwc-3785064246",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nIFS - Information Technology (IT)\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data\/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nAdditional Responsibilities\nSupporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture.\nCustom Orgs\nGlobal LoS\n:\nInternal Firm Services\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nComputer and Information Science, Data Processing\/Analytics\/Science\nAdditional Educational Preferences\nOther related fields of study with relevant experience may be considered.\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success as a team leader:\nPossessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects;\nDisplaying knowledge of data management and governance policies, standards, metrics, controls, and processes;\nHaving knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers;\nPossessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies;\nShowcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture;\nExhibiting proven knowledge and working experience in Microsoft Purview;\nCreating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers;\nShowcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;\nDisplaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog;\nConducting periodic reviews of the data catalogue to corroborate compliance with the DG standards;\nFacilitating the capture of metadata as core change and operational deliverables;\nDemonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers;\nDesigning, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview;\nIdentifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports;\nPossessing ability to create and maintain automated workflows for periodic metadata refresh;\nComplete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR\/HIPPA\/SPI (as applicable);\nHelping manage the inventory of data-related controls on systems that support segment processes and customers;\nShowcasing thorough understanding of data steward\/data owner operating model;\nAbility in designing and rolling out training programs to train the trainer\/end-users;\nBeing a collaborative team player; and,\nHaving a business outcome focused problem-solving mindset.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"Data Governance, Data Management, Azure Purview, Metadata, Data Catalog, Data Lineage, Data Classification, Data Discovery, Data Dictionary, Business Glossary, Sensitive Data, Data Steward, Data Owner, Data Privacy, Data Security, Data Quality, Data Integration, Data Analytics, Data Visualization, Business Intelligence, Machine Learning, Artificial Intelligence, Cloud Computing, Big Data, Data Science, Programming Languages, SQL, Python, Java, C++, R, SAS",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Insights Analyst III (Hybrid - Austin, TX)",
      "company":"Care.com",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-insights-analyst-iii-hybrid-austin-tx-at-care-com-3781005203",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"About Care.com\nCare.com is a consumer tech company with heart. We're on a mission to solve a human challenge we all face: finding great care for the ones we love. We're moms and dads and pet parents. We have parents and grandparents, so we understand that everyone, at some point in their lives, could use a helping hand. Our culture and our products reflect that.\nHere, entrepreneurs, self-starters, team players, and big thinkers unite behind a common cause. Here, we're applying data analytics, AI, and the latest technologies to solve universal problems and connect people in new ways. If you like having autonomy, if you thrive on collaboration and building new things, and if you're all about using your talent for good, Care.com is the place for you.\nPosition Overview:\nCare.com is looking for a Data Insights Analyst III to join the Analytics & Data Insights team to support the core consumer business. This analyst will be passionate about learning the business while using data, technology, and analytics to provide valuable insights to drive the company's critical business decisions. This position is product analytics focused, so we're looking for folks who have demonstrated experience in product analytics, preferably with experience doing funnel\/conversion analysis, understanding the impact of new features, A\/B testing, clickstream analysis, data visualization, and extremely strong SQL background.\nThis position is hybrid (2 days per week in office) in either our Austin, TX or NYC office locations.\nWhat You'll Do:\nPartner with product managers, marketing leaders, and other internal teams to address complex business questions and provide insightful analysis and strategic recommendations through strong storytelling capabilities to both technical and non-technical stakeholders\nTurn data-based observations and insights into hypotheses through analytical rigor, leading to A\/B tests that will confirm or deny those hypotheses and ultimately improve the performance of our sites\nTake ownership, from definition to reporting, of metrics related to the functional area that you support\nMonitor engagement and conversion trends across the Care.com platform, identify breaks in trends, understand underlying drivers, and surface opportunities and threats\nDevelop advanced metrics and visuals, by collecting and integrating data from various sources, including web analytics tools and internal databases\nBe a Care data guru - be the point of contact for all data questions and insights\nWho You Are:\nAt least 3+ years of professional experience in a business intelligence analyst and\/or data analyst position\nTake initiative in solving business questions that data could potentially answer by producing top-down data driven solutions to address them\nStrong product development mindset and focus on actionable analytics: e.g., Ability to surface signals in our data and work with Product\/Engineering to transform these into concrete tests\nExperience using relational databases and big data via writing performant queries in SQL against large datasets in various environments\nUnderstanding of Clickstream data and ability to extract and analyze event data\nBe a creative, global thinker & team player\nStrong SQL skills are required (MSSL, BQ, Hive, Presto)\nBig Data Cloud experience a plus (Snowflake, Hadoop, etc)\nStrong skills in Tableau for data visualization and experience in R, or Python for ETL and complex analyses\nExperience with Amplitude a plus\nStatistical knowledge and modeling a plus\nAbility to work independently with high-level direction\nWillingness to proactively engage with partners across many disciplines\nProficiency in analyzing and interpreting data to while also acting as a mentor to other analysts from other internal teams\nConsistent ability to produce quality, accurate and highly detailed work products\nFor a list of our Perks + Benefits, click\nhere!\nCare.com supports diverse families and communities and seeks employees who are just as diverse. As an equal opportunity employer, Care.com recognizes the power of a diverse and inclusive workforce and encourages applications from individuals with varied experiences, perspectives, and backgrounds. Care.com is committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or accommodation, please reach out to talent@care.com.\nCompany Overview:\nAvailable in more than 20 countries, Care.com is the world's leading platform for finding and managing high-quality family care. Care.com is designed to meet the evolving needs of today's families and caregivers, offering everything from household tax and payroll services and customized corporate benefits packages covering the care needs of working families, to innovating new ways for caregivers to be paid and obtain professional benefits. Since 2007, families have relied on Care.com's industry-leading products\u201a\u00c4\u00eefrom child and elder care to pet care and home care. Care.com is an IAC company (NASDAQ: IAC).\nSalary Range:\n$115,000 to $150,000.\nT\nhe base salary range above represents the anticipated low and high end of the national salary range for this position.\nActual salaries may vary and may be above or below the range based on various factors including but not limited to work location, experience, and performance.\nThe range listed is just one component of Care.com's total compensation package for employees. Other rewards may include annual bonuses and short- and long-term incentives. In addition, Care.com provides a variety of benefits to employees, including health insurance coverage, life, and disability insurance, a generous 401K employer matching program, paid holidays, and paid time off (PTO).\nShow more\nShow less",
      "job_skills":"Data Analytics, AI, SQL, Clickstream Analysis, Data Visualization, Tableau, R, Python, ETL, Amplitude, Statistical Modeling, Big Data Cloud, Snowflake, Hadoop, MSSL, BQ, Hive, Presto",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Catalog and Lineage Central Governance Analyst",
      "company":"PwC",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-catalog-and-lineage-central-governance-analyst-at-pwc-3785062694",
      "search_city":"Mansfield",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nIFS - Information Technology (IT)\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data\/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nAdditional Responsibilities\nSupporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture.\nCustom Orgs\nGlobal LoS\n:\nInternal Firm Services\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nComputer and Information Science, Data Processing\/Analytics\/Science\nAdditional Educational Preferences\nOther related fields of study with relevant experience may be considered.\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success as a team leader:\nPossessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects;\nDisplaying knowledge of data management and governance policies, standards, metrics, controls, and processes;\nHaving knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers;\nPossessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies;\nShowcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture;\nExhibiting proven knowledge and working experience in Microsoft Purview;\nCreating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers;\nShowcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;\nDisplaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog;\nConducting periodic reviews of the data catalogue to corroborate compliance with the DG standards;\nFacilitating the capture of metadata as core change and operational deliverables;\nDemonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers;\nDesigning, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview;\nIdentifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports;\nPossessing ability to create and maintain automated workflows for periodic metadata refresh;\nComplete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR\/HIPPA\/SPI (as applicable);\nHelping manage the inventory of data-related controls on systems that support segment processes and customers;\nShowcasing thorough understanding of data steward\/data owner operating model;\nAbility in designing and rolling out training programs to train the trainer\/end-users;\nBeing a collaborative team player; and,\nHaving a business outcome focused problem-solving mindset.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"Data management, Data Governance, Azure Purview, Data lineage, Data catalog, Data standards, Data policies, Data governance policies, Metadata management, Data security, Data privacy, Data regulations, Data Analytics, Data processing, Data Science, Business Intelligence, Business Glossary, Data Discovery, Data Classification, Data Taxonomy, Data Architecture, Data Stewardship, Data Catalog, Data Dictionary, Data Lineage, Data Warehousing, Data Quality, Data Integration, Data Migration, Data Engineering, Data Visualization, Data Visualization, Agile, Scrum, Kanban, Data security standards, Microsoft Purview, Data Sensitive Data, GDPR, HIPPA, SPI, OOTB, Data stewardship\/data owner operating model, Data asset identification, Data asset ownership, Data access control, SQL, NoSQL, Machine Learning, Artificial Intelligence, Python, Java, Scala, Spark, Hadoop, Hive, Pig, R, SAS, Tableau, Power BI, Data Visualization software, Data Management software, Data Governance software, Data Analytics software, Business Intelligence software",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst V",
      "company":"Texas Health and Human Services",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-v-at-texas-health-and-human-services-3724707742",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nPerforms highly complex (senior-level) data analysis, data research work, data transformation, and development of reporting tools within the Performance Management Analytics System (PMAS) project, which aims to integrate new and existing HHSC program data to enhance and inform decision-making. The position reports to the Director of the Performance Visualization Team, a team responsible for leveraging these data to build visualization for performance monitoring and reporting purposes. The data analyst will become an essential member of the PMAS sprint team, collaborating with other Office of Data, Analytics, and Performance (DAP) teams, as well as PMAS IT teams. Responsibilities include planning, developing, implementing, and advancing the transformation of data into actionable information to help strengthen the programs that support the citizens of Texas. The data analyst works under limited supervision, with moderate latitude for the use of initiative and independent judgment.\nEssential Job Functions\n40% Data Analysis: Work involves conducting detailed analysis of data, including applying statistical techniques; developing proof of concept mockups to ensure data quality ; and converting raw data into database table structures from a variety of source formats. Compiles and manipulates data points using SQL, Python, or other languages from a variety of source formats, to support complex analyses of program area data sets, such as Medicaid and CHIP. Cleans and prepares data to produce datasets required for data visualization software products.\n30% Data Quality\/Integrity: Provides suggestions regarding systematic changes that will improve the efficiency and quality of data analysis processes. Assesses data quality by identifying any missing, erroneous, incongruent, or duplicate data in data sets used by the unit. Coordinates with other internal groups within DAP or other areas to improve data quality. Consults and provides requirements for the improvement of data collection systems and the methods used to perform data analytics. Recommend the selection of data management tools. Define, develop, and implement data and reporting standards.\n20% Visualization: Determines the most effective method to address a given data request, construct performance measures, or implement visualizations to monitor various service trends. Interprets business requirements to be used as input to performance measure visualizations and reports for large and complex agency programs.\n10% Customer Focus and Communication: The analyst engages with a variety of stakeholders across the agency to build strong relationships and to find creative solutions to analytic projects. Utilizes communication skills to gather the information necessary from customers to assess and address their needs. Explains tool development in clear and non-scientific language as necessary to ensure that customers can leverage the information in decision-making. Coordinates with program subject matter experts and leadership to ensure accuracy in the final products.\nKnowledge Skills Abilities\nKnowledge of data visualization development, including data model creation, advanced calculations, and interactive visualizations.\nKnowledge of relational databases and database design.\nKnowledge of custom SQL Table\/View creation with multi-level join conditions.\nKnowledge in writing queries to extract data, joining data, and loading data using SQL\/PSQL.\nKnowledge of Cloud usage for visualization development.\nKnowledge of performance management and continuous quality improvement processes.\nKnowledge of Agile Scrum Methodology.\nKnowledge of Tableau or other visualization software.\nKnowledge of statistics and analyzing data sets; running queries, report writing, and presenting findings; and record keeping, including security procedures for handling, protecting, and distributing confidential data.\nSkill in creating graphical user interfaces, mockups, prototypes, and design documents.\nSkill in critical thinking and problem-solving.\nSkill preferred in using SAS, SPSS, Python or other statistical software.\nSkill in using EXCEL or other spreadsheet software.\nSkill in graphical, tabular and geographical presentation of data.\nAbility to translate complex data into user-friendly information.\nAbility to identify problems, evaluate alternatives, and implement effective solutions.\nAbility to build, establish, and maintain effective working relationships and coalitions.\nAbility to plan, organize, and conduct data analytic projects and prepare reports.\nAbility to develop and interpret statistical data charts, maps, and tables.\nRegistration Or Licensure Requirements\nN\/A\nInitial Selection Criteria\nFour-year college degree in Computer Information Systems, Computer Science, Social Science, or related degree required.\nMaster's degree or higher preferred.\nFive years or more work and experience with data acquisition, data collection, management, analyses, and visualization of health and human services-related data and\/or large datasets preferred.\nExperience working with Prevention and Early Intervention (PEI) system preferred.\nAdditional Information\nAttends work on a regular and predictable schedule in accordance with agency leave policy and performs other duties as assigned. Mentors internal staff, trains and assists others. Any applicants within the state may be considered for employment working remotely. Criminal Background Check and\/or Finger Print Check may be requested.\nMOS Code\nN\/A\nTop 10 Tips for Success when Applying to Jobs at HHSC and DSHS\nHHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work.\nI-9 Form - Click here to download the I-9 form.\nIn compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.\nShow more\nShow less",
      "job_skills":"Data analysis, Data research, Data transformation, Reporting tools development, Performance Management Analytics System (PMAS), Visualization, Statistical techniques, Data quality, Data integrity, Data visualization development, Data model creation, Advanced calculations, Interactive visualizations, Relational databases, Database design, SQL Table\/View creation, SQL\/PSQL, Cloud usage, Performance management, Continuous quality improvement processes, Agile Scrum Methodology, Tableau, Visualization software, Statistics, Data sets, Running queries, Report writing, Findings presenting, Record keeping, Security procedures, Graphical user interfaces, Mockups, Prototypes, Design documents, Critical thinking, Problemsolving, SAS, SPSS, Python, Statistical software, EXCEL, Spreadsheet software, Graphical presentation, Tabular presentation, Geographical presentation of data, Userfriendly information, Problem identification, Alternatives evaluation, Effective solutions implementation, Working relationships, Coalitions, Project planning, Project organization, Project conduction, Report preparation, Statistical data charts, Maps, Tables",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst V",
      "company":"Texas Health and Human Services",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-v-at-texas-health-and-human-services-3704136709",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nThe Texas Department of Family and Protective Services (DFPS) is currently seeking a senior Data Analyst within the Chief Technology Office (CTO) team of ITS Department to perform advanced data analysis, research and data governance work.\nPerforms advanced data systems analysis, research and data governance work. Work involves coordinating the planning and analysis of data modeling; conducting detailed analysis of and extensive research on data, providing results to implement and manage database systems, data warehouses, and data analytics, ensuring data quality; and working in a team environment in designing strategies and setting standards for development, operations and programming.\nThe mission of DFPS is to protect children, the elderly, and people with disabilities from abuse, neglect, and exploitation by involving clients, families, and communities. We are looking to grow our teams with people who share our energy and enthusiasm to get behind our mission of protecting those among us who are most in need.\nThe Data Analyst works under minimal supervision, with considerable latitude for the use initiative and independent judgement.\nEssential Job Functions\nPerforms highly complex (senior-level) data analysis and data research work. Works under limited supervision, with moderate latitude for the use of initiative and independent judgment.\nGuide the selection of data management tools and the development of standards, usage guidelines, and procedures for those tools.\nDefine, develop, and implement data and reporting standards\nImplements data archival and data retention policies.\nDevelop data quality measures, analyze data quality results, and implement necessary changes to ensure data quality improvement\nDevelop software applications or programming to use for statistical modeling, data analysis, and graphic analysis.\nImplementation experience of data protection and data encryption techniques.\nHelp set\/inform standards and compliance for Data Security and Privacy\nExperience applying security principles to data management and governance processes.\nAnalyzes data using standard statistical tools, methods, and techniques.\nConsults with internal and external customers to identify user needs.\nCompiles and queries data.\nIdentifies data gaps, errors, anomalies, inconsistencies, and redundancies by analyzing the content, structure, and relationships within data.\nInterprets results to identify significant differences in data. Identifies and interprets data patterns and trends and assesses data quality.\nCleans and prunes data to discard irrelevant information.\nPrepares concise, comprehensive technical reports to present and interpret data, identify alternatives, and make and justify recommendations on data revisions.\nMay develop and implement databases, data collection systems, data analytics, and other strategies that optimize statistical efficiency and quality.\nKnowledge of statistics and analyzing data sets; of running queries, report writing, and presenting findings; of data models, database design development, data mining, and segmentation techniques; and of record keeping, including security procedures for handling, protecting, and distributing confidential data.\nSkill in the use of a computer and applicable software, in analyzing problems and devising effective solutions, in conducting data searches, in evaluating and translating large amounts of data, and in critical thinking.\nAbility to compile, review, and analyze data; to prepare reports; to maintain accuracy and attention to detail; to communicate effectively; and to provide guidance to others.\nPerforms related work as assigned.\nSkill in analyzing and eliciting business requirements, to translate them and develop business a business centric view of data management.\nBuild use case requirements for data, data quality management, business data glossary management.\nLeverage tools and technology to develop an agency wide access point for key program terminology.\nParticipate in the agency\u201a\u00c4\u00f4s data governance program and work with business stakeholders to identify key datasets as candidates for MDM and define associated data quality rules and measures.\nContribute ideas and explore new technology while gaining excellent insights into the core functions of the agency to facilitate adoption of data governance policies within IT processes and project management activities.\nProvide data management and governance guidance and best practices in new, changing, and complex technology environments: cloud and on premise.\nAssist in implementation and maintenance of Business Metadata by entering new and\/or updating existing business\/logical names, definitions, and valid values in a business metadata repository.\nRecommend deployment of tools to monitor and control data quality to business data owners and determine the level of business impact for data quality issues.\nWork with IT Data management team to establish, monitor and maintain data processes and provide recommendations to support integration of data security and privacy standards for agency data platforms.\nKnowledge Skills Abilities\nBachelor\u201a\u00c4\u00f4s degree in relevant field; Information Technology, Computer Science or Engineering\nStrong SQL skills are required. SQL queries and PL\/SQL development (creating packages, procedures, etc.)\nData warehousing processes (refreshing and freezing data, Unix scripting, ETL processes, etc.)\nInformatica ETL development\nReport building and automation (.ASP files, automated reporting, Tableau, etc)\nPython development skills\nR programming skills\nData management, data governance and MDM implementation experience\nExperience interacting with master data management and data quality tools.\nExperience with data modeling tools.\nStrong knowledge and working experience of data governance concepts and frameworks\nMust have experience with relational database systems, data architecture and data modeling\nData profiling experience\nExcellent communication skills verbally and in writing used when leading development activities, presenting to leadership, and training less experienced IT staff. keen attention to detail\nExperience performing problem analysis for data-related issues and developing solutions to resolve data quality issues\nAbility to develop positive and collaborative relationships with business partners and effectively communicate with both business and technology data stakeholders\nExperience with data\/reporting tools like \u201a\u00c4\u00ec Microsoft Power BI\nRegistration Or Licensure Requirements\nInitial Selection Criteria:\nGraduation from a four-year college or university with major coursework in computer engineering, computer science, information systems, information technology or related field. Work experience may be substituted for education on a year-for-year basis.\nData management, data governance and MDM (Master Data Management) implementation experience\nExperience with relational database systems, data architecture and data modeling\nExperience performing problem analysis for data-related issues and developing solutions to resolve data quality issues\nAdditional Information\nMOS Code:\nMilitary occupation(s) that relate to the initial selection criteria and registration or licensure requirements for this position may include 25B, 255A, 255S, IT, 182X, 682X, 782X, 275, 26, 030, C4|10, C4|11, ISM, 0171, 8846, 8858, 3D0X4. All active duty military, reservists, guardsmen, and veterans are encouraged to apply if qualified to fill this position. For more information see the Texas State Auditor\u201a\u00c4\u00f4s Military Crosswalk at http:\/\/www.hr.sao.state.tx.us\/Compensation\/JobDescriptions.aspx.\nAs a state agency, DFPS is required Texas Administrative Code (TAC 206 and 213) to ensure all Electronic Information Resources (EIR) follow accessibility standards. The staff must be familiar with the WCAG 2.1 AA and Section 508 to create accessible content including but not limited to; Microsoft Office documents, Adobe PDFs, webpages, software, training guides, video, and audio files.\nHHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work.\nI-9 Form - Click here to download the I-9 form.\nIn compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Governance, Data Modeling, Database Systems, Data Warehousing, Data Analytics, Data Quality, Statistical Analysis, Data Mining, Data Segmentation, Data Protection, Data Encryption, Data Security, Data Privacy, SQL, PL\/SQL, Unix Scripting, ETL Processes, Informatica ETL, Report Building, Automation, Python, R Programming, Data Management, Data Governance, MDM Implementation, Master Data Management, Data Quality Tools, Data Modeling Tools, Data Architecture, Data Profiling, Microsoft Power BI, Accessibility Standards, WCAG 2.1 AA, Section 508, EVerify, I9 Form, Americans with Disabilities Act (ADA)",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst",
      "company":"Rezilient Health",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-rezilient-health-3781946727",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"We're not telehealth and we're not a traditional doctor's office: we're the best parts of both.\nOur mission at Rezilient is simple: to make access to primary care convenient, timely and seamless. Because we virtually beam our doctors into our CloudClinics, our members can choose their doctor based on their preferences, not their location, for a completely different primary care experience.\nOur doctors can be anywhere, while our CloudClinics are conveniently placed close to where people live, work and shop. Each CloudClinic is staffed by an experienced clinic specialist who becomes the doctor\u201a\u00c4\u00f4s hands. Our members can also interact with their Rezilient doctors through chat and video, providing a continuous relationship with their doctor no matter where they are.\nAbove all, our tech-forward approach streamlines the primary care experience so our doctors have the time to treat our members as a whole person, not just a collection of symptoms. And we\u201a\u00c4\u00f4re continuing to add specialty services and breakthrough technology to offer the most comprehensive, convenient care possible.\nWe are looking for a Data Analyst to come in to support our growing multi-disciplinary operations and set the foundation for intelligent service delivery and rapid scaling. The ideal candidate excels in the analysis and manipulation of large data sets with the ability to create meaningful insights from the data. This candidate should have a passion for doing high-quality work, continuously learning and improving, effectively analyzing healthcare data, consistently developing and improving data and analytics methodologies, and regularly exceeding customer and internal stakeholder expectations. You will work closely with the product, data engineering, clinical, finance, and go-to-market teams in a cross-functional work environment to identify and implement process improvements, develop and maintain timely and accurate reporting and analytics, and support business planning and forecasting.\nThe selected candidate will have ample opportunity to refine sophisticated analytical skills, hone project management skills, and grow their career, skill sets, and expertise within the healthcare industry. This position is located at our St. Louis HQ in the beautiful DeBaliviere neighborhood, steps from Forest Park.\nKey Responsibilities:\nWork closely with the CTO, CMO, and CoS on all new data and analytics initiatives. You\u201a\u00c4\u00f4ll have a seat at the table and the ability to learn on the fly\nCollaborate with cross-functional team to understand business needs and identify areas for process improvement\nDevelop and maintain reporting and analytics to track key performance indicators and provide insights across the business\nAssist with planning and forecasting by analyzing data and providing recommendations\nCollaborate with cross-functional teams to identify and implement solutions to improve efficiency and effectiveness through a data-driven approach\nContinuously learn, build, and improve across all things \u201a\u00c4\u00fadata\u201a\u00c4\u00f9 at Rezilient, including:\nData Engineering \u201a\u00c4\u00ec perform Extract, Transform, Load (ETL) processes to ensure accurate and timely movement of data from diverse sources into a centralized data repository, employing data cleansing and transformation techniques to maintain data quality and integrity\nData Analysis \u201a\u00c4\u00ec conduct comprehensive and innovative analysis from claims and clinical data to extract and interpret relevant data, while extracting unique insights or trends from insurance claims and clinical data, such as comorbidities and common healthcare services utilized, and investigate discrepancies between clinical concepts and how they manifest in the data sets\nGenerating Insights \u201a\u00c4\u00ec collaborate with the Product, Marketing, and Clinical teams to translate data insights into actionable strategies for engaging identified members through analysis of clinical data of engaged and enrolled members (e.g., identify correlations with prior healthcare utilization)\nClinical Operations Insight \u201a\u00c4\u00ec analyze the performance of treatment protocols, achievement of milestones, and variance at different levels; work with cross-functional teams to generate and validate hypotheses regarding clinical operations\nClient Reporting and Material Preparation \u201a\u00c4\u00ec prepare and maintain dashboards that translate data insights into internal and external facing materials; develop predictive models for future results and forecasts of early indicators into long-term value; prepare performance year retrospective summaries\nRequirements\nDegree in Data Science, Computer Science, Statistics, Biostatistics, or related field\n2-3 years in a similar role is preferred \u201a\u00c4\u00ec with experience working with healthcare data and taxonomies (e.g. claims, eligibility, etc.)\nDetail-oriented with a commitment to accuracy\nStrong analytical and problem-solving skills \u201a\u00c4\u00ec with an ability to translate complex data into understandable insights\nSelf-starter that is intellectually curious, able to work independently in a team environment, and excited to build from the ground-up without a predefined playbook\nProficiency in Excel, as well as SQL, Python, and other relevant programming languages\nFamiliarity with modern data stack technologies and cloud-based platforms (e.g., AWS, Snowflake, Dbt, ETL, etc.)\nProficiency in visualization preferably with PowerBI, Looker, etc\nFamiliarity with Github\/Notebook documentation\nExceptional communication and organizational skills\nBenefits\nUnlimited Vacation & PTO\nMedical, Dental, Vision and Life Insurance\nErgonomic Desk Setup\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Engineering, Data Science, Computer Science, Statistics, Biostatistics, Data Mining, Data Visualization, Machine Learning, Python, SQL, Excel, PowerBI, Looker, Github, Notebook documentation, AWS, Snowflake, Dbt, ETL, Clinical Data, Healthcare Data, Claims Data, Eligibility Data, Data Manipulation, Data Cleansing, Data Transformation, Data Quality, Data Integrity, Data Insights, Business Intelligence, Healthcare Industry, Cloudbased Platforms",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Analyst",
      "company":"SteadyMD",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-steadymd-3697498895",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Be part of a team enabling access to better healthcare at SteadyMD!\nSteadyMD is a technology company and healthcare provider that powers high-quality telehealth experiences for its partners, including fast-growing digital healthcare companies, labs, pharmacies, large employers, and Fortune 100 companies like Amazon, AmerisourceBergen, and Abbott. SteadyMD initially launched in two states: California and Missouri. By 2018, the company was licensed, operating, and providing care in all 50 states. We\u201a\u00c4\u00f4ve raised over $60 million in funding from top tier investors including Lux Capital, Pelion Ventures and AB Health Ventures.\nWe are currently seeking a talented\nSr. Data Analyst\nto join our Product team. As a Sr. Data Analyst you will play a pivotal role in transforming raw data into meaningful insights. You will collaborate with cross-functional teams to analyze data, identify trends, and provide actionable recommendations. Reporting to the VP of Product Management, this position offers an exciting opportunity to work with different datasets, contribute to data-driven initiatives, and impact the success of our company. This is a hybrid role in which you will be located in the St. Louis, MO area.\nAt SteadyMD, we value what diverse teams can accomplish together, and we honor each of our unique lived experiences. We look for a diverse pool of applicants, including those from historically marginalized groups, and we are committed to ensuring a safe work environment that is distinctly anti-discriminatory against any person. This is one of the reasons we are ranked #81 on Forbes\u201a\u00c4\u00f4 America\u201a\u00c4\u00f4s Best Startup Employers List. We know the value of building a team that encompasses a variety of backgrounds, experiences, and skills.\nWorks with other teams to provide key analytics support in identifying process, software, and data improvements\nDefine, maintain, and communicate the data \u201a\u00c4\u00fasource of truth\u201a\u00c4\u00f9 for cross-functional teams to use in assessing performance and quality\nProvide support and documentation for associated business units to understand how to use data and insights\nCreates and owns ETLs: identifies data sources, writes queries, validates, and makes modifications as needed\nWrite clean code that can be maintained and extended by other technical stakeholders\nEnsure safe and secure data handling by partnering with company security leaders\nSets up and manages usage, reliability, quality, and performance of products, services, solutions or processes and proposes improvements\nGuides business leaders with data-driven reports, dashboards, and visualizations\nInterprets data, analyzes results, and provides insights to support data-driven decision-making for ad hoc and on-going reports\nStay up-to-date with industry technologies and frameworks to identify trends to maintain best and cutting edge practices in data analysis\nParticipate in special projects and initiatives as needed\nRequirements\n4+ years of related experience in a business analytics or data management experience\nRelevant Industry Experience or Bachelor\u201a\u00c4\u00f4s Degree with emphasis in: Information Technology, Mathematics, Management Information System (MIS), Statistics, Engineering, Computer Science, or related\nStrong proficiency in:\nSQL, Python, writing SQL queries\nAdvanced SQL aggregation functions\ndatabase performance concepts and query optimization techniques\nExperience with Looker and Tableau\nCan provide helpful insights from dense datasets\nCreative self-starter capable of first principles thinking\nStrong interpersonal skills that can work across a highly cross-functional environment\nExcellent oral and written communication skills required\nDetail oriented and strong organizational skills\nPrevious experience in a B2B SaaS start-up preferred\nExperience in healthcare is a bonus\nBenefits\nCompetitive Compensation. The annual salary range for this role is $85,000 - $110,000 depending on experience, and participation in the company bonus program\nFast-paced Startup Environment. An environment that is focused on disrupting the status quo and challenging conventional professional norms. We are focused on the results you can achieve, not how many hours you spend at a desk\nComplimentary Lemonaid Primary Care Membership. So that you can experience what we have to offer and be able to speak first-hand about what the future of medicine will look like\nCompany-paid health, dental, and vision insurance. Also includes Basic Life and ADD offerings\n401k with Match & Parental Leave Benefits offered to all full-time employees\nUnlimited PTO. We trust our employees to make the right decisions for the business, and we also recognize that means taking time to take care of yourself\nShow more\nShow less",
      "job_skills":"SQL, Python, Looker, Tableau, Data analysis, Query optimization, Data visualization, Datadriven decisionmaking, Data management, Business analytics, ETLs, Data pipelines, Data quality, Data security, Data governance, Healthcare, B2B SaaS, Communication skills, Interpersonal skills, Problem solving, Analytical thinking, Critical thinking, Business intelligence, Data mining, Machine learning, Artificial intelligence, Statistics, Programming",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst",
      "company":"Sunbelt Solomon",
      "job_location":"Temple, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-sunbelt-solomon-3762242004",
      "search_city":"Killeen",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"The data analyst role is responsible for cleaning, analyzing, interpreting, and displaying data. This role is responsible for communicating findings to internal customers and key stakeholders.\nDesign, develop, test, and implement BI solutions and platforms including but not limited to real-time data pipeline, data visualizations, interactive reports and custom ad-hoc reporting.\nContinuously develops and maintains an understanding of Business Intelligence technology, including ETL processing, reporting tools, and other methods of information delivery.\nUnderstand and implement data-driven and advanced analytical solutions that leverage predictive analytics, data mining techniques, machine learning, open-source tools, orchestration tools, R, Spark, Python, etc.\nDetermine how existing data could be transformed and\/or combined with additional data sources in order to solve an analytical problem.\nSynthesize data into meaningful business insights and assist in preparation of analytics deliverables including reports, presentations, etc.\nRequirements:\nBachelor\u201a\u00c4\u00f4s Degree in Business Analytics or related field, required.\n1-3 years working experience in field required.\nExperience with SAS, Python, Tableau, Excel for Analytics, Power BI or other Analytics and Visualization tools.\nExperience\/familiarity with querying languages such as SQL, PostgreSQL, MSSQL, or MySQL.\nMust able to learn quickly and apply learned business rules to scale on large data sets.\nSalesforce and Power BI experience is a plus.\nIntermediate to expert level experience in Microsoft Office Suite.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Cleaning, Data Interpretation, Data Visualization, Business Intelligence, ETL Processing, Reporting Tools, Predictive Analytics, Data Mining, Machine Learning, OpenSource Tools, Orchestration Tools, R, Spark, Python, SQL, PostgreSQL, MSSQL, MySQL, SAS, Tableau, Excel for Analytics, Power BI, Salesforce, Microsoft Office Suite",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst",
      "company":"System Soft Technologies",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-system-soft-technologies-3782001516",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"System Soft is a seeking a Data Analyst for a long term contract with our client in Fort Worth, TX. The role will be onsite for the 2 months and then have the possibility for a hybrid schedule after based on performance.\n*You will need to provide work examples in order to be considered*\nOur client is seeking a strong background in analytics, with proven expertise in statistical\nanalysis, data modeling, and predictive analytics.\nKey skills:\n1. proficiency in programming languages such as, R, or Python.\n2. extensive knowledge of working with visualization tools like Power BI.\n3. solid understanding of machine learning techniques and big technologies.\n4. Excellent analytical skills\n5. attention to detail\n6. the ability to derive meaningful insights from complex sets.\n7. Strong communication skills for translating technical findings into clear, actionable business insights.\n8. adept at managing multiple projects simultaneously\n9. demonstrating both independent-solving abilities and teamwork skills.\nRequirements:\nData Visualization: Transform raw into visually appealing and easily understandable reports and dashboards. Ability to create a variety of visualizations, including charts, graphs, and maps.\nData Integration: Integrate with a vast array of sources, including-based and on-premises\ndata sources, Excel spreadsheets, and big.\nReal-time Analytics: Create real-time dashboard updates, allowing departments to monitor their operations as events unfold.\nAdvanced Analytics: Perform advanced analytics such as predictive modeling and machine learning, providing deeper insights into.\nAdvanced Knowledge of Excel\nShow more\nShow less",
      "job_skills":"R, Python, Power BI, Machine learning, Big data, Analytical skills, Attention to detail, Data visualization, Data integration, Realtime analytics, Advanced analytics, Excel",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Scientist",
      "company":"Anblicks",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-scientist-at-anblicks-3725725761",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position: Senior Data Scientist\nPosition: Full time\nLocation: Dallas, TX\nKey Responsibilities:\nCollaborate with cross-functional teams to identify business challenges and translate them into data science use cases.\nUtilize advanced statistical and machine learning techniques to extract actionable insights from complex datasets.\nLead and mentor junior data scientists, providing guidance and fostering a culture of data-driven decision-making.\nExpertise in Databricks platform to efficiently manage and analyze large-scale data sets.\nDrive the development and deployment of machine learning models to enhance business operations and decision-making.\nSkilled in articulating and presenting complex findings and data-driven recommendations to non-technical stakeholders.\nGood knowledge of Azure platform (including Synapse, Blob, ADF and SQL server + concepts of hierarchy, key vault, app-insights)\nQualifications:\nBachelor\u201a\u00c4\u00f4s degree in Tech or Tech adjacent field (master\u201a\u00c4\u00f4s Preferred)\nProven experience in data science and machine learning. 3 \u201a\u00c4\u00ec 5-years experienced candidates preferred\nProficiency in Databricks for data processing and analysis. (Preferably certified in Databricks)\nStrong programming skills in languages like Python or R.\nExcellent communication, problem-solving skills.\nPower- BI or Tableau is a value add but not required.\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Statistical Analysis, Databricks, Apache Spark, Python, R, Azure, Synapse, Blob, ADF, SQL, Hierarchy, Key Vault, AppInsights, Power BI, Tableau",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior, Data Scientist, Marketplace Acceleration",
      "company":"Walmart",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-marketplace-acceleration-at-walmart-3787380490",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position Summary...\nWhat you'll do...\nWe are seeking a highly motivated and skilled Senior Data Scientist to join Marketplace Applied AI team. You will play a critical part in driving data-driven decisions by developing advanced models, machine learning and computational algorithms. You will work closely with cross-functional teams to develop machine learning platform and services to optimize business processes and drive growth for Walmart Marketplace.\nAs a Walmart Senior Data Scientist , we are looking for a sharp, thoughtful, and collaborative problem solver, who enjoys uncovering key business drivers and challenges, and then building data science and analytics solutions to enable strategic decision making\nAbout The Team\nMarketplace Applied AI team builds reusable technologies that aid in acquiring customers, onboarding and empowering merchants besides ensuring a seamless experience for both these stakeholders. We also optimize tariffs and assortment, adhering to the Walmart philosophy - Everyday Low Cost. In addition to ushering in affordability, we also create personalized experiences for customers the omnichannel way, across all channels - in-store, on the mobile app and websites. Marketplace is the gateway to domestic and international Third-Party sellers; we enable them to manage their end-to-end onboarding, catalog management, order fulfilment, return & refund management. Our team is responsible for design, development, and operations of large-scale distributed systems by leveraging cutting-edge technologies in web\/mobile, cloud, big data & AI\/ML. We interact with multiple teams across the company to provide scalable robust technical solutions.More about Marketplace: https:\/\/marketplace.walmart.com\/\nWhat You'll Do\nAs a Senior Data Scientist for Global Marketplace team at Walmart, you'll have the opportunity to\nDrive data-derived insights across the wide range of retail divisions by developing advanced statistical models, machine learning algorithms and computational algorithms based on business initiatives.\nDirect the gathering of data, assessing data validity and synthesizing data into large analytics datasets to support project goals.\nUtilize big data analytics and advanced data science techniques to identify trends, patterns, and discrepancies in data. Determine additional data needed to support insights.\nBuild and train statistical models and machine learning algorithms for replication for future projects.\nCommunicate recommendations to business partners and influencing future plans based on insights.\nCollaborate with cross-function teams to promote advanced modeling and algorithms into machine learning services and platforms.\nWhat You'll Bring\nExperience with Data Source Identification : Requires knowledge of Functional business domain and scenarios; Categories of data and where it is held; Business data requirements; Database technologies and distributed datastores (e.g. SQL, NoSQL);\nExperience with Data Quality : Existing business systems and processes, including the key drivers and measures of success. To Understand the appropriate data set required to develop simple models by developing initial drafts. Support the identification of the most suitable source for data Maintains awareness of data quality.\nExperience with Analytical Modeling : Requires knowledge of feature relevance and selection; Exploratory data analysis methods and techniques; Advanced statistical methods and best-practice advanced modelling techniques (e.g., graphical models, Bayesian inference, basic level of NLP, Vision, neural networks, SVM, Random Forest etc.) Basic classical optimization techniques (e.g., Newton-Rapson methods, Gradient descent); Numerical methods of optimization (e.g. Linear Programming, Integer Programming, Quadratic Programming, etc.)\nAdvanced excel techniques and Programming languages like R\/Python .\nExperience with coding language such as SQL and Python.\nExperience with language such as Java, C++ and other are preferred.\nExperience in Analyzing the Complex Problems and translate it into data science algorithms.\nThe above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.\nAbout Global Tech\nImagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered.\nWe train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.\nFlexible, hybrid work\nWe use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.\nBenefits & Perks\nBeyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.\nEqual Opportunity Employer\nWalmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\nMinimum Qualifications...\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\nOption 1- Bachelor's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.\nPreferred Qualifications...\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\nData science, machine learning, optimization models, Master's degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)\nPrimary Location...\n603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America\nShow more\nShow less",
      "job_skills":"Machine Learning, Python, R, SQL, Advanced Analytics, Data Science, Statistical Modeling, Data Quality, Data Engineering, Feature Engineering",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior, Data Scientist",
      "company":"Walmart",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-walmart-3755998366",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position Summary...\nWhat you'll do...\nChance to work on GenAI to solve complex retail problems\/challenges. Utilize deep learning methods and architectures to fine tune NLP models to make intelligent.\nOption-1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 6 years' experience in an analytics related field.\nOption 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field.\nAbout Team\nOur team works closely with our US stores and eCommerce business to better serve customers by empowering team members, stores, and merchants with technological innovation. From groceries and entertainment to sporting goods and crafts, Walmart U.S. offers an extensive selection that our customers value, whether they shop online at Walmart.com, through one of our mobile apps, or in-store. Focus areas include customers, stores and employees, in-store service, merchant tools, merchant data science, and search and personalization.\nWhat You'll Do\nBuild NLP and\/or recommendation systems\nDevelop data science models for retail & e-commerce\nDeploy trained ML models into cloud for business\/customers\nWhat You'll Bring\nPreferred Qualifications...\nOutlined below are the optional preferred qualifications for this position.\nData science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, Pytorch)\nExcellent understanding of AI\/ML\/DL and Statistics, as well as coding proficiency using related open source libraries and frameworks\nSignificant proficiency in SQL and languages like Python, PySpark and\/or Scala\nAbout Walmart Global Tech\nImagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.\nFlexible, Hybrid Work\nWe use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.\nBenefits\nBenefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.\nEqual Opportunity Employer\nWalmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\nThe above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.\nMinimum Qualifications...\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\nOption 1- Bachelor's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.\nPreferred Qualifications...\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\nData science, machine learning, optimization models, Master's degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)\nPrimary Location...\n603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America\nShow more\nShow less",
      "job_skills":"NLP, Recommendation systems, Data science, Machine learning, Optimization models, Deep learning, Python, Spark, Scala, R, scikit learn, Tensorflow, Pytorch, SQL, PySpark",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior, Data Scientist",
      "company":"Walmart",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-walmart-3774944690",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position Summary...\nWhat you'll do...\nYou will team up with a cross functional team of data scientist, machine learning engineers and software developers that builds NLP driven products and services within an organization focused on AI software.\nAbout Team: Leverage AI\nLeverage AI builds AI-infused software applications for use within back-office services at Walmart. Our team's mission is to rapidly drive productivity and value by seamlessly bringing the power of an AI suite of products that is natively built to handle Walmart's scale\nWhat You'll Do\nResearch and implement state-of-art NLP models(e.g. GPT, BARD, BERT, T5, ELMo, etc.)\nCollaborate on modeling techniques to support the full spectrum of LLM tuning from prompt engineering, instruction tuning to fine tuning.\nDevelop scalable, efficient and automated processes for large scale data analysis, machine learning model development, validation and serving.\nWork closely with product team and engineering teams on gathering detailed requirements, developing technical designs and implementing end-to-end production systems.\nWhat You'll Bring\n3 - 5 years of prior work experience as a data scientist or machine learning engineer\nDeep understanding of modern NLP systems, including word embeddings, transformer architectures, and software design principles.\nHands on experience in most of the following: Generative AI, Large Language Models (LLMs) applications, Information Retrieval, Machine Comprehension, Question Answering\/Conversational AI.\nPassionate about staying current with the latest advancements in AI and machine learning, and eager to drive innovation\nAbility to closely collaborate with a diverse set of data scientists, developers, product managers and business stakeholders to identify needs and deliver AI\/ML solutions\nAbout Walmart Global Tech\nImagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.\nFlexible, Hybrid Work\nWe use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.\nBenefits\nBenefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.\nEqual Opportunity Employer\nWalmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\nThe above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.\nMinimum Qualifications...\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\nOption 1- Bachelor's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.\nPreferred Qualifications...\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\nData science, machine learning, optimization models, Master's degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)\nPrimary Location...\n603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America\nShow more\nShow less",
      "job_skills":"NLP, GPT, BARD, BERT, T5, ELMo, LLM, Generative AI, Large Language Models, Information Retrieval, Machine Comprehension, Question Answering, Conversational AI, Word embeddings, Transformer architectures, TensorFlow, PyTorch, Scikitlearn, Python, Spark, Scala, R",
      "Category":"Backend Development"
  },
  {
      "job_title":"Project Engineer Data Manager Data Scientist",
      "company":"ComForCare Home Care (Raleigh, NC)",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/project-engineer-data-manager-data-scientist-at-comforcare-home-care-raleigh-nc-3771566738",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Project Engineer (Data Manager\/Data Scientist) Part Time \u201a\u00c4\u00ec Houston Remote\nPart Time Position \u201a\u00c4\u00ec minimum 8 hours a week up to 20 hours a week. Expected 2-3 hours a day + weekend hours if needed\nThe primary responsibility of this role is to extract meaningful insights from complex datasets, present this data to help guide the project in data-driven decision making, and to contribute to the development of data-driven product and solutions.\nMinimum of 15 years of experience in the engineering \/ construction industry, with proven leadership and excellent communication skills\nKnowledge of Lean process and philosophy\nKnowledge of organizational structure, scheduling systems, and management of available resources\nAbility to quickly and effectively solve complex problems\nAbility to set up and establish project specific technologies to support project delivery strategy\nMinimum 3 years of experience with Python (numpy, pandas, scikit-learn), SQL, Power BI, and Data Analysis\nBuild out SQL queries and views, Power BI dashboards, and data science ML models, and present methodology and key insights to stakeholders\nUse a diverse set of techniques spanning machine learning and other forms of statistical modeling to solve important business and product problems\nCollaborate with business leaders, subject matter experts, and decision makers to develop success criteria and optimize new products, features, policies, and models\nAbility to build relationships and collaborate within a team, internally and externally\nPreferred Education requirement: Masters Degree in an advanced quantitative and\/or scientific field, such as Data Science\nThis is a remote position.\nShow more\nShow less",
      "job_skills":"Project Management, Data Analysis, Data Visualization, Python, Numpy, Pandas, Scikitlearn, SQL, Power BI, Machine Learning, Statistical Modeling, Data Science",
      "Category":"Backend Development"
  },
  {
      "job_title":"Hybrid Work - Need Data Science Manager in Fort Worth TX",
      "company":"Steneral Consulting",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/hybrid-work-need-data-science-manager-in-fort-worth-tx-at-steneral-consulting-3687682439",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"please note this role is like a data scientist- looking for Machine Learning SME\nThank you!\nTitle\n: Manager of Ops Measures\nLocation\n: Fort Worth, TX- 2-3 days per week on site\nTerm\n: 12 month CTH (USC\/ GC Holder only)\nTOP SKILLS Required\nteam is breaking into Machine Learning\/Predictive Analytics\ncandidate has to be local\nbuilding python notebooks\nable to find data with little direction and use SQL to extract data\nQualifications\nSME around Machine Learning and leadership skills\nAdvanced analytical skills with the ability to carry out self-directed analysis\nAbility to extract, manipulate, and analyze information using multiple data platforms\nHighly effective interpersonal and communication skills (verbal and written)\nAbility to manage multiple projects and deadlines simultaneously\nFamiliarity, and proficiency in Microsoft Office Suite of tools\nAbility to write and understand structured query language (SQL)\nWorking knowledge of one or more of a variety of software products & languages (SAS, Python, Tableau, Power BI) to prototype and develop various reports and predictive analytical tools\nBachelor's and\/or Master's degree in analytics, business or related field\nDemonstrated experience with all stages of the machine learning project life cycle\nKnowledge of deep learning model building and implementation\nWorking knowledge of measurement systems and reports (DPR, SCORE, Corporate Dashboard, Terminal Dashboard, NOC Dashboard, etc.) preferred\nStrong personal and project organizational skills\nAbility to work independently and drive analyses and projects to conclusion\nStrong data analysis skills\nQuality focus on deliverables\nAbility to structure and deliver presentations at all levels internal \/ external\nResponsibilities\nThe Mgr Ops Measures performs a key leadership role in managing analyses coupled with performance management initiatives supporting the Network Strategy, Design and Innovation department.\nResponsibilities involve providing senior management with performance metrics, recommendations on key metrics focused to improve productivity, and analysis of business performance. Duties include the design and development of performance reporting systems, effective and efficient analytical techniques, and application design on key metrics for rail operations. The position will play a key role in supporting the client and Network Strategy, Design and Innovation Long-Term initiatives.\nProvide analytical support to Network Strategy, Design, Innovation, and Transportation leaders on key operating topics including train, yard, and block volume changes; car velocity and utilization; terminal and train operational performance; and blocking integrity.\nProvide support and expertise among ongoing data and systems transformations across internal, customer facing, and regulatory required platforms\nPerform timely analyses and deliver clear communication of complex material.\nSupport modernization of metrics, tools and reports as new data sources are implemented (e.g., TSS 2.0).\nShow more\nShow less",
      "job_skills":"Machine Learning, Predictive Analytics, Python, SQL, SAS, Tableau, Power BI, Deep learning, Measurement systems, Data analysis, Data presentation, Data extraction, Analytical techniques, Microsoft Office Suite",
      "Category":"Backend Development"
  },
  {
      "job_title":"Hybrid Work - Need Data Science Manager in Fort Worth TX",
      "company":"Steneral Consulting",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/hybrid-work-need-data-science-manager-in-fort-worth-tx-at-steneral-consulting-3687085487",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"please note this role is like a data scientist- looking for Machine Learning SME\nTitle\n: Manager of Ops Measures\nLocation\n: Fort Worth, TX- 2-3 days per week on site\nTerm\n: 12 month CTH (USC\/ GC Holder only)\nTOP SKILLS Required\nteam is breaking into Machine Learning\/Predictive Analytics\ncandidate has to be local\nbuilding python notebooks\nable to find data with little direction and use SQL to extract data\nQualifications\nSME around Machine Learning and leadership skills\nAdvanced analytical skills with the ability to carry out self-directed analysis\nAbility to extract, manipulate, and analyze information using multiple data platforms\nHighly effective interpersonal and communication skills (verbal and written)\nAbility to manage multiple projects and deadlines simultaneously\nFamiliarity, and proficiency in Microsoft Office Suite of tools\nAbility to write and understand structured query language (SQL)\nWorking knowledge of one or more of a variety of software products & languages (SAS, Python, Tableau, Power BI) to prototype and develop various reports and predictive analytical tools\nBachelor's and\/or Master's degree in analytics, business or related field\nDemonstrated experience with all stages of the machine learning project life cycle\nKnowledge of deep learning model building and implementation\nWorking knowledge of measurement systems and reports (DPR, SCORE, Corporate Dashboard, Terminal Dashboard, NOC Dashboard, etc.) preferred\nStrong personal and project organizational skills\nAbility to work independently and drive analyses and projects to conclusion\nStrong data analysis skills\nQuality focus on deliverables\nAbility to structure and deliver presentations at all levels internal \/ external\nResponsibilities\nThe Mgr Ops Measures performs a key leadership role in managing analyses coupled with performance management initiatives supporting the Network Strategy, Design and Innovation department.\nResponsibilities involve providing senior management with performance metrics, recommendations on key metrics focused to improve productivity, and analysis of business performance. Duties include the design and development of performance reporting systems, effective and efficient analytical techniques, and application design on key metrics for rail operations. The position will play a key role in supporting the client and Network Strategy, Design and Innovation Long-Term initiatives.\nProvide analytical support to Network Strategy, Design, Innovation, and Transportation leaders on key operating topics including train, yard, and block volume changes; car velocity and utilization; terminal and train operational performance; and blocking integrity.\nProvide support and expertise among ongoing data and systems transformations across internal, customer facing, and regulatory required platforms\nPerform timely analyses and deliver clear communication of complex material.\nSupport modernization of metrics, tools and reports as new data sources are implemented (e.g., TSS 2.0).\nShow more\nShow less",
      "job_skills":"Machine Learning, Predictive Analytics, Python, SQL, SAS, Tableau, Power BI, Microsoft Office Suite, Structured Query Language, Data Analysis, Data Manipulation, Data Extraction, Data Platforms, Measurement Systems, Deep Learning, Model Building, Model Implementation, Analytics, Performance Reporting, Reporting Systems, Metrics, Data Visualization, Data Transformation, Data Communication, Data Integration",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist - Aviation\/Aerospace",
      "company":"The Patriot Group, Inc. (TPGI)",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-aviation-aerospace-at-the-patriot-group-inc-tpgi-3774080349",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Data Scientist \u201a\u00c4\u00ec Growing Aerospace Company\nWork for one of the most dynamic and fastest growing Aerospace companies in Texas. With a great leadership team, incredible employee appreciation and undeniable chances to grow \u201a\u00c4\u00ec look what we have to offer you!\nWork Schedule:\n9\/80 work schedule, in-office position, some flexibility may be considered.\nPay:\n$110-$130K annually plus benefits\nCompany Profile\nBased in Fort Worth Texas area, the company was founded with a vision of bringing advanced vertical lift solutions to the civil market.\nCompany has established a strong reputation as a technology innovator in vertical takeoff and landing (VTOL) aircraft design.\nCompany strategy incorporates three elements of the business: Science and Technology (S&T), Unmanned Aircraft Systems (UAS), and Sustainment Products and Services.\nMade up of highly experienced engineers and aerospace professionals that have come together as a team to create innovative designs, that use modern technology, that delivers visionary performance in the vertical lift environment.\nFeatures And Benefits\n9\/80 work schedule, in-office position, some flexibility may be considered.\nHealth Insurance Options\nCompetitive 401K with employer matching.\nIn-office position with work from home flexibility.\nRole You Will Play\nCompany is developing cutting-edge, algorithmic-based simulation, operational awareness, and mission planning capabilities to a wide variety of Dept of Defense (DoD) customers. Company specially selected team of industry partners\/academia including engineers, software developers and scientists develop algorithms, software integrated prototypes and solutions for Artificial Intelligence, Machine Learning, Mission Planning, and Operational Awareness.\nThe successful candidate will work on a team developing new code bases that are heavily object-oriented, extensible, and maintainable. The team follows Agile development processes and ensures fast and secure delivery of software services.\nResponsibilities\n: As a Senior Data Scientist, you will:\nWork with a team of data engineers, software developers, and data scientists to develop and deploy capabilities to address highly complex AI\/ML challenges.\nCollaborate with data and subject matter experts from customers to seek, understand, validate, interpret, and correctly use new data elements.\nLead a small university team of data engineers through an Agile development process, maintain schedules, and provide overall technical direction for successful completion of projects.\nExternally, maintain customer relationships and serve as a subject matter expert.\nBe the subject matter expert for the team in data science and algorithm development in a variety of fields including data transformation, predictive analytics, time series data, visualization, and advanced metrics.\nTake a holistic approach to algorithm development to ensure the most value added to the warfighter. This includes considering not just the algorithm itself, but the whole system including labels, software infrastructure, and user interface.\nBACKGROUND PROFILE\nMust Haves\nAt least 8 years of relevant experience.\nExpertise using Python to solve data science problems.\nExperience with data management pipeline technology\nSolid understanding of physics, linear algebra, statistics, algorithms, optimization, and\/or machine learning methods.\nDemonstrated performance in managing program schedules to successful program conclusion in an Agile environment.\nProven record interfacing with customers and developing external relationships.\nBe well equipped to take on various roles.\nBachelor\u201a\u00c4\u00f4s degree or higher in Engineering, Applied Mathematics, Physics, or a related field.\nNice To Haves\nExperience implementing cloud services, a plus.\nExperience evaluating the quality of advanced models, a plus.\nNatural language processing experience, a plus\nShow more\nShow less",
      "job_skills":"Python, Data engineering, Agile development, Objectoriented programming, Machine Learning, Data analytics, Data transformation, Timeseries data, Data visualization, Data management pipelines, Physics, Linear algebra, Statistics, Algorithms, Optimization",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Center Lead Engineer",
      "company":"Kforce Inc",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-lead-engineer-at-kforce-inc-3777072402",
      "search_city":"McKinney",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nKforce is immediately seeking an experienced Lead Data Center Engineer in support of our enterprise networking and cloud solutions client based in Richardson, TX. Summary: In this role, the Data Center Lead Engineer will work as part of the L&C Data Center Operations Team, which plans, operates, and maintains the L&C Data Center footprint globally, catering to tens of thousands of lab requests per year. They will also work with the wider L&C team to support IT professionals' learning and training needs in outstanding ways. We provide world class training, community outreach, educational events, technical documentation, and hands-on learning across all of the company's portfolio of solutions. We are passionate about education, learning and improving careers. The Data Center Lead Engineer will also work closely with Cisco product teams across the entire Cisco portfolio - including Networking, Security, Data Center, Collaboration, and Applications. Safe to say, you won't always be in a Data Center, though you'll feel right at home in one. Responsibilities:\nDedicated to maintaining a 'Source of truth' for the network through our NetOps Tooling\nGenerate first rate technical documentation of new, existing, evolving data center and network implementation\nOwn high and low visibility issues and be accountable for resolving them\nTroubleshoot & resolve incidents, providing excellent levels of clear communication\nInnovate - Identify and lead continuous improvement of systems, tools, and processes\nThe Engineer will plan, build and manage the existing footprint and expansion of all aspects of a data center including:\nPower, cooling, and equipment air flow management\nRack, Infrastructure, Cable Design & Management\nDevice Network & IP Management\nIssue Resolution Management of Infrastructure & Network\nAsset Management\nCapacity Management\nVendor Management\nCompliance Management\nData Center Policy Compliance\nRequirements\nCCNP\/CCIE certification (R&S and\/or DC)\n5+ years of experience in Data Center Operations & Production Network Operation roles\n3+ years of experience with various Operating Systems: Windows, Linux, and Cisco network operating systems\nStrong Data Center knowledge including Nexus Routing & Switching\nExperience operating and troubleshooting complex networks with segmentation and virtualization\nExperience with implementing dynamic routing with OSPF, EIGRP and BGP\nExperience with implementing client and site-to-site VPN solutions\nExperience with virtual machine networking with VMWare\nVMWare, ESXi, vCenter, and VM configuration, and operation experience\nExperience with Cisco ACI, DNA and automation with Ansible and Python\nAble to manage core routers, switches, firewalls, etc.\nSelf-starter who requires little guidance to achieve the goals of complex data center projects\nDeep and multifaceted technical expertise and enjoy working on a team and mentoring others\nSee the big picture even when analyzing multiple sophisticated factors under pressure, having an eye and a passion for the details\nExcellent verbal and written skills and hold yourself to high standards in your results and communication\nExperience in the following products\/solutions:\nCisco Nexus 2000, 3000, 5000, 7000, 9000\nCatalyst 9000 switches\nISR 4000 and 1000 routers\nASA and Firepower Firewalls\nUCS server management\nThe pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.\nWe offer comprehensive benefits including medical\/dental\/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.\nNote: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.\nThis job is not eligible for bonuses, incentives or commissions.\nKforce is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nSalary: $50 - $68 per hour\nShow more\nShow less",
      "job_skills":"Python, Ansible, VMWare, ESXi, Cisco Nexus, Cisco ACI, Cisco DNA, CSR, vCenter, NetOps, Cisco 9000, Catalyst 9000, ISR 4000, ISR 1000, ASA Firewalls, Firepower Firewalls, UCS Server management, Windows, Linux, Cisco network operating systems, CCNP, CCIE, OSPF, EIGRP, BGP, VLAN, VPN",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Analyst",
      "company":"FUJIFILM Diosynth Biotechnologies",
      "job_location":"College Station, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-at-fujifilm-diosynth-biotechnologies-3773361365",
      "search_city":"College Park",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"The work we do at FDB has never been more important\u201a\u00c4\u00eeand we are looking for talented candidates to join us. We are growing our locations, our capabilities, and our teams, and looking for passionate, mission-driven people like you who want to make a real difference in people\u201a\u00c4\u00f4s lives. Join FDB and help create the next vaccine, cure, or gene therapy in partnership with some of the most innovative biopharma companies across the globe. We are proud to cultivate a culture that will fuel your passion, energy and drive - what FDB call Genki.\nCollege Station, Texas may be a small, university town, but the lively cultural scene and local amenities make it a great place for families as well as those who want the ease of small-town life and the convenience of living close to the vibrant pulse of big cities. Eighty-seven percent of Texas' population lives within a 180-mile radius, so we are in the center of it all in Texas. And our site is nestled in the hub of innovation, representing a source of pride for the area.\nSummary:\nWorks under the supervision of the Data Analytics Manager or other data governance leadership appropriate for the scope of work. This role is responsible for data analytics and additional support of performance measures, ongoing measurement, data collection, reporting, data visualizations and information dissemination. Responsible for structuring the strategic design and maintenance of business intelligence applications. Identifies, researches, and resolves technical problems. Ensures that the use of data and business intelligence applications enhances business operations and decision making capabilities. Contributes to complex aspects of a project. Work is generally independent and collaborative in nature. Engages in data exploration exercises with a variety of complex business intelligence tools, requiring knowledge of relational database structures. Collaborates with other departments.\nExternal US\nEssential Functions:\nDevelop and execute on data analytics projects as assigned by the Data Analytics Manager\nUtilize company resources across departments and sites to curate data\nAnalyze data for trends and patterns\nGenerate reports and dashboards and transfer to super users\nTrain and provide technical support to super users\nCoordinate with other departments and sites to develop and implement new data collection models\nPerform data profiling to identify anomalies\nAll other duties as assigned\nRequired Skills & Abilities:\nCreate data models using tools using software applications such as Python, SAS, Alteryx, or equivalents for visualization in Tableau, Smartsheet, Power BI, or equivalent\nTranslate data into dynamic dashboards\nKnowledge of databases such as Microsoft SQL, MySQL, PostgreSQL, or equivalent\nWorking understanding of relational database design\nWorking understanding of statistics and mathematical models\nFamiliarity with data collection software and protocol\nExperience integrating new software and programs to data services\nAbility to prioritize multiple projects while still achieving deadlines\nExcellent analytical and forecasting ability\nStrong written and verbal communication skills\nProficient understanding of current data protection and privacy laws\nWorking Conditions & Physical Requirements:\nThe physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee is regularly required to:\nExperience prolonged sitting, some bending, stooping, and stretching.\nUse hand-eye coordination and manual dexterity sufficient to operate a keyboard, photocopier, telephone, calculator, and other office equipment is required.\nMinimum Qualifications:\nBachelor\u201a\u00c4\u00f4s degree preferably in Data or Computer Science, Engineering, Mathematics, Statistics, or other scientific field with 4 years of experience\nPreferred Qualifications:\nAdvanced degree and\/or certifications in data science, analytics, or computer science\nJoin us! FDB is advancing tomorrow\u201a\u00c4\u00f4s medicine, impassioning employees to chase the impossible and continually expand their potential. We are a company of emboldened goal seekers \u201a\u00c4\u00ec driven by an innate desire to better ourselves, our families, our workplace, our company, our community and the world at large.\nWe are an equal opportunity and affirmative action employer.\u201a\u00c4\u00d8 All qualified applicants will receive consideration without regard to race, color, national origin, sex, gender identity, sexual orientation, religion, disability, protected veteran status or any other characteristic protected by applicable federal, state or local law. If an accommodation to the application process is needed, please email FDBTHR@fujifilm.com or call 979-431-3500.\nTo all agencies: Please, no phone calls or emails to any employee of FUJIFILM about this requisition. All resumes submitted by search firms\/employment agencies to any employee at FUJIFILM via-email, the internet or in any form and\/or method will be deemed the sole property of FUJIFILM, unless such search firms\/employment agencies were engaged by FUJIFILM for this requisition and a valid agreement with FUJIFILM is in place. In the event a candidate who was submitted outside of the FUJIFILM agency engagement process is hired, no fee or payment of any kind will be paid.\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Visualization, Tableau, Smartsheet, Power BI, Python, SAS, Alteryx, Microsoft SQL, MySQL, PostgreSQL, Statistics, Mathematical Models, Data Collection, Data Protection, Data Privacy",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"IDR, Inc.",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-idr-inc-3789737121",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"IDR is seeking a\nData Scientist\nto join one of our top clients in Las Colinas, TX. This is a long-term, hybrid opportunity! If you are looking for an opportunity to join a large organization and work within an ever-growing team-oriented culture, please apply today!\nResponsibilities For The Data Scientist\nThe Data Scientist will join the project management office.\nThe Data Scientist will focus on the following areas: Statistics, Time Series Analysis \/ Forecasting, Machine Learning Algorithms, Mathematical Optimization.\nThe ideal candidate will be responsible for integrating new data sources into the backend platform, creating custom data science models from scratch using the integrated data sources as well as maintaining existing data science tools.\nAdditionally, the candidate should be comfortable building custom data science models based on large datasets as well as financial modeling based on structured data and hybrid models that consider both.\nThe Data Scientists will provide leadership with updates on ongoing data analytics initiatives in a layman-friendly, business-oriented manner.\nRequired Skills For The Data Scientist\n3-5 years experience in Data Science and Analytics\n3-5 years experience using Python and SQL\nExperience with data visualizations and data models in one of the following platforms: Power BI, Tableau, Python Visuals\nExperience communication with executive leadership\nShow more\nShow less",
      "job_skills":"Data Science, Data Analytics, Statistics, Time Series Analysis, Forecasting, Machine Learning Algorithms, Mathematical Optimization, Python, SQL, Power BI, Tableau, Python Visuals",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Inspiregence Inc.",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-inspiregence-inc-3784017878",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Role :\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Senior Data Scientist\n12+ years of experience.\nLocation :\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Irving, TX, Basking Ridge, NJ, Alpharetta, GA\nDuration:\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Long Term Contract\nResponsibilities:\n\u201a\u00c4\u00a2 Support the various AI\/Client models that need to be deployed to production\n\u201a\u00c4\u00a2 Troubleshoot various activities and rectify any problems that arise in the end-to-end model pipeline\n\u201a\u00c4\u00a2 Test and validate AI Models. Deploy and manage models throughout the end to end lifecycle.\n\u201a\u00c4\u00a2 Industrialize the model pipeline which includes Testing & validation of the model pipeline\n\u201a\u00c4\u00a2 Be part of the requirements for new enhancements in model\/solution\n\u201a\u00c4\u00a2 Propose new ideas\/solutions that can be helpful for the project overall\n\u201a\u00c4\u00a2 Analyze and understand problems and issues to convert these insights into system requirements\n\u201a\u00c4\u00a2 Build scalable and high performance Machine Learning and Data Mining algorithms\nMUST HAVE SKILLS :\n(Most Important): Python, PySpark, SQL, Deep Learning, A\/B Testing, Critical Thinking\nDESIRED SKILLS:\nNeural Network\nShow more\nShow less",
      "job_skills":"Python, PySpark, SQL, Deep Learning, A\/B Testing, Critical Thinking, Neural Networks, Machine Learning Algorithms, Data Mining Algorithms",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Scientist",
      "company":"NiSource",
      "job_location":"Flower Mound, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-scientist-at-nisource-3701441456",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description\nLead Data Scientist\nFull Time Perm\nLocation:\nHybrid or Remote\nThe Data Science organization at NiSource is the recently established advanced analytics arm of the company. We are building a talented team that is leveraging best-in-class tools and techniques to solve our company's highest value analytics use cases. With a strong team culture and commitment to innovative problem solving, the solutions that we build will be a competitive advantage for our company for many years to come.\nThis position will report up through the Enterprise Data & Analytics Organization and function as a technical consultant in Data Science organization in order to:\nBuild and run advanced analytics models leveraging Machine Learning and Statistics\nPerform data exploration and data mining\nServe as an expert in translating complex data into key strategy insights and valuable actions\nDiscover business narratives told by the data and present them to other scientists, business stakeholders, and managers at various levels\nDevelop and test heuristics\nCreate business intelligence, dashboards, visualizations, and\/or other advanced analytics reports to adequately tell the business narrative and offer recommendations that are practiced, actionable, and have material impact, in addition to being well-supported by analytical models and data.\nResponsibilities\nYour responsibilities may include, but are not limited to:\nServe as a mentor and coach to other Data Scientists in the organization\nDesign new processes and build large complex data sets\nConduct statistical modeling and experiment design\nTest and validate predictive models\nConduct scalable data research on and off the cloud\nMinimum Qualifications\n7+ years of experience as a data scientist, data analyst, or similar role\n7+ years of experience coding in statistical and database languages (SQL, Python, R, Spark, etc)\n7+ years of experience using machine learning such as NLP, image recognition, boosted trees, or related duties\nPreferred Qualifications\nMaster\u201a\u00c4\u00f4s or advanced degree in statistics, data science, physics, mathematics, engineering, computer science, or comparable discipline\nExperience working with data engineers and architects\nExperience leading a team of analytics professionals and aligning to a common goal\nKnowledge of Data governance techniques in the analytics space\nDisclaimer\nThe preceding description is not designed to be a complete list of all duties and responsibilities required of the position.\n#DataSci #DS #DataScientist #Remote #Ohio #Columbus #OhioMeansJobs #SQL #Python #Spark #MachineLearning #ML #DataGoverance #NLP\nInclusion & Diversity\nValue inclusion within your day to day responsibilities by respecting others perspectives\/convictions, engaging others opinions, creating a safe environment where people, ideas, and opinions are valued within your Team\/Customers and external partners.\nRespect and take into consideration diversity within your Team\/Customers and external work partners by valuing different world views, challenges, and cultures that represent all walks of life and all backgrounds.\nTreat others with respect and consideration. Actively participate in creating and contributing to a positive work environment.\nEqual Employment Opportunity\nNiSource is committed to providing equal employment opportunities in each of its companies to all employees and applicants for employment without regard to race, color, religion, national origin or ancestry, veteran status, disability, gender, age, marital status, sexual orientation, gender identity, genetic information, or any protected group status as defined by law. Each employee is expected to abide by this principle.\nBy applying, you may be considered for other job opportunities.\nSafety Statement\nPromote a safe work environment by actively participating in all aspects of our employee safety program. Report any unsafe conditions and take actions to prevent personal injuries. Support our interdependent safety culture by ensuring the safety of your co-workers. Stay focused on the task at hand and promote productivity through good work habits.\nPosting Start Date\n2023-08-22\nPosting End Date (if Applicable)\nPlease note that the job posting will close on the day before the posting end date.\nShow more\nShow less",
      "job_skills":"Machine Learning, Statistics, Data Mining, Data Exploration, Data Visualization, Data Governance, NLP, Image Recognition, Boosted Trees, Python, R, SQL, Spark, Data Analytics, Data Science",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Scientist",
      "company":"McKesson",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-scientist-at-mckesson-3781664915",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve \u201a\u00c4\u00ec we care. What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow\u201a\u00c4\u00f4s health today, we want to hear from you.\nPosition Description\n:\nMcKesson Technology Enterprise Analytics is seeking a Lead Data Scientist that is passionate about developing machine learning applications that ensure patients receive the medications they need, when they need them; improve quality of care for oncology patients; and exemplify operational excellence so that the business can focus on what matters most, creating value for our customers.\nKey responsibilities:\nDevelop, design, build, and oversee data science solutions to provide predictive insights that further McKesson\u201a\u00c4\u00f4s vision to improve care in every setting.\nDrive adoption of best-in-class capabilities, including Deep Learning, Natural Language Processing, Large Language Models and Next Best Action Recommenders.\nDirect in-house data scientists and consulting teams; Provide analytics leadership; Provide machine learning and statistical expertise. Serve as an advisor for data scientists across the Enterprise.\nCollaborate with multi-disciplinary team members (data scientists, data engineers and business analysts); Manage business stakeholder relationships to drive action and value from data science insights.\nCollaborate with multi-disciplinary team members; Manage business stakeholder relationships to drive action and value from data science insights;\nRecruit top talent data scientists to join our team.\nCommunicate strategy and results to technical and non-technical audiences; Develop and maintain strong relationships with key stakeholders, partners, and internal clients.\nSolve problems from the business point of view, define KPIs, build and execute solid analytics work plans, gather and organize large and complex data assets, perform relevant analyses (data exploration and statistical modeling), automate work streams, foster teamwork in interactions, develop client relationships with business stakeholders, and communicate hypotheses and findings in a structured way.\nMinimum Requirements\n:\nMaster\u201a\u00c4\u00f4s degree +6 years of work experience or PhD +3 years, with relevant experience providing advanced analytics solutions The degree should be in computer science, applied mathematics, statistics, machine learning, or a related data centric-technical field.\nCritical Skills\n:\nMentorship experience with machine learning engineers\/data scientists in business or scientific research settings.\nIndustry experience using TensorFlow, Pytorch and open source software libraries to develop Representation Machine Learning Systems; e.g. Next-Best-Action, Recommendation systems; Deep Learning Neural Networks; Image understanding; Document classification and keyword extraction.\nExperience in core data science and predictive analytics methods: Statistics (t-tests, Poisson process), Segmentation and clustering techniques, predictive modeling: e.g. regression, classification, Time Series analysis: e.g. ARIMA, Traditional machine learning methods: e.g. Random Forest, ensemble model techniques, Optimization: e.g. linear programming.\nExperience in SQL, relational databases: e.g. Snowflake, HANA, Microsoft SQL.\nExpert level skill in a programming language: Python + additional languages (e.g. Java, C\/C++).\nExperience with Linux, Shell scripting: e.g. Bash.\nFamiliarity with a data visualization tool: e.g. Tableau, Power BI, R.\nAbility to process and synthesize complex data.\nAbility to communicate effectively and professionally, delivering impactful solutions and presenting work in a concise and thoughtful manner.\nDesired Skills\n:\nExperience with cloud computing data platforms: e.g. Azure, GCP.\nExperience with distributed computing: e.g. Hadoop, Spark.\nExperience developing open-source machine learning libraries.\nDesire to work in a project-based environment to address business .issues and implement business solutions..\nDriven by making impact with technical and data science expertise, acute strategic and analytical skills; Highly organized with the ability to multitask and prioritize workload.\nSelf-motivated, demonstrated ability to manage engagements, serve as a champion of Data Science and able to act as a full member of project team.\nExperience in applied analytics for business problem solving, demand forecasting, analytics solution for pricing, loyalty program effectiveness, customer segmentation, customer LTV maximization, cost and profit analysis, CRM management etc.\nAt McKesson, we care about the well-being of the patients and communities we serve, and that starts with caring for our people. That\u201a\u00c4\u00f4s why we have a Total Rewards package that includes comprehensive benefits to support physical, mental, and financial well-being. Our Total Rewards offerings serve the different needs of our diverse employee population and ensure they are the healthiest versions of themselves. For more information regarding benefits at McKesson, please click here.\nAs part of Total Rewards, we are proud to offer a competitive compensation package at McKesson. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered.\nOur Base Pay Range for this position\n$147,500 - $245,800\nMcKesson is an Equal Opportunity\/Affirmative Action employer.\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.Qualified applicants will not be disqualified from consideration for employment based upon criminal history.\nMcKesson is committed to being an Equal Employment Opportunity Employer and offers opportunities to all job seekers including job seekers with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to Disability_Accommodation@McKesson.com. Resumes or CVs submitted to this email box will not be accepted.\nCurrent employees must apply through the internal career site.\nJoin us at McKesson!\nShow more\nShow less",
      "job_skills":"Machine learning, Deep learning, Natural language processing, Next best action recommenders, Data science, Python, SQL, Linux, Tableau, Power BI, R, Snowflake, HANA, Microsoft SQL, Java, C\/C++, Bash, Hadoop, Spark, Azure, GCP, TensorFlow, Pytorch",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Scientist",
      "company":"Vistra Corp.",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-scientist-at-vistra-corp-3774883560",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"If you have what it takes to become part of the Vistra family and would like to start a promising career with a global leader, take a look at the exciting employment opportunities that are currently available and apply online.\nJob Summary\nThe Lead Data Scientist role takes end-to-end ownership of achieving business objectives through the development, application and deployment of advanced analytical (prescriptive, predictive, machine learning, AI) models. In order to succeed in this role, the applicant should be eager to take on challenges and responsibility of increasing complexity, have impeccable attention to detail, be fully accountable for business outcomes, be able to improvise and solve problems in the absence of perfect data, be able to simplify and communicate complex results to key business stakeholders via presentation and visualization tools and mentor and coach other Data Scientists on the project team.\nJob Description\nKey\nAccountabilities\nDevelop and implement advanced analytics solutions (predictive, prescriptive models, machine learning algorithms, AI models) to support \/ optimize business outcomes\nLead advanced analytical initiatives to support key strategic priorities and focus areas.\nProvide actionable business insights via experimental design and testing; leverage learnings to drive further optimization in campaign performance\nLead working sessions with cross-functional business partners to identify gaps and understand areas of opportunity\nDemonstrate tangible business value from his\/her models and ensure that stakeholders are aligned with expected and actual results\nMaintain balance between pragmatic and deeply rigorous solutions depending on business context\nStaying up to date on new machine learning techniques and approaches to data science\nAbility to lead a cross-functional project team and provide direction and coaching to junior analysts\nLead a project team from initial analysis to readying a model for production\nProvide technical guidance and mentorship on analyses produced by the team\nStructure and present analyses to executives and key business stakeholders\nMust be an independent thinker, with a strong bias towards action\nActively participate in cross-functional initiatives, providing expertise, offering original perspectives and challenging conventional views\nHandle and appropriately prioritize multiple overlapping projects\nEducation, Experience & Skill Requirements\nMasters\/+ degree in Applied Mathematics, Operations Research, Industrial Engineering, Economics, Statistics or a related quantitative discipline\n5+ years of experience in the areas of developing predictive & prescriptive analytical models and Machine Learning & Optimization algorithms to improve business performance\nSolid theoretical background in mathematics, statistics, database technology, mathematical optimization, graph algorithms and related disciplines\nStrong computer programming skills in a high-level programming language (Python, SQL, SAS)\nWork with Big \/ Fast data, creating scalable, robust and accurate augmented intelligent solutions\nDesign and run experiments, research new algorithms, and work closely with stakeholders to deploy our algorithms and models into practice\nStrong leadership & project management skills\nInnovative problem solver who can handle both high breadth & depth of advanced analytics problems\nExperience in a customer-focused role and building relationships with key internal stakeholders\nExcellent communication skills \u201a\u00c4\u00ec oral and written\nKey\nMetrics\nEffectively lead large cross-functional work teams within Vistra, External Business Partners and Regulatory workgroups with the goal to greatly improve work processes related to the Retail customer retention and growth\nServes as a SME and provides guidance and work direction to team members\nWorks under minimal supervision\nEnsure continuous improvement and optimization of processes for maximum team efficiency\nHigh level of initiative in terms of learning the business and designing valuable analyses\nExcellent consulting, negotiating, consensus building and conflict resolution skills\nEnsure continuous improvement and optimization of processes for maximum team efficiency\nJob Family\nMarketing\nCompany\nVistra Corporate Services Company\nLocations\nIrving, Texas\nTexas\nWe are a company of people committed to: Exceeding Customer Expectations, Great People, Teamwork, Competitive Spirit and Effective Communication. If this describes you, then apply today!\nIf you currently work for Vistra or its subsidiaries, please apply via the internal career site.\nIt is the policy of the Company to comply with all employment laws and to afford equal employment opportunity to individuals in all aspects of employment, including in selection for job opportunities, without regard to race, color, religion, sex, sexual orientation, gender identity, pregnancy, national origin, age, disability, genetic information, military service, protected veteran status, or any other consideration protected by federal, state or local laws.\nIf you are an individual with a disability and need assistance submitting an application or would like to request an accommodation, please email us at assistance@vistraenergy.com to make a request.\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, AI, Predictive Modeling, Prescriptive Modeling, Optimization Algorithms, Mathematics, Statistics, Database Technology, Mathematical Optimization, Graph Algorithms, Python, SQL, SAS, Big Data, Fast Data, Augmented Intelligence, Experiment Design, Leadership, Project Management, Communication, CustomerFocused Role, Consulting, Negotiating, Consensus Building, Conflict Resolution",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Amtex Systems Inc.",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-amtex-systems-inc-3595300248",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"FT Worth Texas - Onsite\/Hybrid\nContract\nThe Data Scientist will assist in our efforts to expand our capabilities within Positive Train Control analytics. This role will use analytical, statistical, and programming knowledge to collect, analyze and interpret large data sets. Experienced candidate needs to be innovative and show proven ability to work independently on big projects. Candidate should be very comfortable working with unstructured data and be able to demonstrate their abilities.\nRequired Qualifications\nAble to adapt to fast-paced working environment.\nComfortable structuring text data utilizing regex\nSQL experience is a must\nProgramming background and exposure to python is required.\nAble to build analytics solution from scratch. Includes data exploration, extraction, cleaning, transformation, modeling, testing and implementation.\nMust have a clear understanding and implementation of different machine learning algorithms such as logistic regression, decision trees, SVM, Na ve Bayes, KNN, neural networks, gradient descent, Random forest, etc.\nExpertise in building machine learning algorithms using at least one of the following languages: Python, R and Scala\nAdditional Preferred Qualifications\nBachelor's degree from an accredited university in Computer Science, Statistics, Applied Mathematics, Analytics, or related field.\n3 years+ experience in data analytics, data mining and statistical analysis.\nExcellent pattern recognition and predictive modeling skills.\nExperience working with structured and unstructured data.\nAbility to understand business requirements, collaborate with team, provide ideas, and clearly present new findings\/ solutions.\nStrong understanding of basic statistics, linear algebra, and calculus.\nExposure to any reporting tool. Tableau is preferred.\nExperience working with natural language processing and text mining.\nOpen to learn new tools and technologies.\nShow more\nShow less",
      "job_skills":"Python, R, Scala, SQL, Regex, Machine Learning Algorithms, Tableau, Data Analytics, Data Mining, Text Mining, Natural Language Processing, Reporting Tools, Data Exploration, Data Extraction, Data Cleaning, Data Transformation, Data Modeling, Data Testing, Data Implementation, Data visualization, Business Requirements, Data Interpretation",
      "Category":"Backend Development"
  },
  {
      "job_title":"R&D Data Scientist",
      "company":"Harnham",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/r-d-data-scientist-at-harnham-3770795265",
      "search_city":"Layton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"R&D DATA SCIENTIST\n$165,000 - $185,000 + BONUS + BENEFITS\nHYBRID \u201a\u00c4\u00ec OFFICE LOCATED IN HOUSTON, TX\nThis growing startup in Houston, Texas is looking to fight climate change with their products. If you have a broad understanding of biology, chemistry, of chemical engineering and are passionate about green chemistry and the environment, this role may be for you!\nTHE ROLE\n- Collaborate and build strong relationships with R&D teams to understand their challenges, goals, and objectives\n- Utilize advanced sequential experimental design to execute rigorous experiments\n- Implement Bayesian Optimization methods to enhance the chemical innovation processes\n- Utilize Python to make sense of complex data\nSKILLS AND EXPERIENCE\n- A Master's or PhD degree in Chemical Engineering, Biology, Chemistry, or a closely related area of study\n- Proficiency in Python and SQL\n- Broad comprehension of chemical and biological processes\n- Deep understanding of Bayesian Optimization, specifically knowing its key equations, understanding it end to end, and being able to modify these models\n- Ability to work with diverse teams and provide recommendations to both technical and non-technical stakeholders\nBENEFITS\n$165,000 - 185,000 Base Salary + Bonus + Benefits + Relocation for those not already in the Greater Houston Area\nHOW TO APPLY\nPlease register your interest by sending your Resume to Emma Spagnola via the Apply link on this page and at emmaspagnola@harnham.com.\nShow more\nShow less",
      "job_skills":"Chemical Engineering, Biology, Chemistry, Green Chemistry, Python, SQL, Bayesian Optimization, Experimental Design, Data Analysis",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst (Bangkok Based, relocation provided)",
      "company":"Agoda",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-bangkok-based-relocation-provided-at-agoda-3750111635",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"About Agoda\nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u201a\u00c4\u00d8enhancing the ability for our customers to experience the world.\nGet to Know our\nTeam:\nThe Performance Marketing Team of Agoda is a world leader in online marketing. This department is highly data-driven and focused on developing at-scale marketing programs that improve the lifetime value of Agoda customers through measurable marketing programs and channels. The team is a blend of the best analysts, marketing strategists, and data scientists in the world. The marketing leadership at Agoda have deep experience in data science, product, strategy, and other marketing fields and have built an organization that thrives on data, creative ideas, and technology. The Performance Marketing Team also fosters a great learning environment. You will be able to learn and grow by working closely with experts from a variety of backgrounds from all over the world.\nIn this Role, you\u201a\u00c4\u00f4ll get\nto:\nSearch: Experiment with text ads, bidding, and campaign structures on Google, Bing, Baidu, Naver, and other search engines. Adapt to new product features and roll out changes from successful tests\nDisplay: Test, analyze, and optimize campaigns on Facebook, Twitter, Instagram, and others\nModeling: Analyze the vast amounts of data generated by experiments, develop models we can use for optimization, and build dashboards for account managers\nWhat you\u201a\u00c4\u00f4ll Need to\nSucceed:\nBachelor\u201a\u00c4\u00f4s Degree or higher from top university in a quantitative subject (computer science, mathematics, engineering, statistics or science)\nAbility to communicate fluently in English\nExposure to one or more data analysis packages or databases, e.g., SAS, R, SPSS, Python, VBA, SQL, Tableau\nGood numerical reasoning skills\nProficiency in Excel\nIntellectual curiosity and analytical skills\nIt\u201a\u00c4\u00f4s Great if you\nHave:\nExperience in digital marketing\nAcademic research experience\n#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz  #baku #minsk #brussels #antwerp #ghent #charleroi  #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra  #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester  #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner\nEqual Opportunity Employer\nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u201a\u00c4\u00f4s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\nShow more\nShow less",
      "job_skills":"python, data analysis, data mining, Tableau, SQL, data science, pandas, data visualization, data analytics, statistics, business intelligence, machine learning, Microsoft SQL Server, R, artificial intelligence, analytics, finance",
      "Category":"Backend Development"
  },
  {
      "job_title":"Chemical Data Scientist",
      "company":"Harnham",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/chemical-data-scientist-at-harnham-3771191263",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"CHEMICAL DATA SCIENTIST\nHOUSTON, TX -- HYBRID\n$160,000 - $180,000 + BONUS + BENEFITS\nThis growing startup in Houston is looking to fight climate change with its products. If you have a broad understanding of biology, chemistry, of chemical engineering and are passionate about green chemistry and the environment, this role may be for you!\nTHE ROLE\nCollaborate and build strong relationships with R&D teams to understand their challenges, goals, and objectives\nUtilize advanced sequential experimental design to execute rigorous experiments\nImplement Bayesian Optimization methods to enhance the chemical innovation processes\nUtilize Python to make sense of complex data\nYOUR SKILLS AND EXPERIENCE\nYour skills include:\nPhD\/Masters in Chemical Engineering, Biology, Chemistry or related fields\nIndustry experience in Python and SQL\nBroad comprehension of chemical and biological processes\nDeep understanding of Bayesian Optimization - specifically key equations, model modification, and end-to-end understanding.\nAbility to work with diverse teams and provide recommendations to both technical and non-technical stakeholders\nTHE BENEFITS\nSalary range of $160,000-$180,000 + Bonus\nComprehensive medical, dental, vision, and 401k\nShow more\nShow less",
      "job_skills":"Chemical Engineering, Biology, Chemistry, Green Chemistry, Python, SQL, Bayesian Optimization, Experimental Design, Data Analytics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Forthea - Digital Marketing Agency",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-forthea-digital-marketing-agency-3641771299",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Forthea is an award-winning digital marketing agency that improves lead generation for clients by focusing on superior data analytics and creative executions that produce measurable results. Forthea's rock-solid commitment to core values and sustained business excellence has led to successful partnerships with a variety of B2B and B2C clients around the world. Forthea was founded in 2006 in Houston, where it maintains its U.S. corporate headquarters.\nForthea has been recognized as one of the best places to work in Houston, one of the fastest-growing companies in Houston, and one of the largest Houston-area advertising agencies. Forthea President Christopher Pappas has been recognized as one of Houston's top young business leaders.\nWe're seeking a Data Scientist with a marketing background who will be a member of our analytics team and help with needs across all our clients. This person will lead the creation of various advanced marketing models. They will also be responsible for applying advanced analytics methods and algorithms for identifying trends and solutions for our clients.\nKey Responsibilities:\nAnalyze clickstream data on eCommerce website to optimize conversion rates\nWork closely with various teams by providing data visualization around business and functional performance.\nEnsure up-to-date dashboard information highlighting critical areas for decision making.\nProvide training to users on the use of the dashboards.\nProvide monthly \/ quarterly reports on KPI's using various software (Excel, Power BI, SQL, R, Python, etc.).\nAutomate data gathering and curation of all data sources\nPerform other duties and projects as assigned, related to data analytics\nLead technical development of cutting-edge analytics and decision support tools\nAble to partner with various teams and help with storytelling to clients\nWork with datasets and develop solutions (i.e., methodology and algorithms) for problems.\nSolve non-routine, inter-disciplinary analysis problems by applying analytical methods as needed.\nRequirements:\nMS or higher degree in Industrial Engineering, Chemical Engineering, Computer Science, Statistics or Operations Research with a specialization in data science or analytics\n3-5+ years of relevant industry experience\nStrong programming skills in Python or at least one major programming language\nDemonstrated ability to follow software development best practices\nExperience with data visualization\nVery good knowledge of MS Office\nStrong analytical and problem-solving skills\nShow more\nShow less",
      "job_skills":"Data Science, Marketing, Python, R, SQL, Power BI, Excel, Data Visualization, Machine Learning, Software Development, Data Analysis, Data Analytics, Data Curation, Dashboard Creation, Decision Support Tools, Storytelling, Algorithms",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior ML\/NLP Data Scientist",
      "company":"Ayata",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-ml-nlp-data-scientist-at-ayata-3660337552",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Ayata\nis developing its Prescriptive Analytics\u00ac\u00c6 software by integrating the latest Artificial Intelligence (AI) and related technologies. We are looking for people with multi-disciplinary skills, especially in software design and artificial intelligence, who can write solid clean code and who are excited about applying those skills to build industrial strength software. You will be part of a multi-disciplinary team working to design, develop and implement our unique software. Your contributions will directly impact the success of the company.\nJob Responsibilities And Duties\nAyata\nis looking for\nAI Scientist\nwho will develop AI techniques for business applications in various industries and build cloud-based AI software for predictive analytics business solutions.\nResponsibilities\nAI technique development, providing methodology, strategy, ideas, architect, and solutions for real-word, industrial-scale and mission-critical business operations\nBuild and integrate AI technique components into a full-functioning AI business software\nInteract with business clients, understand business requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients\nUnderstand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering\nDocument data dictionary, data understanding, modeling strategy and approaches, and build company\u201a\u00c4\u00f4s knowledge base of data and models\nCommunicate effectively with team members, management, and clients\nRequirements\nPh.D. degree in computer science, or mathematics\/statistics\/physics or engineering\n3-5 years of experience in machine learning\/AI technology and software development\nNatural Language Processing (NLP) Information retrieval and information extraction\nDigital Image Processing experience including OpenCV, OCR experience to convert images to text\nExcellent hands-on code development skills in Python\nProven ability as a quick learner\nAdditional Qualifications\nExpertise in ETL is a plus (Spark, Hadoop, SQL) in big data environments\nFront-end software development experience is a plus\nThis position is remote at this time. When we are over the Covid concerns, Ayata may move to a flexible schedule where working out of an office could be requested at times.\nYou must have a PHD to be considered for this position.\nBenefits\nCompensation package (base salary + performance bonus + stock options) commensurate with experience.\nIndustry (tech\/software industry) standard benefits package - medical, dental, vision, 401(k) plan, work-from-home (if applicable), flexible holidays, and more.\nShow more\nShow less",
      "job_skills":"Artificial Intelligence, Prescriptive Analytics, Machine Learning, Software Design, Solid Clean Code, Natural Language Processing, Information Retrieval, Information Extraction, Digital Image Processing, OpenCV, OCR, Python, Hadoop, SQL, ETL, Spark, Frontend Software Development",
      "Category":"Backend Development"
  },
  {
      "job_title":"Staff Scientist - Data Science",
      "company":"Baylor College of Medicine",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/staff-scientist-data-science-at-baylor-college-of-medicine-3758724700",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Title: Staff Scientist - Data Science\nDivision: Surgery\nSchedule: Monday - Friday, 8:00 a.m. - 5:00 p.m.\nWork Location: Houston, TX\nSalary Range: Hiring up to $87,149\nFLSA Status: Exempt\nRequisition ID: 17739\nSummary\nThe Office of Surgical Research (OSR) within the Michael E. DeBakey Department of Surgery is seeking a Staff Scientist to develop advanced analytic tools (data mining, machine learning, and artificial intelligence) for research projects using surgical data. The Staff Scientist will collaborate with research faculty and other research personnel to design and conduct research experiments using machine learning algorithms and creating predictive models. The ideal candidate must demonstrate a robust background in data science and machine learning, encompassing the application of statistical methods, the creation of predictive models, and the development of machine learning algorithms. Proficiency in Python, MATLAB, and R, combined with experience in signal and image analysis, as well as familiarity with electronic health data, will be distinct advantages.\nJob Duties\nPlan, direct, and conduct research projects related to surgical data.\nCollect, clean, and preprocess structured and unstructured data from various sources to build high-quality datasets for analysis.\nAnalyze large amounts of data to find patterns and solutions.\nDevelop prediction systems and machine learning algorithms to select features, create and optimize classifiers.\nDesign and conduct experiments to validate findings.\nPrototype, troubleshoot, and fine-tune machine learning models for outcome predictions relevant to surgery.\nEvaluate machine learning training using tools such as precision-recall metrics, receiver-operator curves, and confusion matrices.\nPresent data to investigators.\nAuthor scientific manuscripts.\nMinimum Qualifications\nDoctoral Degree. Experience may not be substituted in lieu of degree.\nThree years of post doctoral research experience.\nBaylor College of Medicine is an Equal Opportunity\/Affirmative Action\/Equal Access Employer.\n17739\nSN\nShow more\nShow less",
      "job_skills":"Data Mining, Machine Learning, Artificial Intelligence, Python, MATLAB, R, Signal Analysis, Image Analysis, Electronic Health Data, Data Collection, Data Cleaning, Data Preprocessing, Data Analysis, Predictive Modeling, Feature Selection, Classifier Optimization, Experiment Design, Experiment Validation, Model Prototyping, Model Troubleshooting, Model Finetuning, PrecisionRecall Metrics, ReceiverOperator Curves, Confusion Matrices, Data Presentation, Scientific Writing",
      "Category":"Backend Development"
  },
  {
      "job_title":"job_title",
      "company":"company",
      "job_location":"job_location",
      "job_link":"job_link",
      "search_city":"search_city",
      "search_country":"search_country",
      "job level":"job level",
      "job_type":"job_type",
      "job_summary":"job_summary",
      "job_skills":"job_skills",
      "Category":"Other"
  },
  {
      "job_title":"Data Science (Senior - Advisor)",
      "company":"Halliburton",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-science-senior-advisor-at-halliburton-3783165137",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job description:\nHalliburton Multi-Chem\nis currently looking for an R&D Data Scientist who possesses analytical, statistical, and programming skills to collect, analyze, and interpret large data sets, using this information to develop data-driven solutions to business challenges. The R&D Data Scientist has a strong experience using a variety of data mining \/ data analysis methods, and a variety of data tools to build and implement models. Must have a proven ability to drive technology development and business results from data-based information by working with computational and data scientists as well as business domain experts across Engineering, Chemistry, Product Management, and Sales.\nResponsibilities:\nWork with R&D, and Technology stakeholders to identify opportunities for leveraging analytical and product performance data to drive business solutions.\nMine and analyze data to drive optimization and improvement of product testing methods.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize product performance, customer experiences, revenue generation, and margins optimization.\nDevelop processes, reports, and dashboards (e.g., Power BI) to monitor and analyze model performance and data accuracy.\nQualifications:\nCompletion of an undergraduate degree in STEM and 4+ years of related experience is required. Master\u201a\u00c4\u00f4s degree in Chemistry or Chemical Engineering is preferred.\nBasic understanding of oil & gas operations and processes.\nBasic understanding of oilfield chemicals, laboratory testing methods, quality control, etc.\nAdvanced coding skills and experience with: Python, SQL, Power Query (Power BI), etc.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.).\nKnowledge of advanced statistical techniques and concepts and demonstrated experience in their application.\nExcellent written and verbal communication skills for coordinating across teams.\nCandidates having qualifications that exceed the minimum job requirements will receive consideration for higher-level roles given (1) their experience, (2) additional job requirements, and\/or (3) business needs. Depending on education, experience and skill level, a varity of job opportunities might be available from the Senior Data Scientist, Principal Data Scientist up to the Advisor Data Scientist\nProfile description:\nHalliburton Multi-Chem\nis currently looking for an R&D Data Scientist who possesses analytical, statistical, and programming skills to collect, analyze, and interpret large data sets, using this information to develop data-driven solutions to business challenges. The R&D Data Scientist has a strong experience using a variety of data mining \/ data analysis methods, and a variety of data tools to build and implement models. Must have a proven ability to drive technology development and business results from data-based information by working with computational and data scientists as well as business domain experts across Engineering, Chemistry, Product Management, and Sales.\nResponsibilities:\nWork with R&D, and Technology stakeholders to identify opportunities for leveraging analytical and product performance data to drive business solutions.\nMine and analyze data to drive optimization and improvement of product testing methods.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize product performance, customer experiences, revenue generation, and margins optimization.\nDevelop processes, reports, and dashboards (e.g., Power BI) to monitor and analyze model performance and data accuracy.\nQualifications:\nCompletion of an undergraduate degree in STEM and 4+ years of related experience is required. Master\u201a\u00c4\u00f4s degree in Chemistry or Chemical Engineering is preferred.\nBasic understanding of oil & gas operations and processes.\nBasic understanding of oilfield chemicals, laboratory testing methods, quality control, etc.\nAdvanced coding skills and experience with: Python, SQL, Power Query (Power BI), etc.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.).\nKnowledge of advanced statistical techniques and concepts and demonstrated experience in their application.\nExcellent written and verbal communication skills for coordinating across teams.\nCandidates having qualifications that exceed the minimum job requirements will receive consideration for higher-level roles given (1) their experience, (2) additional job requirements, and\/or (3) business needs. Depending on education, experience and skill level, a varity of job opportunities might be available from the Senior Data Scientist, Principal Data Scientist up to the Advisor Data Scientist\nWe offer:\nWe invest in our employees through competitive compensation plans, health benefits, work-life programs, and reward and incentive plans. We have the right people to develop the right technologies and bring innovative solutions to the industry \u201a\u00c4\u00ec and we value those people as an unmatched competitive advantage.\nShow more\nShow less",
      "job_skills":"Data mining, Data analysis, Python, SQL, Power Query, Power BI, Predictive modeling, Machine learning, Clustering, Decision tree learning, Artificial neural networks, Statistical techniques",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Patterson-UTI Drilling",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-patterson-uti-drilling-3764415406",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Patterson-UTI\u201a\u00c4\u00f4s Data Science team is a growing group of energetic, passionate individuals working to improve and inform the Company through data. We work exclusively with the Drilling Automation team to help design, evaluate, and improve novel drilling automation technology.\nSome example projects that we are applying analytics and data science to include:\nModeling greenhouse gas emissions from the rig fleet to reduce environmental impact and improve reporting\nDesigning drilling advisory systems to improve drilling efficiency\nDeveloping automated monitoring, detection, and alerting of operational events\nBuilding models to predict failure of downhole and surface equipment\nThe Senior Data Scientist will be responsible for both leading Data Scientists and performing individual work. She \/ he will manage analytics projects of varying complexity, along with coaching and mentoring more junior individuals on the team. Projects include creating actionable reports, algorithms, and models that will directly impact the development of new automation technologies. The candidate will be involved in all aspects of the project life cycle, including interviewing stakeholders, cleaning and analyzing data, generating visuals and reports, and presenting results. The ideal candidate would be a team player and leader, possess advanced data science skills, be expert in working with large data sets in Python, and be able to communicate clearly with numerous stakeholders.\nThis role performs under general direction of the Lead Data Scientist.\nDetailed Description:\nLead, mentor, and coach a small team of data scientists working on a variety of projects\nExecute as an individual contributor multiple analytics projects of varying complexity and data sources (~1 week to ~3 months; time series and relational databases)\nBecome the subject matter expert on projects, including visiting rigs to gain a deeper understanding of drilling rig operations.\nMaintain standards on code quality and code management\nBe the focal point for analytics: work and communicate with multiple stakeholders, understand project requirements, and deliver analytics solutions that add business value\nAssist with developing and improving our suite of data analytics applications and visualizations, including developing requirements and working with developers\nIndependently manage and execute above projects from start-to-finish, including understanding stakeholder needs; acquiring necessary data; cleaning \/ analyzing data and innovating beyond initial requirements; generating visuals \/ reports; and presenting results to stakeholders\nIdentify opportunities for more advanced data science solutions\nJob Requirements\nPrior experience in oil and gas data analytics\nExperience leading, mentoring, and coaching a team of data scientists\nExpert in programming to generate analyses, algorithms, and visuals\nAble to articulate complex data science techniques to end-users that have minimum technical background\nHave excellent soft skills to gain rapport within the organization and seek out buy-in for our analytics team\nAble to work both independently and as part of a team, managing multiple tasks and projects simultaneously to meet challenging deadlines\nAble to think strategically and translate concepts into action plans and track results\nAble and willing to visit a drilling rig location on a semi-regular basis to gain subject matter knowledge\nExcellent verbal and written communication skills\nDemonstrated ability in the following leadership competencies\nBuilds and Maintains Effective Relationships\nDevelops Self and Others\nBuilds Effective Teams\nCourageous Leadership\nManaging Vision and Purpose\nBusiness Acumen\nDrive for Results\nCustomer focus\nDecision Quality\nMinimum Qualifications\nBachelor\u201a\u00c4\u00f4s degree in Physics, Engineering, Computer Science, or related field\n2+ years\u201a\u00c4\u00f4 leading data analytics teams or projects\nor\n5+ years\u201a\u00c4\u00f4 experience working on analytics projects\nExperience applying data analytics to industrial applications (i.e. Oil and Gas, chemicals, manufacturing, etc.)\n2+ years\u201a\u00c4\u00f4 experience in Python for data analysis and visualization (including Jupyter Notebooks, Pandas, Numpy, Matplotlib)\nExperience in SQL and general data extraction\nPreferred Qualifications\nMaster\u201a\u00c4\u00f4s degree or higher in Engineering, Data Science\/Analytics, Computer Science, or related field\nExperience developing Machine Learning\/Artificial Intelligence solutions (scikitlearn \/ tensorflow \/ pytorch)\nExperience in software project management (SCRUM \/ Agile \/ etc.)\nExperience using git for code management\nPrevious experience working in cross-functional roles and communicating directly with product users\nExperience with big data architectures (Hadoop, Spark)\nAdditional Details:\nWork is primarily in a climate controlled \/ office environment with minimal safety \/ health hazard potential. The employee is regularly required to sit, stand, or walk with occasional lifting (overhead, waist level) from floor, bending and frequent near vision use for reading and use of computer, telephone and other office equipment. Frequent travel to other Company offices and drilling rig work sites, often in remote locations, is required during normal rig operating conditions (day\/night, outdoor hot\/cold weather), and employee will be expected to properly use designated personal protective equipment (PPE).\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Science, Python, SQL, Machine Learning, Artificial Intelligence, Software Project Management, Git, Hadoop, Spark, Jupyter Notebooks, Pandas, Numpy, Matplotlib",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Patterson-UTI",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-patterson-uti-3631837222",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nPatterson-UTI Drilling\nThe New Standard for Drilling Performance\nDrill safer, smarter and faster with Patterson-UTI Drilling\u201a\u00c4\u00f4s comprehensive fleet of pad-capable rigs featuring advanced walking systems to enhance your operations so you can reach your apex.\nPatterson-UTI\u201a\u00c4\u00f4s Data Science team is a growing group of energetic, passionate individuals working to improve and inform the Company through data. We work exclusively with the Drilling Automation team to help design, evaluate, and improve novel drilling automation technology.\nSome example projects that we are applying analytics and data science to include:\nModeling greenhouse gas emissions from the rig fleet to reduce environmental impact and improve reporting\nDesigning drilling advisory systems to improve drilling efficiency\nDeveloping automated monitoring, detection, and alerting of operational events\nBuilding models to predict failure of downhole and surface equipment\nThe Senior Data Scientist will be responsible for both leading Data Scientists and performing individual work. She \/ he will manage analytics projects of varying complexity, along with coaching and mentoring more junior individuals on the team. Projects include creating actionable reports, algorithms, and models that will directly impact the development of new automation technologies. The candidate will be involved in all aspects of the project life cycle, including interviewing stakeholders, cleaning and analyzing data, generating visuals and reports, and presenting results. The ideal candidate would be a team player and leader, possess advanced data science skills, be expert in working with large data sets in Python, and be able to communicate clearly with numerous stakeholders.\nThis role performs under general direction of the Lead Data Scientist.\nDetailed Description\nLead, mentor, and coach a small team of data scientists working on a variety of projects\nExecute as an individual contributor multiple analytics projects of varying complexity and data sources (~1 week to ~3 months; time series and relational databases)\nBecome the subject matter expert on projects, including visiting rigs to gain a deeper understanding of drilling rig operations.\nMaintain standards on code quality and code management\nBe the focal point for analytics: work and communicate with multiple stakeholders, understand project requirements, and deliver analytics solutions that add business value\nAssist with developing and improving our suite of data analytics applications and visualizations, including developing requirements and working with developers\nIndependently manage and execute above projects from start-to-finish, including understanding stakeholder needs; acquiring necessary data; cleaning \/ analyzing data and innovating beyond initial requirements; generating visuals \/ reports; and presenting results to stakeholders\nIdentify opportunities for more advanced data science solutions\nJob Requirements\nPrior experience in oil and gas data analytics\nExperience leading, mentoring, and coaching a team of data scientists\nExpert in programming to generate analyses, algorithms, and visuals\nAble to articulate complex data science techniques to end-users that have minimum technical background\nHave excellent soft skills to gain rapport within the organization and seek out buy-in for our analytics team\nAble to work both independently and as part of a team, managing multiple tasks and projects simultaneously to meet challenging deadlines\nAble to think strategically and translate concepts into action plans and track results\nAble and willing to visit a drilling rig location on a semi-regular basis to gain subject matter knowledge\nExcellent verbal and written communication skills\nDemonstrated ability in the following leadership competencies\nBuilds and Maintains Effective Relationships\nDevelops Self and Others\nBuilds Effective Teams\nCourageous Leadership\nManaging Vision and Purpose\nBusiness Acumen\nDrive for Results\nCustomer focus\nDecision Quality\nMinimum Qualifications\nBachelor\u201a\u00c4\u00f4s degree in Physics, Engineering, Computer Science, or related field\n2+ years\u201a\u00c4\u00f4 leading data analytics teams or projects or 5+ years\u201a\u00c4\u00f4 experience working on analytics projects\nExperience applying data analytics to industrial applications (i.e. Oil and Gas, chemicals, manufacturing, etc.)\n2+ years\u201a\u00c4\u00f4 experience in Python for data analysis and visualization (including Jupyter Notebooks, Pandas, Numpy, Matplotlib)\nExperience in SQL and general data extraction\nPreferred Qualifications\nMaster\u201a\u00c4\u00f4s degree or higher in Engineering, Data Science\/Analytics, Computer Science, or related field\nExperience developing Machine Learning\/Artificial Intelligence solutions (scikitlearn \/ tensorflow \/ pytorch)\nExperience in software project management (SCRUM \/ Agile \/ etc.)\nExperience using git for code management\nPrevious experience working in cross-functional roles and communicating directly with product users\nExperience with big data architectures (Hadoop, Spark)\nAdditional Details\nWork is primarily in a climate controlled \/ office environment with minimal safety \/ health hazard potential. The employee is regularly required to sit, stand, or walk with occasional lifting (overhead, waist level) from floor, bending and frequent near vision use for reading and use of computer, telephone and other office equipment. Frequent travel to other Company offices and drilling rig work sites, often in remote locations, is required during normal rig operating conditions (day\/night, outdoor hot\/cold weather), and employee will be expected to properly use designated personal protective equipment (PPE).\nShow more\nShow less",
      "job_skills":"Python, Pandas, Numpy, Matplotlib, Jupyter Notebooks, SQL, Machine Learning, Artificial Intelligence, Data Analysis, Data Visualization, Data Extraction, Data Analytics, Software Project Management, Git, Hadoop, Spark",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Tokio Marine HCC",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-tokio-marine-hcc-3765337527",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description\nPosition at Tokio Marine HCC\nAbout TMHCC\nTokio Marine HCC is a leading specialty insurance group with offices in the United States, the United Kingdom, Europe and other exciting locations. With the strength and stability that comes from being a member of the Tokio Marine Group, and more than forty years of growth, profitability, and stability, we offer important insurance products that most people don\u201a\u00c4\u00f4t even know exist. Every policy we write is special, enabling our clients to do amazing things. From insuring the crops that feed us to the rock concerts that entertain us, to rescuing international travelers in trouble, we offer more than 100 classes of specialty insurance. Applying our Mind Over Risk philosophy to writing insurance allows our customers take on opportunity with confidence. That philosophy defines our way of thinking, unites us as a team, and differentiates us from our competitors. We are much more than just an insurance company; we are a good company.\nWhat We Offer\nJust as Tokio Marine HCC Group of Companies is customer centric, we are also employee centric offering our employees a competitive salary and employee benefit package, strong learning culture, collaboration, 401K match, paid parental leave, hybrid work schedule, travel opportunities and an opportunity to love what you do.\nAbout The Team\nOur Data Science team provides analytical support for the various underwriting units including pricing and claims support, budget support, and providing key statistics on results to underwriting units. We are always looking to innovate, improve, and provide new products to our customers and are looking for a Senior Product Innovation Data Scientist.\nKey Responsibilities\nD eliver start-to-finish on projects leveraging large spectrum of different types of data.\nDesign, build, and validate models using techniques that may include advanced AI and Deep Learning solutions.\nLead cross-functional project teams to build project road maps, establish deadlines, and implement models.\nDevelop a high-level understanding of cutting-edge data science tools and techniques.\nEstablish and promote best practices by applying leadership and problem-solving skills.\nB uild collaborative relationships across the organization.\nMinimum Knowledge, Qualifications And Education Requirements\nPhD or Masters in quantitative discipline, such as statistics, data science, computer science, mathematics, engineering, physics, etc. with preference to having proven work experience in NLP, Deep Learning, or AI.\nProven experience interacting with non-technical business managers to identify opportunities to apply predictive analytics to business opportunities.\nRelevant experience managing multiple projects simultaneously.\nExcellent interpersonal communication.\nStrong Working experience with analytical modeling tools such as:\nR or Python\nPredictive modeling\nMachine learning\nExperimental design\nNLP\nDeep learning related technologies\nDemonstrated leadership competencies, including teambuilding, creative problem-solving, flexibility, and willingness to challenge the status quo.\nShow more\nShow less",
      "job_skills":"Predictive analytics, NLP, R, Python, Machine learning, Experimental design, Deep learning, AI",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Scientist, Houston, Texas( Remote but Local Only)",
      "company":"Stellent IT",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-scientist-houston-texas-remote-but-local-only-at-stellent-it-3584717446",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Sr Data Scientist,\nHouston, Texas( Remote but Local Only)\nPhone + Skype\nJd\nThe position can be worked remotely but they would like someone local to the Houston area.\nMust be a Sr Engineer capable of working on a team and supporting multiple projects at any given time with limited supervision. Must be Senior.\nTeck stack Azure, Azure Synapse, Databricks, Python, and SQL\nSAP experience is a big plus.\nShow more\nShow less",
      "job_skills":"Senior Data Scientist, Azure, Azure Synapse, Databricks, Python, SQL, SAP",
      "Category":"Backend Development"
  },
  {
      "job_title":"Project Engineer Data Manager Data Scientist",
      "company":"ComForCare Home Care (Raleigh, NC)",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/project-engineer-data-manager-data-scientist-at-comforcare-home-care-raleigh-nc-3771573083",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Project Engineer (Data Manager\/Data Scientist) Part Time \u201a\u00c4\u00ec Houston Remote\nPart Time Position \u201a\u00c4\u00ec minimum 8 hours a week up to 20 hours a week. Expected 2-3 hours a day + weekend hours if needed\nThe primary responsibility of this role is to extract meaningful insights from complex datasets, present this data to help guide the project in data-driven decision making, and to contribute to the development of data-driven product and solutions.\nMinimum of 15 years of experience in the engineering \/ construction industry, with proven leadership and excellent communication skills\nKnowledge of Lean process and philosophy\nKnowledge of organizational structure, scheduling systems, and management of available resources\nAbility to quickly and effectively solve complex problems\nAbility to set up and establish project specific technologies to support project delivery strategy\nMinimum 3 years of experience with Python (numpy, pandas, scikit-learn), SQL, Power BI, and Data Analysis\nBuild out SQL queries and views, Power BI dashboards, and data science ML models, and present methodology and key insights to stakeholders\nUse a diverse set of techniques spanning machine learning and other forms of statistical modeling to solve important business and product problems\nCollaborate with business leaders, subject matter experts, and decision makers to develop success criteria and optimize new products, features, policies, and models\nAbility to build relationships and collaborate within a team, internally and externally\nPreferred Education requirement: Masters Degree in an advanced quantitative and\/or scientific field, such as Data Science\nThis is a remote position.\nShow more\nShow less",
      "job_skills":"Project Management, Data Science, Data Analysis, SQL, Python (numpy pandas scikitlearn), Power BI, Machine Learning, Statistical Modeling, Data Visualization, Business Intelligence, Collaboration, Communication, Leadership, Lean Process, Organizational Structure, Scheduling",
      "Category":"Backend Development"
  },
  {
      "job_title":"Machine Learning Data Scientist",
      "company":"MD Anderson Cancer Center",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/machine-learning-data-scientist-at-md-anderson-cancer-center-3789664465",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"The primary purpose of the Data Scientist position is to design, implement and maintain the process of building automated image interpretation tools and the extraction of tumor measurements to fulfill the TMI objective. This activity is an important sub-component of the overall function of TMI and requires a combination of computational skill and subject matter (imaging) expertise.\nThis individual will be working with internal and external teams developing specific image analysis algorithms and will coordinate these efforts in a fashion that supports scientific\/technical evaluation and integration into the broader TMI effort.\nThis individual will have demonstrated experience with programming languages and scripting methods (Python, MATLAB, C++, CUDA, Bash, and\/or SQL), machine learning \/ deep learning methods, data analytics, and medical image analysis. Preference is for candidates with experience with common open-source scientific computing libraries such as PyTorch and TensorFlow. The ideal candidate will have strong computational and analytical skills particularly in deep learning and is motivated by solving challenging medical research problems for patient benefit. Additionally, experience identifying opportunities to streamline and optimize code and imaging pipeline processes is a plus. Interest in continuously and independently exploring and learning new technologies and solutions beyond current knowledge base is also required.\nTechnical Expertise\nTools\/models Development And Management\nWorking independently and with researchers in analyzing, defining, and resolving analytical problems and bugs.\nParticipating in discussion and implementation of machine learning model management solutions.\nEvaluating existing algorithms\/tools and developing new and user-friendly routines in an automated fashion that can be deployed to the broader TMI effort.\nMaintaining knowledge of cutting-edge machine learning approaches and technologies and implementing these where appropriate.\nMaintaining high code quality and ensuring code is thoroughly and consistently tested before deploying for end user use.\nOrganizing data and publishing code with documentation, in line with departmental standards.\nProviding support for existing software systems as they evolve.\nAnalytical Thinking\nComputational Programming Skills\nProviding analysis of data, design, and feasibility of proposed solutions.\nDeveloping solutions to ensure data flow through different platforms within the Context Engine and performing testing and documentation.\nDesigning and developing automated module testing routines (unit testing, integration testing, etc.) and defining version control procedures.\nIdentify and evaluate publicly available, pre-developed containers and models to enrich the TMI container library.\nOral and Written Communication\nTeam Support And Guidance\nTransferring knowledge, expertise, and methodologies by proactively providing technical assistance to researchers and peers.\nServing as primary technical contact for members of the TMI automation team to receive\/review requests and assisting researchers to analyze a wide variety of clinical data, evaluate, and interpret the results.\nPresenting results and progress in project meetings as well as external meetings, workshops, conferences, etc.\nCommunicating and assisting cooperatively and effectively with leaders, peers, end users and support teams when required.\nOther duties as assigned\nEducation Required: Bachelor's degree in Biomedical Engineering, Electrical Engineering, Computer Engineering, Physics, Applied Mathematics, Science, Engineering, Computer Science, Statistics, Computational Biology, or related field.\nExperience Required: Three years experience in scientific software development\/analysis. With Master's degree, one years experience required. With PhD, no experience required.\nPreferred Experience: Experience with common open-source scientific computing\/machine learning libraries (e.g., PyTorch \/ TensorFlow), containerization, and cloud-native technologies (Docker & Kubernetes) is preferred.\nKnowledge of version control protocols, automated test frameworks, and high-performance computing is highly desired.\nIt is the policy of The University of Texas MD Anderson Cancer Center to provide equal employment opportunity without regard to race, color, religion, age, national origin, sex, gender, sexual orientation, gender identity\/expression, disability, protected veteran status, genetic information, or any other basis protected by institutional policy or by federal, state or local laws unless such distinction is required by law. http:\/\/www.mdanderson.org\/about-us\/legal-and-policy\/legal-statements\/eeo-affirmative-action.html\nAdditional Information\nRequisition ID: 164116\nEmployment Status: Full-Time\nEmployee Status: Regular\nWork Week: Days\nMinimum Salary: US Dollar (USD) 91,000\nMidpoint Salary: US Dollar (USD) 113,500\nMaximum Salary : US Dollar (USD) 136,000\nFLSA: exempt and not eligible for overtime pay\nFund Type: Hard\nWork Location: Hybrid Onsite\/Remote\nPivotal Position: Yes\nReferral Bonus Available?: Yes\nRelocation Assistance Available?: Yes\nScience Jobs: No\nShow more\nShow less",
      "job_skills":"Python, MATLAB, C++, CUDA, Bash, SQL, Machine learning, Deep learning, Data analytics, Medical image analysis, PyTorch, TensorFlow, Docker, Kubernetes, Version control, Automated testing, Highperformance computing",
      "Category":"Backend Development"
  },
  {
      "job_title":"DATA SCIENCE CONSULTANT HOUSTON",
      "company":"Management Solutions",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-science-consultant-houston-at-management-solutions-3621078635",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"You will be working in key projects for leading organizations in data mining & knowledge Discovery, predictive modeling, trend modeling, Simulation models (Monte Carlo), Review of credit rating and scoring models and quant support to the business and R&D projects.\nRequirements\nRecent graduates or final year students from disciplines relating to Mathematics, Physics, Statistics, Econometrics or other Quantitative fields.\nPostgraduate studies and\/or specialised courses are an asset, especially in Data Science, Quantitative Finance or similar.\nShould desirably have knowledge of modeling techniques (logit, GLM, time series, decision trees, random forests, clustering), statistical programming languages (SAS, R, Python, Matlab) and big data tools and platforms (Hadoop, Hive, etc.).\nSolid academic record.\nStrong computer skills.\nKnowledge of other languages is desirable.\nGet-up-and-go attitude, maturity, responsibility and strong work ethic.\nStrong ability to learn quickly.\nAble to integrate easily into multidisciplinary teams.\nWe Offer\nThe best environment to develop talent\nWe offer you the possibility to join a firm that provides all you need to develop your talent to the fullest:\nWorking in the highest-profile consulting projects in the industry,\nfor the largest companies, leaders of their respective markets,\nalongside top industry management as they face challenges at the national and global level,\nas part of an extraordinary team of professionals whose values and corporate culture are a benchmark for the industry\nOngoing training plan, with approximately 10% of business turnover spent in training\nSpecialist knowledge courses, external expert courses, professional skills courses, and language courses.\nLast year our staff as a whole received over 330.000 hours of training, spanning more than 750 courses.\nClearly defined career plan\nInternal promotion based solely on merit.\nPartnership-based management model offers all professionals the opportunity to become part of the Firm\u201a\u00c4\u00f4s group of partners.\nComplementary experiencies\nUniversity: we maintain a close relationship with the world\u201a\u00c4\u00f4s most prestigious universities.\nSocial Action: we organize more than 30 community support activities.\nSports Club: internal and external tournaments.\nShow more\nShow less",
      "job_skills":"Data mining, Knowledge discovery, Predictive modeling, Trend modeling, Simulation models, Monte Carlo simulation, Credit rating, Scoring models, Statistical programming, SAS, R, Python, Matlab, Hadoop, Hive, Big data, Logit, GLM, Time series, Decision trees, Random forests, Clustering, Mathematics, Physics, Statistics, Econometrics, Quantitative finance, Computer skills, Multidisciplinary teams",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Scientist (Bangkok based, relocation provided)",
      "company":"Agoda",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-scientist-bangkok-based-relocation-provided-at-agoda-3736665747",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"About Agoda\nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u201a\u00c4\u00d8enhancing the ability for our customers to experience the world.\nGet to Know Our Team\nThe Data department , based in Bangkok , oversees all of Agoda\u201a\u00c4\u00f4s data-related requirements. Our ultimate goal is to enable and increase the use of data in the company through creative approaches and the implementation of powerful resources such as operational and analytical databases, queue systems, BI tools, and data science technology. We hire the brightest minds from around the world to take on this challenge and equip them with the knowledge and tools that contribute to their personal growth and success while supporting our company\u201a\u00c4\u00f4s culture of diversity and experimentation. The role the Data team plays at Agoda is critical as business users, product managers, engineers, and many others rely on us to empower their decision making. We are equally dedicated to our customers by improving their search experience with faster results and protecting them from any fraudulent activities. Data is interesting only when you have enough of it, and we have plenty. This is what drives up the challenge as part of the Data department, but also the reward.\nThe Opportunity\nPlease note -The role will be based in Bangkok.\nWe are looking for ambitious and agile data scientists that would like to seize the opportunity to work on some of the most challenging productive machine learning and big data platforms worldwide, processing some 600B events every day and making some 5B predictions.\nAs part of the Data Science and Machine Learning (AI\/ML) team you will be exposed to real-world challenges such as: dynamic pricing, predicting customer intents in real time, ranking search results to maximize lifetime value, classifying and deep learning content and personalization signals from unstructured data such as images and text, making personalized recommendations, innovating algorithm-supported promotions and products for supply partners, discovering insights from big data, and innovating the user experience. To tackle these challenges, you will have the opportunity to work on one of the world\u201a\u00c4\u00f4s largest ML infrastructure employing dozens of GPUs working in parallel, 30K+ CPU cores and 150TB of memory.\nIn This Role, You\u201a\u00c4\u00f4ll Get to\nDesign, code, experiment and implement models and algorithms to maximize customer experience, supply side value, business outcomes, and infrastructure readiness\nMine a big data of hundreds of millions of customers and more than 600M daily user generated events, supplier and pricing data, and discover actionable insights to drive improvements and innovation\nWork with developers and a variety of business owners to deliver daily results with the best quality\nResearch discover and harness new ideas that can make a difference\nWhat You\u201a\u00c4\u00f4ll Need To Succeed\n4+ years hands-on data science experience\nExcellent understanding of AI\/ML\/DL and Statistics, as well as coding proficiency using related open source libraries and frameworks\nSignificant proficiency in SQL and languages like Python, PySpark and\/or Scala\nCan lead, work independently as well as play a key role in a team\nGood communication and interpersonal skills for working in a multicultural work environment\nIt\u201a\u00c4\u00f4s Great if You Have\nPhD or MSc in Computer Science \/ Operations Research \/ Statistics or other quantitative fields\nExperience in NLP, image processing and\/or recommendation systems\nHands on experience in data engineering, working with big data framework like Spark\/Hadoop\nExperience in data science for e-commerce and\/or OTA\nWe welcome both local and international applications for this role. Full visa sponsorship and relocation assistance available for eligible candidates.\n#sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #sydney #melbourne #perth #toronto #vancouver #montreal #shanghai #beijing #shenzhen #prague #Brno #Ostrava #cairo #alexandria #giza #estonia #paris #berlin #munich #hamburg #stuttgart #cologne #frankfurt #hongkong #budapest #jakarta #bali #dublin #telaviv #milan #rome #venice #florence #naples #turin #palermo #bologna #tokyo #osaka #kualalumpur #malta #amsterdam #oslo #manila #warsaw #krakow #doha #alrayyan #riyadh #jeddah #mecca #medina #singapore #seoul #barcelona #madrid #stockholm #zurich #taipei #tainan #taichung #kaohsiung #bangkok #Phuket #istanbul #london #manchester  #edinburgh #hcmc #hanoi #lodz #wroclaw #poznan #katowice #rio #salvador #newdelhi #bangalore #bandung #yokohama #nagoya #okinawa #fukuoka #jerusalem #IT #4\nEqual Opportunity Employer\nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u201a\u00c4\u00f4s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\nShow more\nShow less",
      "job_skills":"Python, PySpark, Scala, SQL, AI, ML, DL, Statistics, Open source libraries, Frameworks, NLP, Image processing, Recommendation systems, Data engineering, Big data framework, Spark, Hadoop, Ecommerce, OTA, Data science, Machine learning, Big data platforms, Algorithms, Models, Data mining, Personalization",
      "Category":"Backend Development"
  },
  {
      "job_title":"Project Engineer Data Manager Data Scientist",
      "company":"ComForCare Home Care (Raleigh, NC)",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/project-engineer-data-manager-data-scientist-at-comforcare-home-care-raleigh-nc-3771568942",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Project Engineer (Data Manager\/Data Scientist) Part Time \u201a\u00c4\u00ec Houston Remote\nPart Time Position \u201a\u00c4\u00ec minimum 8 hours a week up to 20 hours a week. Expected 2-3 hours a day + weekend hours if needed\nThe primary responsibility of this role is to extract meaningful insights from complex datasets, present this data to help guide the project in data-driven decision making, and to contribute to the development of data-driven product and solutions.\nMinimum of 15 years of experience in the engineering \/ construction industry, with proven leadership and excellent communication skills\nKnowledge of Lean process and philosophy\nKnowledge of organizational structure, scheduling systems, and management of available resources\nAbility to quickly and effectively solve complex problems\nAbility to set up and establish project specific technologies to support project delivery strategy\nMinimum 3 years of experience with Python (numpy, pandas, scikit-learn), SQL, Power BI, and Data Analysis\nBuild out SQL queries and views, Power BI dashboards, and data science ML models, and present methodology and key insights to stakeholders\nUse a diverse set of techniques spanning machine learning and other forms of statistical modeling to solve important business and product problems\nCollaborate with business leaders, subject matter experts, and decision makers to develop success criteria and optimize new products, features, policies, and models\nAbility to build relationships and collaborate within a team, internally and externally\nPreferred Education requirement: Masters Degree in an advanced quantitative and\/or scientific field, such as Data Science\nThis is a remote position.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Science, Machine Learning, Python, Numpy, Pandas, ScikitLearn, Power BI, Data Modeling, SQL, Lean Process, Project Management, Communication, Collaboration, Stakeholders Management, DataDriven Decision Making, Problem Solving",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Conversion Developer, Senior Associate",
      "company":"PwC",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-conversion-developer-senior-associate-at-pwc-3749937559",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nFunctional & Industry Technologies\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 80%\nA career within Functional and Industry Technologies services will provide you with the opportunity to build secure and new digital experiences for customers, employees, and suppliers. We focus on improving apps or developing new apps for traditional and mobile devices as well as conducting usability testing to find ways to improve our clients\u201a\u00c4\u00f4 user experience. Our team helps clients transform their business through enabling technologies across marketing, finance and operations in the functional areas such as Maximo and PowerPlant.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nBasic Qualifications\nMinimum Degree Required:\nBachelor Degree\nMinimum Years Of Experience\n4 years\nPreferred Qualifications\nDegree Preferred:\nMaster Degree\nCertification(s) Preferred\nAzure Data Engineer Associate\nDatabricks Certified Data Engineer Associate\nPreferred Fields Of Study\nComputer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology\nPreferred Knowledge\/Skills\nDemonstrates a thorough level of abilities with, and\/or a proven record of success as both an individual contributor and team member, identifying and addressing client needs:\nSupports in data analysis techniques to assess source data structures, identify mapping requirements, and define transformation rules for data conversion into Maximo;\nLeads Maximo's modules and functionalities related to Asset Management and Work Order Management and IBM Maximo, including its data structures, configuration settings, and integration capabilities;\nIdentifies relational databases, preferably experience in working with databases commonly used in Maximo, such as IBM DB2, Oracle, Microsoft SQL Server, along with familiarity with Maximo's Integration Framework (MIF) and its capabilities for data integration and conversion;\nSupports in designing and implementing data extraction, transformation, and loading processes for Maximo data conversion;\nShowcases understanding in SQL and database querying languages to extract and manipulate data from source systems along with understanding ETL tools and methodologies commonly used in Maximo data conversion;\nIdentifies technologies commonly used with Maximo, including web services (SOAP, RESTful APIs), XML, JSON, and other relevant data exchange formats;\nSupports in pipeline architecture and development using one of the tools such as Azure ADF, AWS Glue, SSIS, DataBricks (multiple preferred);\nUtilizes data cleansing techniques and methodologies to ensure the integrity and accuracy of converted data in Maximo;\nDevelopes data cleansing functional business rules as per Maximo Business Object (MBO) definitions for source to Maximo conversion requirements;and comprehensive testing plans and executing validation processes to verify the accuracy and integrity of converted data in Maximo;\nCustomizes Maximo options, such as Automation Scripts, Java Customizations, Database Configuration, or Application Designer, to support data conversion requirements;\nIdentifies integrations within Maximo with other enterprise systems, such as ERP systems, GIS systems, or asset management systems. Knowledge of integration patterns, data synchronization, and data exchange protocols; and,\nShowcases work experience as a Data Engineer, Data Architect or similar role, along with experience in programming languages including Python, PySpark, Scala, SQL.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-advisoryseniorassociate\nShow more\nShow less",
      "job_skills":"PwC Professional, Maximo, PowerPlant, Azure Data Engineer Associate, Databricks Certified Data Engineer Associate, SQL, Data Extraction, Data Transformation, Data Loading, ETL, Web Services, XML, JSON, Data Cleansing, Python, PySpark, Scala",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist (Active TS Clearance)",
      "company":"Motion Recruitment",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-active-ts-clearance-at-motion-recruitment-3737589734",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"We are working with a Federal consulting company that is transforming the nations defense and national security with their AI platforms. This company works with various Federal agencies and will need this person to work on-site 2 to 3 days a week.\nCandidates should hold at least an active Top Secret clearance.\nRequirements\nOver 3 years of experience in data science\nExpertise in Python\nExperience with MySQL and Oracle\nExperience with machine learning\nBonus to have PhD in Sciences, Mathematics, or Engineering\nOffer\nCompetitive salary\nAnnual Bonus\nYou Will Receive The Following Benefits\nMedical Insurance\nDental Benefits\nVision Benefits\nPaid Time Off (PTO)\n401(k)\nApplicants must be currently authorized to work in the US on a full-time basis now and in the future.\nPosted By:\nSean Thompson\nShow more\nShow less",
      "job_skills":"Top Secret clearance, Data science, Python, MySQL, Oracle, Machine learning",
      "Category":"Backend Development"
  },
  {
      "job_title":"Consultant, Data Science",
      "company":"Jobs for Humanity",
      "job_location":"Lubbock, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/consultant-data-science-at-jobs-for-humanity-3784529500",
      "search_city":"Lubbock",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Description\nJobs for Humanity is partnering with Dell to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.\nCompany Name: Dell\nJob Description\nConsultant - Data Science\nData Science is about finding answers to important questions for businesses. Our mission is to develop new ways of understanding and adding value to large sets of data. We work with leading experts and engineers to help our customers gain insights from big data.\nJoin us in Round Rock, Texas to make a positive impact as a\nData Science Consultant\n.\nWhat you'll achieve:\nContribute to business strategy and decision-making through deep analysis\nGenerate meaningful recommendations based on complex data sets\nUncover actionable insights by examining unstructured data\nCollaborate with business leaders, engineers, and experts to create predictive models\nShare expertise in presentations to customers and larger audiences\nEssential Requirements:\n12 to 15 years of related work experience with statistical skills\nExperience with Python, R-Studio, and\/or PowerBI\nExperience building Artificial Intelligence \/ Machine Learning models\nUnderstanding of business environment and industry trends\nAbility to work collaboratively with multiple stakeholders\nDesirable Requirements:\nBachelor's or Master's degree\nStrong mentoring and coaching skills\nWho we are:\nWe believe that everyone has the power to make a difference. At Dell Technologies, we value our team members and offer opportunities for growth and innovation.\nDell Technologies is a family of businesses that helps individuals and organizations transform how they work. Join us to build a better future for everyone.\nDell Technologies is committed to equal employment opportunity and a discrimination-free work environment. Read our full Equal Employment Opportunity Policy here.\nJob ID:\nR236880\nDell's Flexible & Hybrid Work Culture:\nAt Dell Technologies, we believe that flexibility is important for our employees. We know that freedom and flexibility allow for innovation and drive results. To learn more about our work culture, please visit our locations page.\nPlease respond to this email with the following bullet points:\nYears of related work experience and proficiency in statistical skills\nExperience with programming languages such as Python, R-Studio, and\/or PowerBI\nExperience building Artificial Intelligence \/ Machine Learning models\nUnderstanding of business environment and industry trends\nAbility to work collaboratively with multiple stakeholders\nEducation level (Bachelor's or Master's degree, if applicable)\nMentoring and coaching skills (if applicable)\nShow more\nShow less",
      "job_skills":"Data Science, Statistical Analysis, Python, RStudio, PowerBI, Artificial Intelligence, Machine Learning, Predictive Modeling, Business Strategy, Data Visualization, Communication, Collaboration, Mentoring, Coaching",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst I",
      "company":"WinMax",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-i-at-winmax-3724252453",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Title:Data Analyst I, Req# 26095179\nLocation:Austin,Tx(Onsite)\nContract:12+ Month\nJob Description\nAMR DC Operations is in search of someone who possesses an adamant sense of drive and organizational aptitude to support DC planning and analytics. This individual will have the opportunity to work directly with and influence decision making with the distribution centers that service client\u201a\u00c4\u00f4s customers in North America.\nResponsibilities\nServe as a key intermediary between internal groups and 3PL providers for forecast and capacity metrics and files\nBuild and maintain headcount\/labor trackers for distribution centers\nUpdate leadership and key stakeholders weekly on headcount tracking to plan and capacity attainment by route to market and DC\nSupport ad-hoc reporting metrics through data analysis\nImprove process documentation\nRequired Skills\nVery savvy in Excel (macros, VBA, etc.)\nAbility to communicate clearly and concisely with Senior Leadership\nAbility to balance competing priorities and manage change\nBusiness analytics background preferred\nPositive attitude in fast paced, short timeline work environment\nAbility to work overtime and weekends as needed\nHistory of consistent performance & attendance at previous employers\nNice To Have\nWorking knowledge of SAP\nTableau experience\nAbility to code in SQL, R, Python, etc.\nEducation\nBS\/BA degree required\nShow more\nShow less",
      "job_skills":"Excel, Macros, VBA, SQL, R, Python, Tableau, SAP, Headcount tracking, Data analysis, Process documentation, Forecasting, Business analytics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Scientist",
      "company":"Infosys",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-scientist-at-infosys-3785762354",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nInfosys is seeking\nLead Data Scientists\nwith Machine Learning (ML), AI and Python experience. Ideal candidate is expected to have prior experience in end-to-end implementation of Machine Learning models that includes identification of \u201a\u00c4\u00f2right\u201a\u00c4\u00f4 problem, designing \u201a\u00c4\u00f2optimum\u201a\u00c4\u00f4 solution, implementing using \u201a\u00c4\u00f2best in class\u201a\u00c4\u00f4 practices and deploying the models to production. Will work in alignment with data strategy at various clients, using multiple technologies and platforms.\nRequired Data Scientist Qualifications\nBachelor\u201a\u00c4\u00f4s Degree or foreign equivalent will also consider three years of progressive experience in the specialty in lieu of every year of education.\nAt least 8 years of Information Technology experience\nAt least 1 years of hands-on data science with machine learning\nExperiences with Python or R\nExperience with data gathering, data quality, system architecture, coding best practices\nExperience with Lean \/ Agile development methodologies\nThis position may require travel, will involve close co-ordination with offshore teams\nThis position is located in Austin, TX and may require relocation to the area\nInfosys encourages U.S. Citizens, lawful permanent residents, and those lawfully authorized to work in the U.S. to apply\nPreferred Data Scientist Qualifications\n4 years of hands-on experience with more than one programming language; Python, R, Scala, Java, SQL\nDeep Learning experience with CNNs, RNN, LSTMs and the latest research trends\nExperience or Knowledge with Generative AI and working with any Large Language Models.\nPrior experience in cognitive services provided by various platforms such as AWS, GCP, Azure, IBM Watson\nPrior experience in Azure chatbot, Google DialogFlow, Alexa, RASA, Amazon Lex\nExperience with perception (e.g. computer vision), time series data (e.g. text analysis)\nBig Data Experience strongly preferred, HDFS, Hive, Spark, Scala\nData visualization tools such as Tableau, Query languages such as SQL, Hive\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.\nAbout Us\nInfosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.\nInfosys is an equal opportunity employer and all qualified applicants will receive consideration without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, spouse of protected veteran, or disability.\nInfosys is an equal opportunity employer and all qualified applicants will receive consideration without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, spouse of protected veteran, or disability.\nShow more\nShow less",
      "job_skills":"Machine Learning, AI, Python, Java, SQL, Scala, R, Tableau, Hadoop Distributed File System (HDFS), Hive, Spark, Big Data, Perception, Time Series Data, Text Analysis, Generative AI, Large Language Models, Cognitive Services, Azure Chatbot, Google DialogFlow, Alexa, RASA, Amazon Lex, Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Long ShortTerm Memory (LSTMs), Computer Vision, Data Visualization, Data Gathering, Data Quality, System Architecture, Coding Best Practices, Lean Development, Agile Development",
      "Category":"Backend Development"
  },
  {
      "job_title":"Consultant, Data Science",
      "company":"Jobs for Humanity",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/consultant-data-science-at-jobs-for-humanity-3784530414",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Description\nJobs for Humanity is partnering with Dell to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.\nCompany Name: Dell\nJob Description\nConsultant - Data Science\nData Science is about finding answers to important business questions by analyzing massive amounts of data. Our mission is to develop innovative methods, tools, and models to derive valuable insights from large data sets. We collaborate with academics, industry experts, and skilled engineers to help our customers gain meaningful knowledge from big data.\nJoin us and make a significant impact on society as a\nData Science Consultant\non our team in Round Rock, Texas.\nWhat You'll Achieve\nContribute to business strategy and decision-making through deep analysis and interpretation of complex data sets.\nProvide actionable recommendations based on insights from data analysis.\nDesign processes to analyze unstructured data and generate valuable insights.\nCollaborate with business leaders, engineers, and experts to develop predictive models and algorithms.\nCreate innovative techniques and approaches to machine learning and predictive modeling.\nPresent as a subject-matter expert to both customers and larger audiences.\nEssential Requirements\n12 to 15 years of experience in advanced statistics with a strong mathematical background.\nProficiency in Python, R-Studio, PowerBI, and other relevant programming languages.\nExperience building artificial intelligence and machine learning predictive models.\nAdvanced understanding of the business environment and industry trends.\nAbility to work collaboratively with multiple stakeholders.\nDesirable Requirements\nBachelor's or Master's degree.\nStrong mentoring and coaching skills.\nWho We Are\nWe believe that each individual can make a difference. At Dell Technologies, we value our team members and their diverse contributions. If you're looking for an opportunity to grow your career with innovative technology and exceptional minds, we want you to join us. Dell Technologies is a family of businesses dedicated to transforming the way people work, live, and play. We are committed to providing equal employment opportunities and a harassment-free work environment for all employees.\nJob ID:\nR236880\nDell's Flexible & Hybrid Work Culture\nDell Technologies believes in offering flexibility to our employees. We understand that freedom and flexibility are important no matter where you're located. Our flexible and hybrid work style allows team members to be innovative and achieve results in their own way. To learn more about our work culture, visit our locations page.\nResponse:\nThank you for the job advertisement for the position of Data Science Consultant at Dell Technologies.\nI am interested in applying for this role and believe that my skills and experience align well with the requirements.\nAs an individual with a background in advanced statistics and a strong interest in data analysis, I am confident that I can contribute to the business strategy and decision-making process based on my ability to interpret complex data sets.\nI have extensive experience in using programming languages such as Python, R-Studio, and PowerBI, which will be beneficial in building artificial intelligence and machine learning predictive models.\nI also possess a deep understanding of the business environment and industry trends, which will allow me to provide valuable insights and recommendations.\nMoreover, I have the ability to work collaboratively with various stakeholders, ensuring effective communication and teamwork throughout projects.\nRegarding qualifications, I hold a [Bachelor's\/Master's] degree and have strong mentoring and coaching skills.\nI am excited about the opportunity to join the Dell Technologies team and contribute to the transformation of the way people work, live, and play.\nI believe that my skills and passion for data science make me a suitable candidate for this role.\nI look forward to discussing my application further and demonstrating how I can make a positive impact as a Data Science Consultant at Dell Technologies.\nI appreciate your time and consideration.\nYours sincerely,\n[Your Name]\nShow more\nShow less",
      "job_skills":"Data Science, Python, RStudio, PowerBI, Advanced Statistics, Machine Learning, Predictive Modeling, Artificial Intelligence, Business Strategy, DecisionMaking, Data Analysis, Programming Languages, Collaboration, Mentoring, Coaching",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"2K",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-2k-3767196715",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Who We Are\nFounded in 2005, the 2K label includes some of the most hard-working game development studios in the world today. Firaxis Games, Visual Concepts, Hangar 13, 2K Czech and Cat Daddy Games. Our world-class team of engineers, developers, graphic artists and publishing professionals are stewards of a growing library of critically-acclaimed franchises such as Battleborn, BioShock, Borderlands, The Darkness, Mafia, NBA 2K, Sid Meier\u201a\u00c4\u00f4s Civilization, WWE 2K, and XCOM. 2K is headquartered in Novato, California and is a wholly owned label of Take-Two Interactive Software, Inc. (NASDAQ: TTWO).\n2K develops and publishes interactive entertainment globally for console systems, handheld gaming systems and personal computers, including smartphones and tablets, which are delivered through physical retail, digital download, online platforms, and cloud streaming services. 2K publishes titles in today\u201a\u00c4\u00f4s most popular gaming genres, including shooters, action, role-playing, strategy, sports, casual, and family entertainment.\nOur vision at 2K is to create a diverse and inclusion environment to \u201a\u00c4\u00faCome as You are and Feel Equipped to do Your Best Work!\u201a\u00c4\u00f9 We are dedicated to promoting diversity, multiculturalism, and equality in all that we do. Our communities are focused on increased access and personal growth, and their greatness depends on a diversity of race, gender, sexual orientation, religion, ethnicity, national origin, and perspective. We're an equal opportunity employer and excited to build the future of co-living with the world's most hardworking and passionate people.\nWhat We Need\nWe seek a\nSr Data Scientist\nto join the experimentation and causal inference team that supports 2K sports games, including NBA2K, WWE 2K, PGA 2K, Lego Drive, and more! Lead data authority who contributes directly to driving the research direction in developing methods and tools that increase the difficulty and efficiency of our experimentation platform and analyses constructed using causal inference techniques. Partner with studio and product leadership to help them understand the true impact of the decisions and tests.\nWhat You Will Do\nEffectively identify and apply analytics, causal inference, experimentation, and machine learning techniques for business problems.\nSignificant experience and excitement with one or more of the following: advanced statistical techniques for A\/B testing, methods for experimental design, observational causal inference, or quasi-experimental analysis.\nExamples include quantile testing, sequential testing, variance reduction techniques, variance estimation for ratio metrics, multi-level\/hierarchical modeling, statistical surrogate modeling, matching methods, regression adjustment, structural equation models, instrumental variables, regression discontinuity design, and graphical approaches to causal inference.\nLead the design, analysis, and interpretation of experiments\nProactively perform data exploration on engagement behaviors to discover future opportunities.\nPartner\/influence directly with and regularly present insights to key strategic business partners (e.g., Growth Strategy, Marketing, Product Development)\nUp-level others on the team through mentorship and peer review using your experience and domain expertise.\nWho We Believe Will Be An Outstanding Fit\n5+ years work experience in data science with a Master or PhD degree in Mathematics, Statistics, Economics, Computer Science, Engineering Sciences (or in another quantitative field)\n5+ years of professional experience with data scripting languages (SQL, python, R, etc.)\nIn depth understanding and experience using supervised and unsupervised machine learning techniques\nSolid understanding of causal inference methods (such as propensity score matching, synthetic control methods, etc.)\nYou are a creative problem solver, a self-starter with the passion and enthusiasm to drive impact and build whatever is necessary.\nYou can optimally balance problem-solving from a technical solution standpoint while providing transparency through concise partner communications.\nExperience in applying statistical analysis, machine learning, and experimentation design within a consumer-facing business\nBonus Points\nExperience in building experimentation platforms and causal inference solutions\nFamiliarity with software engineering practice and working with APIs\nPlease note that 2K Games and its studios never uses instant messaging apps or personal email accounts to contact prospective employees or conduct interviews and when emailing, only use 2K.com accounts.\nShow more\nShow less",
      "job_skills":"Data science, Statistics, Mathematics, SQL, Python, R, Machine learning, Causal inference, A\/B testing, Experimental design, Statistical modeling, Regression analysis, Structural equation modeling, Graphical causal inference, Supervised learning, Unsupervised learning, Propensity score matching, Synthetic control methods, Experimentation platform, Consumerfacing business, Software engineering, APIs",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist, Finance and Accounting",
      "company":"Hinge Health",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-finance-and-accounting-at-hinge-health-3767310563",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Hinge Health is creating a new health care system, built around you. Accessible to 26 million members across 1,500 customers, Hinge Health is the #1 digital clinic for joint and muscle pain, delivering superior member outcomes and proven claims reductions. We pair the industry\u201a\u00c4\u00f4s most advanced motion technology and wearable pain relief with a complete clinical care team of physical therapists, physicians, and board-certified health coaches to help people move beyond pain and reduce surgeries and opioid use. Hinge Health\u201a\u00c4\u00f4s HingeConnect integrates with 1 million+ in-person providers to enable earlier interventions for avoidable MSK surgeries. Four in five health plans and employers with a digital MSK solution trust Hinge Health, including Land O\u201a\u00c4\u00f4Lakes, L.L. Bean, Salesforce, Self-Insured Schools of California, Southern Company, State of New Jersey, US Foods, and Verizon. Learn more at http:\/\/www.hingehealth.com\nHere at Hinge Health, we welcome all applicants and know a diverse team makes us better and stronger. We look for individuals who embody our leadership principles and we value varied experiences and skill sets. Beyond specific work experience, we also look for unique capabilities and skill sets that are key indicators an applicant will thrive in our fast-paced, frequently evolving environment. If this sounds like the kind of place you\u201a\u00c4\u00f4d like to be part of, please apply - we would love to hear from you!\nHinge Health Hybrid Model\nWe believe that remote work and in-person work have their own advantages and disadvantages, and want to be able to leverage the best of both worlds. Some roles which require a greater degree of day-to-day collaboration will benefit from more in-person opportunities. Employees in Hybrid roles are expected to be in office 1 day\/week (Wednesdays) in hub locations that have an office, and may be expanded to 2 days in 2024.\nAbout The Role\nYou will join our rapidly growing Data Science team as Senior Data Scientist, working with our Finance and Accounting teams. You will work closely with our Revenue Cycle Management and Billings teams in designing, auditing, and optimizing our billing frameworks, processes, and accounting [charge capture, contractual adjustments, third-party reimbursements, cash collections, denials, write-offs, bad debt, accounts receivable].\nWhat You\u201a\u00c4\u00f4ll Accomplish\nEvaluating and creating recommendations for different client billing models [e.g. cohort-based vs. individual models]\nIdentification of billing frameworks for new products and expanded offerings\nCreating source of truth reporting for billing milestones, revenue recognition, client revenue retention, and more.\nDeep dive analysis into drivers of revenue growth and realization\nHelping the Finance and Accounting teams prepare and ensure that data, tools, and systems are IPO-ready.\nWhat We're Looking For\n6+ years experience working with large datasets to solve business and technology problems\nProficiency working with scientific computing languages (R \/ Python) and SQL; prior experience with BI\/visualization tools (Tableau, Mode Analytics) a must\nPast experience in Finance, Accounting, RCM preferred, but not required\nExpertise in model development, validation and implementation\nThe ability to communicate results clearly and a focus on driving impact\nAbility to work autonomously and with minimal guidance\nWhat You'll Love About Us\nInclusive healthcare and benefits: On top of comprehensive medical, dental, and vision coverage, we offer employees and their family members help with gender-affirming care, tools for family and fertility planning, and travel reimbursements if healthcare isn\u201a\u00c4\u00f4t available where you live.\nPlanning for the future: Start saving for the future with our traditional or Roth 401k retirement plan options which include a 2% company match.\nModern life stipends: Manage your own learning and development budget, use the mental health to support therapy costs, and lifestyle stipends to cover your favorite wellness services, and work-from-home equipment.\nFlexible vacation and paid time off: Employees have flexibility to choose when, how, and why they take time off to rest and recharge. Exempt employees can take advantage of our flexible pto program. Nonexempt employees can utilize up to two weeks of sick time and up to 17 days of vacation per year, including mental health days.\nIn Office Perks: Daily lunch, coffee\/tea and office snacks, and weekly social hours.\nOther compensation: At Hinge Health, we want every employee to be invested and rewarded in the future success of the company. All full-time positions are eligible for equity.\n$107,500 - $192,000 a year\nConsider the range above plus equity, and benefits. Please note that the base salary range is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location.\nAbout Hinge Health\nLinkedIn recently named Hinge Health one of the Top 50 Startups. Forbes, Fast Company, and Inc. have also recognized our technology, innovation, and culture.\nSince our founding in 2014, we've raised more than $800 million from leading investors, including Coatue and Tiger Global. We work with 1000 customers across every industry and the public sector \u201a\u00c4\u00ee including Salesforce, Verizon, and the State of New Jersey \u201a\u00c4\u00ee to give more than 23 million people access to the care they need. We\u201a\u00c4\u00f4re positioned to continue leading the market with unmatched investments in clinical research, care innovation, machine learning, AI, and computer vision.\nDiversity And Inclusion\nWe\u201a\u00c4\u00f4re committed to building diverse teams that reflect the communities we serve. Visit hingehealth.com\/diversity-equity-and-inclusion to learn more about what moves us.\nHinge Health is an equal opportunity employer and prohibits discrimination and harassment of any kind. We make employment decisions without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, age, veteran status, disability status, pregnancy, or any other basis protected by federal, state or local law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.\nWe provide reasonable accommodations for candidates with disabilities. If you feel you need assistance or an accommodation due to a disability, let us know by reaching out to your recruiter.\nBy providing your information through this page or applying for a job at Hinge Health, you acknowledge that Hinge Health will collect, use, and process your information as part of our job application process. For more information on how Hinge Health processes your personal information, click here to view our Applicant and Personnel Privacy Notice.\nDisclaimer\nThere continues to be a significant increase in phishing attempts across all industries where fraudsters are impersonating real employees and sending fictitious job offers to applicants in a scheme to obtain sensitive information. Please note that we will never ask for your financial information at any part of the interview process including the post-offer stage, and will only correspond through @hingehealth.com domain email addresses.\nIf you encounter any suspicious activity, we recommend you cease all communication with the individual and consider reporting them to the U.S. FBI Internet Crime Complaint Center. If you would like to verify the legitimacy of an email you received from our recruiting team, please forward it to security@hingehealth.com\n*Please do not send resumes via email*\nShow more\nShow less",
      "job_skills":"Python, R, SQL, Finance, Accounting, Revenue Cycle Management, Billings, Tableau, Mode Analytics, BI, Visualization tools, Model development, Model validation, Model implementation, Data analysis, Communication, Team work, Autonomy, Initiative, Problem solving",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist, Product",
      "company":"Hinge Health",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-product-at-hinge-health-3772915070",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Hinge Health is creating a new health care system, built around you. Accessible to 26 million members across 1,500 customers, Hinge Health is the #1 digital clinic for joint and muscle pain, delivering superior member outcomes and proven claims reductions. We pair the industry\u201a\u00c4\u00f4s most advanced motion technology and wearable pain relief with a complete clinical care team of physical therapists, physicians, and board-certified health coaches to help people move beyond pain and reduce surgeries and opioid use. Hinge Health\u201a\u00c4\u00f4s HingeConnect integrates with 1 million+ in-person providers to enable earlier interventions for avoidable MSK surgeries. Four in five health plans and employers with a digital MSK solution trust Hinge Health, including Land O\u201a\u00c4\u00f4Lakes, L.L. Bean, Salesforce, Self-Insured Schools of California, Southern Company, State of New Jersey, US Foods, and Verizon. Learn more at http:\/\/www.hingehealth.com\nHere at Hinge Health, we welcome all applicants and know a diverse team makes us better and stronger. We look for individuals who embody our leadership principles and we value varied experiences and skill sets. Beyond specific work experience, we also look for unique capabilities and skill sets that are key indicators an applicant will thrive in our fast-paced, frequently evolving environment. If this sounds like the kind of place you\u201a\u00c4\u00f4d like to be part of, please apply - we would love to hear from you!\nHinge Health Hybrid Model\nWe believe that remote work and in-person work have their own advantages and disadvantages, and want to be able to leverage the best of both worlds. Some roles which require a greater degree of day-to-day collaboration will benefit from more in-person opportunities. Employees in Hybrid roles are expected to be in office 1 day\/week (Wednesdays) in hub locations that have an office, and may be expanded to 2 days in 2024.\nAbout The Role\nThis role will work cross functionally across the High Risk Member and New Program teams at Hinge Health. These teams help deliver better pain outcomes to our most at-risk members through targeted UI\/UX as well as standing up net new programs such as Women\u201a\u00c4\u00f4s Pelvic Health, Meditation, Balance, and more.\nIf you enjoy 0 to 1 projects and being the de facto quantitative owner of your space, this is the role for you.\nWhat We're Looking For\nActs as an owner of their space, working to understand the business-level problems the team is trying to solve. This candidate will be a thought partner to their Product stakeholders using quantitative learnings to guide team decision making and strategy.\nHas strong written, verbal, and visualization communication skills with the ability to translate complex data analyses into simplistic, actionable outcomes.\nCan ruthlessly prioritize, ensuring both they and the team are only working on the most critical projects that will drive the largest outcomes for our users.\nWhat You\u201a\u00c4\u00f4ll Accomplish\nConsolidate and align goaling\/measurement\/metrics across the High Risk and New Programs spaces.\nConstruct data models and self serve tools to automate\/streamline basic data\nOwn experimentation design, analysis, and communication of results\nConduct deep dive analysis to inform team strategy\/decision making and identify net new opportunities\nDevelop classification models for High Risk members to better identify\/serve them\nWhat You'll Love About Us\nInclusive healthcare and benefits: On top of comprehensive medical, dental, and vision coverage, we offer employees and their family members help with gender-affirming care, tools for family and fertility planning, and travel reimbursements if healthcare isn\u201a\u00c4\u00f4t available where you live.\nPlanning for the future: Start saving for the future with our traditional or Roth 401k retirement plan options which include a 2% company match.\nModern life stipends: Manage your own learning and development budget, use the mental health to support therapy costs, and lifestyle stipends to cover your favorite wellness services, and work-from-home equipment.\nFlexible vacation and paid time off: Employees have flexibility to choose when, how, and why they take time off to rest and recharge. Exempt employees can take advantage of our flexible pto program. Nonexempt employees can utilize up to two weeks of sick time and up to 17 days of vacation per year, including mental health days.\nIn Office Perks: Daily lunch, coffee\/tea and office snacks, and weekly social hours.\nOther compensation: At Hinge Health, we want every employee to be invested and rewarded in the future success of the company. All full-time positions are eligible for equity.\n$107,500 - $192,000 a year\nConsider the range above plus equity, and benefits. Please note that the base salary range is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location.\nAbout Hinge Health\nLinkedIn recently named Hinge Health one of the Top 50 Startups. Forbes, Fast Company, and Inc. have also recognized our technology, innovation, and culture.\nSince our founding in 2014, we've raised more than $800 million from leading investors, including Coatue and Tiger Global. We work with 1000 customers across every industry and the public sector \u201a\u00c4\u00ee including Salesforce, Verizon, and the State of New Jersey \u201a\u00c4\u00ee to give more than 23 million people access to the care they need. We\u201a\u00c4\u00f4re positioned to continue leading the market with unmatched investments in clinical research, care innovation, machine learning, AI, and computer vision.\nDiversity And Inclusion\nWe\u201a\u00c4\u00f4re committed to building diverse teams that reflect the communities we serve. Visit hingehealth.com\/diversity-equity-and-inclusion to learn more about what moves us.\nHinge Health is an equal opportunity employer and prohibits discrimination and harassment of any kind. We make employment decisions without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, age, veteran status, disability status, pregnancy, or any other basis protected by federal, state or local law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.\nWe provide reasonable accommodations for candidates with disabilities. If you feel you need assistance or an accommodation due to a disability, let us know by reaching out to your recruiter.\nBy providing your information through this page or applying for a job at Hinge Health, you acknowledge that Hinge Health will collect, use, and process your information as part of our job application process. For more information on how Hinge Health processes your personal information, click here to view our Applicant and Personnel Privacy Notice.\nDisclaimer\nThere continues to be a significant increase in phishing attempts across all industries where fraudsters are impersonating real employees and sending fictitious job offers to applicants in a scheme to obtain sensitive information. Please note that we will never ask for your financial information at any part of the interview process including the post-offer stage, and will only correspond through @hingehealth.com domain email addresses.\nIf you encounter any suspicious activity, we recommend you cease all communication with the individual and consider reporting them to the U.S. FBI Internet Crime Complaint Center. If you would like to verify the legitimacy of an email you received from our recruiting team, please forward it to security@hingehealth.com\n*Please do not send resumes via email*\nShow more\nShow less",
      "job_skills":"Python, R, SQL, Tableau, Power BI, Machine learning, AI, Computer vision, Clinical research, Care innovation, Data visualization, Data analysis, Experimentation design, Classification modeling, Statistical analysis, Quantitative analysis, Datadriven decisionmaking, Communication, Collaboration, Problemsolving, Critical thinking, Business acumen",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"VMC Soft Technologies Private Limited",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-vmc-soft-technologies-private-limited-3785356637",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Hi Everyone,\n100 % Closure Position\n***** W2 Contract Only *****\nImmediate Requirement and sure shot interview\nNote: All visa type Accepted and Long-term Project\nJob Title: Data Scientist\nLocation: Austin, TX \/Sunnyvale, CA (Hybrid Model Like 3 days in a week Onsite)\nJob Description :\n- 8+ years of data scientist experience\n- 5+ years of data querying languages (e.g. SQL)\n- 5+ years of strong experience in Python, Panda, Perl, or another scripting language\n- 3+ years of machine learning\/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience\n- Experience applying theoretical models in an applied environment\n- Experience in training and leveraging LLM's like ChatGPT\nRole Expectation :\n-Map business problems to high-impact solutions leveraging off data and insights.\n-Contribute to the development of end-to-end machine learning solutions and data processing pipelines\n-Support the team in all aspects of the practical machine learning development cycle, encompassing sound use of data pre-processing techniques, analysis, modeling, and validation methods\nInterested candidates please share your resume to my mail id:\npriyanka@vmcsofttech.com\nor reach out me\n602- 666 - 1740\n.\n#w2 #W2requirements #w2jobs #w2usajobs #w2contract #w2project #w2only #w2requirement #w2 #Datascientist #datascientitjobs #Python #chatgpt #javascript #Austinjobs #TXjobs #sunnyvalejobs #CAjobs\nShow more\nShow less",
      "job_skills":"Data Scientist, SQL, Python, Pandas, Perl, Machine Learning, Statistical Modeling, Data Analysis, Data Preprocessing, Data Validation, ChatGPT",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist, Growth",
      "company":"Hinge Health",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-growth-at-hinge-health-3767313562",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Hinge Health is creating a new health care system, built around you. Accessible to 26 million members across 1,500 customers, Hinge Health is the #1 digital clinic for joint and muscle pain, delivering superior member outcomes and proven claims reductions. We pair the industry\u201a\u00c4\u00f4s most advanced motion technology and wearable pain relief with a complete clinical care team of physical therapists, physicians, and board-certified health coaches to help people move beyond pain and reduce surgeries and opioid use. Hinge Health\u201a\u00c4\u00f4s HingeConnect integrates with 1 million+ in-person providers to enable earlier interventions for avoidable MSK surgeries. Four in five health plans and employers with a digital MSK solution trust Hinge Health, including Land O\u201a\u00c4\u00f4Lakes, L.L. Bean, Salesforce, Self-Insured Schools of California, Southern Company, State of New Jersey, US Foods, and Verizon. Learn more at http:\/\/www.hingehealth.com\nHere at Hinge Health, we welcome all applicants and know a diverse team makes us better and stronger. We look for individuals who embody our leadership principles and we value varied experiences and skill sets. Beyond specific work experience, we also look for unique capabilities and skill sets that are key indicators an applicant will thrive in our fast-paced, frequently evolving environment. If this sounds like the kind of place you\u201a\u00c4\u00f4d like to be part of, please apply - we would love to hear from you!\nHinge Health Hybrid Model\nWe believe that remote work and in-person work have their own advantages and disadvantages, and want to be able to leverage the best of both worlds. Some roles which require a greater degree of day-to-day collaboration will benefit from more in-person opportunities. Employees in Hybrid roles are expected to be in office 1 day\/week (Wednesdays) in hub locations that have an office, and may be expanded to 2 days in 2024.\nAbout The Role\nYou will join our rapidly growing Data Science team as Senior Data Scientist in the Growth neighborhood. You will work closely with Growth Marketers and channel leads in using email and other channels to drive new user acquisition, onboarding, and early lifecycle retention through deep dive analysis, experimentation, and model development [attribution, cost curves, customer segmentation, etc].\nWhat You\u201a\u00c4\u00f4ll Accomplish\nDeveloping measurement frameworks for HH\u201a\u00c4\u00f4s growth channels\nDeveloping hypotheses for channel optimization and efficiency, user growth, and leading growth channel experimentation\nExplaining root causes of business performance and working with Growth Marketers to develop actions to accelerate growth\nWorking with Data Engineers to build growth data models and ensure accurate \/ efficient ingestion \/ transformation of required datasets\nBuilding out customer segmentation and attribution models to better enable new user growth.\nWhat We're Looking For\n6+ years experience working with large datasets to solve business and technology problems\nProficiency working with scientific computing languages (R \/ Python) and SQL; prior experience with BI\/visualization tools (Tableau, Mode Analytics) a must\nKnowledge of time series, statistics, and \/ or machine learning helpful\nExpertise in model development, validation and implementation\nThe ability to communicate results clearly with a non-technical audience and a focus on driving impact\nAbility to work autonomously and with minimal guidance\nWhat You'll Love About Us\nInclusive healthcare and benefits: On top of comprehensive medical, dental, and vision coverage, we offer employees and their family members help with gender-affirming care, tools for family and fertility planning, and travel reimbursements if healthcare isn\u201a\u00c4\u00f4t available where you live.\nPlanning for the future: Start saving for the future with our traditional or Roth 401k retirement plan options which include a 2% company match.\nModern life stipends: Manage your own learning and development budget, use the mental health to support therapy costs, and lifestyle stipends to cover your favorite wellness services, and work-from-home equipment.\nFlexible vacation and paid time off: Employees have flexibility to choose when, how, and why they take time off to rest and recharge. Exempt employees can take advantage of our flexible pto program. Nonexempt employees can utilize up to two weeks of sick time and up to 17 days of vacation per year, including mental health days.\nIn Office Perks: Daily lunch, coffee\/tea and office snacks, and weekly social hours.\nOther compensation: At Hinge Health, we want every employee to be invested and rewarded in the future success of the company. All full-time positions are eligible for equity.\n$88,700 - $192,000 a year\nConsider the range above plus equity, and benefits. Please note that the base salary range is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location.\nAbout Hinge Health\nLinkedIn recently named Hinge Health one of the Top 50 Startups. Forbes, Fast Company, and Inc. have also recognized our technology, innovation, and culture.\nSince our founding in 2014, we've raised more than $800 million from leading investors, including Coatue and Tiger Global. We work with 1000 customers across every industry and the public sector \u201a\u00c4\u00ee including Salesforce, Verizon, and the State of New Jersey \u201a\u00c4\u00ee to give more than 23 million people access to the care they need. We\u201a\u00c4\u00f4re positioned to continue leading the market with unmatched investments in clinical research, care innovation, machine learning, AI, and computer vision.\nDiversity And Inclusion\nWe\u201a\u00c4\u00f4re committed to building diverse teams that reflect the communities we serve. Visit hingehealth.com\/diversity-equity-and-inclusion to learn more about what moves us.\nHinge Health is an equal opportunity employer and prohibits discrimination and harassment of any kind. We make employment decisions without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, age, veteran status, disability status, pregnancy, or any other basis protected by federal, state or local law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.\nWe provide reasonable accommodations for candidates with disabilities. If you feel you need assistance or an accommodation due to a disability, let us know by reaching out to your recruiter.\nBy providing your information through this page or applying for a job at Hinge Health, you acknowledge that Hinge Health will collect, use, and process your information as part of our job application process. For more information on how Hinge Health processes your personal information, click here to view our Applicant and Personnel Privacy Notice.\nDisclaimer\nThere continues to be a significant increase in phishing attempts across all industries where fraudsters are impersonating real employees and sending fictitious job offers to applicants in a scheme to obtain sensitive information. Please note that we will never ask for your financial information at any part of the interview process including the post-offer stage, and will only correspond through @hingehealth.com domain email addresses.\nIf you encounter any suspicious activity, we recommend you cease all communication with the individual and consider reporting them to the U.S. FBI Internet Crime Complaint Center. If you would like to verify the legitimacy of an email you received from our recruiting team, please forward it to security@hingehealth.com\n*Please do not send resumes via email*\nShow more\nShow less",
      "job_skills":"Data Science, Scientific computing languages (R \/ Python), SQL, BI\/visualization tools (Tableau Mode Analytics), Time series, Statistics, Machine learning, Model development, Model validation, Model implementation, Nontechnical communication, Autonomy, Minimal guidance",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist, Product Analytics",
      "company":"Expedia Group",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-product-analytics-at-expedia-group-3740177650",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"If you need assistance during the recruiting process due to a disability, please reach out to our Recruiting Accommodations Team through the Accommodation Request\nform\n. This form is used only by individuals with disabilities who require assistance or adjustments in applying and interviewing for a job. This form is not for inquiring about a position or the status of an application.\nSenior Data Scientist, Product Analytics\nAre you excited by the opportunity to pioneer the future of travel? Do you want to redefine the way people plan, search for, and book their travel?\nAt Expedia Group, we believe that travel brings the world together, and we are passionate about the endless possibilities. This role is a great opportunity to join our global Product Analytics and Experimentation team where we are user experience optimization obsessed!\nThe Performance Insights and Measurement Strategy team leads product performance related strategic analytics and customer experience advanced insight , ensuring that top level understanding of performance and the resulting decisions are being made are off the back of sound data and analytics principles. This results in simplification, efficiency improvement, consistency and clear accountability on product performance measurement.\nAs a senior data scientist in the team, you will work closely with our Brands and Product teams in leading our efforts to understand performance of our products . Examples include investigating weekly performance trends alongside automating our capabilities for understanding and detecting changes in core metrics and communicating metric performance to senior leadership.\nWhat You'll Do\nCarry out weekly analytics of core performance metrics with a focus on understanding the drivers of conversion\nIdentify opportunities to leverage advanced analytics methods to develop a deeper understanding of performance for example through increased segmentation of metrics\nUnderstand the interaction of key metrics and their relationship with strategic and performance goals\nExploratory analysis to identify friction across the funnel impacting metrics, and quantify the business impact of this\nCollaborate across the Centre of Excellence team to define how we embed new metrics into our experimentation culture\nDefine a strategy for anomaly detection alongside the data visualization and engineering teams\nWork with the wider product analytics team at Expedia Group to get a deeper understanding of our performance\nWho You Are\nExcellent logical thinking\nBachelor's or Master's degree in a quantitative field such as mathematics, physics, engineering, operations research, data science or similar\n6 years of experience in industry or equivalent\nExperience creating and analyzing drivers of performance metrics\nDemonstrated ability to work through complex business problems and implement suitable solutions\nAbility to use and interpret machine learning models such as propensity modelling and forecasting techniques\nCreative and analytical in thinking with a love for data, to both disagree with and convince senior partners backed by data\nStrong stakeholder management skills for senior leadership\nExperience in web analytics using tools such as Adobe Analytics or Google Analytics\nExperience with large datasets and proficient in SQL and another programming language ( e.g. R, Python)\nExcellent verbal, written and data visualization skills\nAbility to prioritize among conflicting demands and be comfortable with ambiguity\nSharp focus on results and strong attention to detail\nThe total cash range for this position in Austin is $173,000.00 to $242,500.00. Employees in this role have the potential to increase their pay up to $277,000.00, which is the top of the range, based on ongoing, demonstrated, and sustained performance in the role.\nStarting pay for this role will vary based on multiple factors, including location, available budget, and an individual\u201a\u00c4\u00f4s knowledge, skills, and experience. Pay ranges may be modified in the future.\nExpedia Group is proud to offer a wide range of benefits to support employees and their families, including medical\/dental\/vision, paid time off, and an Employee Assistance Program. To fuel each employee\u201a\u00c4\u00f4s passion for travel, we offer a wellness & travel reimbursement, travel discounts, and an International Airlines Travel Agent (IATAN) membership. View our full list of benefits .\nAbout Expedia Group\nExpedia Group (NASDAQ: EXPE) powers travel for everyone, everywhere through our global platform. Driven by the core belief that travel is a force for good, we help people experience the world in new ways and build lasting connections. We provide industry-leading technology solutions to fuel partner growth and success, while facilitating memorable experiences for travelers. Expedia Group's family of brands includes: Brand Expedia\u00ac\u00c6, Hotels.com\u00ac\u00c6, Expedia\u00ac\u00c6 Partner Solutions, Vrbo\u00ac\u00c6, trivago\u00ac\u00c6, Orbitz\u00ac\u00c6, Travelocity\u00ac\u00c6, Hotwire\u00ac\u00c6, Wotif\u00ac\u00c6, ebookers\u00ac\u00c6, CheapTickets\u00ac\u00c6, Expedia Group\u201a\u00d1\u00a2 Media Solutions, Expedia Local Expert\u00ac\u00c6, CarRentals.com\u201a\u00d1\u00a2, and Expedia Cruises\u201a\u00d1\u00a2.\n\u00ac\u00a9 2021 Expedia, Inc. All rights reserved. Trademarks and logos are the property of their respective owners. CST: 2029030-50\nEmployment opportunities and job offers at Expedia Group will always come from Expedia Group\u201a\u00c4\u00f4s Talent Acquisition and hiring teams. Never provide sensitive, personal information to someone unless you\u201a\u00c4\u00f4re confident who the recipient is. Expedia Group does not extend job offers via email or any other messaging tools to individuals to whom we have not made prior contact. Our email domain is @expediagroup.com. The official website to find and apply for job openings at Expedia Group is careers.expediagroup.com\/jobs .\nExpedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. This employer participates in E-Verify. The employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization.\nShow more\nShow less",
      "job_skills":"Data science, Machine learning, Statistical modeling, Data visualization, SQL, Python, R, Adobe Analytics, Google Analytics, Experimentation, Performance measurement, Business intelligence, Datadriven decision making, Problemsolving, Stakeholder management",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer",
      "company":"INSPYR Solutions",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-at-inspyr-solutions-3780037374",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Role: Data Engineer\nDuration: Direct Hire\nLocation: Houston, TX 77040 (HYBRID)\nWork Authorization: US Citizen, Green Card Holders or Authorized to work in the US\nSeeking talented Data Analyst \/ Engineers with expertise in SQL\/SSIS who are looking to grow into Data Scientists \/ Analytics Professionals.\nPosition Summary\nThe Data Engineer will have a background in data analysis, data analytics, data visualization, dashboards, KPIs & metrics reporting and will be proficient in SQL, SSIS, & SSRS. The candidate should have knowledge of structured and unstructured data concepts and tools, experience with OLAP tools, and the ability to code against APIs using Python for data extraction, transformation, and loading (ETL). This role will entail hands-on day to day data manipulation, transmission, and ETL work and also play and integral role in guiding the organization forward with larger analytics projects.\nResponsibilities:\nBe the primary support for our data analytics and business intelligence software.\nAnalyzes existing business processes in search of productivity gains through automation.\nProvides data integration services around our corporate data warehouse.\nCustomize 3rd party software applications.\nCompletes database, web, and client programming as needed.\nRequirements:\nBachelor's degree in MIS or CS or equivalent work experience.\nMaster's degree in Data Science or Data Analytics preferred.\n2 - 5 years of technical and relevant experience as Data Analyst focused on ETL work.\nProficient in SQL, SSIS, & SSRS\nAbility to code against APIs using Python for data extraction, transformation, and loading (ETL).\nPrior experience working in data analytics, data visualization, dashboards, KPIs & metrics reporting.\nKnowledge of structured and unstructured data concepts and tools.\nExperience with OLAP tools, including IBM Planning Analytics, is a preferred.\nAbout INSPYR Solutions:\nTechnology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients\u201a\u00c4\u00f4 business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.\nINSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities\nShow more\nShow less",
      "job_skills":"SQL, SSIS, SSRS, Python, Data Analytics, Data Visualization, Dashboards, KPIs, Metrics Reporting, Structured Data, Unstructured Data, OLAP, IBM Planning Analytics, Data Integration, Data Manipulation, Data Transmission, API Coding, Data Extraction, Data Transformation, Data Loading",
      "Category":"Backend Development"
  },
  {
      "job_title":"Urgent Requirement -- Data Analyst-- Remote",
      "company":"Jade Business Services (JBS)",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/urgent-requirement-data-analyst-remote-at-jade-business-services-jbs-3655955679",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description\nJob Title: Digital Data Analyst\nJob Type: Contract- W2\nLocation: Remote\nJob Summary\nWe are seeking a Digital Data Analyst to lead the reporting and analysis of digital data across a suite of consumer properties (prospect website, online account area, mobile apps). The candidate will be responsible for analyzing and reporting on the behavior of customers on all digital properties and working with teams across the department to provide data driven solutions to optimize and align experiences to our digital strategy.\nEssential Duties\/Responsibilities\nCreate and Analyze Digital Analytics reporting from Google and Adobe Analytics\nWork with our experience team to identify data driven opportunities for optimization and improvement\nCreate robust analysis of optimization tests and enhancements\nConglomerate data from a variety of sources (Adobe Analytics, Behavioral Analytics Tool, Offline Data) into easy to comprehend reporting\/dashboards\nReport and communicate digital campaigns results\nSupport ad-hoc requests for insights\nWork with external teams including technical partners to ensure data integrity and enhance available information\nManage multiple and concurrent projects, and initiatives, keeping them on schedule and within scope\nAnalyze, document, and communicate results and data-driven recommendations of all initiatives and A\/B\/N tests to stakeholders regularly\nModel and identify trends within the digital experience\nCollaborate with Digital Experience Team, Designers, Developers, Content\/SEO Team and Product Owners to provide data, insights and reporting needed to successfully execute digital strategy\nWorking Conditions\nRemote work position\nSome overtime required as special projects arise\nTravel N\/A\nMinimum Requirements\n2+ years of relevant work experience\nBachelor's Degree in Statistics, Mathematics, Economics, Business Intelligence or similar degree preferred\nPrevious experience with Digital Ecommerce Analysis\nProficiency With\nDigital Analytics (i.e. Google Analytics, Adobe Analytics, mobile app analytics)\nR, Python, or similar language\nData Analysis\nFamiliarity with A\/B\/n and Multi-Variate Testing\nStrong analytical, organizational and project management skills with excellent verbal and written ability\nProficiency with MS Office\nPreferred Qualifications\nEnergy experience preferred, but not required\nFamiliarity with digital experience and optimization\nAdditional Details\nDoes position require driving? : No\nWill this position need NERC or ERCOT access? : No\nShow more\nShow less",
      "job_skills":"Google Analytics, Adobe Analytics, Digital Analytics, Optimization, A\/B\/n Testing, MultiVariate Testing, R, Python, Data Analysis, Datadriven Solutions, Reporting, Dashboards, Data Integrity, Project Management, Communication, Microsoft Office, Energy Experience, Digital Experience",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Capgemini Engineering",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-capgemini-engineering-3783989051",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Life at Capgemini\nCapgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:\nFlexible work\nHealthcare including dental, vision, mental health, and well-being programs\nFinancial well-being programs such as 401(k) and Employee Share Ownership Plan\nPaid time off and paid holidays\nPaid parental leave\nFamily building benefits like adoption assistance, surrogacy, and cryopreservation\nSocial well-being benefits like subsidized back-up child\/elder care and tutoring\nMentoring, coaching and learning programs\nEmployee Resource Groups\nDisaster Relief\nAbout Capgemini Engineering\nWorld leader in engineering and R&D services, Capgemini Engineering combines its broad industry knowledge and cutting-edge technologies in digital and software to support the convergence of the physical and digital worlds. Coupled with the capabilities of the rest of the Group, it helps clients to accelerate their journey towards Intelligent Industry. Capgemini Engineering has more than 55,000 engineer and scientist team members in over 30 countries across sectors including Aeronautics, Space, Defense, Naval, Automotive, Rail, Infrastructure & Transportation, Energy, Utilities & Chemicals, Life Sciences, Communications, Semiconductor & Electronics, Industrial & Consumer, Software & Internet.\nCapgemini Engineering is an integral part of the Capgemini Group, a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided every day by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of \u201a\u00c7\u00a822 billion.\nGet the Future You Want | www.capgemini.com\nDisclaimer\nCapgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity\/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.\nThis is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and\/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.\nCapgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.\nClick the following link for more information on your rights as an Applicant http:\/\/www.capgemini.com\/resources\/equal-employment-opportunity-is-the-law\nApplicants for employment in the US must have valid work authorization that does not now and\/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.\nJob Role:\nWe are looking for an experienced data scientist with a background in the energy or utilities to join us and help solve the complex, real-world challenges faced by industry-leading companies at the forefront of science and technology. You will combine your expertise to create, develop and deliver solutions that truly make a difference in the world! Our work in this industry varies, from solving client's computational problems such as reservoir modeling in upstream oil and gas, to utility network optimization and image analysis for vegetation management.\nKey Responsibilities:\nCombining domain knowledge and technical skills to understand and solve the complex challenges facing our clients.\nUsing data science, analytics and a variety of analytical, statistical or machine learning techniques to interpret client data, helping them to make better-informed business decisions.\nDesigning and developing custom software solutions or tools.\nBuilding strong relationships, communicating and collaborating with clients and colleagues.\nRequired Skills:\n3+ years professional experience of data science and\/or scientific software development in the energy or utilities sector.\nThe ability to interpret complex data using a variety of analytical, statistical or machine learning techniques.\nExposure to computational modelling, algorithm development or software engineering in languages such as Python, R, MATLAB, Java, C# or C++.\nThe eagerness and capacity to quickly learn new domains and technologies.\nExcellent interpersonal & communication skills.\nGood To Have:\nProject management and\/or business analysis experience or qualifications.\nAny experience in software engineering with an analytics or data driven focus.\nShow more\nShow less",
      "job_skills":"Data Science, Scientific Software Development, Python, R, MATLAB, Java, C#, C++, Analytical Techniques, Statistical Techniques, Machine Learning, Computational Modeling, Algorithm Development, Software Engineering, Project Management, Business Analysis",
      "Category":"Backend Development"
  },
  {
      "job_title":"Media Data Analytics Specialist",
      "company":"The Pedowitz Group",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/media-data-analytics-specialist-at-the-pedowitz-group-3784804969",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Media Data Analytics Specialist - On-site Dallas, Texas\nJob Summary:\nWe are seeking a highly skilled and motivated individual to join our team as a Media Data Analytics Specialist. In this role, you will be responsible for analyzing media performance data, developing insights, and recommending media plan optimizations to maximize effectiveness and efficiency. You will work closely with cross-functional teams, including media, business analytics, and IT to measure and drive data-informed campaign performance reporting. Additionally, the ideal candidate will be able to work independently with little direction and will be able to communicate clearly in a high-level business environment.\nResponsibilities:\nCollect, analyze, and interpret media campaign data from various sources to identify trends, patterns, and performance insights.\nDevelop and maintain reports and dashboards to track key performance indicators (KPIs) and communicate campaign performance to stakeholders.\nProvide actionable recommendations based on data insights to drive media effectiveness \/ efficiency to achieve campaign objectives.\nConduct A\/B testing and other experiments to optimize media campaigns and drive continuous improvement.\nConduct research and stay up-to-date with industry trends, best practices, and emerging media planning and buying technologies.\nCollaboration and Communication:\nCollaborate with internal stakeholders to develop effective media measurement strategies to optimize campaign performance.\nWork closely with business analytics, data engineering, and IT teams to ensure data integrity, accuracy, and consistency in reporting.\nPresent findings, insights, and recommendations to stakeholders and senior management in a clear and concise manner.\nFoster strong relationships with media vendors, technology partners, and third-party providers to stay informed about new opportunities and industry developments.\nQualifications:\nBachelor's degree in data, analytics, computer science or a related field or relevant level of experience\nStrong analytical skills with the ability to analyze complex data sets, draw actionable insights, and communicate findings effectively.\nFamiliarity with A\/B testing methodologies and statistical analysis.\nProven experience using analytics platforms and tools\nUnderstanding of digital media channels, metrics, and industry best practices.\nExcellent problem-solving skills and the ability to work independently and within a team.\nStrong attention to detail, organizational skills, and the ability to manage multiple projects simultaneously.\nExcellent written and verbal communication skills.\nJoin our dynamic team and contribute to the success of our media campaigns through uncovering data-driven insights. Apply today to be part of a fast-paced and innovative environment.\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Interpretation, Reporting, Dashboarding, KPI Analysis, A\/B Testing, Trend Analysis, Digital Media Metrics, Media Planning, Media Buying, Collaboration, Communication, Data Engineering, Statistical Analysis, Analytics Platforms, Excel, PowerPoint, SQL, Python, R",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Scientist",
      "company":"Public Storage",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-scientist-at-public-storage-3784028054",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Public Storage\nisrecognized as one of\nAmerica\u201a\u00c4\u00f4s Best Large Employers\nin 2022 by Forbes and our employees have also voted us as a\nGreat Place to Work\n,having\nBestCareer Growth\n, ranked us in the\nTop 5% for Work Culture\n,and in the\nTop 10% for Diversity and Inclusion.\nWith more than 2,900 locations nationwide, Public Storage is the leader in the self-storage industry, and given our number of tenants, we may very well be the world's largest landlord. We've experienced unprecedented growth over the past four decades, and it's in no small part due to the dedicated team that has helped us become an S&P 500 industry leader, the country's largest real estate investment trust (REIT), and the most recognizable name in self-storage.\nJob Description\nWe are currently looking for a\nSenior Data Scientist\nto join our Data & Analytics practice in Plano, TX.\nThe\nSenior Data Scientist\nwill have demonstrated his\/her technical skills to lead the design and deployment of data science solutions that balance SOTA with team productivity, model reproducibility as well as support experimentation at scale, with a positive-focused, yet relentless goal for continuous improvement.\nThe role will lead the people, process and tool choices that support the efforts to build and deploy models that explain the real world, using a must-have combination of intuition, math and programming (Python\/R and SQL are mandatory). She\/He will be a continuously learning advocate and teacher with a talent for breaking down complex systems into solvable components and executing against that vision. As part of the role is tomentor data scientists and analysts, you love working with the team on any mix of issues that come to light such as in-depth technical\/code reviews, hackathons, or whiteboarding to break down problems from multiple angles.\nResponsibilities\nExceptional verbal and written skills to convey ideas, problems and solutions\nAble to establish trust and confidence as the data science team lead, up, across and down the organization as needed\nResponsible for designing team processes and applying design patterns that apply statistical and model rigor\nBalance design choices with calculated trade-offs and revisit proactively\nSME on algorithms and designs code that can be refactored easily by a data engineers\nBuilds repo and maintains a library of models that can be applied\/refactored on similar design patterns\nExpert in both unstructured and structured data set ingestion and classification, regression, deep learning etc.\nMentors and trains teams in new techniques and pushes boundaries of existing technology to deliver enterprise value\nOwns the Confluence knowledge repository and GitHub model repo\nRefresh, troubleshoot and update models as needed.\nThought leader on how to converge available data, transfer learning from other projects and test new algorithms that optimize across large, ambiguous data sets\nCoordinate design and architecture with data engineering resources\nQualifications\nBachelors\/Masters in STEM fields such as physics, social\/economics, or business with a strong technical acumen required\nMasters in Comp Science + 4 years of experience or PhD STEM degree preferred\nAlternative to education, 6+ years of experience as contributor\/leader\nKnowledge Skills & Abilities\nStrong verbal communication skills: ability to effectively communicate cross functionally; experience as a DS team lead or department head of data science\nStrong command of applied math (linear\/matrix functions) with deep learning theory and practice; Both frequentist or Bayesian welcome\nProficiency with programming and scripting languages: Python\/R, SQL and C#\/++\nExperience with analytic frameworks and open source libraries\nPassionate about thinking through problems and solving them\nRealistic view of AI and understanding of how to use deep learning in real-world situations\nExceptional programming skills (Python, SQL,C++) in a production environment is required\n#REITJobs\nAdditional Information\nAll your information will be kept confidential according to EEO guidelines.\nShow more\nShow less",
      "job_skills":"Senior Data Scientist, Data Science, Data Analytics, Python, R, SQL, Machine learning, Deep learning, Data engineering, Statistical rigor, Model design, Model deployment, Data sets, Data ingestion, Classification, Regression, Confluence, GitHub, STEM, Computer Science, Applied math, Linear functions, Matrix functions, Programming languages, Analytic frameworks, Open source libraries, AI, C++, C#",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Trinity Industries, Inc.",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-trinity-industries-inc-3784405970",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"TrinityRail\nis searching for a\nData Scientist\nin\nDallas, TX!\nThe successful candidate will be innovation-minded with a blend of skills in data analytics, data engineering, and data science. This individual will dive deep into analytics, model workflows, and data pipelines for our manufacturing business, while concentrating on support for the entire enterprise. This includes production-line workforce modeling & analytics and supporting our lease fleet operations. The role is a unique blend of various skill domains - we're seeking an individual who can navigate these priorities with ease while unlocking value for our integrated business platform.\nJoin our team today and be a part of\nDelivering Goods for the Good of All!\nWhat you'll do:\nLead development of end-to-end analytics projects for our manufacturing, leasing, and supply chain groups from conception through delivery, driving effective collaboration and alignment with business stakeholders\nWork closely with business leaders, project stakeholders, and subject matter experts to understand and optimize key business processes. Apply your SQL, data transformation, and data modeling skills to turn data into actionable insights and optimized solutions\nPartner with data engineers on technical design of complex data sourcing, transformation, and aggregation logic to meet business analytics needs and deliver value. Leverage generative AI in analytical work where applicable\nWork with data analysts to translate business requirements into impactful data visualizations and data models in platforms like Qliksense, Tableau, PowerBI, and other analytics tools\nWhat you'll need:\nBachelor\u201a\u00c4\u00f4s Degree in quantitative field such as Mathematics, Economics, Computer Science, Information Management, Statistics, Finance or Accounting; Masters and\/or PhD preferred\n5+ years relevant experience in related analytics, data science, and business intelligence\nExpert-level skills in Data Analytics with advanced analytical languages (Python, R, Spark, Scala, and\/or Julia)\nMust possess exceptional communication\/presentation skills, both verbal and written\nFamiliarity with industrial manufacturing and supply chain processes highly preferred\nPossess competencies with SQL, Generative AI prompting, and data transformation tools. Seamlessly leverage generative AI tools like GPT, Co-Pilot, and other technologies as core aspects of the development process\nAdvanced skills in Data Architecting, Visualization, SQL, Microsoft Excel, PowerPoint\nTechnical fluency regarding data mining, data models, database design\/development, and other segmentation techniques, usage of Data Orchestration & Modeling platforms (e,g. Azure Databrick & Data Factory)\nExperience with data visualization tools such as Qliksense and techniques in translating business analytics needs into data visualization and semantic data access requirements\nIntermediate skills in Application development with Business Intelligence tools (e,g. Qliksense, Tableau, Power BI, etc.)\nStrong organizational, time management and multi-tasking skills\nPrior experience with Palantir Foundry, including developing integrated workflows, process improvement and automation highly preferred\nEEO\/AA\/Disabled\/Veterans\/Drug-Free Workplace\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Engineering, Data Science, Data Architecting, SQL, Python, R, Spark, Scala, Julia, Generative AI, Data Visualization, Microsoft Excel, PowerPoint, Data Mining, Data Models, Database Design, Data Orchestration, Data Factory, QlikSense, Tableau, Power BI, Azure Databricks, Palantir Foundry",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Verizon",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-verizon-3774250561",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"When you join Verizon\nVerizon is one of the world's leading providers of technology and communications services, transforming the way we connect around the world. We're a human network that reaches across the globe and works behind the scenes. We anticipate, lead, and believe that listening is where learning begins. In crisis and in celebration, we come together-lifting up our communities and striving to make an impact to move the world forward. If you're fueled by purpose, and powered by persistence, explore a career with us. Here, you'll discover the rigor it takes to make a difference and the fulfillment that comes with living the #NetworkLife.\nWhat you'll be doing...\nThe Artificial Intelligence & Data (AI&D) Organization is an exciting new center of excellence supporting all of Verizon, reporting into the Global Network & Technology team. Our team will be a catalyst to Verizon's future in creating networks that move the world forward through the power of Artificial Intelligence & Data.\nYou will be a strategic thinker joining a high profile, high visibility team that powers analytics and strategic thinking for Verizon. You will be part of a team that builds tools, analyses, and insights that informs, quantifies, and enables the visualization of data to drive business decisions for all of Verizon's Networks.\nWith your analytical, big data and reporting expertise, you will deliver business value through business intelligence reporting and analytics by driving insights to actions. You will support the company's analytics and data visualization capabilities and ensure delivery of high-quality analytic solutions. The way you will accomplish this is by analyzing data and developing analytical views utilizing various BI tools such as Tableau, Heavy.AI, Qlik, and web-based applications. You'll also connect various data sources to stage data before analysis and visualizations. The business insights and recommendations you provide will help to improve performance. This role requires the person to be an experienced analytics leader with deep hands-on experience in statistical analysis, predictive modeling, customer analytics, and data visualization.\nPerforming ad-hoc analysis and developing reproducible analytical approaches to meet business requirements.\nPerforming exploratory and targeted data analyses using descriptive statistics and other methods.\nDeriving actionable insights, creating reports, dashboards and presentations for business use\nDeveloping new capabilities and enhancing critical business processes with advanced visualization capabilities. Review existing visualizations to assess opportunities for improvement\nPresenting results and recommendations to senior management and business users.\nWhere you'll be working:\nIn this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.\nWhat we're looking for...\nYou have strong analytical skills, and are eager to work in a collaborative environment with global teams to drive ML applications in business problems, develop end to end analytical solutions and communicate insights and findings to leadership. You work independently and are always willing to learn new technologies. You thrive in a dynamic environment and are able to interact with various partners and cross functional teams to implement data science driven business solutions.\nYou'll need to have:\nBachelor's degree or four or more years of work experience.\nFour or more years of relevant work experience.\nEven better if you have one or more of the following:\nAn MBA or Master's degree in statistics, mathematics, analytics, engineering, computer science, or another technical and\/or financial discipline.\nDemonstrated ability to communicate effectively with all levels of an organization, both technical and non-technical team members.\nKnowledge of 4GLTE\/5G Technologies, IP Networking, RF\/SP engineering tools \/ principles.\nExperience with Big Data architecture and mining for insights across various data sources.\nExperience using ETL (extract, transform, load) tools and experience with large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.\nKnowledge of data warehouse and data lake technology (Teradata, Hadoop, No SQL, graph DB).\nKnowledge of web analytics and business intelligence tools (Tableau, Qlik, Heavy.AI, Looker, ThoughtSpot, Cognos, SAS, SPSS, etc.)\nExperience presenting findings and actionable recommendations through meaningful and insightful data visualizations.\nExperience in applying statistical ideas and methods to data sets to answer business problems.\nExperience with Python, Spark, or SQL to manipulate data and draw insights from large data sets.\nExperience with developing insights, presenting, and influencing strategic decisions using data.,\nThis role is eligible to be considered for the Department of Defense SkillBridge Program.\nWhy Verizon?\nVerizon is committed to maintaining a Total Rewards package which is competitive, valued by our employees, and differentiates us as an Employer of Choice.\nWe are a 'pay for performance' company and your contribution is rewarded through competitive salaries, performance-based incentives and an employee Stock Program. We create an opportunity for us all to share in the success of Verizon and the value we help to create through this broad-based discretionary equity award program.\nYour benefits are market competitive and delivered by some of the best providers.\nYou are provided with a full spectrum of health and wellbeing resources, including a first in-class Employee Assistance Program, to empower you to make positive health decisions.\nWe offer generous paid time off benefits to help you manage your work life balance and opportunities for flexible working arrangements*.\nVerizon provides training and development for all levels, to help you enhance your skills and develop your career, from funding towards education assistance, award-winning training, online development tools and access to industry research.\nYou will be able to take part in volunteering opportunities as part of our environmental, community and sustainability commitment.\nYour benefits package will vary depending on the country in which you work.\n*subject to business approval\nIf Verizon and this role sound like a fit for you, we encourage you to apply even if you don't meet every \"even better\" qualification listed above.\nWhere you'll be working\nIn this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.\nScheduled Weekly Hours\n40\nEqual Employment Opportunity\nWe're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.\nShow more\nShow less",
      "job_skills":"Tableau, Heavy.AI, Qlik, Data Visualization, Data Analysis, Statistical Analysis, Predictive Modeling, Customer Analytics, Business Intelligence, ETL, Data Mining, Hadoop, Teradata, No SQL, SQL, Python, Spark, Artificial Intelligence, Machine Learning",
      "Category":"Backend Development"
  },
  {
      "job_title":"Big Data Developer",
      "company":"Phaxis",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-developer-at-phaxis-3780191547",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Big Data Developer and Analysis Engineer\nDallas TX-Hybrd!\nMANDARIN SPEAKING is preferred!\n$85,000-110,000 Base + Great Benefits!\nWe are seeking a Big Data Developer and Analysis Engineer to join our team based in the Dallas, TX, United States. You will be responsible for developing and maintaining high-quality data pipelines and data analytics and visualization tools to support the company's business decision-making and strategic planning.\nResponsibilities:\n1. Collaborate with business teams to understand their data requirements and provide appropriate solutions.\n2. Collect, organize, and analyze data to support business decision-making and strategic planning.\n3. Identify trends and patterns in the business through data mining and analysis and provide recommendations for business growth and efficiency improvements.\n4. Assist in defining best practices for data collection, pipeline, and analytics development, and ensure data accuracy and consistency.\n5. Monitor and maintain existing data pipelines, analytics, and visualization tools, promptly addressing issues and providing support.\nRequirements:\n1. Bachelor's degree or higher in Computer Science, Data Analytics, or a related field preferred.\n2. Experience in data management and developing data pipelines with Airflow, Apache Spark, Flink and other data ETL tools strongly recommended.\n3. Proficiency in SQL for data querying and analysis, with the ability to clean and process data.\n4. Proficiency in Python for data mining.\n5. Strong communication and teamwork skills, able to effectively collaborate and coordinate with different departments and teams.\n6. Strong problem-solving and self-learning abilities, able to quickly adapt to new technologies and tools.\nShow more\nShow less",
      "job_skills":"Apache Flink, Data Analytics, Airflow, Data Mining, Apache Spark, SQL, Python, Data ETL, Data Analysis, Data Collection, Data Pipelines, Data Visualization",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Futran Solutions",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-futran-solutions-3713035221",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Title - Data scientist\nDuration - 9+ Months\nLocation -\nDallas, TX\nResponsibilities\nHas experience within Telco domain and experience in creating and deriving insights\nFor marketing and workforce productivity , further write reports and present their findings to upper management regarding topics of. market predictions, detailed churn and loyalty analysis. financial goals, employee productivity , training needs\nAbility to communicate complex data in a simple, actionable way\nAbility to visualize data in the most effective way possible for a given project or study\nExperience with machine learning and AI\nFamiliarity with data management tools\nCollecting data through means such as analyzing business results or by setting up and managing new studies\nTransferring data into a new format to make it more appropriate for analysis\nCreating new, experimental frameworks to collect data\nBuilding tools to automate data collection\nSearching through large data sets for usable information\nCreating reports and presentations for business uses\nCorrelating similar data to find actionable results\nExpertise in tools like R\/Python\/Pytorch. Tenser\nExpertise in Model building.\nShow more\nShow less",
      "job_skills":"Telco domain, Data insights, Market predictions, Churn analysis, Loyalty analysis, Financial goals, Employee productivity, Training needs, Data visualization, Machine learning, AI, Data management tools, Data collection, Data analysis, Data transformation, Data experimentation, Data automation, Data mining, Data reporting, Data correlation, R, Python, Pytorch, Tensor, Model building",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Archetype Permanent Solutions",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-archetype-permanent-solutions-3787912756",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are seeking a highly skilled and analytical Data Scientist to join our team. The ideal candidate will be adept at using large data sets to find opportunities for product and process optimization, and using models to test the effectiveness of different courses of action. This role will require both a strong technical background in data analysis and the ability to communicate findings to non-technical teams and stakeholders.\nKey Responsibilities:\nWork with stakeholders to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nQualifications:\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Statistics, Mathematics, Computer Science, or another quantitative field.\n2 years of experience in a Data Scientist or Data Analyst role.\nStrong problem-solving skills with an emphasis on product development.\nExperience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages\/drawbacks.\nExcellent written and verbal communication skills for coordinating across teams.\nPreferred Skills:\nExperience with distributed data\/computing tools: Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\nExperience with AWS, Azure, or another cloud service.\nExperience visualizing\/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.\nBenefits:\nCompetitive salary and benefits package.\nDynamic and innovative work environment.\nOpportunities for professional growth and development.\n[Other company-specific benefits like remote work options, flexible schedules, wellness programs, etc.]\nHow to Apply:\nPlease submit your resume, cover letter, and any relevant work samples\nPowered by JazzHR\nmcXzsLHihP\nShow more\nShow less",
      "job_skills":"Data Science, Data Analysis, Statistics, Mathematics, Computer Science, R, Python, SQL, Data Architectures, Machine Learning, Clustering, Decision Tree Learning, Artificial Neural Networks, Distributed Data\/Computing Tools, Map\/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, Data Visualization, Periscope, Business Objects, D3, ggplot",
      "Category":"Backend Development"
  },
  {
      "job_title":"Generative AI Engineer\/Sr. Data Scientist",
      "company":"Keylent Inc",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/generative-ai-engineer-sr-data-scientist-at-keylent-inc-3768058609",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position:\nGenerative AI Engineer\/Sr. Data Scientist\nLocation:\nDallas, TX (Hybrid)\nDuration:\n12 months\nClient:\nSandbox\nJob Summary\nWe are seeking a highly skilled and experienced Generative AI Engineer to join our team. The ideal candidate will have a deep understanding of language models, text-to-image, and other generative AI models. They must possess advanced knowledge of PyTorch, and the Tensorflow GPU API. They should have experience publishing research and be able to demonstrate their expertise in the field.\nResponsibilities\nDevelop and implement generative AI models, including LLMs and text-to-image models, using PyTorch and TensorFlow.\nDesign and optimize neural network architectures for scalability and performance.\nTrain and evaluate models using large datasets.\nTroubleshoot and debug code to ensure high-quality results.\nKeep up-to-date with the latest developments in the field of generative AI and apply them to our projects.\nCollaborate with other engineers and researchers to develop innovative solutions.\nDeep understanding of how to scale generative models and their limitations\nAbility to quickly identify opportunities for model improvement\nDeep understanding of Nvidia CUDA parallel programming\nRequirements\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\n3+ years of experience in developing generative AI models.\nStrong programming skills in Python and experience with PyTorch, TensorFlow, and the Tensorflow GPU API.\nKnowledge of state-of-the-art generative AI models such as GPT-3, DALL-E, and CLIP.\nExperience with training and evaluating large-scale models on high-performance computing clusters.\nStrong understanding of deep learning, natural language processing, and computer vision.\nExcellent problem-solving skills and ability to work independently and in a team environment.\nExperience publishing research in top-tier conferences and journals is highly desirable.\nPublished research findings in top-tier conferences and journals.\nPreferred Qualifications:\nMaster's or Ph.D. degree in Computer Science, Electrical Engineering, or a related field.\nDemonstrated experience in developing generative AI models and publishing research in top-tier conferences and journals.\nStrong knowledge of deep learning, natural language processing, and computer vision.\nExperience with scaling up generative models and deploying them in production environments.\nAbility to work collaboratively in a team environment and communicate complex technical concepts to non-technical stakeholders.\nShow more\nShow less",
      "job_skills":"Generative AI, Language Models, TexttoImage Models, PyTorch, TensorFlow GPU API, Neural Network Architectures, Nvidia CUDA, Python, GPT3, DALLE, CLIP, HighPerformance Computing Clusters, Deep Learning, Natural Language Processing, Computer Vision, ProblemSolving Skills, Team Environment",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"Globe Life",
      "job_location":"McKinney, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-globe-life-3787035088",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nSenior Data Scientist (two openings) needed in McKinney, Texas to apply mathematical and statistical theory and methods to collect, organize, interpret, and summarize numerical data and use that information to create business solutions and to find effective methods to achieve end goals. Applicants must have the minimum of a Master of Science in Mathematics, MIS, Applied Statistics, or a related field plus demonstrated knowledge using SAS, R, and Python to perform data analytics and to build predictive models using advanced machine learning algorithms. Demonstrated knowledge may be obtained prior to completion of degree. Must have legal authority to work in the U.S. Send resume\/references to: Lisa Matlock, Talent Acquisition Manager, ATTN: ZIP, Globe Life And Accident Insurance Company, 3700 S. Stonebridge Drive, McKinney, TX 75070. EOE.\nCompany Description\nCareer opportunity with excellent benefits including Pension, 401K match, Fitness Reimbursement, Education Assistance, and a great culture!\nCareer opportunity with excellent benefits including Pension, 401K match, Fitness Reimbursement, Education Assistance, and a great culture!\nShow more\nShow less",
      "job_skills":"Data Science, Statistics, Python, R, SAS, Machine Learning, Predictive Modeling, Data Analytics, Mathematical Modeling",
      "Category":"Backend Development"
  },
  {
      "job_title":"Technology Lead (Data Science | Machine Learning)",
      "company":"Ampstek",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/technology-lead-data-science-machine-learning-at-ampstek-3784411559",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Role: Technology Lead (Data Science | Machine Learning)\nLocation: Richardson, TX- On-site hybrid\nDuration: Long Term Contract\nJob description:\nRequired:\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Python, Bigdata Hadoop, Hive, SQL\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020GCP, Vertex AI\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Strong Experience as Data analyst using SQL, Python Scripting\nRecommended:\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020CI\/CD ML\u00ac\u2020Pipelines, Auto ML\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Tableau, Minitab, Databricks, Power BI\nJob Description:\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Overall 10+ yrs. of experience in SQL, Hive, Python Bigdata and Hadoop, Data mining with large data sets of Structured and Unstructured data\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Experience in implementing the solution for data preparation which is responsible for data transformation as wells as handling user stories.\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Developing and testing data Ingestion\/Preparation\/Dispatch jobs.\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Hands on Experience in Data Retrieval and uploading and creating customized reports from Microsoft SQL server database.\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Hands on Experience in python programming for performing complex data transformations and ETL\/ELT processes.\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Experience in Creating and ran python\/spark scripts that require extraction of large data sets.\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Proficient in Big Data with deep understanding of the Hadoop Distributed File System and Eco System (HDFS, Map Reduce, Hive, Sqoop, Oozie, Zookeeper, HBase, Flume, PIG, Apache Kafka) in a range of industries such as Retail and Communication sectors\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Data Acquisition, Data Validation, Predictive Modelling, and Data Visualization.\nExperienced in working with various methodologies, including SDLC, Agile, and Waterfall, to ensure efficient project execution and data analysis.\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Proficient in creating Apache Spark RDD transformations on Data sets in the Hadoop data lake. Used Apache Oozie to combine multiple jobs for Map Reduce, Hive, Pig, Sqoop into one logical unit of work\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Proficient in Python Libraries like NumPy, Pandas, Matplotlib, Seaborn, Scipy, ggplot2, and Pytorch for comprehensive data analysis and visualization.\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Expert in data visualization tools like Tableau, Power BI, and MS Excel for creating compelling, insightful reports and dashboards.\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Skilled in working with GCP Vertex AI & AWS to leverage cloud resources for data analysis, including EMR (Elastic MapReduce), ensuring scalability and efficiency.\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Capable of handling various database systems, such as MYSQL, SQL Server, and NoSQL, for data storage and retrieval.\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Experience in Agile process, Knowledge of using Jira for project management and GitHub for code repositioning.\n\u201a\u00c4\u00a2\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020\u00ac\u2020Proficiency in data cleaning and data wrangling techniques to ensure data quality and accuracy\nShow more\nShow less",
      "job_skills":"Python, Big Data, Hadoop, Hive, SQL, GCP, Vertex AI, Data Analyst, CI\/CD, Machine Learning Pipelines, Auto ML, Tableau, Minitab, Databricks, Power BI, Data Mining, Data Transformation, Data Ingestion, Data Preparation, Data Dispatch, Data Retrieval, Data Uploading, Data Visualization, Microsoft SQL Server, Spark, RDD Transformations, Apache Oozie, Apache Kafka, Apache Pig, Apache Sqoop, Apache Flume, Apache HBase, Apache Zookeeper, Apache MapReduce, HDFS, NumPy, Pandas, Matplotlib, Seaborn, Scipy, ggplot2, Pytorch, EMR, NoSQL, MySQL, SQL Server, Jira, GitHub, SDLC, Agile, Waterfall",
      "Category":"Backend Development"
  },
  {
      "job_title":"Project Engineer Data Manager Data Scientist",
      "company":"ComForCare Home Care (Raleigh, NC)",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/project-engineer-data-manager-data-scientist-at-comforcare-home-care-raleigh-nc-3771567384",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Project Engineer (Data Manager\/Data Scientist) Part Time \u201a\u00c4\u00ec Houston Remote\nPart Time Position \u201a\u00c4\u00ec minimum 8 hours a week up to 20 hours a week. Expected 2-3 hours a day + weekend hours if needed\nThe primary responsibility of this role is to extract meaningful insights from complex datasets, present this data to help guide the project in data-driven decision making, and to contribute to the development of data-driven product and solutions.\nMinimum of 15 years of experience in the engineering \/ construction industry, with proven leadership and excellent communication skills\nKnowledge of Lean process and philosophy\nKnowledge of organizational structure, scheduling systems, and management of available resources\nAbility to quickly and effectively solve complex problems\nAbility to set up and establish project specific technologies to support project delivery strategy\nMinimum 3 years of experience with Python (numpy, pandas, scikit-learn), SQL, Power BI, and Data Analysis\nBuild out SQL queries and views, Power BI dashboards, and data science ML models, and present methodology and key insights to stakeholders\nUse a diverse set of techniques spanning machine learning and other forms of statistical modeling to solve important business and product problems\nCollaborate with business leaders, subject matter experts, and decision makers to develop success criteria and optimize new products, features, policies, and models\nAbility to build relationships and collaborate within a team, internally and externally\nPreferred Education requirement: Masters Degree in an advanced quantitative and\/or scientific field, such as Data Science\nThis is a remote position.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Science, Machine Learning, Python, NumPy, Pandas, ScikitLearn, SQL, Power BI, Tableau, Statistical Modeling, Lean Process, Organizational Structure, Scheduling Systems, Resource Management, Problem Solving, Project Delivery Strategy, Business Intelligence, Data Visualization, Collaboration, Communication, Leadership",
      "Category":"Backend Development"
  },
  {
      "job_title":"Contract Data Science and Analytics Recruiter",
      "company":"Motion Recruitment",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/contract-data-science-and-analytics-recruiter-at-motion-recruitment-3779389251",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"This nationwide leading insurance company has an immediate contract opportunity for an experienced Contract Recruiter with extensive experience recruiting for Data Science and Data Analytics roles in a Corporate environment. Will work remotely but there's a strong preference for candidates within the DFW area. Must work in the CST time zone. This position requires someone with a successful track record of recruiting Data Science professionals, and Data Analytics professionals. Should also have experience recruiting Software Engineering professionals. Must be able to take direction, learn new processes quickly, and build relationships. Need to be adaptable to change with a strategic mindset and a sense of urgency with the capability of delivering exceptional service. Will be responsible for studying the business, working with leaders in Data Science, Data Analytics, and Engineering and Recruiting to understand current\/future recruiting needs, and then be a thought partner in executing solutions.\nIn this role, you will be the subject matter expert for all things engineering\/technical recruiting. You will be expected to find the best talent possible across the country to help lead exceptional teams and take them to the next level. Daily, you will consult with hiring managers to drive talent attraction campaigns and employ innovative search strategies to attract top talent. Additionally, you will consult with hiring teams as the expert on candidate market trends, compensation recommendations, and interviewing best practices.\nContract Duration: 3 Months (with chance for extension\/conversion)\nRequired Skills & Experience\n5+ years of technical recruitment experience hiring Data Science professionals and Data Analytics professionals in a Corporate environment.\nProven experience with recruiting Software Engineers in a Corporate environment (ie. Java, Ruby on Rails, Android, iOS, Telematics, etc).\nKnowledge of and experience with Workday Applicant Tracking System.\nProficient with Microsoft Office Suite or related software.\nAbility to effectively prioritize and organize workload in a constantly changing environment to meet daily, weekly, and monthly deadlines.\nAbility to create and implement sourcing strategies for recruitment for a variety of roles.\nMust be proactive and independent with the ability to take initiative.\nExcellent people skills, with ability to manage sensitive and confidential situations with tact, professionalism, and diplomacy.\nExcellent organizational skills and diligence.\nStrong analytical and critical thinking skills.\nAbility to work in a team and independently.\nExemplary communication skills - we believe the best communication is honest, empathetic, and clear.\nCreative thinking and intellectual curiosity - Often, the best approach isn\u201a\u00c4\u00f4t the first one suggested. The ability to think outside the box will be an asset in this role.\nStrong analytical skills to use data to drive decisions.\nAbility to iterate quickly and change your approach with the dynamic needs of the business.\nOwnership - you\u201a\u00c4\u00f4ll be working with a great deal of autonomy to meet hiring needs.\nWhat You Will Be Doing\nManaging the full recruitment cycle including sourcing strategies, interview processes, and offer negotiations for assigned requisitions.\nLiving between the business and the candidate. It\u201a\u00c4\u00f4s your responsibility to use your context on the needs of the business and the perspective of the candidate to create a best-in-class candidate experience in every touchpoint.\nReaching out to qualified candidates utilizing tools like GitHub, LinkedIn, Stack Overflow, and more.\nExploring new channels and strategic partnerships for recruiting and using data to validate or eliminate each hypothesized approach.\nServing as an advisor to hiring managers throughout the hiring process on matters such as interviewing techniques, compliance, selection protocols, offer management, etc.\nCritically evaluating hiring processes and solutions to ensure that you're approaching each specific problem with the best possible solution.\nShow more\nShow less",
      "job_skills":"Technical Recruiting Experience, Data Science, Data Analytics, Software Engineering, Java, Ruby on Rails, Android, iOS, Telematics, Workday Applicant Tracking System, Microsoft Office Suite, Strategic Mindset, Proactive, Communication, Creative Thinking, Analytical Skills, GitHub, LinkedIn, Stack Overflow",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist-locals",
      "company":"Steneral Consulting",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-locals-at-steneral-consulting-3745145983",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Role:\nData Scientist\nLocation:\nHybrid on site 3 days\/week in Dallas, TX 75254\nTerm:\n3+ months Contract to hire\n$120K\/year salary\n(USC\/ GC Holder ONLY)\nJob Description\nThe successful candidate will be innovation-minded with a blend of skills in data analytics, data engineering, and data science. This individual will dive deep into analytics, model workflows, and data pipelines for our manufacturing business, while concentrating on support for the entire enterprise. This includes production-line workforce modeling & analytics and supporting our lease fleet operations. The role is a unique blend of various skill domains - we're seeking an individual who can navigate these priorities with ease while unlocking value for our integrated business platform.\nWhat You'll Do\nLead development of end-to-end analytics projects for our manufacturing, leasing, and supply chain groups from conception through delivery, driving effective collaboration and alignment with business stakeholders\nWork closely with business leaders, project stakeholders, and subject matter experts to understand and optimize key business processes. Apply your SQL, data transformation, and data modeling skills to turn data into actionable insights and optimized solutions\nPartner with data engineers on technical design of complex data sourcing, transformation, and aggregation logic to meet business analytics needs and deliver value. Leverage generative AI in analytical work where applicable\nWork with data analysts to translate business requirements into impactful data visualizations and data models in platforms like Qliksense, Tableau, PowerBI, and other analytics tools\nWhat You'll Need\nBachelor\u201a\u00c4\u00f4s Degree in quantitative field such as Mathematics, Economics, Computer Science, Information Management, Statistics, Finance or Accounting. Masters and\/or PhD preferred\n5+ years relevant experience in related analytics, data science, and business intelligence\nExpert-level skills in Data Analytics with advanced analytical languages (Python, R, Spark, Scala, and\/or Julia)\nMust possess exceptional communication\/presentation skills, both verbal and written\nFamiliarity with industrial manufacturing and supply chain processes highly preferred\nPossess competencies with SQL, Generative AI prompting, and data transformation tools. Seamlessly leverage generative AI tools like GPT, Co-Pilot, and other technologies as core aspects of the development process\nAdvanced skills in Data Architecting, Visualization, SQL, Microsoft Excel, PowerPoint\nTechnical fluency regarding data mining, data models, database design\/development, and other segmentation techniques, usage of Data Orchestration & Modeling platforms (e,g. Azure Databrick & Data Factory)\nExperience with data visualization tools such as Qliksense and techniques in translating business analytics needs into data visualization and semantic data access requirements\nIntermediate skills in Application development with Business Intelligence tools (e,g. Qliksense, Tableau, Power BI, etc.)\nStrong organizational, time management and multi-tasking skills\nPrior experience with Palantir Foundry, including developing integrated workflows, process improvement and automation highly preferred\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Engineering, Data Science, Python, R, Spark, Scala, Julia, SQL, Generative AI, Qliksense, Tableau, PowerBI, Microsoft Excel, PowerPoint, Azure Databrick & Data Factory, Palantir Foundry",
      "Category":"Backend Development"
  },
  {
      "job_title":"Urgent Role - Sr. Data Scientist || Hybrid",
      "company":"Steneral Consulting",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/urgent-role-sr-data-scientist-hybrid-at-steneral-consulting-3707649900",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nTitle: Sr. Data Scientist\nLocation:\nHybrid\nDuration: 6+ Months\nPosition Details\nMust be local to either of the 3 locations and under 60 mins commute and willing to work hybrid, 3-days onsite from either of the following client locations:\nPlano, TX\nReston, VA\nBethesda, MD\nMust have at least 5 years of actual experience functioning as a Data Scientist within an enterprise organization\nMust have some form of Mortgage or Financial Services Industry experience in which they have dealt with mortgages and understand the mortgage business and terminology\nMUST HAVE STRONG COMMUNICATION SKILLS as this individual will be the spokesperson for the Data Science Team presenting to senior leadership and executive teams\nResponsibilities\nJOB DESCRIPTION\nFormulating, suggesting, and managing data-driven projects which are geared at furthering the business's interests\nCollating and cleaning data from various entities\nSelecting and employing advanced statistical procedures to obtain actionable insights\nCross-validating models to ensure their generalizability\nEstablishing governance framework and documentation\nProducing and disseminating non-technical reports that detail the successes and limitations of each project\nSuggesting ways in which insights obtained might be used to inform business strategies, and presenting to senior leadership teams s the spokesperson for the Data Science Team\nStaying informed about developments in Data Science and adjacent fields to ensure that outputs are always relevant\nRequirements\nAdvanced degree in data science, statistics, computer science, or similar\nExtensive experience as a data scientist must have at least 5 years of experience functioning in a true Data Scientist role within an enterprise organization\nProficiency Python and R\nProficiency working with Domino Data Lab, Sage Maker, and Alteryx\nIn-depth understanding of SQL\nCompetent in machine learning principles and techniques\nDemonstrable history of devising and overseeing data-centered projects\nAbility to relay insights in layman's terms, such that these can be used to inform business decisions\nTeam leadership and mentorship abilities\nCapacity to foster a healthy, stimulating work environment that frequently harnesses teamwork\nCompliance with prevailing ethical standards\nPreferred experience working with Business Intelligence 7 Analytics Teams utilizing tools such as Tableau, SQL, and Python\nSkilled in Data Modeling, working with Conceptual data models, logical data models and physical data models\nShow more\nShow less",
      "job_skills":"Data Science, Statistical Analysis, Machine Learning, Python, R, Domino Data Lab, Sage Maker, Alteryx, SQL, Data Cleaning, Data Governance, Data Visualization, Tableau, Business Intelligence, Data Modeling",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Scientist || Plano, TX || Reston, VA || Bethesda, MD",
      "company":"Steneral Consulting",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-scientist-plano-tx-reston-va-bethesda-md-at-steneral-consulting-3710640456",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Need candidate salary expectations\nCandidates will need to have been a part of launching a Data Science practice for an enterprise, or have been involved in leading a Data Science practice. This candidate will be launching this Data Science Team and needs to have been a part of such type of activities.\nMust be local to either of the 3 locations and under 60 mins commute and willing to work hybrid, 3-days onsite from either of the following client locations:\nPlano, TX\nReston, VA\nBethesda, MD\nMust have at least 5 years of actual experience functioning as a Data Scientist within an enterprise organization\nMust have some form of Mortgage or Financial Services Industry experience in which they have dealt with mortgages and understand the mortgage business and terminology\nMUST HAVE STRONG COMMUNICATION SKILLS as this individual will be the spokesperson for the Data Science Team presenting to senior leadership and executive teams\nResponsibilities\nJOB DESCRIPTION\nFormulating, suggesting, and managing data-driven projects which are geared at furthering the business's interests\nCollating and cleaning data from various entities\nSelecting and employing advanced statistical procedures to obtain actionable insights\nCross-validating models to ensure their generalizability\nEstablishing governance framework and documentation\nProducing and disseminating non-technical reports that detail the successes and limitations of each project\nSuggesting ways in which insights obtained might be used to inform business strategies, and presenting to senior leadership teams s the spokesperson for the Data Science Team\nStaying informed about developments in Data Science and adjacent fields to ensure that outputs are always relevant\nRequirements\nAdvanced degree in data science, statistics, computer science, or similar\nExtensive experience as a data scientist must have at least 5 years of experience functioning in a true Data Scientist role within an enterprise organization\nProficiency Python and R\nProficiency working with Domino Data Lab, Sage Maker, and Alteryx\nIn-depth understanding of SQL\nCompetent in machine learning principles and techniques\nDemonstrable history of devising and overseeing data-centered projects\nAbility to relay insights in layman's terms, such that these can be used to inform business decisions\nTeam leadership and mentorship abilities\nCapacity to foster a healthy, stimulating work environment that frequently harnesses teamwork\nCompliance with prevailing ethical standards\nPreferred experience working with Business Intelligence 7 Analytics Teams utilizing tools such as Tableau, SQL, and Python\nSkilled in Data Modeling, working with Conceptual data models, logical data models and physical data models\nShow more\nShow less",
      "job_skills":"Data Science, Launching Data Science Team, Communication Skills, Collating Data, Statistical Procedures, CrossValidating Models, Governance Framework, NonTechnical Reports, Business Strategies, Data Science Developments, Advanced Degree in Data Science or Related, Data Scientist Experience, Proficiency in Python and R, Proficiency in Domino Data Lab Sage Maker and Alteryx, SQL, Machine Learning, DataCentered Projects, Business Insights, Team Leadership, Mentorship, Teamwork, Data Modeling, Conceptual Data Models, Logical Data Models, Physical Data Models",
      "Category":"Backend Development"
  },
  {
      "job_title":"Hybrid Work - Need Sr Data Scientist in Plano, TX Reston, VA Bethesda, MD",
      "company":"Steneral Consulting",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/hybrid-work-need-sr-data-scientist-in-plano-tx-reston-va-bethesda-md-at-steneral-consulting-3723238852",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Need candidate salary expectations\nCandidates will need to have been a part of launching a Data Science practice for an enterprise, or have been involved in leading a Data Science practice. This candidate will be launching this Data Science Team and needs to have been a part of such type of activities.\nMust be local to either of the 3 locations and under 60 mins commute and willing to work hybrid, 3-days onsite from either of the following client locations:\nPlano, TX\nReston, VA\nBethesda, MD\nMust have at least 5 years of actual experience functioning as a Data Scientist within an enterprise organization\nMust have some form of Mortgage or Financial Services Industry experience in which they have dealt with mortgages and understand the mortgage business and terminology\nMUST HAVE STRONG COMMUNICATION SKILLS as this individual will be the spokesperson for the Data Science Team presenting to senior leadership and executive teams\nResponsibilities\nJOB DESCRIPTION\nFormulating, suggesting, and managing data-driven projects which are geared at furthering the business's interests\nCollating and cleaning data from various entities\nSelecting and employing advanced statistical procedures to obtain actionable insights\nCross-validating models to ensure their generalizability\nEstablishing governance framework and documentation\nProducing and disseminating non-technical reports that detail the successes and limitations of each project\nSuggesting ways in which insights obtained might be used to inform business strategies, and presenting to senior leadership teams s the spokesperson for the Data Science Team\nStaying informed about developments in Data Science and adjacent fields to ensure that outputs are always relevant\nRequirements\nAdvanced degree in data science, statistics, computer science, or similar\nExtensive experience as a data scientist \u201a\u00c4\u00ec must have at least 5 years of experience functioning in a true Data Scientist role within an enterprise organization\nProficiency Python and R\nProficiency working with Domino Data Lab, Sage Maker, and Alteryx\nIn-depth understanding of SQL\nCompetent in machine learning principles and techniques\nDemonstrable history of devising and overseeing data-centered projects\nAbility to relay insights in layman's terms, such that these can be used to inform business decisions\nTeam leadership and mentorship abilities\nCapacity to foster a healthy, stimulating work environment that frequently harnesses teamwork\nCompliance with prevailing ethical standards\nPreferred experience working with Business Intelligence 7 Analytics Teams utilizing tools such as Tableau, SQL, and Python\nSkilled in Data Modeling, working with Conceptual data models, logical data models and physical data models\nShow more\nShow less",
      "job_skills":"Data Science, Statistical Analysis, Machine Learning, Python, R, Domino Data Lab, Sage Maker, Alteryx, SQL, Tableau, Data Modeling, Conceptual Data Models, Logical Data Models, Physical Data Models",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Scientist|| LOCAL Plano, TX Reston, VA Bethesda, MD",
      "company":"Steneral Consulting",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-scientist-local-plano-tx-reston-va-bethesda-md-at-steneral-consulting-3712853881",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Need candidate salary expectations\nCandidates will need to have been a part of launching a Data Science practice for an enterprise, or have been involved in leading a Data Science practice. This candidate will be launching this Data Science Team and needs to have been a part of such type of activities.\nMust be local to either of the 3 locations and under 60 mins commute and willing to work hybrid, 3-days onsite from either of the following client locations:\nPlano, TX\nReston, VA\nBethesda, MD\nMust have at least 5 years of actual experience functioning as a Data Scientist within an enterprise organization\nMust have some form of Mortgage or Financial Services Industry experience in which they have dealt with mortgages and understand the mortgage business and terminology\nMUST HAVE STRONG COMMUNICATION SKILLS as this individual will be the spokesperson for the Data Science Team presenting to senior leadership and executive teams\nResponsibilities\nJOB DESCRIPTION\nFormulating, suggesting, and managing data-driven projects which are geared at furthering the business's interests\nCollating and cleaning data from various entities\nSelecting and employing advanced statistical procedures to obtain actionable insights\nCross-validating models to ensure their generalizability\nEstablishing governance framework and documentation\nProducing and disseminating non-technical reports that detail the successes and limitations of each project\nSuggesting ways in which insights obtained might be used to inform business strategies, and presenting to senior leadership teams s the spokesperson for the Data Science Team\nStaying informed about developments in Data Science and adjacent fields to ensure that outputs are always relevant\nRequirements\nAdvanced degree in data science, statistics, computer science, or similar\nExtensive experience as a data scientist must have at least 5 years of experience functioning in a true Data Scientist role within an enterprise organization\nProficiency Python and R\nProficiency working with Domino Data Lab, Sage Maker, and Alteryx\nIn-depth understanding of SQL\nCompetent in machine learning principles and techniques\nDemonstrable history of devising and overseeing data-centered projects\nAbility to relay insights in layman's terms, such that these can be used to inform business decisions\nTeam leadership and mentorship abilities\nCapacity to foster a healthy, stimulating work environment that frequently harnesses teamwork\nCompliance with prevailing ethical standards\nPreferred experience working with Business Intelligence 7 Analytics Teams utilizing tools such as Tableau, SQL, and Python\nSkilled in Data Modeling, working with Conceptual data models, logical data models and physical data models\nShow more\nShow less",
      "job_skills":"Data Science, Statistical Procedures, CrossValidation, Governance Framework, Business Strategies, Python, R, Domino Data Lab, Sage Maker, Alteryx, SQL, Machine Learning, Business Intelligence, Tableau, Data Modeling, Conceptual Data Models, Logical Data Models, Physical Data Models",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"IDR, Inc.",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-idr-inc-3781650316",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"IDR is seeking a\nData Scientist\nto join one of our top clients in the North Dallas area. This is a long-term opportunity, so if you are looking for an opportunity to join a large organization and work within an ever-growing, team-oriented culture, please apply today!\nResponsibilities For The Data Scientist\nLead development of end-to-end analytics projects for our client\u201a\u00c4\u00f4s manufacturing, leasing, and supply chain groups from conception through delivery, driving effective collaboration and alignment with business stakeholders\nWork closely with business leaders, project stakeholders, and subject matter experts to understand and optimize key business processes. Apply your SQL, data transformation, and data modeling skills to turn data into actionable insights and optimized solutions\nPartner with data engineers on technical design of complex data sourcing, transformation, and aggregation logic to meet business analytics needs and deliver value. Leverage generative AI in analytical work where applicable\nWork with data analysts to translate business requirements into impactful data visualizations and data models in platforms like Qliksense, Tableau, PowerBI, and other analytics tools\nRequired Skills For The Data Scientist\nBachelor\u201a\u00c4\u00f4s Degree in quantitative field such as Mathematics, Economics, Computer Science, Information Management, Statistics, Finance or Accounting. Masters and\/or PhD preferred\n5+ years relevant experience in related analytics, data science, and business intelligence\nPrior experience working for an industrial manufacturing and\/or supply chain company\n4+ years experience with Python and R\nExperience with data visualizations and data models in platforms like Qliksense, Tableau, PowerBI, and other analytics tools is preferred\nExcellent Communication and the ability to effectively communicate data stories to key stakeholders\nWhat\u201a\u00c4\u00f4s in it for you?\nCompetitive compensation package\nFull Benefits; Medical, Vision, Dental, and more!\nOpportunity to get in with an industry leading organization\nClose-knit and team-oriented culture\nWhy IDR?\n20+ Years of Proven Industry Experience in 4 major markets\nEmployee Stock Ownership Program\nDedicated Engagement Manager who is committed to you and your success\nMedical, Dental, Vision, and Life Insurance\nClearlyRated\u201a\u00c4\u00f4s Best of Staffing\u00ac\u00c6 Client and Talent Award winner 10 years in a row\nShow more\nShow less",
      "job_skills":"Data Science, Analytics, SQL, Data Transformation, Data Modeling, Generative AI, Data Visualization, QlikSense, Tableau, PowerBI, Python, R, Communication, Data Storytelling, Mathematics, Economics, Computer Science, Information Management, Statistics, Finance, Accounting",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Scientist",
      "company":"Keylent Inc",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-scientist-at-keylent-inc-3768063413",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Position:\nLead Data Scientist\nLocation:\nDallas, TX (Hybrid)\nDuration:\n12 months\nDevelop and operate AI\/Client , NLP models using Python\nExp with Big data, ETL , Database and BI tools\nShow more\nShow less",
      "job_skills":"Lead Data Scientist, Data Science, Artificial Intelligence, Natural Language Processing, Python, Big Data, ETL, Database, BI tools",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineering Specialist",
      "company":"Revature",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineering-specialist-at-revature-3787699911",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description:\nSenior Data Engineer:\n\u201a\u00c4\u00a2 Problem Formulation: Identifies possible options to address the business problems within one's discipline through analytics, big data analytics and automation.\n\u201a\u00c4\u00a2 Applied Business Acumen: Supports the development of business cases and recommendations. Owns delivery of project activity and tasks assigned by others. Supports process updates and changes to solves business issues.\n\u201a\u00c4\u00a2 Data Governance: Supports the documentation of data governance processes. Supports the implementation of data governance practices.\n\u201a\u00c4\u00a2 Data Strategy: Understands, articulates and applies principles of the defined strategy to routine business problems that involve a single function.\n\u201a\u00c4\u00a2 Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current analytics trends.\n\u201a\u00c4\u00a2 Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data.\n\u201a\u00c4\u00a2 Data Modeling: Analyzes complex data elements, systems, data flows, dependencies and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary, foreign keys and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyzes data-related system integration challenges and proposes appropriate solutions.\n\u201a\u00c4\u00a2 Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Contributes code documentation, maintains playbooks, and provides timely progress updates.\n\u201a\u00c4\u00a2 Demonstrates up-to-date expertise, applies this to the development and execution.\n\u201a\u00c4\u00a2 Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders. Adapt to competing demands, organizational changes and new responsibilities.\n\u201a\u00c4\u00a2 Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans.\n\u201a\u00c4\u00a2 You have consistently high standards, your passion for quality is inherent in everything.\n\u201a\u00c4\u00a2 Well versed with Hadoop, Hive, Spark using Scala.\n\u201a\u00c4\u00a2 You evangelize an extremely high standard of code quality, system reliability, and performance\n\u201a\u00c4\u00a2 You have a proven track record coding with at least one programming language (e.g., Java, Python)\n\u201a\u00c4\u00a2 You\u201a\u00c4\u00f4re experienced in computing platforms (e.g., GCP, Azure)\n\u201a\u00c4\u00a2 You\u201a\u00c4\u00f4re skilled in data modeling & data migration protocols\n\u201a\u00c4\u00a2 Experience with ThoughtSpot, Druid, Big Query and ClickHouse is added advantage.\n\u201a\u00c4\u00a2 Experience with the integration tools like Automic, Airflow\nShow more\nShow less",
      "job_skills":"Hadoop, Hive, Spark, Scala, Java, Python, GCP, Azure, ThoughtSpot, Druid, Big Query, ClickHouse, Automic, Airflow, Data governance, Data strategy, Data transformation, Data integration, Data modeling, Code development, Testing, Compliance, Data pipelines",
      "Category":"Backend Development"
  },
  {
      "job_title":"Staff, Data Scientist",
      "company":"Walmart",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/staff-data-scientist-at-walmart-3781739616",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"We are looking for a\nStaff Data Scientist\nto join\nSam\u201a\u00c4\u00f4s Club Fraud\ndetection team. As a Staff Data Scientist, you will be responsible for owning fraud risks in various product segments and being a strategic partner to product & business teams. You will be tasked to set goals, create strategy, and closely collaborate with product managers, engineers and business stakeholders. You\u201a\u00c4\u00f4ll be responsible for detecting changed fraud trends, building and implementing ML models with high-dimensional, fast moving real time dataset and driving innovation in detecting & preventing fraud across various channels.\nWhat you'll do:\nUse machine learning to develop models\nfor\nfraud detection\nin areas such as E-Commerce & In-club payment fraud, Return abuse, Account takeover (ATO) etc.\nPartnering with business and technical stakeholders to translate fraud business problems into data science solutions.\nWork on highly-scalable ML models and algorithms\nin big data mining, graph modeling & other domains.\nWork with engineering teams to implement model pipeline and deploy the service at scale.\nSwiftly respond to system issues and deep dive into root cause analysis\nWhat you'll bring:\nIndustry experience in building production machine learning systems at scale.\nExperienced with languages used to manipulate data and draw insights from large data sets (e.g. Python, SQL, etc.)\nExperience working with large data sets and distributed computing tools (PySpark\/GCP\/BigQuery).\nExperience in fraud risk solutions is desirable\nExperience in working with cross-functional product and engineering teams to understand requirements and incorporate them in the roadmap.\nAbout Walmart General\/Not Function Specific\nSam Walton opened the first Sam's Club in 1983 to meet a growing need among customers who wanted to buy merchandise in bulk. Since then, Sam's Club has grown rapidly, opening more than 600 clubs in the U.S. and 100 clubs internationally. By offering affordable, wholesale merchandise to members, Sam's Club helps make saving simple for families and small business owners. Sam's Club employs about 110,000 associates in the U.S. The average club is 134,000 square feet and offers bulk groceries and general merchandise. Most clubs also have specialty services, such as a pharmacy, an optical department, a photo center, or a tire and battery center.\nFlexible, hybrid work:\nWe use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.\nBenefits:\nBeyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.\nEqual Opportunity Employer:\nSam\u201a\u00c4\u00f4s Club is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, abilities, ideas and opinions- while being inclusive of all people.\nThe above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.\nShow more\nShow less",
      "job_skills":"Data Science, Fraud Detection, Machine Learning, Python, SQL, PySpark, GCP, BigQuery, Data Manipulation, Data Insights, Distributed Computing, Model Pipeline, Model Deployment, System Issues, Root Cause Analysis",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Pinnacle Group, Inc.",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-pinnacle-group-inc-3787392082",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Role: Data Scientist\nLocation: Tampa, FL OR Irving, TX (Hybrid)\nDuration: 6 Month Contract (Possible Extension or Hire)\nW2 ONLY NO C2C!!\nJob Overview:\nThe Data Scientist must be able to work with large and complex data sets to evaluate, recommend, and support the implementation of business strategies. The ideal candidate has experience in solving analytical problems using quantitative approaches with a passion for data & statistics.\nResponsibilities:\n\u201a\u00c4\u00a2 Mine and analyze large sets of data\n\u201a\u00c4\u00a2 Identify gaps and opportunities for improvement\n\u201a\u00c4\u00a2 Leverage this data to develop strategic roadmaps\n\u201a\u00c4\u00a2 Define and deploy metrics for measuring process improvement\n\u201a\u00c4\u00a2 Institute feedback models to enable continuous process improvement\n\u201a\u00c4\u00a2 Conduct research and publish artifacts to drive simplification\n\u201a\u00c4\u00a2 Review \/ Author operational procedures\n\u201a\u00c4\u00a2 Distill information provided by subject matter experts and other partners into executive-level narratives\n\u201a\u00c4\u00a2 Establish foundational and execution work streams for process improvement and automation initiatives\n\u201a\u00c4\u00a2 Partner with Domain and Technical architecture teams to drive efficiency\nTo be effective in this role, the candidate should possess the following:\n\u201a\u00c4\u00a2 5-8 years of Data Analysis, or relevant experience with at least 2 years as a Data Scientist.\n\u201a\u00c4\u00a2 Knowledge and experience of a variety of exploratory data analysis, predictive modelling, anomaly detection and their real-world advantages\/drawbacks.\n\u201a\u00c4\u00a2 Experience using statistical computer languages like Python, R, etc.\n\u201a\u00c4\u00a2 Working to deep knowledge of financial products and automation solutions\n\u201a\u00c4\u00a2 Machine learning experience is a plus\n\u201a\u00c4\u00a2 Experience in predictive model a\/b testing and training models\n\u201a\u00c4\u00a2 Experience in complex data extraction techniques and data cleansing methodologies\n\u201a\u00c4\u00a2 Ability to deconstruct descriptive data into meaningful categories for predictive modeling and visual analysis.\n\u201a\u00c4\u00a2 Responsible for documenting data requirements, data collection \/ processing \/ cleaning, and exploratory data analysis; which may include utilizing statistical models \/ algorithms and data visualization techniques\n\u201a\u00c4\u00a2 Identifies and compiles data sets using a variety of tools (e.g. SQL, Access) to help predict, improve, and measure the success of key business to business outcomes\n\u201a\u00c4\u00a2 Experience in all the phases of a software development lifecycle project including requirements gathering, analysis, design, and implementation through agile and\/or waterfall and\/or hybrid methodologies\n\u201a\u00c4\u00a2 Excellent problem-solving skills, including the ability to grasp new concepts quickly, lead diverse partners toward reasonable recommendations, and prepare decisions in a logical fashion with supporting impact, to aid in timely decision making\n\u201a\u00c4\u00a2 Ability to develop and manage a comprehensive program plan and dependencies\n\u201a\u00c4\u00a2 Intellectually curious, consistently seeking and developing new opportunities\n\u201a\u00c4\u00a2 Self-starter, with an ability to lead and execute work with limited to no supervision\n\u201a\u00c4\u00a2 Ability in strategic thinking and the ability to frame business problems\n\u201a\u00c4\u00a2 Excellent written and verbal communication skills; must be able to understand detailed problem resolution discussions and condense pertinent facts for senior leadership\n\u201a\u00c4\u00a2 Experienced with data visualization tools a plus\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Scientist, Exploratory Data Analysis, Predictive Modelling, Anomaly Detection, Python, R, Machine Learning, Predictive Model A\/B Testing, Data Extraction, Data Cleansing, Data Requirements, Data Collection, Data Processing, Data Cleaning, Exploratory Data Analysis, Statistical Models, Algorithms, Data Visualization, SQL, Access, Software Development Lifecycle, Requirements Gathering, Analysis, Design, Implementation, Agile, Waterfall, Hybrid Methodologies, ProblemSolving, Program Plan, Comprehensive Dependencies, Strategic Thinking, Business Problems, Communication Skills, Data Visualization Tools",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Radley James",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-radley-james-3783659834",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Join a highly analytical, team-oriented derivatives trading firm headquartered in Dallas, Texas dedicated to assisting the world in pricing and managing risk. They are currently seeking a talented Data Scientist to join their team.\nPosition Overview:\nThis role is more prescriptive in nature where you will work on large amounts of messy data which is both internally generated as well as external data from vendors and exchanges. Your will work closely with Quant Researchers, Engineers and Traders to optimize trading strategies by owning and maintaining useful datasets, measuring the impact of various parameters in our strategies. You will write production code to make relevant data available to trading strategies both in real time and for offline analysis to provide good feedback to desk that will improve the KPIs\nKey Responsibilities:\nApply machine learning techniques to analyze and model large scale financial data.\nDevelop and implement data-driven trading strategies and risk management solutions.\nUtilize Python, including Pandas, NumPy, and SciPy, for data manipulation and analysis.\nOptimize trading strategies and help traders identify where the opportunities lie\nDesign experiments and analyze large datasets to identify market opportunities.\nPropose hypothesis to improve strategies, design experiment to measure the changes and apply rigorous statistical tests to prove\/disprove the hypothesis.\nCommunicate findings and recommendations effectively to stakeholders.\nQualifications:\nBachelor's or Master's degree in Computer Science, Data Science, Statistics, or a related field.\n4+ years of experience in wrangling and manipulating large scale data efficiently and dealing with data issues that come with it\nExcellent skills in Python, with proficiency in Pandas, NumPy, and SciPy.\nUnderstanding real time data feed, building models and using them for real time to make predictions and decision.\nProven experience with large scale data management, creating pipelines and extracting insights from large data sets\nExpertise in SQL to write efficient queries and basic familiarity with Linux\nAbility to work independently and collaboratively in a fast-paced trading environment.\nFamiliarity with financial markets and trading is a big plus.\nWhat We Offer:\nCompetitive compensation, including performance-based bonuses & relocation support within the US\nGenerous medical coverage, paid parental leave, free breakfast and lunch, wellness.\nThe opportunity to work on cutting-edge trading strategies and risk management solutions.\nProfessional development and training opportunities.\nA collaborative and innovative work culture that values excellence.\nShow more\nShow less",
      "job_skills":"Machine Learning, Data Analysis, Data Science, Python, Pandas, NumPy, SciPy, Data Manipulation, Statistical Modeling, Statistical Testing, Hypothesis Testing, Experiment Design, Data Management, Data Pipelines, SQL, Linux, Financial Markets, Trading Strategies, Risk Management",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"IDR, Inc.",
      "job_location":"Coppell, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-idr-inc-3784019064",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"IDR is seeking a\nData Scientist\nto join one of our top clients in\nLas Colinas, TX\n. This is a long-term, hybrid opportunity! If you are looking for an opportunity to join a large organization and work within an ever-growing team-oriented culture, please apply today!\n**THIS POSITION IS W2 ONLY!**\nResponsibilities for the Data Scientist:\nThe Data Scientist will join the project management office.\nThe Data Scientist will focus on the following areas: Statistics, Time Series Analysis \/ Forecasting, Machine Learning Algorithms, Mathematical Optimization.\nThe ideal candidate will be responsible for integrating new data sources into the backend platform, creating custom data science models from scratch using the integrated data sources as well as maintaining existing data science tools.\nAdditionally, the candidate should be comfortable building custom data science models based on large datasets as well as financial modeling based on structured data and hybrid models that consider both.\nThe Data Scientists will provide leadership with updates on ongoing data analytics initiatives in a layman-friendly, business-oriented manner.\nRequired Skills for the Data Scientist:\n3-5 years experience in Data Science and Analytics\n3-5 years experience using Python and SQL\nExperience with data visualizations and data models in one of the following platforms: Power BI, Tableau, Python Visuals\nExperience communication with executive leadership\nShow more\nShow less",
      "job_skills":"Data Science, Analytics, Statistics, Time Series Analysis, Forecasting, Machine Learning Algorithms, Mathematical Optimization, Python, SQL, Data Visualization, Data Models, Power BI, Tableau, Python Visuals, Executive Communication",
      "Category":"Backend Development"
  },
  {
      "job_title":"AI\/ML Developer \/ Lead Data Scientist",
      "company":"Synechron",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/ai-ml-developer-lead-data-scientist-at-synechron-3765446667",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Title: AI\/ML Developer \/ Lead Data Scientist\nJob Type: Consulting\nJob Location: Dallas, Texas, United States\nOverview:\nWe are seeking a highly skilled and motivated AI\/ML Engineer with NLP and LLM (Language and Learning Models) experience to join our team. The ideal candidate will have a strong background in artificial intelligence, machine learning, natural language processing (NLP), and experience working with large language models (LLM). The AI\/ML Engineer will be responsible for developing and implementing AI\/ML models and algorithms to solve complex problems related to language understanding and generation. This role requires a deep understanding of cutting-edge AI\/ML technologies, strong programming skills, and a passion for pushing the boundaries of AI capabilities.\nResponsibilities:\nDevelop and implement AI\/ML models and algorithms for natural language understanding and generation.\nWork closely with cross-functional teams to define and refine project requirements.\nConduct research and stay up-to-date with the latest advancements in AI\/ML, NLP, and LLM.\nDesign and implement data collection and preprocessing strategies.\nTrain, fine-tune, and evaluate AI\/ML models using large-scale datasets.\nOptimize and deploy AI\/ML models in production environments.\nCollaborate with software engineers to integrate AI\/ML models into existing systems.\nPerform thorough testing and debugging of AI\/ML models to ensure accuracy and reliability.\nMonitor and analyze model performance, identify areas for improvement, and propose solutions.\nStay informed about industry best practices and incorporate them into the development process.\nDocument code, models, methodologies, and experimental results for future reference.\nRequirements:\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\nStrong background in artificial intelligence, machine learning, and natural language processing.\nProficiency in programming languages such as Python, Java, or C++.\nExperience with AI\/ML frameworks and libraries such as TensorFlow, PyTorch, or Scikit-learn.\nIn-depth knowledge of NLP techniques, including text classification, sentiment analysis, named entity recognition, and topic modeling.\nFamiliarity with large language models (LLM) such as GPT, BERT, or Transformer models.\nExperience with data preprocessing, feature engineering, and data augmentation techniques.\nSolid understanding of statistical analysis, data mining, and data visualization.\nStrong problem-solving and analytical skills.\nExcellent communication and collaboration skills.\nAbility to work independently and in a team-oriented environment.\nProven track record of delivering high-quality AI\/ML solutions.\nWe can offer you:\nA highly competitive compensation and benefits package\nA multinational organization with 44 offices in 19 countries and the possibility to work abroad\nLaptop and a mobile phone\n10 days of paid annual leave (plus sick leave and national holidays)\nMaternity & Paternity leave plans\nA comprehensive insurance plan including: medical, dental, vision, life insurance, and long-\/short-term disability (plans vary by region)\nRetirement savings plans\nA higher education certification policy\nCommuter benefits (varies by region)\nExtensive training opportunities, focused on skills, substantive knowledge, and personal development\nOn-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses\nCoaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups\nCutting edge projects at the world\u201a\u00c4\u00f4s leading tier-one banks, financial institutions and insurance firms\nA flat and approachable organization\nAn excellent working atmosphere: regular drinks, sports activities, offsite weekends with a young, dynamic team\nA truly diverse, fun-loving and global work culture\nSYNECHRON\u201a\u00c4\u00f4S DIVERSITY & INCLUSION STATEMENT\nDiversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative \u201a\u00c4\u00f2Same Difference\u201a\u00c4\u00f4 is committed to fostering an inclusive culture \u201a\u00c4\u00ec promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more.\nAll employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant\u201a\u00c4\u00f4s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.\nThanks and Regards\nVikarant Kumar\nShow more\nShow less",
      "job_skills":"AI, Machine Learning, Natural Language Processing (NLP), Language and Learning Models (LLM), Python, Java, C++, TensorFlow, PyTorch, Scikitlearn, Text classification, Sentiment analysis, Named entity recognition, Topic modeling, GPT, BERT, Transformer models, Data preprocessing, Feature engineering, Data augmentation, Statistical analysis, Data mining, Data visualization, Problemsolving, Analytical",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"ValueBase Consulting",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-valuebase-consulting-3782839037",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Company Description\nValueBase Consulting is a Minnesota-based IT consulting firm that provides services to industries such as Information Technologies and Human Resource Management. Our clients have confidence in us, which is why our firm continues to grow every day.\nData Scientist\n12+ Months\nDallas, TX (Mostly Remote)\n$50\/HR on W2 or $55\/HR on C2C\nCandidates should be local and should be able to work on our W2.\nRole Description\nThis is a senior data scientist contract role located in Dallas, TX, with flexibility for some remote work. The Senior Data Scientist will be responsible for performing data analysis, statistical analysis, data visualization, and data analytics on complex data sets. They will use advanced machine learning techniques to build predictive models and develop strategies for improving business performance.\nQualifications\nData Science and Analytics skills, including machine learning, data mining, natural language processing, and deep learning\nExpertise in statistical analysis and modeling, including statistical packages such as R or Python\nProficiency in data visualization and reporting tools, such as Tableau or Power BI\nExperience in data analysis and data cleaning with large data sets\nStrong problem-solving and critical thinking skills\nAbility to work in a fast-paced and deadline-driven environment\nExcellent communication and collaboration skills\nA Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, or a related field\nExperience in Information Technologies or Human Resource Management industry is preferred\nShow more\nShow less",
      "job_skills":"Data Science, Analytics, Machine Learning, Data Mining, Natural Language Processing, Deep Learning, Statistical Analysis, Modeling, Tableau, Power BI, R, Python",
      "Category":"Backend Development"
  },
  {
      "job_title":"Business Intelligence Data Quality Engineer",
      "company":"Maxor National Pharmacy Services, LLC",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/business-intelligence-data-quality-engineer-at-maxor-national-pharmacy-services-llc-3742773210",
      "search_city":"Dallas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Overview\nMaxor is seeking an experienced, remote-based\nBusiness Intelligence Data Quality Engineer\nto join our dynamic Clinical Analytics and Business Intelligence Team. In this role, you are responsible for ensuring the highest levels of data quality and data integrity by setting up quality check processes, understanding the business, and working with various individuals to resolve data issues. Identifies, researches, and resolves technical problems. Ensures that the use of business intelligence applications enhances business decision making capabilities. Designs test plans and validates data and processes accordingly. Works closely with other associates to understand data flows and relationships in order to optimize data analyses. Gains exposure to some of the complex tasks within the job function.\nPosition Location\nThis is a remote-based position where you will work from your home office.\nOur Company\nFounded in 1926, Maxor is a leading, independent pharmacy solutions platform that improves prescription drug affordability and outcomes. Over time, Maxor has built a unique and complementary suite of services and technology offerings that deliver clinical, financial and strategic value to patients, payors and providers across the pharmacy supply chain.\nMaxor has a proud heritage of growth and innovation earned over the decades. Amarillo, Texas is the legacy headquarters for Maxor, but our talent base is national. We operate pharmacies and other business operation sites across the United States with more than 1100 employees working from 42 states.\nWhy Maxor?\nPharmacies are essential to healthcare, with nearly 90% of the US population living within 5 miles of one and seeing their pharmacist an average of 12 times a year. Providing a positive patient experience is crucial to ensuring patients adhere to their therapies.\nAt Maxor, we recognize that our employees are our most valuable assets. We actively seek and retain talented professionals who are mission-driven to improve healthcare outcomes for patients. Our employees are essential to their own well-being, finding fulfillment in meaningful work, competitive compensation, diverse and inclusive teams, and limitless career possibilities.\nWith a workforce of 1,000+ and almost a century of pharmacy experience, we offer the stability of a Fortune 500 company and the energy and innovation of a startup. Our expertise and technology support the entire pharmacy ecosystem, but our impact goes beyond pharmacy services. We enable pharmacy care.\nResponsibilities\nParticipates in the strategic design and maintenance of BI Applications\nEnsures data quality and integrity by owning various QA processes across multiple business domains.\nIdentifies, researches, and resolves technical problems.\nEnsures that the use of business intelligence applications enhances business decision making capabilities.\nCreate reports and write queries across multiple systems within multiple business units.\nQualifications\nEducation:\nBachelor\u201a\u00c4\u00f4s degree in Computer Information Systems, Computer Science, Business Management, or similar discipline from an accredited college or university or equally relevant experience .\nExperience:\n3-5 years directly related to the duties and responsibilities of the position\n3-5 years of advanced SQL coding and advanced quality assurance experience\n1+ years experience\/knowledge of the healthcare industry (i.e. PBMs and Health Plans) is desirable\n1+ years experience with Azure data products is desirable\nKnowledge, Skills, and Abilities:\nExcellent written communication skills to deliver technical specifications and professional products\nExcellent verbal communication skills to interview & gather requirement from business personnel\nDesign and develop testing plans for programs from conception to completion\nTest the functionality and performance of data processes based on the testing plans\nIdentify flaws, bugs, and glitches in the data related processes\nResolve any issues that are found and determining how to prevent them from happening again\nLook for potential areas of improvement to continually refine programs and provide an optimal user experience\nExcellent planning, organizational, and time management skills\nFundamental analytical and conceptual thinking skills in order to understand how business works\nAbility to analyze projects and solve complex problems or processes\nExperience creating detailed reports and giving\nAnalytical skills that allow for the development of data-driven reports\nDemonstrated ability to manage time and prioritize projects to meet deadlines\nStrong knowledge of SQL, database tables, and structures.\nWorking knowledge of Business Intelligence\/Reporting platforms (such as Power BI \/ SSRS, Tableau, and Cognos)\nCompetency in Microsoft Office Suite including Word, PowerPoint, Access, and Visio\nAdvanced skills in Microsoft Excel is preferred (VLOOKUP, data models, queries, etc\u201a\u00c4\u00b6)\nExperience participating in top performing teams and being a team player while also being able to work independently and self-learn as needed\nWE OFFER\nAt Maxor, we foster a diverse and progressive culture that promotes a work-from-home model and a \"dress-for-your-day\" approach to work attire. Our team-oriented environment encourages collaboration and innovation.\nWe offer highly competitive compensation and comprehensive health benefits including:\nComprehensive mental health and wellbeing resources\nNationwide Blue Cross Blue Shield PPO with employee-friendly plan design, including a $850 individual annual medical deductible and $25 office visit copays, with low biweekly premiums\nCompany-paid basic life\/AD&D, short-term and long-term disability insurance\nRx, dental, vision, other voluntary benefits, and FSA\nEmployer-matched 401k Plan\nIndustry-leading PTO plan\nAnd more!\nApply today at https:\/\/www.maxor.com\/careers\/\nMaxor is an EOE, including disability\/vets\nShow more\nShow less",
      "job_skills":"QA processes, SQL, Azure data products, Business Intelligence, Power BI \/ SSRS, Tableau, Cognos, Microsoft Office Suite, Microsoft Excel, Data models, Queries, Microsoft Word, Microsoft PowerPoint, Microsoft Access, Microsoft Visio, Datadriven reports, Machine learning, Python, Java, R, C++, Shell scripting",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"Fox Robotics",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-fox-robotics-3772673939",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Fox Robotics is at the bleeding edge of warehouse automation, with a focus on autonomous forklifts. As the leader in this space, Fox has clear product market fit and is scaling fast, with plans to nearly double from ~90 employees in the next year. With this growth, employees have a once-in-a-career opportunity to learn, all while working as part of a mission-driven team focused on\nmaking robots that work\n.\nWhat you'll do:\nWe are looking to hire an experienced Data Scientist to oversee our Data Analytics and create processes, systems, and dashboards that scale. Responsibilities will evolve, and will include the below:\nDesign, develop, and maintain scalable and robust data pipelines and platforms, ensuring the efficient extraction, transformation, and loading (ETL) of data from various sources.\nFurther, you will leverage your experience with SQL and Tableau to improve the overall quality, stability, and reliability of our platforms\nCollaborate with cross-functional teams, including Product, Engineering, to understand data requirements and develop data models that facilitate advanced analytics, machine learning, and predictive modeling.\nOptimize data storage and retrieval systems to ensure high performance, scalability, and data integrity.\nTroubleshoot data-related issues and perform root cause analysis, ensuring timely resolution to minimize impact on data availability and accuracy.\nContinuously evaluate and recommend improvements to existing data infrastructure, tools, and processes to enhance efficiency and reliability.\nDesign and deploy modern reports, analytics and visualizations to support Fox Robotics and our customers\nProduce architectural documentation and mentor team on proper development techniques to ensure quality, efficiency and compliance with the team standards\nWhat you'll need:\nBachelor's degree in Computer Science, Engineering, or a related field. Advanced degree is a plus.\nManagement Experience\nProven experience as a Data Analyst, Architect, Engineer or similar role, with a strong understanding of data warehousing concepts, data modeling, and ETL processes.\nProficient in SQL and programming languages such as Python, Java, or Scala.\nExperience in implementing data governance practices and ensuring data quality and integrity.\nStrong problem-solving skills and ability to work in a fast-paced, collaborative environment.\nExcellent communication skills with the ability to effectively articulate complex technical concepts to non-technical stakeholders.\nExpertise in translating logical design into one or more physical databases, and how the data will flow through the successive stages involved\nNice to have:\nExperience with the following systems and programs is a plus\nNice to have worked with robotics or an adjacent field\nExperience with Jira \/ Atlassian tool chain\nBenefits and perks:\nA once in a career opportunity to build, alongside colleagues who deeply care (plus robots that aren't bad, either!)\nCompetitive salary and stock options\nGenerous healthcare options\n401k match\nGenerous PTO\nOther perks that connect us, including lunch on Fridays, team building activities, and more!\nMore About Fox Robotics\nWe make robots that work.\nWe envision a world where robots serve as a human multiplier for dull and dangerous work. The warehousing industry sees more than 52,000 cases of injuries every year in the US. Our first product is an automated trailer unloader (forklift) that quickly demonstrates measurable value to our customers by both improving efficiency while also increasing safety.\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Pipelines, Data Platforms, ETL, SQL, Tableau, Machine Learning, Predictive Modeling, Data Storage, Data Retrieval, Data Integrity, Data Governance, Data Quality, Python, Java, Scala, Jira, Atlassian, Robotics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Scientist II",
      "company":"LS Technologies",
      "job_location":"Mountain View, WY",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-ii-at-ls-technologies-3748874374",
      "search_city":"Wyoming",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This position is in support of the NASA Ames Research Center (ARC), whose primary focus is on research and development (R&D) including fundamental scientific research, concept development, prototype testing, and new technology creation. ARC performs R&D in support of NASA missions in collaboration with other NASA centers, academia, other federal organizations, not-for-profit organizations, and industry partners. Successful candidates will support success of NASA and ARC mission and goals in aeronautics, science, space technology, and human exploration in partnership with leading edge technical and research expertise from both student and faculty researchers.\nThis work is directly supporting NASA Academic Mission Services-2 (NAMS-2) which will provide the Aeronautics Directorate and the Exploration Technology Directorate of NASA ARC with capabilities to fulfill mission requirements from fundamental R&D through field-test deployments and operational missions. NAMS-2 includes a broad scope of evolving research, including the development of new and emerging capabilities and technologies. Projects include scientific research associated with air traffic management, advanced technology, nanoelectronics, and prototype software. This team will help meet aeronautics and technology mission objectives, particularly the improvement of aircraft and airspace safety as well as the transition of advanced aeronautics technologies into future air vehicles.\nJob Description\nPerform statistical and data analyses to characterize and quantify the benefits of Air Traffic Management (ATM) concepts and technologies.\nQuantify and interpret the various metrics to assess the benefits.\nThis is done by writing python scripts to format the data and creating data visualizations, such as scatter plots, histograms, or confusion matrices, for easier comparisons between data elements.\nCreating a report and a user guide are desired to document the research and development.\nRequirements\nA master's degree in computer science, mathematics, engineering or equivalent.\nRequires 5 - 8 years of related experience.\nLS Technologies, LLC provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, ender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\nJob Posted by ApplicantPro\nShow more\nShow less",
      "job_skills":"Python, Data analysis, Data visualization, Statistical analysis, Machine learning, Software development, Report writing, User guide creation, Air Traffic Management (ATM), Aeronautics, Aerospace engineering, Nanoelectronics, Prototype software",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist",
      "company":"CARFAX",
      "job_location":"Columbia, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-carfax-3774844231",
      "search_city":"Missouri",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description\nJoin Team CARFAX as a Data Scientist\nIsn't it time you bragged about where you work? At CARFAX, we do, every day. We pride ourselves on being mission-focused on helping to grow a brand built on accuracy and integrity. We care deeply about our products and our customers. We\u201a\u00c4\u00f4re more than just a company: We help millions of consumers make more-informed decisions every day. We know that our teammates are our most valuable asset, and we value a balanced life while tackling challenging projects in a fast-paced environment. One last thing: Our four-day week continues in Summer 2024!\nAs a Data Scientist, you will be working with the Data Services and Data Technologies teams to create machine learning solutions for key company products. You will work collaboratively with data engineers and data mappers to design, build and scale our ambitious machine learning and natural language processing solutions.\nThis role has an expectation of 3 days in the office per week, subject to change based on future business needs.\nWhat You\u201a\u00c4\u00f4ll Be Doing\nLeading the design, development and deployment of our deep learning, ML and NLP solutions\nMaintaining and improving established, advanced machine learning processes on data mining\nProviding actionable ad hoc analytics insights for internal stakeholders\nBuilding and maintaining reports\/applications for internal stakeholders to make data-driven decisions\nUsing advanced analytical methods to explore and extract additional data value for existing and emerging products\nDocumenting analysis results and presenting value to stakeholders\nCreating reusable processes to assist data evaluation and analysis across teams within the Data Services department\nWhat We\u201a\u00c4\u00f4re Looking For\nMaster\u201a\u00c4\u00f4s Degree in Statistics, Data Science or related field\n4+ years\u201a\u00c4\u00f4 experience in SQL\/Spark, R, Python\n4+ years of experience in building and applying machine learning, predictive modeling, or natural language processing solutions to business problems\n2+ years of experience in Shiny application is a plus\nDeep understanding and experience with advanced statistics and modern machine learning predictive techniques, including GLMs, decision trees, boosted ensembles, neural networks, deep learning, etc.\nExperience with Named Entity Recognition (NER), Sentiment Analysis, Data Tokenization, Lexical Semantics, Relationship Extraction, etc.\nAbility to effectively communicate analysis and insights to all levels of the organization\nA passion for continuous learning\nConfidence to challenge the status quo\nWhat\u201a\u00c4\u00f4s In It For You\nCompetitive compensation, benefits and generous time-off policies\n4-Day summer work weeks and a winter holiday break\n401(k) \/ DCPP matching\nAnnual bonus program\nCasual, dog-friendly, and innovative office spaces\nDon\u201a\u00c4\u00f4t Just Take Our Word For It\n10X Virginia Business Best Places to Work\n9X Washingtonian Great Places to Work\n9X Washington Post Top Workplace\nSt. Louis Post-Dispatch Best Places to Work\nAbout CARFAX\nCARFAX, part of S&P Global Mobility, helps millions of people every day confidently shop, buy, service and sell used cars with innovative solutions powered by CARFAX vehicle history information. The expert in vehicle history since 1984, CARFAX provides exclusive services like CARFAX Used Car Listings, CARFAX Car Care, CARFAX History-Based Value and the flagship CARFAX\u00ac\u00c6 Vehicle History Report\u201a\u00d1\u00a2 to consumers and the automotive industry. CARFAX owns the world\u201a\u00c4\u00f4s largest vehicle history database and is nationally recognized as a top workplace by The Washington Post and Glassdoor.com. Shop, Buy, Service, Sell \u201a\u00c4\u00ec Show me the CARFAX\u201a\u00d1\u00a2. S&P Global Mobility is a division of S&P Global (NYSE: SPGI). S&P Global is the world\u201a\u00c4\u00f4s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets.\nCARFAX is an Affirmative Action\/Equal Opportunity Employer. It is the policy of CARFAX to provide equal employment opportunity to all persons regardless of race, color, sex, pregnancy, religion, national origin, age, ancestry, citizenship status, veteran status, military status, disability or handicap, sexual orientation, genetic information or any other status protected by federal, state or local law. In addition, CARFAX will provide reasonable accommodations for qualified individuals with disabilities. We maintain a drug-free workplace. We are a participant in E-Verify.\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Natural Language Processing, SQL, Spark, R, Python, Shiny, Statistics, Predictive Modeling, Named Entity Recognition (NER), Sentiment Analysis, Data Tokenization, Lexical Semantics, Relationship Extraction, Data Mining, Ad Hoc Analytics, Reporting, Application Development, Data Visualization, Continuous Learning, Communication Skills",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Analyst",
      "company":"Barkley",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-barkley-3784882135",
      "search_city":"Excelsior Springs",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Our Data Management & Measurement (DMM) team lives at the center of marketing results and business impacts. We assess how our clients can best optimize their marketing efforts to maximize the direct impact on business results.\nWe are looking for a Sr. Data Analyst, who will work on the front lines of our practice - delivering impactful and inspiring reporting for our internal media teams and our clients. This person will ideally become a trusted expert regarding their clients' marketing performance data and its impact on business results. As a member of the DMM team, you will play an important role in discovering, analyzing and presenting findings and reports related to all media channels. You will be at the heart of uncovering and measuring the connections between marketing results and business objectives.\nResponsibilities\nHave a passion for data analysis, critical thinking and storytelling\nBe able to work with internal media and reporting teams to develop measurement solutions for client campaigns.\nAnalyze campaign performance and other marketing efforts to assess their impact on client KPIs and make recommendations for improvements.\nParticipate in the creation of our clients' measurement strategies, including KPI selection, data capture requirements, measurement frameworks and data visualization\nBecome a trusted expert regarding clients' marketing performance data and will assist team members across departments in accessing and interpreting results.\nHave experience with digital tracking, including tagging, mobile and social limitations\nExcellent verbal and written communication skills to interpret and present business value to clients.\nWork with client internal analytics and IT teams to implement custom tracking parameters\nImplement and maintain media performance dashboard reporting across platforms like Excel, Sheets, Data Studio, PowerPoint, Slides, Datorama, Tableau and Power BI\nDemonstrate problem-solving ability with emphasis on drawing inferences with data\nPersonal characteristics:\nIntellectual curiosity, problem solving skills and determination\nDetail-oriented and thorough\nEffective communications verbally and in writing\nAbility to listen to stakeholders, process feedback and provide solutions\nStrong work ethic and integrity\nQualifications\n2+ years of marketing analytics and business intelligence experience with an emphasis on media and marketing measurement\nExperience with data visualization tools, especially Power BI, is a plus. This includes both the data visualization component of dashboard development and backend data preparation and aggregation.\nStrong working knowledge of spreadsheet platforms (i.e. Excel, Sheets, etc)\nExperience with advertising planning, buying and performance metrics\nExperience with media reporting platform(s) (Doubleclick, Adwords, etc)\nExperience with web analytics platform(s) (Adobe, Google Analytics,etc.)\nData analysis experience including spreadsheet (Excel) and SQL platforms\nRelational database programming languages (e.g. SQL) and statistical tools (e.g. SAS, SPSS, Python) is a plus\nEffectiveness in managing multiple projects across multiple clients and stakeholders\nExperience in analysis, research and presentation creation\nBarkley's Commitment to Diversity & Inclusion\nWe believe being radically diverse and inclusive is the key to becoming one of the world's great creative idea companies. By embracing everything that makes our partners who they are and what makes them unique to the world around them, we create the conditions and capacity to help creative, original thinking thrive.\nBarkley is committed to Diversity, Equity, Inclusion and Belonging as part of our corporate strategic goals, supported by a formal DEI+B program, Employee Resource Groups, Director of Diversity leadership and agency commitment to The Brand Lab.\nShow more\nShow less",
      "job_skills":"Marketing Analytics, Business Intelligence, Data Visualization, Data Analysis, Excel, Sheets, Data Studio, PowerPoint, Slides, Datorama, Tableau, Power BI, SQL, SAS, SPSS, Python, Doubleclick, Adwords, Adobe Analytics, Google Analytics, Web Analytics, Spreadsheet",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Scientist || O\u201a\u00c4\u00f4Fallon, MO (onsite required)",
      "company":"Steneral Consulting",
      "job_location":"O'Fallon, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-scientist-o%E2%80%99fallon-mo-onsite-required-%C2%A0-at-steneral-consulting-3687689934",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Title- Sr. Data Scientist\nLocation- O'Fallon, MO (\nonsite required)\nMUST BE LOCAL TO MO as there would be an onsite Interview.\nGlider Assessment Required: Y\n-\n'Data Sci Prof I\/II (Python, R, SQL)' There would be a Glider test.\nJD -\nPython skills, in the UNIX environment\nRest API\nRefactoring of an existing application - Design and document.\nRedesign the backend and microservice architecture currently in production\nOptimize scheduling and implement event-driven architecture\nRevisit current REST architecture\nImprove parallelization where possible to improve throughput\nImprove fault tolerance, logging and restartability.\nThis position requires talent who is\nExpert Python programmer in a Unix environment\nWith proven track record in ML pipeline design including LSF and NiFi\nWith experience in designing large-scale data-intensive applications\nWith parallel programming experience with Python in Unix\nShow more\nShow less",
      "job_skills":"Python, UNIX, REST API, Refactoring, Microservices, Scheduling, Eventdriven architecture, Parallelization, Fault tolerance, Logging, Restarting, ML pipeline design, LSF, NiFi, Largescale dataintensive applications, Parallel programming",
      "Category":"Backend Development"
  },
  {
      "job_title":"Lead Data Scientist",
      "company":"GCTECHINFO",
      "job_location":"O'Fallon, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-scientist-at-gctechinfo-3711935886",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title: Lead Data Scientist\nCompany: Rose International\nLocation: O\u201a\u00c4\u00f4Fallon, MO 63368\nDuration: 12 months\nEmployment Type: Temp\nOverview\nThe AI Services team is looking for a Data Scientist who is passionate about data analysis, Machine Learning, and Artificial Intelligence. The person in this role will be joining a team of leading-edge data scientists who are not just building models but are working to solve foundational business problems for the Company. The ideal candidate is comfortable working with Big data sources and able to implement and validate predictive models to provide insights and solutions for different business problems. The person in this role will be responsible for data interpretation and presentation to aid business partners in making informed data-driven decisions to improve business outcomes. The right candidate is able to collaborate with other data scientists and various internal business partners to help solve business problems using advanced ML\/AI. The person in this role must be organized and follow best practices in coding and documentation.\nResponsibilities\nLead, design, develop and deliver innovative ML\/AI solutions for various data science projects.\nBe responsible for documenting and articulating various data science projects across the organization following our engagement model, the Cross-Industry Standard Process for Data Mining (CRISP-DM).\nGain a clear understanding of business operations and data needed to solve problem statements for specific projects.\nPull and prepare data, train and test models, and be responsible for overall execution on projects using Client operational and transaction data to glean insights for our partners.\nPresent your approach to the solution and model output to various business partners.\nMaintain a curent knowledge of advanced ML\/AI tools and techniques.\nWork with different partner teams and be an integral part of model deployment.\nNeed to build and maintain strong relationships with internal Client partners.\nAbout You\nMasters or PhD in a highly quantitative field (mathematics, statistics, computer science, or related fields).\nExperience leading large data science projects, with a passion for solving business challenges through data science.\nExperience leading other data scientists from a technical perspective\nDemonstrated research ability a plus\nAbility to quickly pick up new tools and technologies.\nExcellent oral and written communication skills.\nExperience in predictive modeling, data science, and analysis in both batch and streaming settings.\nProficiency in Python\/R, Hadoop, Spark, MySQL with documentation for reproducibility.\nExperience in anomaly detection, supervised\/unsupervised learning, time-series data, and natural language processing. Experience in entity resolution a plus\nHands-on experience with ML tools such as Numpy, SciPy, Pandas, Scikit-learn, Tensorflow, Keras, NLTK, Gensim, BERT, NetworkX, etc.\nExcellent organization and interpersonal skills.\nVery detail-oriented with an ability to think creatively.\nExcellent problem-solving skills.\nSelf-motivated and capable of working independently but with a collaborative nature.\nProficient with data visualization and translating complex problems into actionable insights.\nJOB CODE: 1000057\nShow more\nShow less",
      "job_skills":"Data Analysis, Machine Learning, Artificial Intelligence, Predictive Modeling, Big Data, Data Interpretation, Data Presentation, DataDriven Decision Making, CRISPDM, Python, R, Hadoop, Spark, MySQL, Numpy, SciPy, Pandas, Scikitlearn, TensorFlow, Keras, NLTK, Gensim, BERT, NetworkX, Anomaly Detection, Supervised Learning, Unsupervised Learning, TimeSeries Data, Natural Language Processing, Entity Resolution",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist Lead\/SME",
      "company":"Steneral Consulting",
      "job_location":"Maryland Heights, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-lead-sme-at-steneral-consulting-3735082405",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Share only 2 profiles\nThis is 3 days onsite 2 days remote in Maryland Heights, MO!\nLocal candidates only\nData Scientist Lead\/SME\nDetails\nThis group is responsible for anything data and data science for clients governance verticals. Anytime there is a data conversion, business re-alignment, or process change, this group is responsible for creating solutions to data problems and ensuring that governance standards are met.\nSeeking a Data Science SME that can explore different open -source options to research and recommend what their best options are. Specifically, Python open-source tools.\nThis person will have very high visibility and need to meet with all levels of the org to understand the current state of the environment and then do the work to research and understand what tools to recommend and then demo them.\nShow more\nShow less",
      "job_skills":"Python, Data science, Data conversion, Business realignment, Process change, Data problems, Governance standards, Opensource tools, Research, Recommendation, Demo",
      "Category":"Backend Development"
  },
  {
      "job_title":"Power BI Data Analyst",
      "company":"Propper International",
      "job_location":"St Charles, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/power-bi-data-analyst-at-propper-international-3763854966",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Title:\nPower BI Data Analyst:\nPropper International is looking for a forward-thinking and innovative Power BI Data Analyst to provide business insights that drive improvements. The Power BI Data Analyst will play a key role by capturing, processing, and transforming datasets into clear summaries to fuel data-driven business decisions and solutions. The Data analyst will be heavily involved in the integration of different data sources, the use of ETL, SQL databases, and Power BI to successfully deliver BI solutions on a periodic basis.\nResponsibilities\nWork closely with business stakeholders to understand their requirements and use multiple data sources and Power BI to deliver data-driven insights and informed decisions.\nUse Power BI to create customized reports, dashboards, and KPIs to monitor key performance indicators.\nProvide live Power BI data through development of dynamic reporting, dashboarding, drill-down capabilities, and visualization solutions.\nDevelop processes for data mining, data modeling, and data production.\nCreate test plans and scenarios to ensure quality and requirement traceability for final deliverable.\nProvide Power BI training on various levels of expertise to companywide users and executives as needed.\nImplement data security measures to protect sensitive information and ensure compliance with data protection regulations.\nActively identify solutions to enhance the existing Business Intelligence infrastructure, processes, and technology.\nPerform other duties as assigned.\nRequirements (Must Have)\n4-year bachelor's degree in IT or related fields\n5+ years in Data Analysis using Microsoft Business Intelligence Stack (Power BI, SSAS, SSRS, SSIS, Data Factory, Power Query, MDX, DAX, etc.)\nSolid knowledge of SQL Data Warehousing and database fundamentals such as multidimensional database and relational database design.\nStrong programming skills in SQL. Knowledge of Python is a plus.\nProficiency with data science techniques and in manipulating data through data cleansing, data transformation, and data modeling.\nStrong analytical and problem-solving skills.\nSolid project management skills using Agile methodologies to meet project deadlines, budgets, and business requirements.\nGood communication and presentation skills\nExcellent Customer Service Orientation is a MUST.\nPosition Details\nOn-Site, Monday thru Friday 8am-5pm\n1099 Contract position. Contract duration is 6 months to 12 months, with possibility of direct hire\nHourly range of $39.00\/hr to $43.00\/hr depending upon experience.\nWho Is Propper\nWe got our start in 1967 with a contract for the U.S. Navy, manufacturing the iconic \"Dixie Cup\" hat worn by U.S. sailors. Over the decades, we've supplied more than 120 million garments to the U.S. Department of Defense, law enforcement agencies, and the public safety community.\nYou may not have heard of us, but you've definitely seen our work.\nOur heritage informs how we operate. We are a retail brand, but we still think like a contract manufacturer. Contracts aren't won by selling a particular lifestyle, telling unique stories, or appealing to emotion. They are won with features, quality, and demonstrable value. Contracts are won on the concrete.\nThis mentality drives every aspect of our production. Make it Work. Make it Last. Make it Real. Or don't make it at all.\nEqual opportunity Employer\nShow more\nShow less",
      "job_skills":"Power BI, Microsoft Business Intelligence Stack, ETL, SQL, Python, Data science, Data cleansing, Data transformation, Data modeling, Agile methodologies, Data Warehousing, Multidimensional database, Relational database design",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist II",
      "company":"Children's Mercy Kansas City",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-ii-at-children-s-mercy-kansas-city-3774858427",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"The Health Services and Outcomes Research division at Children\u201a\u00c4\u00f4s Mercy Kansas City invites applications for a research scientist in health data science. This position comes with an initial two-year appointment (with possible renewal).\nThis position is not eligible work remotely, which means that the person hired will be required to work onsite at one of our Children\u201a\u00c4\u00f4s Mercy locations and may not work from home.\nWorking as part of a multi-disciplinary team, the applicant will work closely with Dr. Keith Feldman, members of Children\u201a\u00c4\u00f4s Mercy Research Institute, and Children\u201a\u00c4\u00f4s Mercy\u201a\u00c4\u00f4s clinical faculty to undertake an array of projects focusing on data extracted from electronic medical records, administrative records, and\/or collected from large national consortium applied to the improvement of pediatric healthcare. In particular, within intensive care settings such as the NICU, where despite extensive monitoring and documentation a significant portion of the recorded information remains underutilized.\nEmphasis will be on a) methodological research in representation learning b) exploration and analysis of observational longitudinal health data; focused on advancing evidence-based medicine through improved temporal representation of patient conditions, quantification of variability, and development of explainable patient models. While the scientist will be engaged in several ongoing projects, this opportunity will include emphasis on professional and scholarly development, including the opportunity to engage and lead new collaborations, develop funding proposals, and mentor junior trainees. The ideal candidate will be a self-motivated, solution-oriented thinker with a strong background in biostatistics, epidemiology, machine learning or data science.\nAt Children\u201a\u00c4\u00f4s Mercy, we are committed to ensuring that everyone feels welcomed within our walls. A successful candidate for this position will join us as we strive to create a workplace that reflects the community we serve, as well as our core values of kindness, curiosity, inclusion, team, and integrity.\nMore information can be found at:\nhttps:\/\/www.childrensmercy.org\/childrens-mercy-research-institute\/\nDivision of Population Health: https:\/\/www.childrensmercy.org\/childrens-mercy-research-institute\/about\/areas-of-emphasis\/population-health\/\nDr. Keith Feldman: https:\/\/kfeldman.github.io\/\nFluency in python and\/or R programming languages. Demonstrated experience in applied data mining, machine learning or statistical research - Preferred experience with common analytic packages (e.g., Statsmodels, Scikit-Learn, Tidyverse)\nExperience analyzing and interpreting data from EMR\/EHR and\/or clinical data\nExperience with SQL and other relational database query languages\nExcellent written and oral communication skills with project management skills including the ability troubleshoot independently as challenges arise\nExperienced with good computing research practices (e.g., code documentation, version control, lab notebooks), experience with repositories (e.g., GitHub) a plus.\nPhD Computer Science( preferred), Informatics, Biostatistics, or a closely related field\nShow more\nShow less",
      "job_skills":"Python, R, Data Mining, Machine Learning, Statistical Research, Statsmodels, ScikitLearn, Tidyverse, SQL, Relational Database Query Languages, EMR, EHR, Git, GitHub, Computer Science, Informatics, Biostatistics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Scientist",
      "company":"Honeywell",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-scientist-at-honeywell-3771479738",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Join the industry leader to design the next generation of breakthroughs\nSr. Data Scientist\nHoneywell is a Fortune 100 company that invents and manufactures technologies to address critical challenges linked to global macrotrends such as safety, security, productivity, global urbanization and energy. With approximately 129,000 employees worldwide, including more than 19,000 engineers and scientists, Honeywell has an unrelenting focus on quality, delivery, value, and technology in everything they make and do. Honeywell has been named a Top 100 Global Innovator for seven years in a row, recognizing the company\u201a\u00c4\u00f4s global reach of portfolio and invention influence.\nIn Kansas City, Honeywell Federal Manufacturing & Technologies (FM&T) manages and operates the U.S. Department of Energy\/National Nuclear Security Administration\u201a\u00c4\u00f4s (NNSA) Kansas City National Security Campus. This state-of-the-art engineering, manufacturing, and sourcing facility produces a wide array of intricate components to deliver trusted national security products and government services primarily for the NNSA. Honeywell FM&T\u201a\u00c4\u00f4s culture of integrity, commitment and continuous improvement enables them to deliver responsive, collaborative, and innovative management and technology services and products that translate into cutting edge solutions to complex national security issues\nDuties And Responsibilities\nLead highly complex data science and analytics projects in support of process improvement, defect reduction, and predictive analytics for manufacturing and business applications.\nDemonstrated project management skills, serving as project lead guiding less experienced team members in multiple facets of project execution.\nIndependently develop data science models or algorithms using disciplined software development processes, making recommendations for developing new code or re-using existing code, implementing version control and maintaining documentation of created applications.\nWork directly with customers and business partners to develop requirements, and provide technical solutions through an analysis of manufacturing\/business needs and pain points.\nDefine and implement ingestion, data preparation, curation, and governance of large, multi-faceted data sets supporting analytics models and workflows.\nProactively assess current capabilities to identify areas for improvement \u00ac\u00f8 proposing solutions that align with core strategy and operation.\nGuide and produce information products, supporting visualization and data accessibility in a customer centric manner.\nEvaluate and make recommendations regarding technical advances that improve productivity and quality, reduce flow times, and enhance operational surety.\nDevelop guidelines and standards for analytics and machine learning models, their deployment, and associated processes.\nProvides technical guidance or business process expertise, technical leadership, coaching and mentoring to team members.\nConducts activities in a safe and healthy manner and works in accordance with established HS&E requirements to ensure the protection of employees, the public, and the environment.\nTakes actions necessary to 'stop' work when an unsafe condition or action is identified. Every employee has the right and responsibility to stop work when unsafe conditions or actions are identified.\nYOU MUST HAVE\nBS in engineering from ABET accredited institution or Master's degree in data science or related field, or two years of relevant experience in lieu of a degree.\nFive or more years of relevant experience in data science, data engineering, or related technical activities.\nExpert using scripting and querying languages, such as Python, R, R Markdown, Java, SQL, and others\nDemonstrated experience in serving as a technical lead of moderately complex projects.\nDemonstrated analytical skills, proficient with computer software applications, and the ability to produce and consume written documentation.\nWE VALUE\nAbility to discover, integrate, and curate raw data sources into functional data pipelines that can be leveraged by data scientist and analysts to tackle business problems.\nBuild and leverage API's to securely pass data between systems and data products at scale.\nAbility to understand a broad array of technical and business issues, prioritize work, and analyze issues to develop innovative and effective solutions.\nDemonstrated initiative staying current on industry practice outside of study and training.\nEffectively lead team interaction, including meetings and collaboration, to resolve issues.\nAbility to develop and communicate technical vision for projects and initiatives that can be understood by customers and management.\nProven mentoring ability to drive results and technical growth in peers.\nEffective communication skills (verbal, written, and presentation) for interacting with customers and peers.\nDemonstrated application of statistics, statistical modeling, and statistical process control.\nUser experience mindset, including the production of visualizations and infographics to distill complex information.\nExperience producing analytics data visualizations, preferably using Tableau, MicroStrategy, or equivalent.\nDemonstrated experience working with Hadoop, Hive, Apache Spark, etc.\nDemonstrated experience with machine learning, computer vision, neural networks, deep learning.\nFMT2021\nAdditional Information\nJOB ID: req426054\nCategory: Engineering\nLocation: 14520 Botts Road,Kansas City,Missouri,64147,United States\nExempt\nMust have or be eligible for a security clearance due to contractual requirements.\nHoneywell FM&T Overview\nHoneywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, religion, or veteran status.\nShow more\nShow less",
      "job_skills":"Data Science, Analytics, Machine Learning, Predictive Analytics, Data Engineering, Data Visualization, Statistics, Statistical Modeling, Statistical Process Control, Apache Spark, Hadoop, Hive, Tableau, MicroStrategy, SQL, Python, R, Java, R Markdown",
      "Category":"Backend Development"
  },
  {
      "job_title":"Big Data Engineer",
      "company":"TMS",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-engineer-at-tms-3728846367",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"A Data Engineer Will\nThe Data Engineer will participate on data management aspects of client engagements to deliver Test & Learn solutions, as well as contribute to and foster a high performance collaborative workplace.\nIndependently executes projects through design, implementation, automation, and maintenance of large scale enterprise ETL processes for a global client base\nAct as an expert data resource within the team\nDeliver on-time, accurate, high-value, robust data solutions across multiple clients, solutions and industry sectors\nBuild trust-based working relationships with peers and clients across local and global teams\nAll About You\nGood understanding of Python \u201a\u00c4\u00ec Pandas, Numpy, PySpark and Impala.\nHands-On experience on visualization tools i.e. Power BI, Tableau, Qlik Sense etc..\nExperience in doing data analysis and extraction on Hadoop.\nExperience with Enterprise Business Intelligence Platform\/Data platform.\nStrong SQL and higher-level programming languages with solid knowledge of data mining, machine learning algorithms and tools\nExperience with data integration tools \u201a\u00c4\u00ec ETL\/ELT tools (i.e. Apache NiFi, Azure Data Factory, Pentaho, Talend)\nExperience with Databrick, Snowflake, Graph Database is a plus.\nExperience in hands-on data modeling, programming, querying, data mining and report development using large volumes of granular data to deliver business intelligence and custom reporting solutions.\nExposure to collecting and\/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies.\nStrong understanding of the application of analytical methods and data visualization to support business decisions.\nAbility to understand complex operational systems and analytics\/business intelligence tools for the delivery of information products and analytical offerings to a large, global user base.\nShow more\nShow less",
      "job_skills":"Python, Pandas, Numpy, PySpark, Impala, Power BI, Tableau, Qlik Sense, Hadoop, SQL, Data mining, Machine learning, Apache NiFi, Azure Data Factory, Pentaho, Talend, Databrick, Snowflake, Graph Database, Data modeling, Data programming, Data querying, Report development, Business intelligence, Data visualization, Business decisions, Analytical methods",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Science Advisor - Clinical Pharmacy Analytics - Hybrid",
      "company":"The Cigna Group",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-science-advisor-clinical-pharmacy-analytics-hybrid-at-the-cigna-group-3787352230",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Overview\nA career within Forsyth Health\u201a\u00c4\u00f4s Data & Analytics team will provide you with the opportunity to help Pharma\/Life Science organizations uncover patient and market insights. At Forsyth Health, we focus on a collection of data management, business intelligence and advanced analytics capabilities to support various functions within these organizations to meet their business needs around market access and patient support programs.\nHow You'll Make a Difference\nThe Sr. Data Scientist role is a key role to the enterprise and will be supporting a highly complex and growing area within the health care data and analytics services space. As a strong individual contributor, the role will lead client engagements to define, develop and communicate insights critical to Commercial, Market Access, HEOR and Evidence Generation functions at Pharma\/Life Science. Responsibilities include leading Outcomes Research studies, Advanced Analytics, ML model development and general analytic support for all stakeholders. This role will work closely with the internal Sales and Technology teams. This person will need to be able to understand the needs within the Commercial Pharma Analytics space and translate those into actionable insights.\nRole Summary\nThe Data Science Advisor- Pharmacy Analytics position is an opportunity for an analytics professional to provide leadership on complex analytics projects and initiatives. This role will work with an innovative team on setting and executing the vision for how advanced embedded analytics can lead Cigna to achieving our growth goals. This role will work collaboratively with our business stakeholders to provide partnership in analytics, developing analytics solutions, leveraging data science and technologic capabilities and embedding analytics driven processes.\nThe job responsibilities include, but are not limited to the following:\nLead analyses related to Healthcare Resource Utilization, Total Healthcare Cost and Clinical Outcomes with a focus on Specialty Medications\/Rare diseases, Channel Management, Utilization Management, and specific Therapeutic area research (root cause analyses, Health Outcome Studies, Opportunity analysis including descriptive and multivariate statistics to identify patterns in the data.)\nDevelop new reports, models and analytic solutions with innovative ways to present data internally and externally in order to support Forsyth Health\u201a\u00c4\u00f4s Sales & Business stakeholders. This requires combining business knowledge and data acumen along with technical (SAS, SQL) skills to efficiently complete these ad-hoc requests. Query data warehouse(s) using variety of tools available. Extract data and manipulate into reports for client both internal and external. Maintain turn-around times per agreements.\nConsultation with Data & Analytics matrix partners to develop best practices and help understand complex issues and requests. Cross-Functional collaboration as needed to create alignment with stakeholders.\nProject management and prioritization \u201a\u00c4\u00ec Advisor role will support multiple projects and will need to be able to work with Forysth Health Sales\u201a\u00c4\u00f4 and Analytics team to manage multiple initiatives at the same time and negotiate timelines\/priority with stakeholders.\nManage the analytic solution development efforts in the role of a Product Owner, requiring effective project management, technical and functional documentation, communication and stakeholder alignment.\nExplore and visualize the data using advanced tools such as including Tableau, PowerBI, Thoughtspot and\/or Looker. (Largely Tool agnostic environment)\nExtraction and analysis of large healthcare claims data using state of the art big-data infrastructure leveraging cloud and on premise tools i.e. SAS, Analytic platform (Python), R, Teradata, Hadoop, etc.\nQualifications\nBS\/MS\/PhD in Econometrics, Actuarial Science, Data Science, Health Outcomes, Epidemiology, Statistics, or in any technical field that provides a solid basis for analytics highly desired.\nMinimum 6 years of industry experience in solving Health Plan, PBM business or Commercial Pharma Analytic problems through the application of analytic approaches.\nPrior experience in Healthcare analytics, Specialty Medication or Specialty Condition analytics or Health Outcomes required\nA demonstrated ability to understand and effectively communicate (both verbally and written) analytic and clinical data to a varied audience.\nDeep healthcare data (e.g., PBM experience, Provider Networks, Billing, Medical and Pharmacy claims), statistical analysis experience, and an understanding of all the associated clinical, utilization and financial levers.\nExperience with statistical software\/programming languages such as SQL programming, SAS, R, Python and other tools preferred (Python knowledge not requisite but preferred).\nExperience with data visualization tools such as Tableau, Thoughtspot or PowerBI.\nA data-driven personality w\/ Intellectual curiosity and internal motivation.\nIf you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download\/5Mbps upload.\nAbout The Cigna Group\nDoing something meaningful starts with a simple decision, a commitment to changing lives. At The Cigna Group, we\u201a\u00c4\u00f4re dedicated to improving the health and vitality of those we serve. Through our divisions Cigna Healthcare and Evernorth Health Services, we are committed to enhancing the lives of our clients, customers and patients. Join us in driving growth and improving lives.\nQualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws.\nIf you require reasonable accommodation in completing the online application process, please email: SeeYourself@cigna.com for support. Do not email SeeYourself@cigna.com for an update on your application or to provide your resume as you will not receive a response.\nThe Cigna Group has a tobacco-free policy and reserves the right not to hire tobacco\/nicotine users in states where that is legally permissible. Candidates in such states who use tobacco\/nicotine will not be considered for employment unless they enter a qualifying smoking cessation program prior to the start of their employment. These states include: Alabama, Alaska, Arizona, Arkansas, Delaware, Florida, Georgia, Hawaii, Idaho, Iowa, Kansas, Maryland, Massachusetts, Michigan, Nebraska, Ohio, Pennsylvania, Texas, Utah, Vermont, and Washington State.\nShow more\nShow less",
      "job_skills":"Data management, Business intelligence, Advanced analytics, Outcome Research studies, Machine learning model development, SAS, SQL, Tableau, PowerBI, Thoughtspot, Looker, Python, R, Teradata, Hadoop, Econometrics, Actuarial Science, Data Science, Health Outcomes, Epidemiology, Statistics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Statistical Data Analyst - Biostatistics",
      "company":"Washington University in St. Louis",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-statistical-data-analyst-biostatistics-at-washington-university-in-st-louis-3727312628",
      "search_city":"Saint Louis",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Scheduled Hours\n40\nPosition Summary\nThis position is in the Xiong Lab in the Center for Biostatistics. The Center for Biostatistics is part of the Institute for Informatics, Data Science and Biostatistics and the Office of Health Information and Data Science (OHIDS). At OHIDS we have a people-centric approach where our team members are our number one asset. We are committed to providing safe and inclusive working conditions and take great care to support employees\u201a\u00c4\u00f4 health and well-being. We support a flexible work environment in order to support a range of work schedules and better work-life guardrails. Ensuring the well-being of our team members is a top priority.\nPerforms database management, and data harmonization across different studies, and data sharing, as well as data analysis expertly using statistical packages. Assists investigators in the design of experiments, clinical trials, and epidemiological studies. May be required to assume major responsibility on large project.\nJob Description\nPrimary Duties & Responsibilities\nPerforms management duties as part of several large NIH-funded longitudinal data repository containing clinical, psychological, imaging, neuropathologic and biomarker data.\nHarmonizes databases across multiple independent studies by working with database team of each study, standardizing database dictionary and creating standard metadata template for data sharing with both internal and external investigators.\nTransfers QC\u201a\u00c4\u00f4d data to national and local data repository as well as to individual investigators who requested the data, and track the data sharing.\nMonitors and evaluates data integrity.\nPerforms quality control on all forms of data (paper, electronic, etc.);\nAssists with research coordination of projects.\nAssists with research management (administration, scheduling, tracking, recruitment, etc.).\nAssists in development of data capture forms and screens.\nUtilizes REDCap and other EDC systems as required for generation of such forms and reports.\nGenerate routine reports on statistics and figures and tables summarizing the current status of databases, using standard statistical packages, SAS, R.\nPerforms other duties as assigned (e.g. may assist in manuscript preparation).\nPreferred Qualifications\nMaster\u201a\u00c4\u00f4s degree in Biostatistics, Statistics, Informatics, Computer Science or related field.\nExpert knowledge base and experience with database design, management and analysis.\nPC\/UNIX knowledge.\nSkills and demonstrated success in designing and executing appropriate statistical data analysis in SAS, R Python, or other packages.\nExperience in REDCap.\nCapable of assuming a leadership role.\nDemonstrated effective verbal, written and interpersonal communication skills.\nDemonstrated organization skills.\nRequired Qualifications\nBachelor\u201a\u00c4\u00f4s degree and three years of related experience; a combination of college education and\/or relevant experience equaling seven years may substitute for this requirement.\nGrade\nG13\nSalary Range\n$64,700.00 - $110,500.00 \/ Annually\nThe salary range reflects base salaries paid for positions in a given job grade across the University. Individual rates within the range will be determined by factors including one's qualifications and performance, equity with others in the department, market rates for positions within the same grade and department budget.\nAccommodation\nIf you are unable to use our online application system and would like an accommodation, please email CandidateQuestions@wustl.edu or call the dedicated accommodation inquiry number at 314-935-1149 and leave a voicemail with the nature of your request.\nPre-Employment Screening\nAll external candidates receiving an offer for employment will be required to submit to pre-employment screening for this position. The screenings will include criminal background check and, as applicable for the position, other background checks, drug screen, an employment and education or licensure\/certification verification, physical examination, certain vaccinations and\/or governmental registry checks. All offers are contingent upon successful completion of required screening.\nBenefits Statement\nPersonal\nUp to 22 days of vacation, 10 recognized holidays, and sick time.\nCompetitive health insurance packages with priority appointments and lower copays\/coinsurance.\nWant to Live Near Your Work and\/or improve your commute? Take advantage of our free Metro transit U-Pass for eligible employees. We also offer a forgivable home loan of up to $12,500 for closing costs and a down payment for homes in eligible neighborhoods.\nWashU provides eligible employees with a defined contribution (403(b)) Retirement Savings Plan, which combines employee contributions and university contributions starting at 7%.\nWellness\nWellness challenges, annual health screenings, mental health resources, mindfulness programs and courses, employee assistance program (EAP), financial resources, access to dietitians, and more!\nFamily\nWe offer 4 weeks of caregiver leave to bond with your new child. Family care resources are also available for your continued childcare needs. Need adult care? We\u201a\u00c4\u00f4ve got you covered.\nWashU covers the cost of tuition for you and your family, including dependent undergraduate-level college tuition up to 100% at WashU and 40% elsewhere after seven years with us.\nFor policies, detailed benefits, and eligibility, please visit: https:\/\/hr.wustl.edu\/benefits\/\nEEO\/AA Statement\nWashington University in St. Louis is committed to the principles and practices of equal employment opportunity and especially encourages applications by those from underrepresented groups. It is the University\u201a\u00c4\u00f4s policy to provide equal opportunity and access to persons in all job titles without regard to race, ethnicity, color, national origin, age, religion, sex, sexual orientation, gender identity or expression, disability, protected veteran status, or genetic information.\nDiversity Statement\nWashington University is dedicated to building a diverse community of individuals who are committed to contributing to an inclusive environment \u201a\u00c4\u00ec fostering respect for all and welcoming individuals from diverse backgrounds, experiences and perspectives. Individuals with a commitment to these values are encouraged to apply.\nShow more\nShow less",
      "job_skills":"Database management, Data harmonization, Data analysis, Statistical analysis, Biostatistics, SAS, R, Python, REDCap, Epidemiological studies, Clinical trials, Data capture forms, Database design, Metadata, Data sharing, Data integrity, Quality control, Data repository, Data integration, Data standardization, Research coordination, Project management, Leadership, Communication skills",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist with Security Clearance",
      "company":"ClearanceJobs",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-with-security-clearance-at-clearancejobs-3776419223",
      "search_city":"Saint Louis",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Number: R0185824 Data Scientist\nThe Opportunity: As a data scientist, you're excited at the prospect of unlocking the secrets held by a data set, and you're fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors-from fraud detection to cancer research to national intelligence-we need you to help find the answers in the data. On our team, you'll use your analytical skills and data science knowledge to create real-world impact. You'll work closely with your clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You'll develop algorithms and systems and use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to help clients make informed decisions. Ultimately, you'll provide a deep understanding of the data, what it all means, and how it can be used. Work with us as we use data science for good. Join us. The world can't wait. You Have: * 10+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining * 10+ years of experience with statistical and general-purpose programming languages for data analysis * Experience analyzing structured and unstructured data sources * Experience developing predictive data models, quantitative analyses, and visualization of targeted data sources * Knowledge of Machine Learning, Artificial Intelligence, or Natural Language Processing * Knowledge of text mining or machine learning techniques * Active TS\/SCI clearance; willingness to take a polygraph exam * Bachelor's degree Nice If You Have: * 10+ years of experience in the development of algorithms leveraging Visual Basic, R, Python, or SQL and NoSQL * 10+ years of experience with Distributed data and computing tools and visualization tools, including ArcGIS, SPSS, SAS, Matlab, or Tableau * Experience with manipulating data using Postgreql, ORACLE, SQL or ACCESS database management system * Bachelor's degree in Data Science or related field preferred; Master's degree in Data Science or a related field a plus Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS\/SCI clearance is required. Create Your Career: Grow With Us Your growth matters to us-that's why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs , tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. A Place Where You Belong Diverse perspectives cultivate collective ingenuity. Booz Allen's culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you'll develop your community in no time. Support Your Well-Being Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we'll support you as you pursue a balanced, fulfilling life-at work and at home. Your Candidate Journey At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we've compiled a list of resources so you'll know what to expect as we forge a connection with you during your journey as a candidate with us. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,000.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. Work Model\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. * If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.\nIf this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role. EEO Commitment We're an equal employment opportunity\/affirmative action employer that empowers our people to fearlessly drive change - no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Artificial Intelligence, Natural Language Processing, Text Mining, Predictive Data Models, Quantitative Analyses, Data Exploration, Data Cleaning, Data Analysis, Data Visualization, Data Mining, Statistical Programming, GeneralPurpose Programming, Databases, SQL, NoSQL, Distributed Data, Computing Tools, Visualization Tools, ArcGIS, SPSS, SAS, Matlab, Tableau, Postgreql, ORACLE, ACCESS, Visual Basic, R, Python",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Analyst",
      "company":"SteadyMD",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-steadymd-3697498895",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Be part of a team enabling access to better healthcare at SteadyMD!\nSteadyMD is a technology company and healthcare provider that powers high-quality telehealth experiences for its partners, including fast-growing digital healthcare companies, labs, pharmacies, large employers, and Fortune 100 companies like Amazon, AmerisourceBergen, and Abbott. SteadyMD initially launched in two states: California and Missouri. By 2018, the company was licensed, operating, and providing care in all 50 states. We\u201a\u00c4\u00f4ve raised over $60 million in funding from top tier investors including Lux Capital, Pelion Ventures and AB Health Ventures.\nWe are currently seeking a talented\nSr. Data Analyst\nto join our Product team. As a Sr. Data Analyst you will play a pivotal role in transforming raw data into meaningful insights. You will collaborate with cross-functional teams to analyze data, identify trends, and provide actionable recommendations. Reporting to the VP of Product Management, this position offers an exciting opportunity to work with different datasets, contribute to data-driven initiatives, and impact the success of our company. This is a hybrid role in which you will be located in the St. Louis, MO area.\nAt SteadyMD, we value what diverse teams can accomplish together, and we honor each of our unique lived experiences. We look for a diverse pool of applicants, including those from historically marginalized groups, and we are committed to ensuring a safe work environment that is distinctly anti-discriminatory against any person. This is one of the reasons we are ranked #81 on Forbes\u201a\u00c4\u00f4 America\u201a\u00c4\u00f4s Best Startup Employers List. We know the value of building a team that encompasses a variety of backgrounds, experiences, and skills.\nWorks with other teams to provide key analytics support in identifying process, software, and data improvements\nDefine, maintain, and communicate the data \u201a\u00c4\u00fasource of truth\u201a\u00c4\u00f9 for cross-functional teams to use in assessing performance and quality\nProvide support and documentation for associated business units to understand how to use data and insights\nCreates and owns ETLs: identifies data sources, writes queries, validates, and makes modifications as needed\nWrite clean code that can be maintained and extended by other technical stakeholders\nEnsure safe and secure data handling by partnering with company security leaders\nSets up and manages usage, reliability, quality, and performance of products, services, solutions or processes and proposes improvements\nGuides business leaders with data-driven reports, dashboards, and visualizations\nInterprets data, analyzes results, and provides insights to support data-driven decision-making for ad hoc and on-going reports\nStay up-to-date with industry technologies and frameworks to identify trends to maintain best and cutting edge practices in data analysis\nParticipate in special projects and initiatives as needed\nRequirements\n4+ years of related experience in a business analytics or data management experience\nRelevant Industry Experience or Bachelor\u201a\u00c4\u00f4s Degree with emphasis in: Information Technology, Mathematics, Management Information System (MIS), Statistics, Engineering, Computer Science, or related\nStrong proficiency in:\nSQL, Python, writing SQL queries\nAdvanced SQL aggregation functions\ndatabase performance concepts and query optimization techniques\nExperience with Looker and Tableau\nCan provide helpful insights from dense datasets\nCreative self-starter capable of first principles thinking\nStrong interpersonal skills that can work across a highly cross-functional environment\nExcellent oral and written communication skills required\nDetail oriented and strong organizational skills\nPrevious experience in a B2B SaaS start-up preferred\nExperience in healthcare is a bonus\nBenefits\nCompetitive Compensation. The annual salary range for this role is $85,000 - $110,000 depending on experience, and participation in the company bonus program\nFast-paced Startup Environment. An environment that is focused on disrupting the status quo and challenging conventional professional norms. We are focused on the results you can achieve, not how many hours you spend at a desk\nComplimentary Lemonaid Primary Care Membership. So that you can experience what we have to offer and be able to speak first-hand about what the future of medicine will look like\nCompany-paid health, dental, and vision insurance. Also includes Basic Life and ADD offerings\n401k with Match & Parental Leave Benefits offered to all full-time employees\nUnlimited PTO. We trust our employees to make the right decisions for the business, and we also recognize that means taking time to take care of yourself\nShow more\nShow less",
      "job_skills":"SQL, Python, Looker, Tableau, ETL, Data analysis, Data management, Datadriven decisionmaking, Database performance concepts, Query optimization, Industry technologies, Frameworks, Healthcare, B2B SaaS",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Analyst",
      "company":"Cushman & Wakefield",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-cushman-wakefield-3779636196",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title\nSr Data Analyst\nJob Description Summary\nThe role is for a Senior Data Analyst as part of a team collecting and analyzing data supporting ad hoc and strategic client projects primarily involving architectural building design.\nThe candidate will provide advanced expertise in data analysis, collaborate with key client partners, support the data team with identifying project requirements, refining project work, and providing recommendations on optimizing data management and workflows.\nJob Description\nCore Responsibilities\nCollect, clean, study, transform, load, and visualize data for ad hoc and strategic projects\nIdentify trends and provide insights from data that contribute to solving business problems\nCode programs, as needed, to help capture and organize relevant data\nCollaborate directly with internal and external partners to satisfy project needs\nClearly communicate useful information to business partners derived from data analysis\nAssist in managing completion of team data analysis tasks\nLead problem-solving and refinement of project activities and tasks\nLead project identifying requirements from analysis of current state versus desired future state\nIdentify opportunities for workflow optimization\nQualifications\nThree or more years of experience in data analytics, data management, or related roles\nAdvanced knowledge of data analytics, cleaning, preparation, and visualization techniques\nAdvanced experience with data analytics tools and programs (Microsoft Excel, Microsoft Power BI, Python, SQL, Tableau)\nAdvanced understanding of best practices in data management and visualization\nStrong critical thinking and problem solving skills\nStrong focus on solutions serving client\/end user\nAbility to write and speak clearly to both technical and non-technical audiences\nKeen attention to both technical detail and quality of work acceptable to client\/end user\nDemonstrated ability to collaborate effectively with partners across multiple teams\nStrong ability to prioritize work tasks in alignment with changing project and team needs\nPreferred candidate will have experience managing\/analyzing architectural design data\nCushman & Wakefield provides equal employment opportunity. Discrimination of any type will not be tolerated. Cushman & Wakefield is an Equal Opportunity \/ Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other characteristic protected by state, federal, or local law.\nIn compliance with the Americans with Disabilities Act Amendments Act (ADAAA), if you have a disability and would like to request an accommodation in order to apply for a position at Cushman & Wakefield, please call the ADA line at\n1-888-365-5406\nor email\nHRServices@cushwake.com\n. Please refer to the job title and job location when you contact us.\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Management, Data Analysis, Data Visualization, Microsoft Excel, Microsoft Power BI, Python, SQL, Tableau, ProblemSolving, Data Cleaning, Data Preparation, Data Loading, Critical Thinking, Attention to Detail, Communication, Collaboration, Prioritization, Workflow Optimization, Business Intelligence, Architecture Design Data",
      "Category":"Backend Development"
  },
  {
      "job_title":"Staff Data Engineer",
      "company":"Recruiting from Scratch",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/staff-data-engineer-at-recruiting-from-scratch-3744395481",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This is for a client of Recruiting from Scratch.\nWho is Recruiting from Scratch:\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nOur Client:\nOur client is a dating app.\nIn this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, deliver analysis to further improve engagement in existing features, and empower our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.\nWhat\u201a\u00c4\u00f4s the job?\nDesign, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.\nSolve technical problems of the highest scope and complexity\nExert significant influence on the company\u201a\u00c4\u00f4s analytical long-range goals and data architecture\nDefine and extend our internal standards for style, maintenance, and best practices for a high-scale data platform\nProvide mentorship for all on your team to help them grow in their technical responsibilities\nPropose ideas to improve the scale, performance, and capabilities of the Data Platform\nMoving implementation to ownership of real-time and batch processing and data governance and policies.\nMaintain and enforce the business contracts on how data should be represented and stored.\nStay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users\nImplementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.\nWork closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.\nWhat We'll Love About You\n7+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field\n7+ years experience using Python\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)\nSignificant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases\nExperience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nExperience with dimensional data modeling and schema design in Data Warehouses\nFamiliar with ETL (managing high-quality reliable ETL pipelines)\nBe familiar with legal compliance (with data management tools) data classification, and retention\nLocation\n: This role will be located in office twice a week minimum in Palo Alto, San Francisco or Chicago.\nSalary Range: $180,000 - 250,000 USD base.\nEquity. Medical, Dental, Vision.\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Data engineering, Business intelligence, Data science, Python, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, SQL, TDD, Pair Programming, Continuous Integration, Automated testing, Deployment, Streamprocessing systems, Kafka, Storm, SparkStreaming, Dimensional data modeling, Schema design, Data Warehouses, ETL, Legal compliance, Data management tools, Data classification, Data retention",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer, Public Company",
      "company":"Recruiting from Scratch",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-public-company-at-recruiting-from-scratch-3748827522",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This is for a client of Recruiting from Scratch.\nWho is Recruiting from Scratch:\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nOur Client:\nOur next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we\u201a\u00c4\u00f4re blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.\nWith a track record of strong financial performance and plans for continued headcount growth, we\u201a\u00c4\u00f4re looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nOur client is looking to bring on a Senior Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. .\nIn this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, delivers analysis to further improve engagement in existing features, and empowers our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.\nWhat\u201a\u00c4\u00f4s the job?\nDesign, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.\nMoving implementation to ownership of real-time and batch processing and data governance and policies.\nMaintain and enforce the business contracts on how data should be represented and stored.\nStay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users\nImplementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.\nWork closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.\nWhat We\u201a\u00c4\u00f4ll Love About You\n5+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field.\n7+ years experience using Python,\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, )\nSignificant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases.\nExperience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment.\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nExperience with dimensional data modeling and schema design in Data Warehouses\nFamiliar with ETL (managing high-quality reliable ETL pipelines)\nBe familiar with legal compliance (with data management tools) data classification, and retention.\nLocation: Palo Alto, San Francisco or Chicago\nSalary Range: $165,000-$210,000 USD base.\nEquity. Medical, Dental, Vision.\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Data Engineering, Business Intelligence, Data Science, Python, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, SQL, TDD, Pair Programming, Continuous Integration, Automated Testing, Kafka, Storm, SparkStreaming, ETL, Dimensional Data Modeling, Schema Design, Legal Compliance, Data Classification, Data Retention",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer, Public Company",
      "company":"Recruiting from Scratch",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-public-company-at-recruiting-from-scratch-3744399380",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This is for a client of Recruiting from Scratch.\nWho is Recruiting from Scratch:\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nOur Client:\nThey are a profitable dating application.\nLocation: This is a hybrid role based in their Chicago office and will require you to be in office Tuesdays and Thursdays.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nOur client is looking to bring on a Senior Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. .\nIn this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, delivers analysis to further improve engagement in existing features, and empowers our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.\nWhat\u201a\u00c4\u00f4s the job?\nDesign, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.\nMoving implementation to ownership of real-time and batch processing and data governance and policies.\nMaintain and enforce the business contracts on how data should be represented and stored.\nStay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users\nImplementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.\nWork closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.\nWhat We\u201a\u00c4\u00f4ll Love About You\n5+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field.\n7+ years experience using Python,\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, )\nSignificant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases.\nExperience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment.\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nExperience with dimensional data modeling and schema design in Data Warehouses\nFamiliar with ETL (managing high-quality reliable ETL pipelines)\nBe familiar with legal compliance (with data management tools) data classification, and retention.\nLocation\n: This role is twice a week in a hybrid role minimum.\nSalary Range: $165,000-$210,000 USD base.\nEquity. Medical, Dental, Vision.\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Data Engineering, Realtime Streaming Technologies, TDD, Automation, Continuous Delivery, Python, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, PySpark, SQL, Agile Engineering Practices, StreamProcessing Systems, Kafka, Storm, SparkStreaming, Dimensional Data Modeling, Schema Design, Data Warehouses, ETL Pipelines, Data Management Tools, Data Classification, Data Retention",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Statistical Data Analyst - Biostatistics",
      "company":"Washington University in St. Louis",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-statistical-data-analyst-biostatistics-at-washington-university-in-st-louis-3727312628",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Scheduled Hours\n40\nPosition Summary\nThis position is in the Xiong Lab in the Center for Biostatistics. The Center for Biostatistics is part of the Institute for Informatics, Data Science and Biostatistics and the Office of Health Information and Data Science (OHIDS). At OHIDS we have a people-centric approach where our team members are our number one asset. We are committed to providing safe and inclusive working conditions and take great care to support employees\u201a\u00c4\u00f4 health and well-being. We support a flexible work environment in order to support a range of work schedules and better work-life guardrails. Ensuring the well-being of our team members is a top priority.\nPerforms database management, and data harmonization across different studies, and data sharing, as well as data analysis expertly using statistical packages. Assists investigators in the design of experiments, clinical trials, and epidemiological studies. May be required to assume major responsibility on large project.\nJob Description\nPrimary Duties & Responsibilities\nPerforms management duties as part of several large NIH-funded longitudinal data repository containing clinical, psychological, imaging, neuropathologic and biomarker data.\nHarmonizes databases across multiple independent studies by working with database team of each study, standardizing database dictionary and creating standard metadata template for data sharing with both internal and external investigators.\nTransfers QC\u201a\u00c4\u00f4d data to national and local data repository as well as to individual investigators who requested the data, and track the data sharing.\nMonitors and evaluates data integrity.\nPerforms quality control on all forms of data (paper, electronic, etc.);\nAssists with research coordination of projects.\nAssists with research management (administration, scheduling, tracking, recruitment, etc.).\nAssists in development of data capture forms and screens.\nUtilizes REDCap and other EDC systems as required for generation of such forms and reports.\nGenerate routine reports on statistics and figures and tables summarizing the current status of databases, using standard statistical packages, SAS, R.\nPerforms other duties as assigned (e.g. may assist in manuscript preparation).\nPreferred Qualifications\nMaster\u201a\u00c4\u00f4s degree in Biostatistics, Statistics, Informatics, Computer Science or related field.\nExpert knowledge base and experience with database design, management and analysis.\nPC\/UNIX knowledge.\nSkills and demonstrated success in designing and executing appropriate statistical data analysis in SAS, R Python, or other packages.\nExperience in REDCap.\nCapable of assuming a leadership role.\nDemonstrated effective verbal, written and interpersonal communication skills.\nDemonstrated organization skills.\nRequired Qualifications\nBachelor\u201a\u00c4\u00f4s degree and three years of related experience; a combination of college education and\/or relevant experience equaling seven years may substitute for this requirement.\nGrade\nG13\nSalary Range\n$64,700.00 - $110,500.00 \/ Annually\nThe salary range reflects base salaries paid for positions in a given job grade across the University. Individual rates within the range will be determined by factors including one's qualifications and performance, equity with others in the department, market rates for positions within the same grade and department budget.\nAccommodation\nIf you are unable to use our online application system and would like an accommodation, please email CandidateQuestions@wustl.edu or call the dedicated accommodation inquiry number at 314-935-1149 and leave a voicemail with the nature of your request.\nPre-Employment Screening\nAll external candidates receiving an offer for employment will be required to submit to pre-employment screening for this position. The screenings will include criminal background check and, as applicable for the position, other background checks, drug screen, an employment and education or licensure\/certification verification, physical examination, certain vaccinations and\/or governmental registry checks. All offers are contingent upon successful completion of required screening.\nBenefits Statement\nPersonal\nUp to 22 days of vacation, 10 recognized holidays, and sick time.\nCompetitive health insurance packages with priority appointments and lower copays\/coinsurance.\nWant to Live Near Your Work and\/or improve your commute? Take advantage of our free Metro transit U-Pass for eligible employees. We also offer a forgivable home loan of up to $12,500 for closing costs and a down payment for homes in eligible neighborhoods.\nWashU provides eligible employees with a defined contribution (403(b)) Retirement Savings Plan, which combines employee contributions and university contributions starting at 7%.\nWellness\nWellness challenges, annual health screenings, mental health resources, mindfulness programs and courses, employee assistance program (EAP), financial resources, access to dietitians, and more!\nFamily\nWe offer 4 weeks of caregiver leave to bond with your new child. Family care resources are also available for your continued childcare needs. Need adult care? We\u201a\u00c4\u00f4ve got you covered.\nWashU covers the cost of tuition for you and your family, including dependent undergraduate-level college tuition up to 100% at WashU and 40% elsewhere after seven years with us.\nFor policies, detailed benefits, and eligibility, please visit: https:\/\/hr.wustl.edu\/benefits\/\nEEO\/AA Statement\nWashington University in St. Louis is committed to the principles and practices of equal employment opportunity and especially encourages applications by those from underrepresented groups. It is the University\u201a\u00c4\u00f4s policy to provide equal opportunity and access to persons in all job titles without regard to race, ethnicity, color, national origin, age, religion, sex, sexual orientation, gender identity or expression, disability, protected veteran status, or genetic information.\nDiversity Statement\nWashington University is dedicated to building a diverse community of individuals who are committed to contributing to an inclusive environment \u201a\u00c4\u00ec fostering respect for all and welcoming individuals from diverse backgrounds, experiences and perspectives. Individuals with a commitment to these values are encouraged to apply.\nShow more\nShow less",
      "job_skills":"Data management, Data harmonization, Data analysis, Statistical packages, SAS, R, Python, REDCap, Database design, Database management, PC\/UNIX, Statistical data analysis, Verbal communication, Written communication, Interpersonal communication, Organization skills",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Analyst",
      "company":"Barkley",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-barkley-3784882135",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Our Data Management & Measurement (DMM) team lives at the center of marketing results and business impacts. We assess how our clients can best optimize their marketing efforts to maximize the direct impact on business results.\nWe are looking for a Sr. Data Analyst, who will work on the front lines of our practice - delivering impactful and inspiring reporting for our internal media teams and our clients. This person will ideally become a trusted expert regarding their clients' marketing performance data and its impact on business results. As a member of the DMM team, you will play an important role in discovering, analyzing and presenting findings and reports related to all media channels. You will be at the heart of uncovering and measuring the connections between marketing results and business objectives.\nResponsibilities\nHave a passion for data analysis, critical thinking and storytelling\nBe able to work with internal media and reporting teams to develop measurement solutions for client campaigns.\nAnalyze campaign performance and other marketing efforts to assess their impact on client KPIs and make recommendations for improvements.\nParticipate in the creation of our clients' measurement strategies, including KPI selection, data capture requirements, measurement frameworks and data visualization\nBecome a trusted expert regarding clients' marketing performance data and will assist team members across departments in accessing and interpreting results.\nHave experience with digital tracking, including tagging, mobile and social limitations\nExcellent verbal and written communication skills to interpret and present business value to clients.\nWork with client internal analytics and IT teams to implement custom tracking parameters\nImplement and maintain media performance dashboard reporting across platforms like Excel, Sheets, Data Studio, PowerPoint, Slides, Datorama, Tableau and Power BI\nDemonstrate problem-solving ability with emphasis on drawing inferences with data\nPersonal characteristics:\nIntellectual curiosity, problem solving skills and determination\nDetail-oriented and thorough\nEffective communications verbally and in writing\nAbility to listen to stakeholders, process feedback and provide solutions\nStrong work ethic and integrity\nQualifications\n2+ years of marketing analytics and business intelligence experience with an emphasis on media and marketing measurement\nExperience with data visualization tools, especially Power BI, is a plus. This includes both the data visualization component of dashboard development and backend data preparation and aggregation.\nStrong working knowledge of spreadsheet platforms (i.e. Excel, Sheets, etc)\nExperience with advertising planning, buying and performance metrics\nExperience with media reporting platform(s) (Doubleclick, Adwords, etc)\nExperience with web analytics platform(s) (Adobe, Google Analytics,etc.)\nData analysis experience including spreadsheet (Excel) and SQL platforms\nRelational database programming languages (e.g. SQL) and statistical tools (e.g. SAS, SPSS, Python) is a plus\nEffectiveness in managing multiple projects across multiple clients and stakeholders\nExperience in analysis, research and presentation creation\nBarkley's Commitment to Diversity & Inclusion\nWe believe being radically diverse and inclusive is the key to becoming one of the world's great creative idea companies. By embracing everything that makes our partners who they are and what makes them unique to the world around them, we create the conditions and capacity to help creative, original thinking thrive.\nBarkley is committed to Diversity, Equity, Inclusion and Belonging as part of our corporate strategic goals, supported by a formal DEI+B program, Employee Resource Groups, Director of Diversity leadership and agency commitment to The Brand Lab.\nShow more\nShow less",
      "job_skills":"Data analysis, KPI, SQL, SAS, SPSS, Python, Excel, Sheets, Data visualization, Dashboard, PowerPoint, Datorama, Tableau, Power BI, Problemsolving, Data preparation, Spreadsheet platforms, Project management, Adobe Analytics, Google Analytics, Media reporting platforms, Marketing analytics, Business intelligence, Digital tracking, Measurement frameworks, Tagging",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Conversion Developer, Senior Associate",
      "company":"PwC",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-conversion-developer-senior-associate-at-pwc-3749935677",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nFunctional & Industry Technologies\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 80%\nA career within Functional and Industry Technologies services will provide you with the opportunity to build secure and new digital experiences for customers, employees, and suppliers. We focus on improving apps or developing new apps for traditional and mobile devices as well as conducting usability testing to find ways to improve our clients\u201a\u00c4\u00f4 user experience. Our team helps clients transform their business through enabling technologies across marketing, finance and operations in the functional areas such as Maximo and PowerPlant.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nBasic Qualifications\nMinimum Degree Required:\nBachelor Degree\nMinimum Years Of Experience\n4 years\nPreferred Qualifications\nDegree Preferred:\nMaster Degree\nCertification(s) Preferred\nAzure Data Engineer Associate\nDatabricks Certified Data Engineer Associate\nPreferred Fields Of Study\nComputer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology\nPreferred Knowledge\/Skills\nDemonstrates a thorough level of abilities with, and\/or a proven record of success as both an individual contributor and team member, identifying and addressing client needs:\nSupports in data analysis techniques to assess source data structures, identify mapping requirements, and define transformation rules for data conversion into Maximo;\nLeads Maximo's modules and functionalities related to Asset Management and Work Order Management and IBM Maximo, including its data structures, configuration settings, and integration capabilities;\nIdentifies relational databases, preferably experience in working with databases commonly used in Maximo, such as IBM DB2, Oracle, Microsoft SQL Server, along with familiarity with Maximo's Integration Framework (MIF) and its capabilities for data integration and conversion;\nSupports in designing and implementing data extraction, transformation, and loading processes for Maximo data conversion;\nShowcases understanding in SQL and database querying languages to extract and manipulate data from source systems along with understanding ETL tools and methodologies commonly used in Maximo data conversion;\nIdentifies technologies commonly used with Maximo, including web services (SOAP, RESTful APIs), XML, JSON, and other relevant data exchange formats;\nSupports in pipeline architecture and development using one of the tools such as Azure ADF, AWS Glue, SSIS, DataBricks (multiple preferred);\nUtilizes data cleansing techniques and methodologies to ensure the integrity and accuracy of converted data in Maximo;\nDevelopes data cleansing functional business rules as per Maximo Business Object (MBO) definitions for source to Maximo conversion requirements;and comprehensive testing plans and executing validation processes to verify the accuracy and integrity of converted data in Maximo;\nCustomizes Maximo options, such as Automation Scripts, Java Customizations, Database Configuration, or Application Designer, to support data conversion requirements;\nIdentifies integrations within Maximo with other enterprise systems, such as ERP systems, GIS systems, or asset management systems. Knowledge of integration patterns, data synchronization, and data exchange protocols; and,\nShowcases work experience as a Data Engineer, Data Architect or similar role, along with experience in programming languages including Python, PySpark, Scala, SQL.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-advisoryseniorassociate\nShow more\nShow less",
      "job_skills":"Maximo, PowerPlant, PwC Professional, Azure Data Engineer Associate, Databricks Certified Data Engineer Associate, Computer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology, Data analysis, SQL, ETL tools, XML, JSON, Data cleansing techniques, Maximo Business Object (MBO), Python, PySpark, Scala, Java Customizations, Database Configuration, ERP systems, GIS systems, Asset management systems",
      "Category":"Backend Development"
  },
  {
      "job_title":"Power BI Data Analyst",
      "company":"Propper International",
      "job_location":"St Charles, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/power-bi-data-analyst-at-propper-international-3763854966",
      "search_city":"Cahokia",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Title:\nPower BI Data Analyst:\nPropper International is looking for a forward-thinking and innovative Power BI Data Analyst to provide business insights that drive improvements. The Power BI Data Analyst will play a key role by capturing, processing, and transforming datasets into clear summaries to fuel data-driven business decisions and solutions. The Data analyst will be heavily involved in the integration of different data sources, the use of ETL, SQL databases, and Power BI to successfully deliver BI solutions on a periodic basis.\nResponsibilities\nWork closely with business stakeholders to understand their requirements and use multiple data sources and Power BI to deliver data-driven insights and informed decisions.\nUse Power BI to create customized reports, dashboards, and KPIs to monitor key performance indicators.\nProvide live Power BI data through development of dynamic reporting, dashboarding, drill-down capabilities, and visualization solutions.\nDevelop processes for data mining, data modeling, and data production.\nCreate test plans and scenarios to ensure quality and requirement traceability for final deliverable.\nProvide Power BI training on various levels of expertise to companywide users and executives as needed.\nImplement data security measures to protect sensitive information and ensure compliance with data protection regulations.\nActively identify solutions to enhance the existing Business Intelligence infrastructure, processes, and technology.\nPerform other duties as assigned.\nRequirements (Must Have)\n4-year bachelor's degree in IT or related fields\n5+ years in Data Analysis using Microsoft Business Intelligence Stack (Power BI, SSAS, SSRS, SSIS, Data Factory, Power Query, MDX, DAX, etc.)\nSolid knowledge of SQL Data Warehousing and database fundamentals such as multidimensional database and relational database design.\nStrong programming skills in SQL. Knowledge of Python is a plus.\nProficiency with data science techniques and in manipulating data through data cleansing, data transformation, and data modeling.\nStrong analytical and problem-solving skills.\nSolid project management skills using Agile methodologies to meet project deadlines, budgets, and business requirements.\nGood communication and presentation skills\nExcellent Customer Service Orientation is a MUST.\nPosition Details\nOn-Site, Monday thru Friday 8am-5pm\n1099 Contract position. Contract duration is 6 months to 12 months, with possibility of direct hire\nHourly range of $39.00\/hr to $43.00\/hr depending upon experience.\nWho Is Propper\nWe got our start in 1967 with a contract for the U.S. Navy, manufacturing the iconic \"Dixie Cup\" hat worn by U.S. sailors. Over the decades, we've supplied more than 120 million garments to the U.S. Department of Defense, law enforcement agencies, and the public safety community.\nYou may not have heard of us, but you've definitely seen our work.\nOur heritage informs how we operate. We are a retail brand, but we still think like a contract manufacturer. Contracts aren't won by selling a particular lifestyle, telling unique stories, or appealing to emotion. They are won with features, quality, and demonstrable value. Contracts are won on the concrete.\nThis mentality drives every aspect of our production. Make it Work. Make it Last. Make it Real. Or don't make it at all.\nEqual opportunity Employer\nShow more\nShow less",
      "job_skills":"Power BI, SQL, Data Analysis, Data Mining, Data Modeling, Data Transformation, Data Visualization, Dashboards, KPIs, Python, Agile, Project Management, SSAS, SSRS, SSIS, Data Factory, Power Query, MDX, DAX",
      "Category":"Backend Development"
  },
  {
      "job_title":"Power & Gas Portfolio Data Analyst",
      "company":"Selby Jennings",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/power-gas-portfolio-data-analyst-at-selby-jennings-3785738308",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"A Global Energy Marketer and Trading House in Houston is looking to bring on a Power & Gas Portfolio Data Analyst to their Data Team.\nThis individual will be supporting the greater Trading function by monitoring North American and European Power Markets and assessing impacts as it relates to Data Management, as well as report and explain P&L impact to the Middle Office and greater business.\nThe ideal candidate will have at least 2 years of experience in a Data Analyst role for another Commodities Trading firm, with an understanding of North American Power Markets. Strong candidates will possess technical skills in SQL, Tableau, Python, etc.\nResponsibilities:\nProvide analytical support to the North American Power trading team by implementing new power contracts, market rules, and ISO protocols\nReport and explain P&L to Middle Office and the larger business\nWork with IT and Trading Teams to develop and test new systems and tools\nMonitor North American and European Power Markets and assessing impacts as it relates to Data Management\nBe the first point of contact for traders for new technical developments and reports\nQualifications:\n2+ YOE in a Data Analyst\/Data Focused role\nUnderstanding of North American Power Markets (ERCOT, PJM, CAISO, etc.)\nWorking ability in Python, SQL, Tableau, Alteryx, etc.\nStrong communication skills and ability to work across different business lines\nShow more\nShow less",
      "job_skills":"SQL, Tableau, Python, Power BI, Alteryx, ERCOT, PJM, CAISO, Energy Trading, Data Management, P&L Analysis, Market Rules, ISO Protocols, Data Analysis, Reporting",
      "Category":"Backend Development"
  },
  {
      "job_title":"Junior Data Visualization Developer",
      "company":"SynergisticIT",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/junior-data-visualization-developer-at-synergisticit-3767588947",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nSYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out you need to have exceptional skills and technologies that's where we come in to make sure you get the attention that you need\nWe are looking for Jobseekers wanting to file H1b visa\nPosition open to all visas and US citizens\nWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, Walmart labs etc to name a few.\nWe have an excellent reputation with the clients. Currently, We are looking for entry-level Python developers, and Data analysts\/ Data Scientists.\nWe welcome candidates with all visas and citizens to apply.\nWe assist in filing for STEM extension and also for H1b and Green card filing to Candidates looking to upskill\/enhance their IT skills.\nCandidates having difficulty in finding jobs or cracking interviews or who want to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience that our clients need with great outcomes\nCandidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement\nWe are looking for Jobseekers wanting to file H1b visa\nPosition open to all visas and US citizens\nCandidates Who Lack Experience\nHave had a break in careers\nLack Technical Competency\nDifferent visa candidates who want to get employed and settle down in the USA\nplease also check the below links\nhttps:\/\/www.synergisticit.com\/candidate-outcomes\/\nhttps:\/\/www.synergisticit.com\/java-track\/\nhttps:\/\/www.synergisticit.com\/data-science-track\/\nhttps:\/\/www.synergisticit.com\/blog\/\nRequired Skills\nBachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT\nHighly motivated, self-learner, and technically inquisitive\nKnowledge of Statistics, Python, and data visualization tools\nExcellent written and verbal communication skills\nPreferred skills: NLP, Text mining, Tableau, Time series analysis\nPlease understand skills are required by clients for selection even if it's a Junior or entry-level position the additional skills are the only way a candidate can be picked by clients.\nNo third-party candidates or c2c candidates\nTo apply for this position, please apply to the posting\nNo phone calls please . Shortlisted candidates would be reached out\nShow more\nShow less",
      "job_skills":"Python, Statistics, Data visualization tools, NLP, Text mining, Tableau, Time series analysis, Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT",
      "Category":"Backend Development"
  },
  {
      "job_title":"Hybrid Work - Need Data Engineer III in Houston TX",
      "company":"Steneral Consulting",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/hybrid-work-need-data-engineer-iii-in-houston-tx-at-steneral-consulting-3722357058",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"100% onsite in Houston, TX 77002, Must be local to Houston\nSchedule: 5 days a week onsite | 7:30am-5pm | **Fridays are half days** (totaling 40 hrs.\/week)\nTop Skills\nExperience ddesigning and implementing reliable data pipelines to integrate disparate data sources into a single Data Lakehouse\n5+ years of experience as a Data Engineer designing and maintaining data pipeline architectures\n5+ years of programming experience in Python, ANSI SQL, PLSQL, and TSQL\nExperience with Dremio and Airbyte\nAdditional Notes\nExperience with Data Lakehouse technologies is REQUIRED, the tools Dremio or Airbyte. Please ensure this is listed on resume.\nResponsibilities Include\nDesign and implement reliable data pipelines to integrate disparate data sources into a single Data Lakehouse\nDesign and implement data quality pipelines to ensure data correctness and building trusted datasets\nDesign and implement a Data Lakehouse solution which accurately reflects business operations\nAssist with data platform performance tuning and physical data model support including partitioning and compaction\nProvide guidance in data visualizations and reporting efforts to ensure solutions are aligned to business objectives\nThe Successful Candidate Will Meet The Following Qualifications\n5+ years of experience as a Data Engineer designing and maintaining data pipeline architectures\n5+ years of programming experience in Python, ANSI SQL, PLSQL, and TSQL\nExperience in various data integration patterns including ETL, ELT, Pub\/Sub, and Change Data Capture\nExperience with common Python Data Engineering packages including pandas, Numpy, Pyarrow Pytest, Scikit-Learn, and Boto3\nExperience in software development practices such as Design Principles and Patterns, Testing, Refactoring, CI\/CD, and version control\nExperience in implementing a Data Lakehouse using Apache Iceberg or Delta Lake\nKnowledgeable of modern data platform technologies including Apache Airflow, Kubernetes, and S3 Object Storage\nExperience with Dremio and Airbyte is preferred\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Lakehouse technologies, Apache Iceberg, Delta Lake, Apache Airflow, Kubernetes, S3 Object Storage, Dremio, Airbyte, Python, ANSI SQL, PLSQL, TSQL, pandas, Numpy, Pyarrow, Pytest, ScikitLearn, Boto3, Design Principles and Patterns, Testing, Refactoring, CI\/CD, Version control",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Backend Engineer \/ Data Engineer",
      "company":"Fluence",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-backend-engineer-data-engineer-at-fluence-3774813683",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"About Fluence:\nFluence Energy, Inc. (Nasdaq: FLNC) is a global market leader in energy storage products and services, and optimization software for renewables and storage. With a presence in over 47 markets globally, Fluence provides an ecosystem of offerings to drive the clean energy transition, including modular, scalable energy storage products, comprehensive service offerings, and the Fluence IQ Platform, which delivers AI-enabled SaaS products for managing and optimizing renewables and storage from any provider. Fluence is transforming the way we power our world by helping customers create more resilient and sustainable electric grids.\nFor more information, visit our website , or follow us on LinkedIn or Twitter . To stay up to date on the latest industry insights, sign up for Fluence's Full Potential Blog .\nOUR CULTURE AND VALUES\nWe are guided by our passion to transform the way we power our world. Achieving our goals requires creativity, diversity of ideas and backgrounds, and building trust to effect change and move with speed.\nWe are Leading\nFluence currently has thousands of MW of energy storage projects operated or awarded worldwide in addition to the thousands of MW of projects managed by our trading platform\u201a\u00c4\u00eeand we are growing every day.\nWe are Responsible\nFluence is defined by its unwavering commitment to safety, quality, and integrity.\nWe are Agile\nWe achieve our goals and meet our customer\u201a\u00c4\u00f4s needs by cultivating curiosity, adaptability, and self-reflection in our teams.\nWe are Fun\nWe value the diversity in thought and experience of our coworkers and customers. Through honest, forthcoming, and respectful communications we work to ensure that Fluence is an inclusive and welcoming environment for all.\nAs a Senior Backend Software Engineer \/ Data Engineer, you will be responsible for developing and maintaining the backend systems and data infrastructure for a large grid-scale storage energy company. Your role will involve working closely with our software engineering teams to optimize access to operational data and design and implement data models and APIs that work well for our user-facing application. You will also work heavily with our data science teams to build and optimize data pipelines, integrate data sets, and ensure data quality and governance.\nWhat does a Senior Backend Engineer\/Data Engineer do at Fluence?\nBuild and optimize data pipelines to ensure efficient data integration and flow across various sources and destinations.\nImplement and maintain automated testing and deployment processes to ensure the reliability and scalability of the backend systems.\nOptimize the performance and scalability of the backend systems to handle large-scale data processing and storage requirements, and design load testing to test and prove systems before field deployments.\nCollaborate with cross-functional teams to design and implement data models that support product features and data-driven decision-making.\nDevelop and maintain backend systems for data cataloging, schema management, and data discovery to facilitate effective data governance and access.\nWhat does the ideal candidate look like?\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\n5+ years of experience working on high-traffic systems, optimizing performance, and implementing scalable solutions to meet business needs effectively.\nStrong knowledge of backend programming languages such as Python, Go, C++, and Rust.\nExperience with database systems, including PostgreSQL, TimescaleDB as well as interacting with larger, more static stores such as data lakes.\nStrong understanding of professional software development practices, including version control, code reviews, and continuous integration and deployment.\nFamiliarity with testing frameworks and automation tools for backend software development, such as Jenkins and TestRail.\nExcellent problem-solving and communication skills, with the ability to work effectively in a collaborative team environment.\nExperience in the energy industry is a plus, but not a must.\n$0 - $0 a year\nFluence IS AN EQUAL OPPORTUNITY EMPLOYER and fully subscribes to the principles of Equal Employment Opportunity to ensure that all applicants and employees are considered for hire, promotion, and job status without regard to race, color, religion, sex, national origin, age, disability, veteran status, sexual orientation, marital or familial status.\nShow more\nShow less",
      "job_skills":"Python, Go, C++, Rust, PostgreSQL, TimescaleDB, Data Lakes, Version control, Code reviews, Continuous integration, Deployment, Testing frameworks, Automation tools, Jenkins, TestRail, SQL, NoSQL, Data pipelines, Data modeling, Data governance, Data cataloging, Schema management, Data discovery, Data quality, Data integration, Data science, Machine learning, Artificial intelligence, Energy storage, Renewables, Optimization, Software development, Backend programming, Software engineering, Load testing",
      "Category":"Backend Development"
  },
  {
      "job_title":"Power BI Data Analyst",
      "company":"ClearpointCo",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/power-bi-data-analyst-at-clearpointco-3781732472",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Title: Power BI Data Analyst\nClient: Energy Oil & Gas Company\nLocation: Houston, Texas\nPay: $55\/hour\nType: Contract role (Houston, Texas)\nSummary:\nAs a Data Analyst specializing in Power BI, and\/or Python you will play a pivotal role in transforming raw data into actionable insights that drive informed decision-making within our supply chain operations. The ideal candidate will possess a strong analytical mindset, attention to detail, and the ability to work independently. This is a project-based role with the potential for long-term engagement based on performance.\n***Must have portfolio with case studies to showcase Power BI projects.***\nDuties:\nData Analysis focused on analyzing large datasets to extract meaningful trends, patterns, and insights.\nUtilize Power BI to create interactive and visually appealing dashboards for reporting purposes.\nDisseminate data developing Excel spreadsheet templates maintaining reports that provide key performance indicators (KPIs) to support supply chain decision-making.\nCollaborate with cross-functional teams to understand reporting requirements and deliver timely, accurate reports.\nLeverage Power BI expertise demonstrating proficiency in Power BI, including data modeling, DAX calculations, and dashboard design.\nExtract, transform, and load (ETL) data from various sources into Power BI for analysis and reporting purposes.\nDesign and implement robust data models and relationships to ensure accurate and efficient data analysis.\nPerform data cleansing, validation, and manipulation to maintain data accuracy and consistency.\nStay current with industry best practices and advancements in Power BI functionality.\nPerform Data Visualization designing visually compelling and user-friendly dashboards that effectively communicate complex data insights to stakeholders.\nEnsure data visualizations align with business objectives and enhance overall decision-making processes.\nManage Power BI assets, including reports, dashboards, workspaces, semantic models, and other components.\nOversee the sharing and distribution of Power BI items, ensuring accessibility and collaboration among team members.\nImplement and maintain security measures to safeguard Power BI assets and sensitive data.\nRequirements:\nMust have portfolio with case studies to showcase Power BI projects.\nMinimum of 2-4 years of relevant experience in data analysis with a focus on Power BI.\nProven experience as a Data Analyst with a focus on Power BI, including Power Query and Power Pivot.\nProficiency in Python is highly preferred.\nProficiency in SQL for data manipulation, extraction, and querying.\nProficiency in a range of other sources of data ingestion.\nAbility to translate complex business requirements into technical specifications for data visualization.\nProficiency in data visualization techniques and best practices.\nEducation:\nBachelor's degree in Data Science, Business Analytics, or related field.\nShow more\nShow less",
      "job_skills":"Power BI, Python, Data Analysis, Data Visualization, DAX, ETL, Data Modeling, Excel, SQL, Business Analytics, Power Query, Power Pivot",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst, Loan Servicing Analytics",
      "company":"DriveTime",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-loan-servicing-analytics-at-drivetime-3774970292",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"What\u201a\u00c4\u00f4s Under The Hood\nDriveTime Family of Brands includes in-house financing and servicing through Bridgecrest, which is one of the country\u201a\u00c4\u00f4s leading financial servicing providers. Bridgecrest services roughly $17 billion in finance receivables for DriveTime and other third parties. We service auto loans across a wide credit spectrum with the intent of creating a strong path to vehicle ownership for our customers.\nThat\u201a\u00c4\u00f4s Nice, But What\u201a\u00c4\u00f4s the Job?\nThis is not a position for which sponsorship will be provided. Individuals with temporary visas or who need sponsorship now or in the future are not eligible for hire at this time.\nThat\u201a\u00c4\u00f4s Nice, But What\u201a\u00c4\u00f4s the Job?\nIn short, as an analyst you will apply your analytical skills as you initiate, build, and develop reports and useful insights into company initiatives.\nIn long, our analysts are responsible for:\nCollect, clean, and validate data from various sources to ensure accuracy, completeness, and reliability.\nAnalyze large datasets using statistical techniques to identify trends, patterns, and insights that support business decision-making.\nDevelop and maintain reports, dashboards, and visualizations to present data in a clear and meaningful manner.\nPartnering with product, tech, data science, and operations to understand data requirements and translate them into effective visualizations.\nEffectively communicate with concise insights and\/or visualizations utilizing software such as Tableau while partnering collaboratively with colleagues and senior leaders in the organization.\nWrite and optimize SQL\/Snowflake queries to extract, manipulate, and analyze data from relational databases.\nPerform data validation and quality checks to ensure accuracy and completeness of SQL query results.\nLeveraging emerging technologies and critical thinking skills to continually innovate and automate existing methodologies, processes, and reporting. Design, develop, test, and implement new products and solutions.\nSo What Kind of Folks Are We Looking for?\nIntellectual curiosity. Why? What? How? Do you find yourself always wanting to learn more and broaden your knowledge base? If so, this could be the role for you.\nPassionate and goal-oriented. We are looking for someone that is enthusiastic about their work and is passionate about not only meeting their goals but exceeding them.\nKiller analytical and reporting abilities. You\u201a\u00c4\u00f4ll need the capability to analyze data and in return, prepare timely reports on your findings.\nMaster multi-tasker. We are looking for someone that is not only good at multi-tasking but thrives in it.\nExcellent verbal and written communication skills. The ability to talk and write with confidence, charisma and competence for a wide variety of audiences including management.\nA mind for the details. Okay we know \u201a\u00c4\u00fadetail-oriented\u201a\u00c4\u00f9 is on about every job description \u201a\u00c4\u00ec but we really mean it!\nThe Specifics.\nBachelor's or Master's degree in a quantitative field such as economics, engineering, finance, statistics, mathematics, or hard science.\n0-2 years\u201a\u00c4\u00f4 experience in analytics, engineering, consulting, or marketing\nSQL, Tableau, advanced Excel skills\nNice to Haves.\nPython, Snowflake\n#DICE\nSo What About the Perks? Perks matter\nMedical, dental, and vision, oh my! DriveTime Family of Brands covers a sizable amount of insurance premiums to ensure our employees receive top-tier healthcare coverage.\nBut Wait, There\u201a\u00c4\u00f4s More. 401(K), Company paid life insurance policy, short and long-term disability coverage to name a few.\nGrowth Opportunities. You grow, I grow, we all grow! But seriously, DriveTime Family of Brands is committed to providing its employees with every opportunity to grow professionally with roughly over 1,000 employees promoted year over year.\nTuition Reimbursement. We\u201a\u00c4\u00f4re as passionate about your professional development as you are. With that, we\u201a\u00c4\u00f4ll put our money where our mouth is.\nWellness Program. Health is wealth! This program includes self-guided coaching and journeys, cash incentives and discounts on your medical premiums through engaging in fun activities!\nGratitude is Green. We offer competitive pay across the organization, because, well\u201a\u00c4\u00b6 money matters!\nIn-House Gym. We want our employees to be the best versions of themselves. So come early, take a break in your day or finish strong with a workout!\nGive Us a Reason (or not), and We\u201a\u00c4\u00f4ll Celebrate. Regardless of whether there is a holiday or not, we are finding ways to kick back and enjoy each other\u201a\u00c4\u00f4s company outside of day-to-day work.\nSmart-Casual Dress. Come dressed in jeans (you\u201a\u00c4\u00f4ll fit right in with the rest of us).\nPaid Time Off & Paid Holidays. Not just lip service: we work hard, to play hard.\nAnything Else? Absolutely.\nDriveTime Family of Brands is Great Place to Work Certified! And get this: 90% of our rockstar employees say they feel right at home here. We could spend a lot of time having you read about ALL our awards, but we\u201a\u00c4\u00f4ll save time (and practice some humility) just naming a few others; Comparably Awards: Best Company for Diversity, Best Company Culture and Best Company Leadership, oh and don\u201a\u00c4\u00f4t forget Phoenix Business Journal Healthiest Employers (okay, we\u201a\u00c4\u00f4ll stop there)!\nHiring is contingent upon successful completion of our background and drug screening process. DriveTime is a drug-free, tobacco-free workplace and an Equal Opportunity Employer.\nAnd when it comes to hiring, we don't just look for the right person for the job, we seek out the right person for DriveTime. Buckle up for plenty of opportunities to grow in a professional, fun, and high-energy environment!\nShow more\nShow less",
      "job_skills":"SQL, Snowflake, Python, Tableau, Excel, Statistics, Data Analysis, Data Visualization, Data Mining, Data Validation, Data Quality, Business Intelligence, Reporting, Communications, Problem Solving, Critical Thinking, DetailOriented, MultiTasking, Teamwork",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Center Lead Engineer",
      "company":"Kforce Inc",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-lead-engineer-at-kforce-inc-3777072402",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nKforce is immediately seeking an experienced Lead Data Center Engineer in support of our enterprise networking and cloud solutions client based in Richardson, TX. Summary: In this role, the Data Center Lead Engineer will work as part of the L&C Data Center Operations Team, which plans, operates, and maintains the L&C Data Center footprint globally, catering to tens of thousands of lab requests per year. They will also work with the wider L&C team to support IT professionals' learning and training needs in outstanding ways. We provide world class training, community outreach, educational events, technical documentation, and hands-on learning across all of the company's portfolio of solutions. We are passionate about education, learning and improving careers. The Data Center Lead Engineer will also work closely with Cisco product teams across the entire Cisco portfolio - including Networking, Security, Data Center, Collaboration, and Applications. Safe to say, you won't always be in a Data Center, though you'll feel right at home in one. Responsibilities:\nDedicated to maintaining a 'Source of truth' for the network through our NetOps Tooling\nGenerate first rate technical documentation of new, existing, evolving data center and network implementation\nOwn high and low visibility issues and be accountable for resolving them\nTroubleshoot & resolve incidents, providing excellent levels of clear communication\nInnovate - Identify and lead continuous improvement of systems, tools, and processes\nThe Engineer will plan, build and manage the existing footprint and expansion of all aspects of a data center including:\nPower, cooling, and equipment air flow management\nRack, Infrastructure, Cable Design & Management\nDevice Network & IP Management\nIssue Resolution Management of Infrastructure & Network\nAsset Management\nCapacity Management\nVendor Management\nCompliance Management\nData Center Policy Compliance\nRequirements\nCCNP\/CCIE certification (R&S and\/or DC)\n5+ years of experience in Data Center Operations & Production Network Operation roles\n3+ years of experience with various Operating Systems: Windows, Linux, and Cisco network operating systems\nStrong Data Center knowledge including Nexus Routing & Switching\nExperience operating and troubleshooting complex networks with segmentation and virtualization\nExperience with implementing dynamic routing with OSPF, EIGRP and BGP\nExperience with implementing client and site-to-site VPN solutions\nExperience with virtual machine networking with VMWare\nVMWare, ESXi, vCenter, and VM configuration, and operation experience\nExperience with Cisco ACI, DNA and automation with Ansible and Python\nAble to manage core routers, switches, firewalls, etc.\nSelf-starter who requires little guidance to achieve the goals of complex data center projects\nDeep and multifaceted technical expertise and enjoy working on a team and mentoring others\nSee the big picture even when analyzing multiple sophisticated factors under pressure, having an eye and a passion for the details\nExcellent verbal and written skills and hold yourself to high standards in your results and communication\nExperience in the following products\/solutions:\nCisco Nexus 2000, 3000, 5000, 7000, 9000\nCatalyst 9000 switches\nISR 4000 and 1000 routers\nASA and Firepower Firewalls\nUCS server management\nThe pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.\nWe offer comprehensive benefits including medical\/dental\/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.\nNote: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.\nThis job is not eligible for bonuses, incentives or commissions.\nKforce is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nSalary: $50 - $68 per hour\nShow more\nShow less",
      "job_skills":"Cisco Nexus, Catalyst, Cisco ISR, ASA, Firepower Firewalls, UCS, NetOps, VMWare, ESXi, vCenter, VM, Cisco ACI, DNA, Ansible, Python, OSPF, EIGRP, BGP, Linux, Windows, Cisco network operating systems, Nexus Routing & Switching, Segmentation, Virtualization, Dynamic Routing, VPN solutions, Virtual Machine Networking, CCNP\/CCIE (R&S and\/or DC)",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analytics Intern (Summer 2024)",
      "company":"DriveTime",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analytics-intern-summer-2024-at-drivetime-3706625453",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"What\u201a\u00c4\u00f4s Under The Hood\nDriveTime Family of Brands is the largest privately owned used car sales finance & servicing company in the nation. Headquartered in Tempe, Arizona and Dallas, Texas, we create opportunities and improve the lives of our customers and our employees by placing a focus on putting the right customer, in the right vehicle, on the right terms and on their path to ownership.\nThe DriveTime Family of Brands spans across DriveTime, Bridgecrest and SilverRock. You can find us at the intersection of technology and innovation as we use our proprietary tools and over two decades of industry knowledge to redefine the process of purchasing, financing, and protecting your vehicle.\nThat\u201a\u00c4\u00f4s Nice, But What\u201a\u00c4\u00f4s the Job?\nWe are looking for skilled Analytics Interns for our 2024 summer internship program. Asan Analytics Intern, you will have the ability to work within one of our analytics groups that are dedicated to supporting a vertical within our complex business. These verticals range from operational analytics to risk analytics to servicing analytics (just to name a few).\nThe Anlaytics Intern will be responsible for things like:\nDeveloping and maintaining forecasting models\nProviding ad hoc analysis and special projects as required.\nWorking with department leaders to understand changes needed and collaborate on solutions for change.\nManipulating, analyzing, and presenting data using programs like SQL, Snowflake, Excel, Tableau, and Python\nInnovating on existing products and processes while using emerging technologies and data analysis to identify new opportunities to improve customer experience and profitability.\nCreating in-depth analyses, collaborating with stakeholders, and leveraging resources skillfully to capitalize on those new opportunities.\nDemonstrating strong communication skills in making recommendations to senior executives across DriveTime\u201a\u00c4\u00f4s family of companies.\nSo what are we looking for?\nKiller analytical and reporting abilities. You\u201a\u00c4\u00f4ll need the capability to analyze data and in return, prepare timely reports on your findings.\nA mind for the details. Okay we know \u201a\u00c4\u00fadetail-oriented\u201a\u00c4\u00f9 is on about every job description \u201a\u00c4\u00ec but we really mean it!\nFantastic problem solver. Your job is not only to find the problem, but more importantly, find the solution.\nAgile in a fast-past environment. We move, and we move quickly. Thriving in an environment that never stops, is a must.\nExcellent verbal and written communication skills. The ability to talk and write with confidence, charisma and competence for a wide variety of audiences including management.\nIntellectual curiosity. Why? What? How? Do you find yourself always wanting to learn more and broaden your knowledge base? If so, this could be the role for you.\nThe Specifics.\nYou are currently pursuing a bachelor's or master\u201a\u00c4\u00f4s with a graduation date of December 2024 \u201a\u00c4\u00ec May 2025\nA quantitative degree in either; economics, finance, analytics, math, engineering, computer science or other STEM field.\nData analysis experience\nKnowledge of Excel, SQL, Tableau, Python or R\nExcel skills\nOur internship program will be 11 weeks starting May 2024 to August 2024\nInternships will be based out of our Home Office in Tempe, AZ and Dallas, TX\nYou can expect a regular on-site schedule Monday-Friday, 40 hours per week\nSo What About the Perks? Perks matter.\nNot Just Coffee Runs. We\u201a\u00c4\u00f4re talking real world experience. You\u201a\u00c4\u00f4ll walk away from our internship program with hands-on experience, completed projects, full portfolios, and newly developed skills.\nWho Says You Have to Walk Away? Across both our Tempe, AZ and Dallas, TX offices, over 60% of our interns stay through the fall semester, return the following summer, or are brought on full-time after graduation.\nGrowth & Development. You will be mentored by industry professionals, be given guidance along the way, and the tools to be successful.\nPhilanthropy: Give for Good. We are proud to be difference makers in our communities. We dedicate time for our Interns to give back with us.\nGratitude is Green. Out Internship Program is paid, because, well\u201a\u00c4\u00b6 money matters!\nIn-House Gym. We want our employees to be the best versions of themselves. So come early, take a break in your day or finish strong with a workout!\nGive Us a Reason (or not), and We\u201a\u00c4\u00f4ll Celebrate. Regardless of whether there is a holiday or not, we are finding ways to kick back and enjoy each other\u201a\u00c4\u00f4s company outside of day-to-day work.\nSmart-Casual Dress. Come dressed in jeans (you\u201a\u00c4\u00f4ll fit right in with the rest of us).\nAnything Else? Absolutely.\nDriveTime Family of Brands is Great Place to Work Certified! And get this: 90% of our rockstar employees say they feel right at home here. We could spend a lot of time having you read about ALL our awards, but we\u201a\u00c4\u00f4ll save time (and practice some humility) just naming a few others; Comparably Awards: Best Company for Diversity, Best Company Culture and Best Company Leadership, oh and don\u201a\u00c4\u00f4t forget Phoenix Business Journal Healthiest Employers (okay, we\u201a\u00c4\u00f4ll stop there)!\nHiring is contingent upon successful completion of our background and drug screening process. DriveTime is a drug-free, tobacco-free workplace and an Equal Opportunity Employer.\nAnd when it comes to hiring, we don't just look for the right person for the job, we seek out the right person for DriveTime. Buckle up for plenty of opportunities to grow in a professional, fun, and high-energy environment!\nShow more\nShow less",
      "job_skills":"Analytics, SQL, Snowflake, Excel, Tableau, Python, R, Data Analysis, Data Manipulation, Data Presentation, Forecasting, Reporting, Problem Solving, Communication, DetailOriented",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer Manager",
      "company":"PepsiCo",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-manager-at-pepsico-3755657823",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Overview\nPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo\u201a\u00c4\u00f4s global business scale to enable business insights, advanced analytics and new product development. PepsiCo\u201a\u00c4\u00f4s\nEnterprise Data Operations (EDO)\nteam is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations, and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\nWhat PepsiCo Enterprise Data Operations (EDO) does:\nMaintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company\nResponsible for day-to-day data collection, transportation, maintenance\/curation and access to the PepsiCo corporate data asset\nWork cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders\nIncrease awareness about available data and democratize access to it across the company\nResponsibilities\nAs a data engineering manager, you will be the key technical expert overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be empowered to create & lead a strong team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.\nAccountabilities\nProvide leadership and management to a team of data engineers, managing processes and their flow of work, vetting their designs, and mentoring them to realize their full potential.\nAct as a subject matter expert across different digital projects.\nOversee\u201a\u00c4\u00d8work with internal clients and external partners to structure and store data into unified taxonomies and link them together with standard identifiers.\nManage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.\nBuild and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.\nResponsible for implementing best practices around systems integration, security, performance and data management.\nEmpower the business by creating value through the increased adoption of data, data science and business intelligence landscape.\nCollaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.\nEvolve the architectural capabilities and maturity of the data platform by engaging with enterprise architects and strategic internal and external partners.\nDevelop and optimize procedures to \u201a\u00c4\u00faproductionalize\u201a\u00c4\u00f9 data science models.\nDefine and manage SLA\u201a\u00c4\u00f4s for data products and processes running in production.\nSupport large-scale experimentation done by data scientists.\nPrototype new approaches and build solutions at scale.\nResearch in state-of-the-art methodologies.\nCreate documentation for learnings and knowledge transfer.\nCreate and audit reusable packages or libraries.\nQualifications\n8+ years of overall technology experience that includes at least 6+ years of hands-on software development, data engineering, and systems architecture.\n6+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.\n6+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).\n4+ years in cloud data engineering experience in Azure.\nFluent with Azure cloud services. Azure Certification is a plus.\nExperience scaling and managing a team of engineers.\nExperience with integration of multi cloud services with on-premises technologies.\nExperience with data modeling, data warehousing, and building high-volume ETL\/ELT pipelines.\nExperience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.\nExperience building\/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.\nExperience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.\nExperience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.\nExperience with version control systems like Github and deployment & CI tools.\nExperience with Azure Data Factory, Azure Databricks and Azure Machine learning tools.\nExperience with Statistical\/ML techniques is a plus.\nExperience with building solutions in the retail or in the supply chain space is a plus\nUnderstanding of metadata management, data lineage, and data glossaries is a plus.\nWorking knowledge of agile development, including DevOps and DataOps concepts.\nFamiliarity with business intelligence tools (such as PowerBI).\nBA\/BS in Computer Science, Math, Physics, or other technical fields.\nSkills, Abilities, Knowledge\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nProven track record of leading, mentoring, hiring and scaling data teams.\nStrong change manager. Comfortable with change, especially that which arises through company growth. Able to lead a team effectively through times of change.\nAbility to understand and translate business requirements into data and technical requirements.\nHigh degree of organization and ability to manage multiple, competing projects and priorities simultaneously.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong leadership, organizational and interpersonal skills; comfortable managing trade-offs.\nFoster a team culture of accountability, communication, and self-management.\nProactively drives impact and engagement while bringing others along.\nConsistently attain\/exceed individual and team goals\nAbility to lead others without direct authority in a matrixed environment.\nHighly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business.\nUnderstands both the engineering and business side of the Data Products released.\nPlaces the user in the center of decision making.\nTeams up and collaborates for speed, agility, and innovation.\nExperience with and embraces agile methodologies.\nStrong negotiation and decision-making skill.\nExperience managing and working with globally distributed teams.\nEEO Statement\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.\nPepsiCo is an Equal Opportunity Employer: Female \/ Minority \/ Disability \/ Protected Veteran \/ Sexual Orientation \/ Gender Identity\nIf you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.\nPlease view our Pay Transparency Statement.\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Warehousing, Data Analytics, SQL, Python, PySpark, Scala, Azure, Kubernetes, Data Modeling, Data Quality, MPP, Data Lineage, DevOps, DataOps, PowerBI, Big Data, Data Lake, Data Pipeline, Data Science, Machine Learning, Statistics, Retail, Supply Chain, Metadata, ETL, ELT, Data Profiling, Data Visualization, Data Integration, Business Intelligence, Data Governance",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Analyst",
      "company":"Glocomms",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-at-glocomms-3745374607",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This client is a fast growing subscription based tech brand that partners directly with law enforcement and is present in every metro area of the country. They are looking for an adaptive problem solver who is flexible working in an agile, fast-paced environment.\nResponsibilities:\nArchitect and standardize advanced metrics, along with meticulous metric definitions and calculations, fostering a cohesive data interpretation throughout the organization. Thoroughly document metadata where applicable.\nDevise and implement sophisticated systems to consistently scrutinize and validate data completeness and configuration accuracy across multifaceted data sources, such as business transactions, case data, sales activity, and pipeline data.\nChampion the development and curation of optimal practices for the storage, condensation, transmission, and utilization of intricate technical and operational data. This encompasses formulating strategic approaches like generating concise summary tables, constructing robust data feeds and pipelines, crafting efficient stored procedures, and streamlining workflows.\nBuild foundational data structures in support of functional teams across the business to enable continuous awareness into system and operational performance.\nDevelop dashboards, tools, and automated reports at scale oriented to a) provide insight into performance and b) provide user-friendly access of the data and insights to non-expert audiences for analysis and manipulation.\nEstablish and maintain effective performance tracking; identify improvement opportunities, form hypotheses, and propose, design and implement tests to drive strategy enhancement and optimization.\nPartner with functional teams to proactively analyze performance; use analytical techniques to assess data and provide recommendations to improve teams\u201a\u00c4\u00f4 operational and strategic approach.\nAnalyze data to determine goals and performance thresholds to drive growth; create processes for automating performance insights via dashboard alerts, notifications, etc.\nProvide analytical support for weekly, monthly, and quarterly business insight reviews.\nServe internal and external customers with diligence, persistence, and energy.\nInitiate and drive special projects such as: critically evaluating user behavior to uncover what drives usage and adoption and help us uncover what our critical success factors should be along the way (e.g., Facebook\u201a\u00c4\u00f4s \u201a\u00c4\u00fa7 friends in 10 days\u201a\u00c4\u00f9).\nQualifications:\n\u201a\u00c4\u00a2 4-5 years of Data Analytics experience; preferably working with big data and are able to make complex analytical concepts look and sound simple to others.\nHave deep understanding of and the ability to execute statistical analysis techniques.\nProficiently using various analytical tools such as SQL, Python, Power BI, Tableau, Excel.\nHave a Bachelor\u201a\u00c4\u00f4s of Science\/Bachelors of Arts, preferably in a field relevant to analytics (statistics, information systems, industrial engineering, finance, business, math, etc.).\nMasters\/Advanced degree in data\/analytical field preferred.\nStrong individual contributor that can work cross-functionally with various department stakeholders.\nWhat We Offer:\n\u201a\u00c4\u00a2 Medical insurance.\nVision insurance.\nDental insurance.\n401(k) Safe Harbor match of 4% after 1 year of employment.\nPaid maternity leave.\nPaid paternity leave.\nDisability insurance.\nFlex schedule.\nRobust PTO package.\n$95,000 - $120,000 a year\nCompany-wide Bonus Target 10%\nShow more\nShow less",
      "job_skills":"SQL, Python, Power BI, Tableau, Excel, Data analytics, Statistical analysis, Data visualization, Data interpretation, Business intelligence, Data warehousing, Data mining, Data modeling, Data governance, Data quality management, Performance management, Process improvement, Strategic planning, Problemsolving, Communication, Teamwork, Collaboration, Leadership, Datadriven decisionmaking, Critical thinking, Analytical thinking, Attention to detail, Problemsolving, Communication, Collaboration, Teamwork",
      "Category":"Backend Development"
  },
  {
      "job_title":"Principal Software Engineer \u201a\u00c4\u00ec Data Platforms",
      "company":"CVS Health",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-software-engineer-%E2%80%93-data-platforms-at-cvs-health-3770984470",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Bring your heart to CVS Health.\nEvery one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand \u201a\u00c4\u00ee with heart at its center \u201a\u00c4\u00ee our purpose sends a personal message that how we deliver our services is just as important as what we deliver.\nOur Heart At Work Behaviors\u201a\u00d1\u00a2 support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.\nPosition Summary\nPrincipal Software Engineer \u201a\u00c4\u00ec Data Platforms (Data, PubTech Data, Insights & Analytics)\nIn this role, you will lead the architecture and development of data infrastructure and services. Our data products and services empower teams across CVS Health with near real time data to support big data analytics, insights, and machine learning at scale. Our structured datasets enable Scientist to train and deploy Machine learning models, provide Publishers with near real time reporting and insights of their data products, and enable Engineers, Product Managers with access to structured and unstructured data. You will build scalable data-intensive infrastructure that processes petabyte size data, catalogs, transactional data, and telemetry signals.\nWhat The Candidate Will Do:\nTechnical Leadership: Provide technical leadership and guidance in designing and implementing data solutions that meet business requirements and align with data governance and architecture principles.\nSolution Development: Collaborate with stakeholders to understand business needs and translate them into scalable and reliable data systems and tools, while ensuring data quality, privacy, and compliance.\nData Governance: Champion and enforce data governance practices, including data lineage, metadata management, data quality controls, and privacy regulations.\nData Architecture: Design and develop large-scale data systems, including databases, data warehouses, and big data platforms, with a strong focus on data governance and compliance requirements.\nSoftware Engineering: Apply software engineering best practices to build robust and maintainable data solutions, ensuring code quality, performance, and scalability in line with data governance guidelines.\nPerformance Optimization: Optimize data processing and query performance using technologies such as data proc, gcs, and Big Query, while ensuring adherence to data governance SLAs.\nAutomation and Efficiency: Drive automation initiatives by developing scripts, utilities, and frameworks to streamline data processes, improve efficiency, and enforce data governance practices.\nCollaboration and Mentoring: Collaborate with cross-functional teams, mentor junior engineers, and foster a culture of data governance and compliance awareness within the team.\nInnovation and Continuous Improvement: Stay updated with the latest industry trends and technologies in data engineering and data governance, evaluate new tools and techniques, and propose innovative solutions to enhance data systems, processes, and governance practices.\nDocumentation and Knowledge Sharing: Maintain comprehensive documentation of data solutions, processes, best practices, and data governance frameworks, and actively share knowledge with the team.\nRequired Qualifications\nExperience: 7 \u201a\u00c4\u00ec 10+ years of experience as a software engineer, with a strong focus on data engineering and large-scale data systems.\nTechnical Expertise: Proficiency in technologies such as Hive, Spark, and Python. Experience with additional data technologies and tools is a plus.\nData Governance: Strong understanding of data governance principles, regulations, and industry best practices, with practical experience in implementing and enforcing data governance frameworks.\nData Architecture: Solid understanding of data architecture principles and proven experience in designing and developing scalable data systems, while considering data governance requirements.\nPreferred Qualifications\nSoftware Engineering Skills: Excellent programming skills, with expertise in building robust and scalable software solutions using modern software engineering practices in alignment with data governance guidelines.\nProblem-Solving Abilities: Analytical mindset with the ability to understand complex business or technical problems and propose effective data solutions, considering data governance and compliance aspects.\nLeadership Skills: Demonstrated ability to provide technical leadership, mentor junior engineers, and drive successful outcomes in a collaborative team environment, with a focus on data governance excellence.\nCommunication Skills: Strong verbal and written communication skills to effectively convey complex technical concepts\nEducation\nBachelor's or master's degree in Computer Science, Engineering, or a related field.\nPay Range\nThe typical pay range for this role is:\n$140,000.00 \u201a\u00c4\u00ec $280,000.00\nThis pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. This position also includes an award target in the company\u201a\u00c4\u00f4s equity award program.\nIn addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company\u201a\u00c4\u00f4s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (\u201a\u00c4\u00faPTO\u201a\u00c4\u00f9) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.\nFor more detailed information on available benefits, please visit jobs.CVSHealth.com\/benefits\nCVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.\nYou are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.\nCVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.\nShow more\nShow less",
      "job_skills":"Software Engineering, Data Platforms, Databases, Data Warehouses, Big Data Platforms, Data Governance, Data Architecture, Data Quality, Privacy, Compliance, Python, Data Proc, GCS, Big Query, Hive, Spark, Machine Learning, AI, Automation, Collaboration, Mentoring, Documentation, Knowledge Sharing, Software Engineering Skills, ProblemSolving Abilities, Leadership Skills, Communication Skills, Computer Science, Engineering",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Wells Fargo",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-wells-fargo-3779720157",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"At Wells Fargo, we want to satisfy our customers' financial needs and help them succeed financially. We're looking for talented people who will put our customers at the center of everything we do. Join our diverse and inclusive team where you'll feel valued and inspired to contribute your unique skills and experience.\nHelp us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.\nWells Fargo Technology\nsets IT strategy; enhances the design, development, and operations of our systems; optimizes the Wells Fargo infrastructure footprint; provides information security; and enables continuous banking access through in-store, online, ATM, and other channels to Wells Fargo's more than 70 million global customers.\nWells Fargo Bank N.A. seeks a\nSenior Data Engineer\nin Irving, TX.\nJob Role And Responsibility\nAs a Senior Data Engineer, you will support the Marketing line of business in the Hemisphere Teradata platform as well as two key data domains within the Enterprise Data Environment (EDE) on the Data Lake which utilizes the Big Data Hadoop platforms. This position will fill a key role on the team to provide development support oversight of various data ingestion activities and ETL conformance processes. The ingestion activities and data product outputs are keys to support a broad user community and drive analytic outcomes. In this capacity, the applicant will work with other MDT team members and upstream data providers to ensure efficient and accurate data ingestion solutions and support a variety of data curation and consumption patterns by various partners. The applicant will also be tasked with partnering across cross functional teams to harden platform tools used across the environment by performing and supporting various ETL activities. Through the creation of these data assets and supporting platform capabilities, it will allow for a more streamlined data ingestion and data consumer experience on the Data Lake. This position has the ability to telecommute. Position must appear in person to the location listed as the work address.\nTravel required:\nNONE\nRequired Qualifications\nBachelor's degree\nin Computer information Systems, Information Technology, or related technical field. Foreign degree equivalent accepted. Employer will accept a 3 year or 4 year Bachelor degree.\nFive (5) years\nof experience in the job offered or in a related position involving application development and implementation experience.\nSpecific Skills Required\n5 years of ETL (Extract, Transform, Load) Programming experience\n3 years of experience delivering ETL, data warehouse and data analytics capabilities on big data architecture such as Hadoop\n3 years of Agile experience\n3 years of SQL experience\n2 years of Hadoop experience\n1 years of Apache Spark design and development experience using Scala, Java, Python or Data Frames with Resilient Distributed Datasets (RDDs)\n1 years of experience in Hadoop ecosystem tools for real-time batch data ingestion, processing and provisioning such as Apache Flume, Apache Kafka, Apache Sqoop, Apache Flink, Apache Spark or Apache Storm\nKnowledge of Hadoop, Aster, and R\nQualified applicants send resume to: recruiter_inbox@wellsfargo.com and reference Requisition #001601 in the subject line.\nWe Value Diversity\nAt Wells Fargo, we believe in diversity, equity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national origin, religion, age, sexual orientation, gender identity, gender expression, genetic information, individuals with disabilities, pregnancy, marital status, status as a protected veteran or any other status protected by applicable law.\nEmployees support our focus on building strong customer relationships balanced with a strong risk mitigating and compliance-driven culture which firmly establishes those disciplines as critical to the success of our customers and company. They are accountable for execution of all applicable risk programs (Credit, Market, Financial Crimes, Operational, Regulatory Compliance), which includes effectively following and adhering to applicable Wells Fargo policies and procedures, appropriately fulfilling risk and compliance obligations, timely and effective escalation and remediation of issues, and making sound risk decisions. There is emphasis on proactive monitoring, governance, risk identification and escalation, as well as making sound risk decisions commensurate with the business unit's risk appetite and all risk and compliance program requirements.\nCandidates applying to job openings posted in US: All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other legally protected characteristic.\nCandidates applying to job openings posted in Canada: Applications for employment are encouraged from all qualified candidates, including women, persons with disabilities, aboriginal peoples and visible minorities. Accommodation for applicants with disabilities is available upon request in connection with the recruitment process.\nDrug and Alcohol Policy\nWells Fargo maintains a drug free workplace. Please see our Drug and Alcohol Policy to learn more.\nReference Number\nR-325331\nShow more\nShow less",
      "job_skills":"Data Engineering, Teradata, Data Lake, Hadoop, ETL, Apache Spark, Scala, Java, Python, Data Frames, Resilient Distributed Datasets, Hadoop ecosystem tools, Apache Flume, Apache Kafka, Apache Sqoop, Apache Flink, Apache Storm, Hadoop, Aster, R, SQL, Agile",
      "Category":"Backend Development"
  },
  {
      "job_title":"Spark (data engineer) Lead",
      "company":"Diverse Lynx",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/spark-data-engineer-lead-at-diverse-lynx-3747323850",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Hello\nHope you are doing well today !\nWe are currently hiring for\nSpark(Data engineer) Lead\nfor my client . JD are mention below please go through the JD once & if you find the JD relevant to your prior experience then please reverts back with \u201a\u00c4\u00fa\nUpdated resume , Visa type & current location\u201a\u00c4\u00f9\nRole: Spark Lead\nLocation: Irving Tx(Day one onsite role)\nType:- Fulltime\nRequired skill ::-\nJenkins , RLM, Ansible , Sensu , Linux\/Unix.\nJob Description\nStrong understanding of\nSRE concept\nand practices with automation implementation.\nSpark Architecture and different critical components and services\nStrong hands-on experience in shell\/python scripting language and good understanding of Linux\/Unix.\nGood to have\nknowledge on Sensu\nHands on experience in Jenkins , RLM, Ansible\nUnderstanding of\nDocker containers\nand ability to author\nDocker images \/ Understanding of Kubernetes\/ OpenShift\/Service\nUnderstanding of CI\/CD workflow and best practices.\nGood to have knowledge and\nunderstanding of K8s.\nGood communication skill.\nDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\nShow more\nShow less",
      "job_skills":"Spark, Jenkins, RLM, Ansible, Sensu, Linux, Unix, Shell scripting, Python scripting, Docker, Kubernetes, OpenShift, CI\/CD",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer, Public Company",
      "company":"Recruiting from Scratch",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-public-company-at-recruiting-from-scratch-3748830440",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This is for a client of Recruiting from Scratch.\nWho is Recruiting from Scratch:\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nOur Client:\nOur next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we\u201a\u00c4\u00f4re blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.\nWith a track record of strong financial performance and plans for continued headcount growth, we\u201a\u00c4\u00f4re looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nOur client is looking to bring on a Senior Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. .\nIn this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, delivers analysis to further improve engagement in existing features, and empowers our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.\nWhat\u201a\u00c4\u00f4s the job?\nDesign, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.\nMoving implementation to ownership of real-time and batch processing and data governance and policies.\nMaintain and enforce the business contracts on how data should be represented and stored.\nStay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users\nImplementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.\nWork closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.\nWhat We\u201a\u00c4\u00f4ll Love About You\n5+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field.\n7+ years experience using Python,\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, )\nSignificant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases.\nExperience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment.\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nExperience with dimensional data modeling and schema design in Data Warehouses\nFamiliar with ETL (managing high-quality reliable ETL pipelines)\nBe familiar with legal compliance (with data management tools) data classification, and retention.\nLocation: Palo Alto, San Francisco or Chicago\nSalary Range: $165,000-$210,000 USD base.\nEquity. Medical, Dental, Vision.\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Python, SQL, Snowflake, Airflow, Kubernetes, Docker, Spark, pySpark, Kafka, Storm, TDD, Pair Programming, Continuous Integration, ETL, Data Warehouses, Kafka, Data classification, Data retention",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior \/ Principal Backend Engineer \u201a\u00c4\u00ec Data Platform (HYBRID)",
      "company":"Dematic",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-principal-backend-engineer-%E2%80%93-data-platform-hybrid-at-dematic-3771477049",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"About Us\nAt Dematic, we are gearing up to revolutionize our data landscape by building a cutting-edge Enterprise Data Lakehouse Platform. We are forming two pivotal platform teams that will spearhead the creation of the platform's foundational components. These teams go beyond traditional data ingestion; they are architects of a microservices-driven platform, providing abstractions that empower other teams to seamlessly extend the platform.\nRole Overview\nWe are seeking a dynamic and highly skilled Principal Data Engineer to lead these foundational efforts. This role demands someone who not only possesses a profound understanding of the data engineering landscape but is also at the forefront of their game. The ideal candidate will contribute significantly to platform development, leading a team of contractors while actively shaping the future of our data ecosystem.\nWhat we offer:\nCareer Development\nCompetitive Compensation and Benefits\nPay Transparency\nGlobal Opportunities\nLearn More Here: https:\/\/www.dematic.com\/en-us\/about\/careers\/what-we-offer\nDematic provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\nThis policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.\nThe base pay range for this role is estimated to be $110,500-138,500 at the time of posting. Final compensation will be determined by various factors such as work location, education, experience, knowledge, and skills.\nWhat We Are Looking For:\nArchitect, design and develop core data platform components with a microservices architecture, abstracting platform, and infrastructure intricacies.\nCreate and maintain essential data platform SDKs and libraries, adhering to industry best practices.\nDesign and develop connector frameworks and modern connectors to source data from disparate application both on-prem and cloud.\nDesign and optimize data storage, processing, and querying performance for large-scale datasets using industry best practices.\nDesign and develop data quality frameworks and processes to ensure the accuracy and reliability of data.\nCollaborate with data scientists, analysts, and cross functional teams to design data models, database schemas and data storage solutions.\nDesign and develop advanced analytics and machine learning capabilities on the data platform.\nDesign and develop observability and data governance frameworks and practices.\nStay up to date with the latest data engineering trends, technologies, and best practices.\nDrive the deployment and release cycles, ensuring a robust and scalable platform.\nTasks and Qualifications:\nRequirements:\n10+ (for senior) 15+ (for principal) of proven experience in modern cloud data engineering, data architectures, data warehousing, and software engineering.\nExpertise in architecting, designing, and building end to end data platforms in the GCP environment using BigQuery and other services while adhering to best practices guidelines such as open standards, cost, performance, time to market and minimize vendor lock.\nSolid experience building data platforms in GCP environment.\nSolid experience designing and developing modular, distributed data platform components with a microservices architecture. Strong experience with Docker, Kubernetes, APIs is needed.\nProficiency in data engineering tools and technologies - SQL, Python, Spark, DBT, Airflow, Kafka.\nSolid experience implementing data lineage, data quality and data observability for big data workflows.\nStrong experience with modern data modeling, data architecture, and data governance principles.\nExcellent experience with DataOps principles and test automation.\nExcellent experience with observability tools - Grafana and Datadog\nApplicants must be authorized to work for any employer in the US without visa requirements. This position is not eligible for an employment visa sponsorship.\nNice to have:\nExperience with Data Mesh architecture.\nExperience building Semantic layers for data platforms.\nExperience building scalable IoT architectures\nShow more\nShow less",
      "job_skills":"Microservices, GCP, BigQuery, Docker, Kubernetes, APIs, SQL, Python, Spark, DBT, Airflow, Kafka, Data lineage, Data quality, Data observability, Data modeling, Data architecture, Data governance, DataOps, Grafana, Datadog",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-capital-one-3781022656",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Locations: TX - Plano, United States of America, Plano, TexasSenior Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking\nData Engineers\nwho are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nOn this team, we are building a suite of products to help our dealers connect with potential car buyers! This team is focusing on building the data infrastructure (right from ingestion to consumption) for all of our products from ground up. We build intelligence for scaling to more dealers and build personalized customer experience.\nWhat You\u201a\u00c4\u00f4ll Do:\nCollaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\nWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems\nUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake\nShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community\nCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\nPerform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply)\nAt least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java\n2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)\n2+ year experience working on real-time data and streaming applications\n2+ years of experience with NoSQL implementation (Mongo, Cassandra)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Java, Scala, Python, RDBMS, NoSQL, Redshift, Snowflake, SQL, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL, Mongo, Cassandra, UNIX\/Linux, Agile",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer \/\/ Dallas, TX",
      "company":"Motion Recruitment",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-dallas-tx-at-motion-recruitment-3767070916",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"We are searching for a Senior Data Engineer for our client. This opportunity is local to Irving, TX. Ideally, they prefer this candidate go in 5-days per-week; however, for the right candidate hybrid could be considered. This is a full-time direct-hire opportunity.\nAs for what the client does, they are an innovative industry leader within automotive restoration. They collaborate with well-known partners within both land and marine industries (sports, leisure, etc.). This company cares about their employees and offers stellar growth opportunities within.\nRequired Skills & Experience\nLengthy experience with ETL\nStrong abilities related to Python\nUsage of Scala in recent positions\nConfident in SQL abilities\nDesired Skills & Experience\nData Warehousing\nData Modeling and SQL Querying\nDatabase architecture\nAzure- Databricks\nPowerBI\nWhat You Will Be Doing\nTech Breakdown\n100% Data Engineering\nDaily Responsibilities\n80% Hands-On\n10% Mentorship\n10% Team Collaboration\nThe Offer\nBonus eligible\nYou Will Receive The Following Benefits\nMedical, Dental, and Vision Insurance\nPTO\nStock Options\nApplicants must be currently authorized to work in the US on a full-time basis now and in the future.\nPosted By:\nKatherine Spalding\nShow more\nShow less",
      "job_skills":"ETL, Python, Scala, SQL, Data Warehousing, Data Modeling, SQL Querying, Database architecture, Azure, Databricks, PowerBI",
      "Category":"Backend Development"
  },
  {
      "job_title":"Principal Data Engineer",
      "company":"hackajob",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-data-engineer-at-hackajob-3776974501",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"hackajob has partnered with a disruptive automotive business that puts innovation at the heart of its new digital products and works with an unrivaled amount of automotive consumer data.\nRole\n: Principal Data Engineer, MDM\nLocation\n: Plano, TX\nWork model:\nhybrid\nQualifications and Requirements\nAt least eight years of hands on ETL development experience\nAt least four years of hands-on experience developing in Azure Data Factory, Databricks Python and Spark\nAt least 2 years leading a technical team, providing leadership, design documentation and diagrams\nAt least 2 years of hands-on experience working with configuration of Azure subscriptions, resource groups, resources and provisioning\nAt least 2 years leading the end-to-end design and development of ETL integrations to be consumed by the enterprise, including monitoring and production support\nExperience with data driven initiatives, with background in MDM or other data management and governance platforms\nProven ability to learn and fully understand new technology, becoming the SME for the platforms and services your team interacts with\nSolid understanding of DevOps capabilities such as automated testing, continuous integration, and continuous delivery\nExperience working with a Master Data Management platform tool (pref. Reltio)\nProven track record of exhibiting strong critical thinking by analyzing facts in order to understand a business request or requirement thoroughly.\nProven ability to mentor and develop others. Experience positively influencing team norms, culture, and technical vision.\nExperience with agile methodologies\nVery strong communication both written and verbal\nIf you're interested in finding out more about this fantastic opportunity please get your application in and we can arrange a call.\nhackajob is a recruitment platform that will match you with relevant roles based on your preferences and in order to be matched with the roles you need to create an account with us.\n*This role requires you to be based in the US*\nShow more\nShow less",
      "job_skills":"Data Engineering, ETL Development, Azure Data Factory, Databricks Python, Spark, Azure Subscriptions, Azure Resource Groups, Azure Resources, DevOps, Automated Testing, Continuous Integration, Continuous Delivery, Master Data Management, Reltio, Agile Methodologies, Communication Skills",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Engineer II",
      "company":"Pizza Hut",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-ii-at-pizza-hut-3760695074",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nWe are seeking an experienced Analytics Data Engineer to join our Pizza Hut US team. This person will be responsible for taking ownership of existing data and analytics builds, automating new data and analytics jobs, and documenting processes in collaboration with, and in support of, teams that build data driven insights that contribute to Pizza Hut\u201a\u00c4\u00f4s growth. While this role will operate in the background, this person will play a critical part in shaping our business strategy on key initiatives, ensuring we deliver the best pizza experience to our customers. The work environment is highly collaborative in a semi-agile setting with cross-functional teammates. The selected candidate will be assigned to the analytics team, but will work closely with data engineering to strictly follow best practices that team defines, especially for changes made to production tables and systems, and for transitioning analytics jobs over to the data engineering team's ownership.\nResponsibilities\nSupport Data Analysis and Reporting:\nSupport internal clients that analyze large datasets to extract meaningful insights and trends.\nDevelop and maintain data and analytics processes that feed dashboards, reports, and visualizations that relay trends, results, and outcomes to stakeholders and senior leadership.\nPerform exploratory and investigative analysis to identify and quantify opportunities across various aspects of our business that can be measured with data.\nBe an expert on our data used for analytical purposes.\nTake ownership of existing automated processes and data products.\nSet up data feeds to 3rd party vendors and partners.\nQA And Data Evolution\nDesign and test processes prior to promoting to production.\nTroubleshoot and fix automation errors.\nProvide recommendations for column, or table design enhancements, or calculations, or attributes that would optimize analytics efficiency or improve data quality.\nBe creative and innovative in building solutions.\nCross-Functional Collaboration\nWork closely with cross-functional teams to understand business goals and objectives.\nEffectively influence, champion, and drive for results through prioritizing data cleansing and standardizing of production tables and views, assisting in the hand off of automated processes\/data builds to the data engineering team, and setting up new automations to support the analytics team and dashboard development.\nProvide analytics support to various departments and assist in solving complex business challenges through set up\/automation, and maintenance of, analytics processes.\nIdentify processes that are good candidates to transition ownership to the data engineering team. Refactor or port over anything necessary to another type of platform or language to promote to the production environment owned by the data engineering team.\nData Management\nEnsure data quality and accuracy by collaborating with the data engineering team.\nStay up-to-date with industry best practices and technologies related to analytics and data management.\nFactors of Success\nRequired\n6+ years of experience in data engineering.\n2+ years of experience in data analytics.\nProficiency in data engineering and governance languages and tools such as Airflow, SQL, and Alation.\nProficiency in data analysis languages and tools such as SQL, Python, R, Alteryx, and dbt.\nProficiency with code repositories and file version systems such as Git.\nData visualization skills using tools like Tableau, Power BI, Domo, or similar.\nWritten and verbal communication skills to convey complex findings to non-technical stakeholders.\nStrong problem-solving abilities and a results-oriented mindset.\nStakeholder management and partnership capabilities.\nVisionary thinker, with the ability to see the bigger picture and ability to design data and systems for where the company should go.\nProficiency in documentation, including:\nDiagramming data processes and table relationships\nDocumenting within code\nCreating and updating project documentation\nCreating data dictionaries\nAnd creating documentation for data and processes for the broader enterprise to leverage\nAbility to translate intricate details into understandable explanations.\nTechnically astute, with a strong grounding in SQL and the conversion of business requirements to practical data and analytics design.\nAbility to think and work in terms of customer-level analytics.\nPreferred\nQSR industry experience in data engineering and analytics\nExperience with data modeling\nSalary Range: $\u00ac\u2260\u00ac\u2260125,000 to $135,000 annually + bonus eligibility.\nThis is the expected salary range for this position. Ultimately, in determining pay, we'll consider the successful candidate\u201a\u00c4\u00f4s location, experience, and other job-related factors.\nAbout Us\nWho We Are\nFounded in 1958, Pizza Hut - a subsidiary of Yum! Brands, Inc. - now operates more than 18,000 restaurants in more than 100 countries. Pizza Hut is leading the way in providing customers with great experiences, innovating with technology and new products, as well as delivering exceptional service.\nOur People & Culture\nWe're looking for people who LOVE pizza and thrive in a fun, past paced, and customer-centric environment. At our corporate campuses, Pizza Hut has created the perfect place for you to grow your career. Every day, you\u201a\u00c4\u00f4ll work to support our franchisees and teams across the U.S., continuously challenging yourself to feed more possibilities. In return, we\u201a\u00c4\u00f4ll provide professional development and career growth opportunities so that you can become your best and achieve your goals. And we\u201a\u00c4\u00f4ll sweeten the deal by immersing you in our world-class recognition culture and providing a robust array of benefits, some highlights include:\n4 weeks PTO, plus standard holidays and time off to volunteer\nGenerous parental leave (16 weeks for moms, 6 weeks for dads)\n401(k) with 6% match, vested immediately\nOn-site daycare\n24\/7 fitness center with laundry services\nHalf-day Fridays, year round\nGiving Back\nAs a global company, Pizza Hut aims to make the world better by acting responsibly with respect to food, planet and people. Whether it\u201a\u00c4\u00f4s donating food through the Harvest Program or supporting literacy with the Pizza Hut BOOK IT! Program \u201a\u00c4\u00ec the company, our franchisees and our team members are committed to improving the communities we serve.\nPizza Hut is an equal opportunity workplace and committed to fostering an inclusive, diverse culture . All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, sexual orientation, or gender identity), national origin, age, disability and genetic information (including family medical history).\nShow more\nShow less",
      "job_skills":"Airflow, SQL, Alation, Python, R, Alteryx, dbt, Git, Tableau, Power BI, Domo, Data visualization, Data engineering, Data analytics, Data management, Data modeling, Business intelligence, Data governance, Data quality assurance, Data integration, Data mining, Machine learning, Natural language processing",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Quality Engineer -- 1 year contract -- Dallas, TX (Day 1 Onsite)",
      "company":"Lorven Technologies Inc.",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-quality-engineer-1-year-contract-dallas-tx-day-1-onsite-at-lorven-technologies-inc-3783919854",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title: Data Quality Engineer\nLocation: Dallas, TX (Day 1 Onsite)\nDuration: 1 year contract\nMandatory Skills: DQLabs\nResponsibilities\nAs a Data Quality Engineer specializing in DQLabs, you will be instrumental in evaluating and implementing data quality tools, conducting pilot tests, and ensuring the effectiveness of the data quality processes. Your role will involve collaboration with cross-functional teams to assess and select the right tools while running pilot tests to validate their suitability for our unique financial datasets.\nAssess and evaluate various data quality tools, with a focus on DQLabs, to determine their suitability for their environment.\nCollaborate with stakeholders to understand data quality requirements and help select tools that align with organizational goals.\nDesign and execute pilot tests for selected data quality tools to assess their performance in a real-world data context.\nEvaluate the effectiveness of tools in identifying and rectifying data quality issues through systematic testing.\nWork with cross-functional teams to develop and implement a comprehensive data quality framework tailored to financial datasets.\nEnsure that the chosen tools integrate seamlessly with the overall data quality\nDevelop and implement automated data quality checks and validations using scripting or coding languages (e.g., Python, SQL) within the DQ Labs environment.\nStreamline data quality processes and workflows to enhance efficiency.\nCollaborate closely with financial analysts, data scientists, and other stakeholders to understand data quality needs and address specific requirements.\nProvide technical expertise and support during pilot tests and tool implementation.\nQualifications\nBachelor's degree in a relevant field (e.g., Computer Science, Information Systems, Finance).\nProven experience as a Data Quality Engineer, with a focus on DQ Labs tools and methodologies.\nSolid understanding of financial data concepts, regulations, and industry best practices.\nProficiency in scripting or coding languages (e.g., Python, SQL) for data quality automation.\nSolid understanding of financial data concepts, regulations, and industry best practices.\nStrong analytical and problem-solving skills with meticulous attention to detail.\nExcellent communication and collaboration skills within a financial context.\nShow more\nShow less",
      "job_skills":"Data Quality, DQLabs, Data Quality Tools, Data Quality Framework, Python, SQL, DQ Labs, Financial Data Concepts, Financial Regulations, Industry Best Practices, Scripting Languages, Coding Languages, Data Quality Automation, Data Quality Checks, Data Quality Validation, Financial Analysts, Data Scientists, Technical Expertise",
      "Category":"Backend Development"
  },
  {
      "job_title":"Azure Data Lead Analyst",
      "company":"Kubota Tractor Corporation",
      "job_location":"Grapevine, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/azure-data-lead-analyst-at-kubota-tractor-corporation-3784645147",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"For Earth For Life\nBASIC PURPOSE AND SCOPE OF POSITION\nThis position requires a collaboration with business users\/analysts\/scientists to identify the required data and bring them into Azure analytics platform.\nPRINCIPAL ACTIVITIES\n: This position does the following in accordance with all applicable Federal, State and local laws \/ regulations and the Company\u201a\u00c4\u00f4s policies, procedures and guidelines:\nDesign, build, and maintain datasets in Azure Data lake\/SQL DB\/Synapse by extracting data from various source systems\nDesign and develop data processing\nMonitor and optimize data storage and data processing\nWork with Security Engineers to implement data security\nActively involved with Production Support and troubleshoot the issues in live system by engaging appropriate internal and external stakeholders, being responsive, leading the root cause analysis and thoughtful on upstream and downstream impacts of the change. Provide quick resolution of the problems ensuring minimal downtime to the business and adhering to the change control process of the organization\nSPECIAL PROJECTS\nAs assigned.\nMinimum Qualifications\nEDUCATION, CERTIFICATIONS, AND TRAINING:\nBachelor's degree in Computer Science, Information systems, Engineering or a related discipline; or equivalent combination of education and experience\nCertification of Data Engineering on Microsoft Azure is preferred\nSkills And Background\nOverall 5+ years of experience in the Data and Analytics domain, performing Data Engineering on Business Intelligence, Digital and Data Warehouse projects.\nAt least 2 full life-cycle Azure implementations preferred\nMust be an expert in implementing data warehouse, data lakes, big data, data streaming and ingestion, data retention and archiving, ETL, etc.\nShould have experience with Azure Storage\/Data Lake, Azure Data Factory, Azure Databricks, Data processing languages SQL and Python or, Data Wrangling, Azure Synapse, and S\/4 data structure, preferred\nParticipates in multiple design activities with authority to make independent choices free from supervision\nRequires strong communication skills to work internally with end user departments, management and peers. Develops and provides written and verbal presentations to end users, peers, and support personnel\nLanguage Requirements\nMust be able to read, write and communicate in English.\nEQUIPMENT OPERATION\n(% of time, description, nature of service):\nOffice equipment including computer, copier, fax, phone, printer\nPhysical Requirements\nTypical office environment.\nAdditional Information\nDISCLAIMER:\nThe information provided in the description has been designed to indicate the general nature and level of work performed by incumbents within the classification. This description is not intended to be a comprehensive inventory of all duties, responsibilities, qualifications and working conditions required of employees assigned to this job\/classification. This job is intended to include the current essential functions of the job. Management reserves the right to add or modify the duties and responsibilities and to designate other functions as essential at any time.\nKubota is an equal opportunity at will employer and does not discriminate against any employee or applicant for employment because of age, race, religion, color, disability, sex, sexual orientation or national origin.\nApply Now\nShow more\nShow less",
      "job_skills":"Azure, SQL, Python, Data engineering, Data warehouse, Big data, Data streaming, Data ingestion, Data retention, Data archiving, ETL, Azure storage, Azure Data Lake, Azure Data Factory, Azure Databricks, Data processing, Azure Synapse, S\/4 data structure",
      "Category":"Backend Development"
  },
  {
      "job_title":"Staff Data Engineer",
      "company":"Recruiting from Scratch",
      "job_location":"Watauga, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/staff-data-engineer-at-recruiting-from-scratch-3744397184",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This is for a client of Recruiting from Scratch.\nWho is Recruiting from Scratch:\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nOur Client:\nOur client is a dating app.\nIn this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, deliver analysis to further improve engagement in existing features, and empower our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.\nWhat\u201a\u00c4\u00f4s the job?\nDesign, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.\nSolve technical problems of the highest scope and complexity\nExert significant influence on the company\u201a\u00c4\u00f4s analytical long-range goals and data architecture\nDefine and extend our internal standards for style, maintenance, and best practices for a high-scale data platform\nProvide mentorship for all on your team to help them grow in their technical responsibilities\nPropose ideas to improve the scale, performance, and capabilities of the Data Platform\nMoving implementation to ownership of real-time and batch processing and data governance and policies.\nMaintain and enforce the business contracts on how data should be represented and stored.\nStay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users\nImplementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.\nWork closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.\nWhat We'll Love About You\n7+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field\n7+ years experience using Python\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)\nSignificant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases\nExperience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nExperience with dimensional data modeling and schema design in Data Warehouses\nFamiliar with ETL (managing high-quality reliable ETL pipelines)\nBe familiar with legal compliance (with data management tools) data classification, and retention\nLocation\n: This role will be located in office twice a week minimum in Palo Alto, San Francisco or Chicago.\nSalary Range: $180,000 - 250,000 USD base.\nEquity. Medical, Dental, Vision.\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Data Engineering, Business Intelligence, Data Science, Python, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, SQL, Kafka, Storm, SparkStreaming, Dimensional Data Modeling, Schema Design, Data Warehouses, ETL, Data Classification, Data Retention",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer, Public Company",
      "company":"Recruiting from Scratch",
      "job_location":"Watauga, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-public-company-at-recruiting-from-scratch-3748831276",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This is for a client of Recruiting from Scratch.\nWho is Recruiting from Scratch:\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nOur Client:\nOur next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we\u201a\u00c4\u00f4re blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.\nWith a track record of strong financial performance and plans for continued headcount growth, we\u201a\u00c4\u00f4re looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nOur client is looking to bring on a Senior Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. .\nIn this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, delivers analysis to further improve engagement in existing features, and empowers our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.\nWhat\u201a\u00c4\u00f4s the job?\nDesign, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.\nMoving implementation to ownership of real-time and batch processing and data governance and policies.\nMaintain and enforce the business contracts on how data should be represented and stored.\nStay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users\nImplementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.\nWork closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.\nWhat We\u201a\u00c4\u00f4ll Love About You\n5+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field.\n7+ years experience using Python,\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, )\nSignificant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases.\nExperience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment.\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nExperience with dimensional data modeling and schema design in Data Warehouses\nFamiliar with ETL (managing high-quality reliable ETL pipelines)\nBe familiar with legal compliance (with data management tools) data classification, and retention.\nLocation: Palo Alto, San Francisco or Chicago\nSalary Range: $165,000-$210,000 USD base.\nEquity. Medical, Dental, Vision.\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Data Engineering, Business Intelligence, Data Science, Python, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, PySpark, SQL, TDD, Pair Programming, Continuous Integration, Automated Testing, Deployment, StreamProcessing Systems, Kafka, Storm, SparkStreaming, Dimensional Data Modeling, Schema Design, ETL, Data Warehouses, Data Management Tools, Data Classification, Data Retention",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Analyst\/Developer",
      "company":"Workcog Inc",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-developer-at-workcog-inc-3747709670",
      "search_city":"Nome",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Healthcare Client\n100% Remote | CST or EST Hours\n12+ Month Contract\nMUST Have\n10+ years\u201a\u00c4\u00f4 experience\nExperience with Identity and Access Management in a large organization.\nWell versed with MySQL database queries and creation of database views.\nDevelopment experience with REST, SOAP, LDAP, MySQL\nDevelopment experience with Java\nSelf-starter who is excellent with managing external relationships and communications (important: following up) with technical contacts\nNice To Have:\nIAM Tools\/Systems:\nRadiant Logic HDAP (High-Availability Directory Access Protocol)\nICS (Industrial Control System)\nFID (Federated Identity)... Formally, known as VDS (Virtual Desk Service).\nShow more\nShow less",
      "job_skills":"Identity and Access Management, MySQL, REST, SOAP, LDAP, Java, Database Queries, Database Views, Radiant Logic HDAP, ICS, FID",
      "Category":"Backend Development"
  },
  {
      "job_title":"Staff Data Engineer",
      "company":"Recruiting from Scratch",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/staff-data-engineer-at-recruiting-from-scratch-3744395172",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This is for a client of Recruiting from Scratch.\nWho is Recruiting from Scratch:\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nOur Client:\nOur client is a dating app.\nIn this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, deliver analysis to further improve engagement in existing features, and empower our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.\nWhat\u201a\u00c4\u00f4s the job?\nDesign, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.\nSolve technical problems of the highest scope and complexity\nExert significant influence on the company\u201a\u00c4\u00f4s analytical long-range goals and data architecture\nDefine and extend our internal standards for style, maintenance, and best practices for a high-scale data platform\nProvide mentorship for all on your team to help them grow in their technical responsibilities\nPropose ideas to improve the scale, performance, and capabilities of the Data Platform\nMoving implementation to ownership of real-time and batch processing and data governance and policies.\nMaintain and enforce the business contracts on how data should be represented and stored.\nStay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users\nImplementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.\nWork closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.\nWhat We'll Love About You\n7+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field\n7+ years experience using Python\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)\nSignificant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases\nExperience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nExperience with dimensional data modeling and schema design in Data Warehouses\nFamiliar with ETL (managing high-quality reliable ETL pipelines)\nBe familiar with legal compliance (with data management tools) data classification, and retention\nLocation\n: This role will be located in office twice a week minimum in Palo Alto, San Francisco or Chicago.\nSalary Range: $180,000 - 250,000 USD base.\nEquity. Medical, Dental, Vision.\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Data engineering, Business intelligence, Data science, Python, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, PySpark, SQL, TDD, Pair programming, Continuous integration, Automated testing, Deployment, Streamprocessing systems, Kafka, Storm, SparkStreaming, Dimensional data modeling, Schema design, Data warehouses, ETL, Data management tools, Data classification, Data retention",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer, Public Company",
      "company":"Recruiting from Scratch",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-public-company-at-recruiting-from-scratch-3748828478",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This is for a client of Recruiting from Scratch.\nWho is Recruiting from Scratch:\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nOur Client:\nOur next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we\u201a\u00c4\u00f4re blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.\nWith a track record of strong financial performance and plans for continued headcount growth, we\u201a\u00c4\u00f4re looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nOur client is looking to bring on a Senior Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. .\nIn this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, delivers analysis to further improve engagement in existing features, and empowers our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.\nWhat\u201a\u00c4\u00f4s the job?\nDesign, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.\nMoving implementation to ownership of real-time and batch processing and data governance and policies.\nMaintain and enforce the business contracts on how data should be represented and stored.\nStay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users\nImplementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.\nWork closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.\nWhat We\u201a\u00c4\u00f4ll Love About You\n5+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field.\n7+ years experience using Python,\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, )\nSignificant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases.\nExperience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment.\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nExperience with dimensional data modeling and schema design in Data Warehouses\nFamiliar with ETL (managing high-quality reliable ETL pipelines)\nBe familiar with legal compliance (with data management tools) data classification, and retention.\nLocation: Palo Alto, San Francisco or Chicago\nSalary Range: $165,000-$210,000 USD base.\nEquity. Medical, Dental, Vision.\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Python, SQL, Snowflake, Data Science, Kubernetes, Docker, Helm, Spark, pySpark, Kafka, Storm, SparkStreaming, ETL, Data Warehouses, Airflow",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer, Public Company",
      "company":"Recruiting from Scratch",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-public-company-at-recruiting-from-scratch-3744393506",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This is for a client of Recruiting from Scratch.\nWho is Recruiting from Scratch:\nRecruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more.\nOur Client:\nThey are a profitable dating application.\nLocation: This is a hybrid role based in their Chicago office and will require you to be in office Tuesdays and Thursdays.\nWhat\u201a\u00c4\u00f4s so interesting about this role?\nOur client is looking to bring on a Senior Data Engineer with chops in cutting edge real-time streaming technologies and ambitions to achieve high quality and reliability with TDD, automation, and continuous delivery. .\nIn this role, you will have the opportunity to work with our product teams, building models and APIs to drive new features, delivers analysis to further improve engagement in existing features, and empowers our business with real-time insights to drive growth in market share, engagement, and revenue. We see 1 trillion events per year and process 10TB of data daily.\nWhat\u201a\u00c4\u00f4s the job?\nDesign, develop and deliver data products to production, complying with internal data governance, security and scalability of our system.\nMoving implementation to ownership of real-time and batch processing and data governance and policies.\nMaintain and enforce the business contracts on how data should be represented and stored.\nStay on top of new technologies through R&D and prototyping to continuously improve our big data architectures and systems to streamline how we deliver value with high quality to our end users\nImplementing ETL processes, moving data between systems including S3, Snowflake, Kafka, and Spark.\nWork closely with our Data Scientists, SREs, and Product Managers to ensure software is high quality and meets user requirements.\nWhat We\u201a\u00c4\u00f4ll Love About You\n5+ years of experience working with data at scale, including data engineering, business intelligence, data science, or related field.\n7+ years experience using Python,\nExperience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, )\nSignificant experience with relational databases and query authoring (SQL) in Snowflake or other distributed Databases.\nExperience with agile engineering practices such as TDD, Pair Programming, Continuous Integration, automated testing, and deployment.\nExperience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming\nExperience with dimensional data modeling and schema design in Data Warehouses\nFamiliar with ETL (managing high-quality reliable ETL pipelines)\nBe familiar with legal compliance (with data management tools) data classification, and retention.\nLocation\n: This role is twice a week in a hybrid role minimum.\nSalary Range: $165,000-$210,000 USD base.\nEquity. Medical, Dental, Vision.\nhttps:\/\/www.recruitingfromscratch.com\/\nShow more\nShow less",
      "job_skills":"Python, Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark, SQL, TDD, Pair Programming, Continuous Integration, automated testing, Kafka, Storm, SparkStreaming, dimensional data modeling, ETL, legal compliance, data classification, retention",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst",
      "company":"Marathon TS",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-marathon-ts-3772601903",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Marathon TS is seeking a\nSenior Data Analyst\nto join a contract with a federal government client in support of an important mission.\nThis\nposition requires employees to be located in the Huntsville, AL area\nin order to report to work on-site at Redstone Arsenal.\nResponsibilities\nProvide highly complex data mining, statistical analysis, trend analysis, and causal analysis.\nPerform as a technical lead responsible for monitoring and providing monthly contract reports and deliverables.\nResponsible for integrating multiple disciplines in an operations research team and translating applicable methods into language and application understandable by operational managers throughout the organization.\nReview and provide quality control methods on products.\nPrepare and update training materials to ensure newly assigned personnel gain an understanding of key analytic tools, procedures, and methodologies used.\nTake structured and unstructured data and distill the information into a cohesive analytical product for a contracting functional business area audience.\nSupport pattern analysis methods to formulate recommendations to operational managers based upon exploiting patterns in the past, current, and anticipated operational environment.\nEducation and Experience\n8 plus years in a technical field\nBA\/BS required\nRequired Skills\nHave experience advising senior DoD decision makers on methodologies, results, and conclusions from applied operations research.\nHave experience with the primary tools used for research services include, but are not limited to, Logistics Management Program, Vantage, Virtual Contracting Enterprise, General Fund Enterprise Business System (\nGFEBS\n), SAP Business Objects\/Web Intelligence Reports, Microsoft SharePoint, Army-specific contract writing systems (Procurement Desktop Defense (\nPD2\n) and Procurement Automated Data and Document System (\nPADDS\n)), and various Government and Commercial business process automation systems.\nPersonnel should have strong data manipulation and problem-solving skills.\nMust have strong technical skills in areas such as statistics, programming languages like R or\nPython\n,\nSQL\n(Structured Query Language), data visualization, and data cleaning and preparation.\nHave good communication skills and problem-solving ability.\nSecurity Clearance\nActive Secret clearance is required\nShow more\nShow less",
      "job_skills":"Data mining, Statistical analysis, Trend analysis, Causal analysis, Operations research, Quality control, Data visualization, Data cleaning, Python, SQL, R, SAP Business Objects, Microsoft SharePoint, Procurement Desktop Defense, Procurement Automated Data and Document System, GFEBS, Logistics Management Program, Vantage, Virtual Contracting Enterprise",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Scientist (Active TS Clearance)",
      "company":"Motion Recruitment",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-active-ts-clearance-at-motion-recruitment-3737589734",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"We are working with a Federal consulting company that is transforming the nations defense and national security with their AI platforms. This company works with various Federal agencies and will need this person to work on-site 2 to 3 days a week.\nCandidates should hold at least an active Top Secret clearance.\nRequirements\nOver 3 years of experience in data science\nExpertise in Python\nExperience with MySQL and Oracle\nExperience with machine learning\nBonus to have PhD in Sciences, Mathematics, or Engineering\nOffer\nCompetitive salary\nAnnual Bonus\nYou Will Receive The Following Benefits\nMedical Insurance\nDental Benefits\nVision Benefits\nPaid Time Off (PTO)\n401(k)\nApplicants must be currently authorized to work in the US on a full-time basis now and in the future.\nPosted By:\nSean Thompson\nShow more\nShow less",
      "job_skills":"Python, Machine Learning, MySQL, Oracle, Data Science",
      "Category":"Backend Development"
  },
  {
      "job_title":"Looking for Azure Data Engineer - Houston, TX - Fulltime",
      "company":"Extend Information Systems Inc.",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/looking-for-azure-data-engineer-houston-tx-fulltime-at-extend-information-systems-inc-3716362615",
      "search_city":"Dahlonega",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Hi,\nI hope you are doing well!\nWe have an opportunity for\nAzure Data Engineer\nwith one of our clients for\nHouston, TX\nPlease see the job details below and let me know if you would be interested in this role.\nIf interested, please send me a copy of your resume, contact details, availability, and a good time to connect with you.\nTitle:\nAzure Data Engineer\nLocation:\nHouston, TX\nTerms:\nFulltime\nJob Details\nTechnical Skills:\nYou have a minimum of 4+ years' experience working with Azure Data tools (ADF,Data Catalog, event hub,IOT hub) etc\nYou have proficiency in PySpark ,Python and SQL\nExperience working with Databricks ,SQL End Point, Synapse\nKnowledge on Power BI and willingness to enhance PBI skill set.\nYou have already written code capable of efficiently handling large volumes of data across large numbers of tables, and brought this code into a controlled productive environment.\nKnowledge and experience in DevOps environments is a plus\nRoles & Responsibilities\nYou are strong on handling large and complex amounts of structured data, you have a track record of having delivered end-to-end data solutions in corporate environments.\nAs an all-rounder, you enjoy taking time to understand business requirement, articulate a data product solution and then roll up your sleeves and develop it into production grade.\nYou enjoy navigating ambiguity and working as part of a distributed team to solve business problems using data.\nYou are comfortable with agile development processes, with both scheduled and ad-hoc release cycles.\nGood English communication skills are a must, both spoken and written\nYou are comfortable working with some level of independence in a multinational environment\nYou are happiest solving concrete problems\nYou are able to lead a discussion with Business and understand requirements\nThanks & Regards\nMonika Singh\nExtend Information System Inc\nPhone: (571)-622-3980\nEmail: monika@extendinfosys.com\n44258 Mercure Circle, UNIT 102 A, Sterling VA, USA 20166\nShow more\nShow less",
      "job_skills":"Azure Data tools (ADF Data Catalog Event Hub IoT hub), PySpark, Python, SQL, Apache Databricks, SQL Endpoint, Synapse, Power BI, DevOps, Agile development, English communication skills (spoken and written)",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst",
      "company":"OmniForce Solutions",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-omniforce-solutions-3787361162",
      "search_city":"Pinehurst",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Must be located in one of the following states:\nTexas\nColorado\nWashington\nNew Jersey\nPennsylvania\nOur client is a Fortune 200 leading retail energy company focused on bringing the power of energy to people and organizations. Putting customers at the center of everything they do, they provide energy solutions to millions of people through their diverse portfolio of retail brands across North America. Take your career to the next level by working on a dynamic, innovative team that moves our world towards a sustainable energy future.\nPosition Overview:\nAs a Data Analyst specializing in Power BI, you will play a pivotal role in transforming raw data into actionable insights that drive informed decision-making within our supply chain operations. The ideal candidate will possess a strong analytical mindset, attention to detail, and the ability to work independently. This is a project-based role with the potential for long-term engagement based on performance.\nKey Responsibilities:\nData Analysis: Analyze large datasets to extract meaningful trends, patterns, and insights.\nUtilize Power BI to create interactive and visually appealing dashboards for reporting purposes.\nReport Generation: Develop and maintain reports that provide key performance indicators (KPIs) to support supply chain decision-making.\nCollaborate with cross-functional teams to understand reporting requirements and deliver timely, accurate reports.\nPower BI Expertise: Demonstrate proficiency in Power BI, including data modeling, DAX calculations, and dashboard design.\nExtract, transform, and load (ETL) data from various sources into Power BI for analysis and reporting purposes.\nDesign and implement robust data models and relationships to ensure accurate and efficient data analysis.\nPerform data cleansing, validation, and manipulation to maintain data accuracy and consistency.\nStay current with industry best practices and advancements in Power BI functionality.\nData Visualization: Design visually compelling and user-friendly dashboards that effectively communicate complex data insights to stakeholders.\nEnsure data visualizations align with business objectives and enhance overall decision-making processes.\nPower BI Asset Management: Manage Power BI assets, including reports, dashboards, workspaces, semantic models, and other components.\nOversee the sharing and distribution of Power BI items, ensuring accessibility and collaboration among team members.\nImplement and maintain security measures to safeguard Power BI assets and sensitive data.\nQualifications:\nProven experience as a Data Analyst focusing on Power BI, including Power Query and Power Pivot.\nProficiency in SQL for data manipulation, extraction, and querying.\nProficiency in a range of other sources of data ingestion.\nAbility to translate complex business requirements into technical specifications for data visualization.\nProficiency in data visualization techniques and best practices.\nStrong analytical and problem-solving skills.\nExcellent communication skills, with the ability to convey complex findings to non-technical stakeholders.\nDemonstrated ability to work independently and manage multiple tasks and priorities effectively.\nProficiency in Python is preferred.\nEducation and Experience:\nBachelor's degree in Data Science, Business Analytics, or related field.\nMinimum of 2-4 years of relevant experience in data analysis with a focus on Power BI.\nShow more\nShow less",
      "job_skills":"Power BI, DAX, Data modeling, ETL, Data cleansing, Data visualization, Python, SQL, Power Query, Power Pivot, Data analysis, Business Analytics, Communication skills",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Engineer",
      "company":"INSPYR Solutions",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-at-inspyr-solutions-3780037374",
      "search_city":"Gadsden",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Role: Data Engineer\nDuration: Direct Hire\nLocation: Houston, TX 77040 (HYBRID)\nWork Authorization: US Citizen, Green Card Holders or Authorized to work in the US\nSeeking talented Data Analyst \/ Engineers with expertise in SQL\/SSIS who are looking to grow into Data Scientists \/ Analytics Professionals.\nPosition Summary\nThe Data Engineer will have a background in data analysis, data analytics, data visualization, dashboards, KPIs & metrics reporting and will be proficient in SQL, SSIS, & SSRS. The candidate should have knowledge of structured and unstructured data concepts and tools, experience with OLAP tools, and the ability to code against APIs using Python for data extraction, transformation, and loading (ETL). This role will entail hands-on day to day data manipulation, transmission, and ETL work and also play and integral role in guiding the organization forward with larger analytics projects.\nResponsibilities:\nBe the primary support for our data analytics and business intelligence software.\nAnalyzes existing business processes in search of productivity gains through automation.\nProvides data integration services around our corporate data warehouse.\nCustomize 3rd party software applications.\nCompletes database, web, and client programming as needed.\nRequirements:\nBachelor's degree in MIS or CS or equivalent work experience.\nMaster's degree in Data Science or Data Analytics preferred.\n2 - 5 years of technical and relevant experience as Data Analyst focused on ETL work.\nProficient in SQL, SSIS, & SSRS\nAbility to code against APIs using Python for data extraction, transformation, and loading (ETL).\nPrior experience working in data analytics, data visualization, dashboards, KPIs & metrics reporting.\nKnowledge of structured and unstructured data concepts and tools.\nExperience with OLAP tools, including IBM Planning Analytics, is a preferred.\nAbout INSPYR Solutions:\nTechnology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients\u201a\u00c4\u00f4 business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.\nINSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities\nShow more\nShow less",
      "job_skills":"SQL, SSIS, SSRS, Python, ETL, Data visualization, Dashboards, KPIs, Metrics reporting, APIs, Data extraction, Data transformation, Data loading, Structured data, Unstructured data, OLAP tools, IBM Planning Analytics, Data analysis, Data analytics, Data science, Data engineering",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Analyst",
      "company":"FUJIFILM Diosynth Biotechnologies",
      "job_location":"College Station, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-at-fujifilm-diosynth-biotechnologies-3773361365",
      "search_city":"College Park",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"The work we do at FDB has never been more important\u201a\u00c4\u00eeand we are looking for talented candidates to join us. We are growing our locations, our capabilities, and our teams, and looking for passionate, mission-driven people like you who want to make a real difference in people\u201a\u00c4\u00f4s lives. Join FDB and help create the next vaccine, cure, or gene therapy in partnership with some of the most innovative biopharma companies across the globe. We are proud to cultivate a culture that will fuel your passion, energy and drive - what FDB call Genki.\nCollege Station, Texas may be a small, university town, but the lively cultural scene and local amenities make it a great place for families as well as those who want the ease of small-town life and the convenience of living close to the vibrant pulse of big cities. Eighty-seven percent of Texas' population lives within a 180-mile radius, so we are in the center of it all in Texas. And our site is nestled in the hub of innovation, representing a source of pride for the area.\nSummary:\nWorks under the supervision of the Data Analytics Manager or other data governance leadership appropriate for the scope of work. This role is responsible for data analytics and additional support of performance measures, ongoing measurement, data collection, reporting, data visualizations and information dissemination. Responsible for structuring the strategic design and maintenance of business intelligence applications. Identifies, researches, and resolves technical problems. Ensures that the use of data and business intelligence applications enhances business operations and decision making capabilities. Contributes to complex aspects of a project. Work is generally independent and collaborative in nature. Engages in data exploration exercises with a variety of complex business intelligence tools, requiring knowledge of relational database structures. Collaborates with other departments.\nExternal US\nEssential Functions:\nDevelop and execute on data analytics projects as assigned by the Data Analytics Manager\nUtilize company resources across departments and sites to curate data\nAnalyze data for trends and patterns\nGenerate reports and dashboards and transfer to super users\nTrain and provide technical support to super users\nCoordinate with other departments and sites to develop and implement new data collection models\nPerform data profiling to identify anomalies\nAll other duties as assigned\nRequired Skills & Abilities:\nCreate data models using tools using software applications such as Python, SAS, Alteryx, or equivalents for visualization in Tableau, Smartsheet, Power BI, or equivalent\nTranslate data into dynamic dashboards\nKnowledge of databases such as Microsoft SQL, MySQL, PostgreSQL, or equivalent\nWorking understanding of relational database design\nWorking understanding of statistics and mathematical models\nFamiliarity with data collection software and protocol\nExperience integrating new software and programs to data services\nAbility to prioritize multiple projects while still achieving deadlines\nExcellent analytical and forecasting ability\nStrong written and verbal communication skills\nProficient understanding of current data protection and privacy laws\nWorking Conditions & Physical Requirements:\nThe physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee is regularly required to:\nExperience prolonged sitting, some bending, stooping, and stretching.\nUse hand-eye coordination and manual dexterity sufficient to operate a keyboard, photocopier, telephone, calculator, and other office equipment is required.\nMinimum Qualifications:\nBachelor\u201a\u00c4\u00f4s degree preferably in Data or Computer Science, Engineering, Mathematics, Statistics, or other scientific field with 4 years of experience\nPreferred Qualifications:\nAdvanced degree and\/or certifications in data science, analytics, or computer science\nJoin us! FDB is advancing tomorrow\u201a\u00c4\u00f4s medicine, impassioning employees to chase the impossible and continually expand their potential. We are a company of emboldened goal seekers \u201a\u00c4\u00ec driven by an innate desire to better ourselves, our families, our workplace, our company, our community and the world at large.\nWe are an equal opportunity and affirmative action employer.\u201a\u00c4\u00d8 All qualified applicants will receive consideration without regard to race, color, national origin, sex, gender identity, sexual orientation, religion, disability, protected veteran status or any other characteristic protected by applicable federal, state or local law. If an accommodation to the application process is needed, please email FDBTHR@fujifilm.com or call 979-431-3500.\nTo all agencies: Please, no phone calls or emails to any employee of FUJIFILM about this requisition. All resumes submitted by search firms\/employment agencies to any employee at FUJIFILM via-email, the internet or in any form and\/or method will be deemed the sole property of FUJIFILM, unless such search firms\/employment agencies were engaged by FUJIFILM for this requisition and a valid agreement with FUJIFILM is in place. In the event a candidate who was submitted outside of the FUJIFILM agency engagement process is hired, no fee or payment of any kind will be paid.\nShow more\nShow less",
      "job_skills":"Python, SAS, Alteryx, SQL, MySQL, PostgreSQL, Tableau, Smartsheet, Power BI, Data analytics, Data collection, Data visualization, Data modeling, Data profiling, Data protection, Machine learning, Statistics, Mathematical models",
      "Category":"Backend Development"
  },
  {
      "job_title":"Azure Data Engineer",
      "company":"Extend Information Systems Inc.",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/azure-data-engineer-at-extend-information-systems-inc-3716008950",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title: Azure Data Engineer\nLocation: Houston, TX (Day 1 Onsite)\nDuration: Full Time\nExperience level : 7+ yrs\nTechnical Skills\nYou have a minimum of 4+ years' experience working with Azure Data tools (ADF,Data Catalog, event hub,IOT hub) etc\nYou have proficiency in PySpark ,Python and SQL\nExperience working with Databricks ,SQL End Point, Synapse\nKnowledge on Power BI and willingness to enhance PBI skill set.\nYou have already written code capable of efficiently handling large volumes of data across large numbers of tables, and brought this code into a controlled productive environment.\nKnowledge and experience in DevOps environments is a plus\nRoles & Responsibilities\nYou are strong on handling large and complex amounts of structured data, you have a track record of having delivered end-to-end data solutions in corporate environments.\nAs an all-rounder, you enjoy taking time to understand business requirement, articulate a data product solution and then roll up your sleeves and develop it into production grade.\nYou enjoy navigating ambiguity and working as part of a distributed team to solve business problems using data.\nYou are comfortable with agile development processes, with both scheduled and ad-hoc release cycles.\nGood English communication skills are a must, both spoken and written\nYou are comfortable working with some level of independence in a multinational environment\nYou are happiest solving concrete problems\nYou are able to lead a discussion with Business and understand requirements\nThanks & Regards\nAnoop Tiwari\nExtend Information Systems\nCell: - 571 - 386 - 2431\nEmail:\nAnoop@extendinfosys.com\nShow more\nShow less",
      "job_skills":"Azure Data tools, ADF, Data Catalog, Event hub, IOT hub, PySpark, Python, SQL, Databricks, SQL End Point, Synapse, Power BI, DevOps, Data solution, Data product solution, Agile development, English communication skills",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Advarra",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-advarra-3782082706",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Advarra provides integrated solutions that safeguard trial participants, empower clinical sites, ensure compliance, and optimize research performance. Connecting the clinical research ecosystem, Advarra delivers solutions through a site-centric approach that unifies and accelerates the drug development lifecycle, making clinical trials safer, smarter, and faster.\nGeneral Summary\nThis role supports the Data Science team as a Sr Data Engineer for enterprise Data Warehouse (DW) Platform. Will require deep expertise in Snowflake and writing complex data transformations to support Business and Product Analytics. Understanding of security measures provided by Snowflake to secure the data on the platform.\nPrincipal Duties & Responsibilities\nResponsible for security and administration of the Snowflake Data Platform.\nBuild data pipeline using Fivetran to ingest large volume of data from both internal applications and external data source.\nWrite data transformation for Enablement of BI\/ Analytics, Data Sciences, and external customers.\nConfigure Snowflake data security features to secure the data on the platform\nSupports MDM implementation plan and direction toward a single version of truth.\nCreate, follow, and ensure compliance with database security.\nProvide technical recommendations for reporting infrastructure project costing.\nDesign, maintain and deploy data sources for operational and strategic dashboards.\nEducation\nBachelor\u201a\u00c4\u00f4s degree or equivalent combination of education and related work experience.\nSnowflake certification preferred.\nExperience\n5 years of experience on Snowflake platform.\nExperience in writing data transformation with dbt platform.\nExperience in building connector with Fivetran platform.\nExperience with Sigma Computing platform is a plu.s\nExperience in writing test automation scripts.\nData Architecture & Data modeling experience in Clinical trials domain \/ Life Sciences.\nKnowledge of data management tools and process; Data governance tools is a plus.\nWorking experience with version control platforms, e.g. Github, and agile methodologies and supporting tools JIRA.\nKnowledge, Skills, Abilities\nUnderstanding of Snowflake Warehouses, reader accounts, SSO Setup, and data masking policies.\nGood understanding of Change Data Capture and Change Data Tracking.\nUnderstanding challenges of ingesting large volume data.\nAbility to writ complex data transformation logic using Advanced SQL query skills such as complex joins, sub-queries, grouping, aggregation, as well as stored procedures.\nProgramming languages, especially Python and Java.\nKnowledge of data modeling and transformation tools like dbt, Tableau data prep etc.\nExpert in data warehousing concepts, methodologies, and best practices.\nPosition requires a high level of responsibility regarding confidential information; must maintain confidentiality at all times.\nMust be comfortable independently evaluating a situation, exercising good judgment and discretion, and independently making a decision matter of significance.\nExcellent oral and written communication skills including the ability to speak in front of large groups.\nComfort working in a geographically distributed team-based environment.\nAbility to handle stress and interact with others in a professional manner.\nPhysical and Mental Requirements:\nSit or stand for extended periods of time at stationary workstation\nOccasionally, carry, raise, and lower objects of up to 10lbs\nLearn and comprehend basic instructions\nFocus and attention to tasks and responsibilities\nVerbal communication; listening and understanding, responding and speaking\n#mogul\nEEO Statement\nAdvarra provides equal employment opportunity to all individuals regardless of their race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, veteran, marital, or domestic partner status, citizenship, genetic information or any other status or characteristic covered by federal, state or local law. Further, the company takes affirmative action to ensure that applicants are employed, and employees are treated during employment without regard to any of these characteristics. Discrimination of any type will not be tolerated.\nEEO\/M\/F\/Disabled\/Vets\nShow more\nShow less",
      "job_skills":"Snowflake, Data Warehouse, dbt, Python, Java, Tableau data prep, Advanced SQL, Fivetran, Sigma Computing",
      "Category":"Backend Development"
  },
  {
      "job_title":"Business Data Analyst",
      "company":"SpecChem",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/business-data-analyst-at-specchem-3779856434",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"SpecChem, LLC supplies and services the concrete distributor network with quality construction chemicals that provide performance and value to the industry.\nWe are seeking an intelligent, energetic candidate for a full-time\nBusiness Data Analyst\nposition in our corporate headquarters located in\nKansas City, MO\n.\nThe ideal candidate for this position has outstanding analytical, problem-solving, and people skills, thinks innovatively, and constantly strives for excellence and improvement.\nResponsibilities\nGenerate, create, and issue reports regarding sales, finance, and operations.\nCreate dashboards, spreadsheets analysis, and presentations as requested.\nTroubleshoot data issues by validating different data sources.\nTrack and analyze reports to identify areas of improvement in business procedures.\nIdentify trends and variances in which positive changes can be made.\nServe as liaison between all departments to support desired result.\nBuild and maintain in-depth knowledge of distributor and manufacturer data files.\nDeliver dependable and complete work and verify accuracy to ensure usability by executives, cross-functional teams, and customers.\nAssist with project management, including capital expenditures and process improvements.\nProactively troubleshoots inconsistencies, errors, missing data and works quickly to make necessary corrections to provide timely support.\nTriage and resolve data issues from identification to resolution - investigate the cause, find solutions and routinely follow-up to ensure consistency.\nOther duties as dictated by business needs.\nRequirements\nBachelor's degree in Accounting, Finance, or Business\n1-3 year's relevant experience processing and organizing data.\nFluency in MS Excel (Pivot Tables, Macros, Data Sorting, etc.) required.\nProblem solving, critical-thinking, and organizational skills required.\nHighly detailed oriented with an ability to stay organized and manage a large workload.\nAbility to work in teams and independently.\nAbility to deal with ambiguity and demonstrates agility as business needs change.\nDemonstrated ability to learn new analytical tools and software.\nExcellent written and verbal communication skills.\nKnowledge\/Experience with R, Python, SQL, and Power BI a plus.\nKnowledge\/Experience of SAP a plus.\nKnowledge\/Experience with manufacturing a plus.\nAbility to pass a background check, pre-employment physical exam, and drug screen.\nAll applicants are considered for all positions without regard to race, religion, color, sex, gender, sexual orientation, military\/veteran status, genetic information, marital status, ethnicity, alienage or any other protected classification, in accordance with applicable federal, state, and local laws.\nShow more\nShow less",
      "job_skills":"MS Excel, Macros, Python, R, SQL, Power BI, SAP",
      "Category":"Backend Development"
  },
  {
      "job_title":"Business Data Analyst II",
      "company":"Simmons Bank",
      "job_location":"Columbia, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/business-data-analyst-ii-at-simmons-bank-3777030290",
      "search_city":"Missouri",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"It's fun to work in a company where people truly BELIEVE in what they're doing!\nWe're committed to bringing passion and customer focus to the business.\nThe Business Data Analyst II position is a member of the Customer Service Support Team that supports reporting needs for the Customer Contact Center and ATM Channel. The role is responsible for processing and analyzing data, as needed, data from API, reports, documents, and other processes. The analyst will follow best practices in using source control and ensure data integrity throughout the process.\nThe Business Data Analyst will need the ability to understand various data sources and their contextual meaning as needed to support analysis and determine which data is needed for various requests.\nEssential Duties And Responsibilities\nPerforming analysis using various tools and techniques as needed\nExtracting data from various systems and sources into usable data\nServe as a resource in determining the approach to be utilized in implementing new analysis and technology\nEstimate project complexity and timeframes\nIdentify and escalate issues as they are identified\nEnsures all data management analysis and reporting activities are documented and maintained.\nResponsible for providing back up to other Customer Service Support Analysts\nEnsures all departmental documents and activities are performed in compliance with applicable laws, regulations, policies, and procedures as applicable to this position, including completion of required compliance training.\nPerforms other duties and responsibilities as assigned.\nQualifications\nTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and\/or ability required.\nSkills\nAbility to ingest data from various formats and perform complex analysis using different tools appropriate for the task\nAbility to read and comprehend simple instructions, short correspondence, and memos\nAbility to write complex reports, simple-to-business correspondence, and procedures\nAbility to effectively speak, respond to questions, and present information to the following: one-on-one\/small groups, employees, managers, and top management\nAbility to apply critical thinking, using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems.\nAbility to work independently as well as collaboratively with a customer-service orientation.\nAbility to read and interpret documents such as procedures manuals, general business correspondence and\/or journals or government regulations.\nAbility to maintain effective interpersonal relationships with management and team members.\nAbility to read and interpret documents such as procedure manuals, general business correspondence and\/or journals or government regulations\nEducation and\/or Experience\nHigh school diploma or its equivalent is required, and\n4 Years of experience in a professional setting, preferably at an institution of higher education, and\nExperience in data analytics and reporting\nComputer Skills\nMS Office programs\nMicrosoft Excel\nMicrosoft Power BI\nPython is a plus\nCertificates, Licenses, Registrations\nOther Qualifications (including physical requirements)\nStrong oral and written communication skills\nStrong organizational, problem solving, and planning skills with the ability to set priorities and meet deadlines\nAbility and desire to learn and use new software applications\nOther\nPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Activities, duties and responsibilities may change at any time with or without notice.\nEqual Employment Opportunity Information: Simmons First National Corporation and its subsidiaries are committed to a policy of equal employment with respect to a person's race, color, religion, sex, ancestry, sexual orientation, gender identity, national origin, covered veterans, military status, physical or mental disability or any other legally protected classifications. Simmons First National Corporation and its subsidiaries are committed to Affirmative Action Programs consisting of results-oriented procedures to ensure equal employment opportunities. These programs require positive action in lieu of neutral non-discrimination and merit hiring\/performance policies.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Extraction, Data Interpretation, Data Management, Data Reporting, Microsoft Office, Microsoft Excel, Microsoft Power BI, Python, Source Control, Project Management, Communication, Problem Solving, Planning, Time Management, Critical Thinking, Teamwork, Customer Service, SQL",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Analyst\/Developer",
      "company":"Workcog Inc",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-developer-at-workcog-inc-3747709670",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Healthcare Client\n100% Remote | CST or EST Hours\n12+ Month Contract\nMUST Have\n10+ years\u201a\u00c4\u00f4 experience\nExperience with Identity and Access Management in a large organization.\nWell versed with MySQL database queries and creation of database views.\nDevelopment experience with REST, SOAP, LDAP, MySQL\nDevelopment experience with Java\nSelf-starter who is excellent with managing external relationships and communications (important: following up) with technical contacts\nNice To Have:\nIAM Tools\/Systems:\nRadiant Logic HDAP (High-Availability Directory Access Protocol)\nICS (Industrial Control System)\nFID (Federated Identity)... Formally, known as VDS (Virtual Desk Service).\nShow more\nShow less",
      "job_skills":"Identity and Access Management, MySQL, REST, SOAP, LDAP, Java, Radiant Logic HDAP, ICS, FID",
      "Category":"Backend Development"
  },
  {
      "job_title":"Analyst II, Credit",
      "company":"Affirm",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/analyst-ii-credit-at-affirm-3777169714",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Affirm is reinventing credit to make it more honest and friendly, giving consumers the flexibility to buy now and pay later without any hidden fees or compounding interest.\nThe Credit team works cross-functionally with Machine Learning, Product, Engineering, Capital Markets, and Commercial teams to responsibly manage the risk profile of the business. We\u201a\u00c4\u00f4re looking for a thoughtful, driven individual who wants to learn, grow, and solve hard problems.\nThe team\u201a\u00c4\u00f4s mandate is to enable sustainable growth while closely managing the profitability and resilience of our portfolio. As Affirm continues on an exciting growth trajectory, thinking through credit strategies for new initiatives and products, shaping ongoing testing and experimentation, and being ready for navigating through any exogenous changes will be important problems to tackle.\nThis role requires extensive use of data analytics to derive insights and develop credit strategies. It also requires a lot of cross-functional partnership. Working with the Machine Learning and Engineering team to develop new underwriting models, with the Product teams to develop new products and features, with the Merchant Pricing team to value different merchants, with the Finance team to help facilitate discussions with debt and equity investors are some parts of the role.\nCome join us in our mission to change consumer finance through better data and technology, lower costs, and increased transparency while providing the best customer experience!\nWhat You'll Do\nLeverage experimentation and advanced data analytics to derive insights. Dissect complex data and translate it into actionable strategies to help optimize credit underwriting\nDetermine and optimize user limit assignments, ensuring they are set optimally to balance risk and growth, driving healthy user engagement\nPlay a pivotal role in optimizing the portfolio, managing risk and ensuring the health and profitability of credit offerings\nDesign and implement inclusive credit strategies by leveraging alternative data, expanding credit to more users while managing the risk strategically\nPartner with Machine Learning and Engineering teams on building effective credit risk capabilities\nWhat we look for\n2-4 years of work experience as a data analyst\/data scientist (consumer credit risk management strongly preferred but not required)\nCurious and passionate to learn new things and think outside the box\nExtensive experience with SQL and Python, or other scripting languages. Experience with Spark is a plus\nAbility to collaborate and influence across different teams in the organization\nPay Grade\n- USA29\nEmployees new to Affirm or promoted into a new role, typically begin in the min to mid range.\nUSA base pay range (CA, WA, NY, NJ, CT) per year:\nMin: $138,800\nMid: $173,500\nMax: $208,200\nUSA base pay range (all other U.S. states) per year:\nMin: $124,900\nMid: $156,100\nMax: $187,300\nAffirm is proud to be a remote-first company! The majority of our roles are remote and you can work almost anywhere within the country of employment. Affirmers in proximal roles have the flexibility to work remotely, but will occasionally be required to work out of their assigned Affirm office. A limited number of roles remain office-based due to the nature of their job responsibilities.\nBenefits\nWe\u201a\u00c4\u00f4re extremely proud to offer competitive benefits that are anchored to our core value of people come first. Some key highlights of our benefits package include:\nHealth care coverage - Affirm covers all premiums for all levels of coverage for you and your dependents\nFlexible Spending Wallets - generous stipends for spending on Technology, Food, various Lifestyle needs, and family forming expenses\nTime off - competitive vacation and holiday schedules allowing you to take time off to rest and recharge\nESPP - An employee stock purchase plan enabling you to buy shares of Affirm at a discount\nWe believe It\u201a\u00c4\u00f4s On Us to provide an inclusive interview experience for all, including people with disabilities. We are happy to provide reasonable accommodations to candidates in need of individualized support during the hiring process.\nBy clicking \"Submit Application,\" you acknowledge that you have read the Affirm Employment Privacy Policy for applicants within the United States, the EU Employee Notice Regarding Use of Personal Data (Poland) for applicants applying from Poland, the EU Employee Notice Regarding Use of Personal Data (Spain) for applicants applying from Spain, or the Affirm U.K. Limited Employee Notice Regarding Use of Personal Data for applicants applying from the United Kingdom, and hereby freely and unambiguously give informed consent to the collection, processing, use, and storage of your personal information as described therein.\nShow more\nShow less",
      "job_skills":"Data analytics, Data science, SQL, Python, Spark, Machine Learning, Credit risk management, Credit strategies, Underwriting models, Portfolio optimization, Risk management, Alternative data, Collaboration, Influence",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Analyst, CRM & Loyalty",
      "company":"Pizza Hut",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-crm-loyalty-at-pizza-hut-3765993100",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nAs a CRM \/ Customer Engagement and Retention (CER) Data Analyst, you\u201a\u00c4\u00f4ll closely support the CER team in making data-driven decisions about marketing campaign execution. This position will own critical analyses and integration projects from beginning to end, including opportunity identification, problem scoping, analysis framing \/ execution, and synthesizing results to project stakeholders as well as internal leadership.\nAnalyze CRM & Loyalty campaigns to provide actionable recommendations to the CER team\nIdentify areas of opportunity based on Loyalty\/CRM analytics, customer segmentations, deployment tactics and audience targeting\nAssist in creating test and learn plans to facilitate tactical optimization and strategic changes to our programs to increase customer annual value (CAV)\nPartner closely with data science and loyalty vendor partners to monitor critical KPI\u201a\u00c4\u00f4s\nEDUCATION\nBachelor\u201a\u00c4\u00f4s degree in computer science, marketing, databases, or a related field with 4+ years of experience working in analytics positions in performance-driven marketing, e-commerce, or consulting organizations.\nMinimum Requirements And Experience\nMaster Level of Experience using SQL; able to easily query complex data and construct data models as needed and experience working with relational databases (Snowflake), query authoring (SQL) as well as working familiarity with a variety of databases\nComfortable with multi-faceted analytics projects, integrating data from multiple sources, and synthesizing & presenting actionable insights from a variety of data-points\nWorking knowledge of a CDP (Treasure Data, Twilio, Bloomreach, Convertlab, Salesforce Data Cloud, etc.)\nWorking knowledge of at least one commonly applied BI tool (Tableau, Power BI, Domo, etc.) Digital Marketing -tools (e.g. Braze, Punchh, etc.) and Project Management tools (e.g. Atlassian, Jira, etc.)\nExperience with data management and manipulation tools (Python, Scala, or R) and a desire to learn more\nExcellent communication skills with a record of successfully advocating to turn insights into action, as well as the ability to synthesize quantitative results to determine implications and make actionable strategic recommendations\nSalary Range: $108,700\u00ac\u2260\u00ac\u2260 to $136,300 annually + bonus eligibility.\nThis is the expected salary range for this position. Ultimately, in determining pay, we'll consider the successful candidate\u201a\u00c4\u00f4s location, experience, and other job-related factors.\nBenefits: Employees (and their eligible family members) may enroll in the following types of insurance coverage: medical, dental, vision, legal, and accidental death and dismemberment, as well as FSA\/HSA (depending on enrolled medical plan). Yum! also provides short-term disability, long-term disability, and life insurance. Employees may enroll in our 401(k) plan. Yum! provides 4 weeks of vacation, paid sick leave, 10 paid holidays, a floating day off and 2 paid days for volunteer time each calendar year. To learn more about working at Yum! - Click here .\nAt Yum!, one of our core values is to Believe in ALL People. This means seeing the value in everyone and unlocking their full potential to be their best self. YUM! Brands, Inc. (including its subsidiaries Yum Restaurant Services Group, LLC (\u201a\u00c4\u00faYRSG\u201a\u00c4\u00f9) and Yum Connect, LLC (\u201a\u00c4\u00faYum Digital and Technology\u201a\u00c4\u00f9)(collectively, \u201a\u00c4\u00faYum\u201a\u00c4\u00f9) is proud to be an equal opportunity employer and is committed to equity, inclusion, and belonging for all dimensions of diversity. We do not discriminate based on race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other protected characteristic. Yum! is committed to working with and providing reasonable accommodation to applicants with disabilities or special needs.\nUS Job Seekers\/Employees -\nClick here\nto view the \u201a\u00c4\u00fa\nKnow Your Rights\n\u201a\u00c4\u00f9 poster and supplement and the Pay Transparency Policy Statement.\nAbout Us\nWho We Are\nFounded in 1958, Pizza Hut - a subsidiary of Yum! Brands, Inc. - now operates more than 18,000 restaurants in more than 100 countries. Pizza Hut is leading the way in providing customers with great experiences, innovating with technology and new products, as well as delivering exceptional service.\nOur People & Culture\nWe're looking for people who LOVE pizza and thrive in a fun, past paced, and customer-centric environment. At our corporate campuses, Pizza Hut has created the perfect place for you to grow your career. Every day, you\u201a\u00c4\u00f4ll work to support our franchisees and teams across the U.S., continuously challenging yourself to feed more possibilities. In return, we\u201a\u00c4\u00f4ll provide professional development and career growth opportunities so that you can become your best and achieve your goals. And we\u201a\u00c4\u00f4ll sweeten the deal by immersing you in our world-class recognition culture and providing a robust array of benefits, some highlights include:\n4 weeks PTO, plus standard holidays and time off to volunteer\nGenerous parental leave (16 weeks for moms, 6 weeks for dads)\n401(k) with 6% match, vested immediately\nOn-site daycare\n24\/7 fitness center with laundry services\nHalf-day Fridays, year round\nGiving Back\nAs a global company, Pizza Hut aims to make the world better by acting responsibly with respect to food, planet and people. Whether it\u201a\u00c4\u00f4s donating food through the Harvest Program or supporting literacy with the Pizza Hut BOOK IT! Program \u201a\u00c4\u00ec the company, our franchisees and our team members are committed to improving the communities we serve.\nPizza Hut is an equal opportunity workplace and committed to fostering an inclusive, diverse culture . All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, sexual orientation, or gender identity), national origin, age, disability and genetic information (including family medical history).\nShow more\nShow less",
      "job_skills":"SQL, Relational databases, Snowflake, Tableau, Power BI, Domo, Braze, Punchh, Atlassian, Jira, Python, Scala, R, Data management, Data manipulation, BI tools, Multifaceted analytics, Customer segmentation, Deployment tactics, Audience targeting, Test and learn plans, Tactical optimization, Strategic changes, KPI monitoring, Customer annual value (CAV), Data science, Loyalty vendor partners",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst (Bangkok Based, relocation provided)",
      "company":"Agoda",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-bangkok-based-relocation-provided-at-agoda-3750111635",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"About Agoda\nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u201a\u00c4\u00d8enhancing the ability for our customers to experience the world.\nGet to Know our\nTeam:\nThe Performance Marketing Team of Agoda is a world leader in online marketing. This department is highly data-driven and focused on developing at-scale marketing programs that improve the lifetime value of Agoda customers through measurable marketing programs and channels. The team is a blend of the best analysts, marketing strategists, and data scientists in the world. The marketing leadership at Agoda have deep experience in data science, product, strategy, and other marketing fields and have built an organization that thrives on data, creative ideas, and technology. The Performance Marketing Team also fosters a great learning environment. You will be able to learn and grow by working closely with experts from a variety of backgrounds from all over the world.\nIn this Role, you\u201a\u00c4\u00f4ll get\nto:\nSearch: Experiment with text ads, bidding, and campaign structures on Google, Bing, Baidu, Naver, and other search engines. Adapt to new product features and roll out changes from successful tests\nDisplay: Test, analyze, and optimize campaigns on Facebook, Twitter, Instagram, and others\nModeling: Analyze the vast amounts of data generated by experiments, develop models we can use for optimization, and build dashboards for account managers\nWhat you\u201a\u00c4\u00f4ll Need to\nSucceed:\nBachelor\u201a\u00c4\u00f4s Degree or higher from top university in a quantitative subject (computer science, mathematics, engineering, statistics or science)\nAbility to communicate fluently in English\nExposure to one or more data analysis packages or databases, e.g., SAS, R, SPSS, Python, VBA, SQL, Tableau\nGood numerical reasoning skills\nProficiency in Excel\nIntellectual curiosity and analytical skills\nIt\u201a\u00c4\u00f4s Great if you\nHave:\nExperience in digital marketing\nAcademic research experience\n#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz  #baku #minsk #brussels #antwerp #ghent #charleroi  #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra  #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester  #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner\nEqual Opportunity Employer\nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u201a\u00c4\u00f4s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\nShow more\nShow less",
      "job_skills":"SQL, Python, R, SAS, SPSS, VBA, Tableau, Data analysis, Data mining, Data science, Data visualization, Databases, Business analysis, Business intelligence (BI), Microsoft SQL Server, Machine learning, Statistics, Microsoft Power BI, Java, Finance, Data representation, Analytical skills, Artificial intelligence (AI), Ecommerce, Information technology, Google, Facebook, Ctrip, Trip.com, MakeMyTrip, Grab, Amazon, Pandas (software)",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Analyst (Product Team) (Bangkok Based, relocation provided)",
      "company":"Agoda",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-product-team-bangkok-based-relocation-provided-at-agoda-3750113018",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"About Agoda\nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u201a\u00c4\u00d8enhancing the ability for our customers to experience the world.\nGet to Know our Team:\nIn Product, ideas come alive. The world is moving fast so our culture empowers ownership and minimal bureaucracy. That\u201a\u00c4\u00f4s the environment that enables you to do what you think is right \u201a\u00c4\u00ec and quickly. Product Operations is a large, multicultural team of diversely talented individuals that serve as the curators of Agoda\u201a\u00c4\u00f4s content. We manage all the content our customers and partners see on each of our products. As a part of our team,\u201a\u00c4\u00d8you will\u201a\u00c4\u00d8take ownership\u201a\u00c4\u00d8of\u201a\u00c4\u00d8processes that are critical to multiple other teams across the business.\u201a\u00c4\u00d8We are\u201a\u00c4\u00d8driving\u201a\u00c4\u00d8property-level\u201a\u00c4\u00d8content to map inventories\u201a\u00c4\u00d8from\u201a\u00c4\u00d83 rd \u201a\u00c4\u00d8party supplies\u201a\u00c4\u00d8which\u201a\u00c4\u00d8will enable our reach to span the globe. Content Operations is also keen on self-improvement and innovation. We run our own structured data and analyze\u201a\u00c4\u00d8it\u201a\u00c4\u00d8to make impactful decisions. With the support of state-of-the-art technology and an enriching work environment, we strengthen the bottom line and drive new business for Agoda.\nThe Opportunity:\nAs an Analyst\/Senior Analyst, you will report directly to either the Senior Manager or Associate Director within the Product Department and this will be an individual contributor role. You will be responsible and fully empowered to work with the partners on the ground. You will be supported by a team within the Product department and work closely with other Team members within Agoda. You will be instrumental in ensuring there is consistency in data being used for reporting, identifying value-added data to help the business grow as well as using data to make strategic business decisions. You will be expected to dig into data to provide business insights, guide decision-making and offer valuable inputs to further grow our business model.\nIn this Role, you\u201a\u00c4\u00f4ll get to\n:\nTranslate internal briefs into analytical projects (to include refining the initial brief and asking the \u201a\u00c4\u00f2right questions\u201a\u00c4\u00f4, working through potential hypotheses and storyboarding the output)\nUse and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders\nConducted an analysis of customer behavior and their path through the platform, guaranteeing that the conversion rates for each front-end page met the established benchmarks and continually pinpointed opportunities for enhancement\nPartnered with the Product Design and User Research team to generate fresh data-driven projects, one of which involved the development of a Dashboard designed for more efficient monitoring of user behavior and the measurement of novel business metrics\nDrive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply\nIdentify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence\nAutomate manual operational processes and present back on time savings gained through modernization of business operations\nWhat you\u201a\u00c4\u00f4ll Need to Succeed:\nBachelor\u201a\u00c4\u00f4s degree or higher in Mathematics, Business, Economics, Data Science, Information Technology or similar field\nBachelor\u201a\u00c4\u00f4s Degree or higher in computer sciences, engineering, mathematics, statistics, data science or a related degree program. Masters degree preferred\nAdvanced domain of data analysis and data visualization tools and software such as Excel, SQL, Tableau, Python or similar\nAnalytical mindset, with proven track record in using data to measure performance and make decisions\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written), with proven ability to convey complex messages clearly and with conviction\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\n#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz  #baku #minsk #brussels #antwerp #ghent #charleroi  #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra  #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester  #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server #productanalyst #product\nEqual Opportunity Employer\nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u201a\u00c4\u00f4s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\nShow more\nShow less",
      "job_skills":"Excel, SQL, Tableau, Python, Data representation, Data analysis, Data analytics, Data mining, Data science, R, Analytical skills, Data visualization, Databases, Business analysis, Business intelligence (BI), Microsoft SQL Server",
      "Category":"Backend Development"
  },
  {
      "job_title":"Digital Analyst",
      "company":"Brunel",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/digital-analyst-at-brunel-3782220342",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Brunel is currently seeking a\nDigital Analyst\nto work for a major oil & gas company, for a 3 months contract with the possibility of extension. The successful candidate will support business in\nHouston, TX.\nQualifications:\n(Educational Professional) \u00ac\u00df Bachelor\u201a\u00c4\u00f4s degree or relevant in Engineering, Computer Science, General Business or related field experience in lieu of degree\nPowerBI\n(Required)\nAdvanced skills with MS\nExcel\nsoftware (Required)\nMinimum of\n3 years of experience in software development, automation,\nor related field\nExperience in developing automation solutions using RPA, AI, and ML technologies\nProficient in programming languages such as Python, Java, or C#\nExperience in developing automation workflows and scripts using RPA tools around Microsoft Power Platform environment\nStrong understanding of data structures, algorithms, and software designprinciples\nAbility to work independently and as part of a team\nUnderstand Subsea business\n(Required)\nAnalytical skills\n(Required)\nKnowledge of Software per business requirements:\nVBA, PowerQuery, SQL\n(Required)\nWhat We Offer\nWhy apply through Brunel? Finding the next step in your career can be a fulltime job in itself. We manage the process for you: from submitting your resume to coordinating interviews to extending offers and assisting with on-boarding. We\u201a\u00c4\u00f4ll get you going while you get on with the job.\nAbout Us\nBrunel has a reputation for working with some of the best in the business. That\u201a\u00c4\u00f4s what we continually strive for. Over 45 years, we\u201a\u00c4\u00f4ve created a global network of interesting clients and talented individuals working together through a vast array of services.\nShow more\nShow less",
      "job_skills":"Digital Analyst, PowerBI, MS Excel, RPA, AI, ML, Python, Java, C#, Microsoft Power Platform, Data structures, Algorithms, Software design principles, VBA, PowerQuery, SQL, Subsea business, Analytical skills",
      "Category":"Backend Development"
  },
  {
      "job_title":"Urgent Requirement -- Data Analyst-- Remote",
      "company":"Jade Business Services (JBS)",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/urgent-requirement-data-analyst-remote-at-jade-business-services-jbs-3655955679",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description\nJob Title: Digital Data Analyst\nJob Type: Contract- W2\nLocation: Remote\nJob Summary\nWe are seeking a Digital Data Analyst to lead the reporting and analysis of digital data across a suite of consumer properties (prospect website, online account area, mobile apps). The candidate will be responsible for analyzing and reporting on the behavior of customers on all digital properties and working with teams across the department to provide data driven solutions to optimize and align experiences to our digital strategy.\nEssential Duties\/Responsibilities\nCreate and Analyze Digital Analytics reporting from Google and Adobe Analytics\nWork with our experience team to identify data driven opportunities for optimization and improvement\nCreate robust analysis of optimization tests and enhancements\nConglomerate data from a variety of sources (Adobe Analytics, Behavioral Analytics Tool, Offline Data) into easy to comprehend reporting\/dashboards\nReport and communicate digital campaigns results\nSupport ad-hoc requests for insights\nWork with external teams including technical partners to ensure data integrity and enhance available information\nManage multiple and concurrent projects, and initiatives, keeping them on schedule and within scope\nAnalyze, document, and communicate results and data-driven recommendations of all initiatives and A\/B\/N tests to stakeholders regularly\nModel and identify trends within the digital experience\nCollaborate with Digital Experience Team, Designers, Developers, Content\/SEO Team and Product Owners to provide data, insights and reporting needed to successfully execute digital strategy\nWorking Conditions\nRemote work position\nSome overtime required as special projects arise\nTravel N\/A\nMinimum Requirements\n2+ years of relevant work experience\nBachelor's Degree in Statistics, Mathematics, Economics, Business Intelligence or similar degree preferred\nPrevious experience with Digital Ecommerce Analysis\nProficiency With\nDigital Analytics (i.e. Google Analytics, Adobe Analytics, mobile app analytics)\nR, Python, or similar language\nData Analysis\nFamiliarity with A\/B\/n and Multi-Variate Testing\nStrong analytical, organizational and project management skills with excellent verbal and written ability\nProficiency with MS Office\nPreferred Qualifications\nEnergy experience preferred, but not required\nFamiliarity with digital experience and optimization\nAdditional Details\nDoes position require driving? : No\nWill this position need NERC or ERCOT access? : No\nShow more\nShow less",
      "job_skills":"Digital Analytics, Google Analytics, Adobe Analytics, R, Python, A\/B Testing, MultiVariate Testing, Data Analysis, Data Visualization, Reporting, Communication, Project Management, MS Office",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Analyst (Houston, TX)",
      "company":"Love's Travel Stops",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-houston-tx-at-love-s-travel-stops-3786435846",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Req ID:\n427217\nPOSITION OVERVIEW:\nThe Sr Data Analyst is a dynamic member of a software development team servicing Musket Corporation, a trading, supply and logistics company and integral part of the Love\u201a\u00c4\u00f4s Family of Companies. This individual serves as a conduit between the business and development team, serving as the functional subject matter expert for the businesses supported, communicating business needs, and collaborating closely with cross-functional teams to build out tools that help optimize trading activity. The ideal candidate is ambitious and energetic with a passion for technology, development, and turning data into a competitive advantage.\nREQUIREMENTS:\nFunction as a key contributor to a software development team\nFundamental understanding and some experience building data integrations\nAbility to analyze data sets to determine relevance and identify anomalies\nExperience working with ETL\/ELT pipelines, including data acquisition, transformation\/cleansing, and loading into an enterprise data warehouse\nPossess excellent interpersonal and strong communication skills\nCommunicate effectively, both verbally and in writing, exhibit strong listening and feedback skills\nProven ability to thrive\/be successful in a fast-paced corporate environment\nTrack record of delivering on deadlines\nExcellent analytical skills and close attention to detail\nAbility to easily capture business requirements from the internal customer and communicate those needs to project team members including developers, project managers, IT staff, and management\nAbility to quickly understand and explain complicated processes clearly\nAbility to quickly analyze and identify more efficient workflows\/processes\nAbility to serve as a change agent in the organization\nMAJOR RESPONSIBILITIES:\nCreate efficient processes for gathering, organizing, and cleaning appropriate data for analysis\nUse data analysis to understand its value and extract meaningful insights\nDevelop models that help identify potential trading opportunities and market trends\nCreate user-friendly tools to analyze real-time data, simplifying complex mathematical concepts\nCollaborate with diverse teams, offering insights without overwhelming technical jargon\nApply understanding of data imports\/exports and common software concepts to facilitate discussions\nDocument business processes in an understandable manner to enhance team efficiency\nAct as a bridge between technical aspects and user needs, ensuring system functionality aligns with business goals\nProvide user support, resolving issues promptly without delving into intricate technicalities\nRepresent the team during Change Management discussions, presenting changes without overwhelming technical details\nCommunicate updates clearly to users, including essential information in release notes and outage notices\nDevelop user-friendly guides, making complex system processes accessible to all team members\nConduct training sessions, focusing on practical functionality without unnecessary technical complexities\nEDUCATION AND EXPERIENCE:\n5+ years working in a software development team preferred\n5-7+ years developing, maintaining and supporting relevant data solutions\nBachelor\u201a\u00c4\u00f4s degree in a related field (e.g., Mathematics, Statistics, Finance, Computer Science, Management Information Systems) with a focus on data analysis.\nExperience using applied mathematics to build analytical models, including linear regression and time-series analysis, as demonstrated in a working environment or collegiate project(s)\nExperience with Reporting Tools \u201a\u00c4\u00ec PowerBI (required), Tableau, SSRS or similar technology\nExperience with Python, R, SQL, or similar a plus\nExperience with the software development lifecycle (SDLC), waterfall, Agile, Kanban\nExperience working in project management applications such as Microsoft Project, Azure DevOps, JIRA, or similar\nExperience with Salesforce, ServiceNow, Zendesk or similar\nExperience in energy supply chain, specifically as it pertains to the movement of commodities such as oil, natural gas, refined products a plus\nPHYSICAL REQUIREMENTS:\nAbility to engage in repetitive motions, including movements of the hands, wrists, or fingers\nAbility to sit for prolonged periods\nAbility to speak, including expressing oneself or exchanging information with others\nAbility to hear, including perceiving the nature of sounds at normal speaking levels with or without correction\nAbility to see and distinguish shapes with or without corrective eyewear\nAbility to receive detailed information through oral communication and to make discriminations in sound\nMay be required to lift objects less than 25 pounds, occasionally\nJob Function(s):\nCorporate\nLove\u201a\u00c4\u00f4s Travel Stops & Country Stores is the industry-leading travel stop network in the United States. For more than 55 years, we\u201a\u00c4\u00f4ve provided customers with highway hospitality and \u201a\u00c4\u00faClean Places, Friendly Faces.\u201a\u00c4\u00f9 We\u201a\u00c4\u00f4re passionate about serving drivers with clean, modern facilities stocked with fuel, food and supplies. We offer meals from popular restaurant chains, trucking supplies, showers and everything needed to get back on the road quickly. The Love\u201a\u00c4\u00f4s Family of Companies includes:\nGemini Motor Transport, one of the industry\u201a\u00c4\u00f4s safest trucking fleets\nSpeedco, the light mechanical and trucking service specialists\nMusket, a rapidly growing, Houston-based commodities supplier and trader\nTrillium, a Houston-based alternative fuels expert\nShow more\nShow less",
      "job_skills":"Data integration, Data Analysis, ETL\/ELT pipelines, Verbal Communication, Written Communication, Feedback skills, Analytical skills, Attention to detail, Data imports\/exports, Software concepts, Business process documentation, Change Management, Release notes, User guides, Training, PowerBI, Tableau, SSRS, Python, R, SQL, SDLC, Waterfall, Agile, Kanban, Microsoft Project, Azure DevOps, JIRA, Salesforce, ServiceNow, Zendesk",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Analyst Fundamentals Analysis",
      "company":"Optimus - People. Solutions. Delivered.",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-fundamentals-analysis-at-optimus-people-solutions-delivered-3709608255",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"A key Optimus client is looking to hire a\nSenior Fundamental Analysis Analyst.\nKey activities include:\nDeveloping or improving models to forecast supply and demand in key markets\nDeveloping or improving models to forecast commodity prices\nAnalysis of environmental regulations and resulting impact on markets\nFundamental research\nCreating presentation materials\nPresenting analysis results to members of the senior management team\nRelevant Skills and Experience:\nBachelors or advanced economics, mathematics, business, engineering, or other quantitative\ndiscipline with at least three years of experience in energy sector is required. Knowledge base\nshould cover a subset of the following topics:\nPower, natural gas, and emissions markets\nFamiliarity with research tools such as ABB-Ventyx Energy Velocity, SNL, and Bloomberg\nFamiliarity with modeling languages such as Python, R, or MatLab\nFamiliarity with Power plant operations and technology (conventional and renewable)\nStrong Microsoft Power Point skills\nStrong verbal and written communication skills.\nWorks within broad guidelines; able to work independently with minimal supervision.\nTeam player who is used to diving into issues, brainstorming solutions, and learning new methods and tools to address; results oriented.\nShow more\nShow less",
      "job_skills":"Fundamental analysis, Energy sector, Economics, Mathematics, Engineering, Quantitative discipline, Power markets, Natural gas markets, Emissions markets, Research tools, Python, R, MATLAB, Power plant operations, Power Point, Communication skills, Independent work, Teamwork, Problem solving, Learning new methods and tools",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst I",
      "company":"WinMax",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-i-at-winmax-3724252453",
      "search_city":"Hollywood",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Title:Data Analyst I, Req# 26095179\nLocation:Austin,Tx(Onsite)\nContract:12+ Month\nJob Description\nAMR DC Operations is in search of someone who possesses an adamant sense of drive and organizational aptitude to support DC planning and analytics. This individual will have the opportunity to work directly with and influence decision making with the distribution centers that service client\u201a\u00c4\u00f4s customers in North America.\nResponsibilities\nServe as a key intermediary between internal groups and 3PL providers for forecast and capacity metrics and files\nBuild and maintain headcount\/labor trackers for distribution centers\nUpdate leadership and key stakeholders weekly on headcount tracking to plan and capacity attainment by route to market and DC\nSupport ad-hoc reporting metrics through data analysis\nImprove process documentation\nRequired Skills\nVery savvy in Excel (macros, VBA, etc.)\nAbility to communicate clearly and concisely with Senior Leadership\nAbility to balance competing priorities and manage change\nBusiness analytics background preferred\nPositive attitude in fast paced, short timeline work environment\nAbility to work overtime and weekends as needed\nHistory of consistent performance & attendance at previous employers\nNice To Have\nWorking knowledge of SAP\nTableau experience\nAbility to code in SQL, R, Python, etc.\nEducation\nBS\/BA degree required\nShow more\nShow less",
      "job_skills":"Excel, VBA, SAP, Tableau, SQL, R, Python, Business analytics, Communication, Teamwork, Time management, Problemsolving, Data analysis, Reporting",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst",
      "company":"System Soft Technologies",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-system-soft-technologies-3782001516",
      "search_city":"Hollywood",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"System Soft is a seeking a Data Analyst for a long term contract with our client in Fort Worth, TX. The role will be onsite for the 2 months and then have the possibility for a hybrid schedule after based on performance.\n*You will need to provide work examples in order to be considered*\nOur client is seeking a strong background in analytics, with proven expertise in statistical\nanalysis, data modeling, and predictive analytics.\nKey skills:\n1. proficiency in programming languages such as, R, or Python.\n2. extensive knowledge of working with visualization tools like Power BI.\n3. solid understanding of machine learning techniques and big technologies.\n4. Excellent analytical skills\n5. attention to detail\n6. the ability to derive meaningful insights from complex sets.\n7. Strong communication skills for translating technical findings into clear, actionable business insights.\n8. adept at managing multiple projects simultaneously\n9. demonstrating both independent-solving abilities and teamwork skills.\nRequirements:\nData Visualization: Transform raw into visually appealing and easily understandable reports and dashboards. Ability to create a variety of visualizations, including charts, graphs, and maps.\nData Integration: Integrate with a vast array of sources, including-based and on-premises\ndata sources, Excel spreadsheets, and big.\nReal-time Analytics: Create real-time dashboard updates, allowing departments to monitor their operations as events unfold.\nAdvanced Analytics: Perform advanced analytics such as predictive modeling and machine learning, providing deeper insights into.\nAdvanced Knowledge of Excel\nShow more\nShow less",
      "job_skills":"R, Python, Power BI, Machine Learning, Big Data, Data Visualization, Data Integration, Realtime Analytics, Advanced Analytics, Excel",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst\/Report Writer :: Austin , TX [ Hybrid 2 days week ]",
      "company":"TekIntegral",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-report-writer-austin-tx-hybrid-2-days-week-at-tekintegral-3681009812",
      "search_city":"San Juan Capistrano",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Hi ,\nHope you are doing great.\nPlease find the requirement below, if you are comfortable send me your updated resume on my mail\nrshrivastava@tekintegral.com\nPLEASE DISREGARD THIS EMAIL IF YOU FEEL YOU RECEIVED IT IN ERROR OR ARE NOT LOOKING FOR A NEW OPPORTUNITY. YOUR RESUME HAS BEEN IDENTIFIED IN OUR DATABASE AS A POTENTIAL FIT FOR AN OPENING WITH ONE OF OUR CLIENTS***\nTitle: Data Analyst\/Report Writer\nDuration: 12 months\nLocation: Austin, TX 2 days a week\nMode of Interview: Video\nData Analyst\/Report Writer resource with our public sector client located in Austin, TX.\n*This is a hybrid role, where this resource will work 2 days per week onsite, at the discretion of the client manager.\nRole: Data Analyst\/Report Writer\nDescription\nThis resource will perform complex (Journey-level) data analysis and data research work.\nKey Activities\/Responsibilities\nWork involves conducting detailed analysis of and extensive research on data, providing results, and monitoring and implementing data quality.\nDevelop and implement customer-centric metrics and reporting.\nSupport performance, quality, and improvement efforts to help streamline processes through data analysis and visualization.\nManage the analysis of data and embrace evaluative thinking that includes posing thoughtful questions about data, getting feedback from key stakeholders, and using data to support staff, programs, and operations.\nMay provide guidance to others.\nWorks under limited supervision, with moderate latitude for the use of initiative and independent judgment.\nRequired Qualifications\nMinimum of 4 years of experience working with data visualization tools.\nMinimum of 4 years of experience manipulating large data sets through statistical software or other methods.\nMinimum of 4 years of strong functional expertise developing front-end reporting solutions.\nMinimum of 4 years of demonstrated proficiency with MS Office Suite. Able to learn new software systems. Considerable knowledge in Excel, including creating pivot tables, conditional formulas, and formatting, VLOOKUPS, etc.\nMinimum of 4 years of knowledge\/experience in Tableau Desktop and Tableau Prep.\nMinimum of 4 years of knowledge\/experience with SQL, Python, or similar language.\nPreferred Qualifications\nGraduation from an accredited 4-year college or university with major course work in Computer Science, Data Analysis, Data Science, Statistics, or related field.\nTableau Desktop certification.\nRoshan Srivastava\nSr.Technical Recruiter\nTekIntegral Inc.\n500 N Central Expwy #500G\nPlano, TX USA 75074\n+14965981924\nrshrivastava@tekintegral.com\nlinkedin.com\/in\/roshanattekintegral\nwww.tekintegral.com\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Visualization, Statistical Software, FrontEnd Reporting, MS Office Suite, Pivot Tables, Conditional Formulas, VLOOKUPs, Tableau Desktop, Tableau Prep, SQL, Python, Computer Science, Data Analysis, Data Science, Statistics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst (Bangkok Based, relocation provided)",
      "company":"Agoda",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-bangkok-based-relocation-provided-at-agoda-3750111593",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"About Agoda\nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u201a\u00c4\u00d8enhancing the ability for our customers to experience the world.\nGet to Know our\nTeam:\nThe Performance Marketing Team of Agoda is a world leader in online marketing. This department is highly data-driven and focused on developing at-scale marketing programs that improve the lifetime value of Agoda customers through measurable marketing programs and channels. The team is a blend of the best analysts, marketing strategists, and data scientists in the world. The marketing leadership at Agoda have deep experience in data science, product, strategy, and other marketing fields and have built an organization that thrives on data, creative ideas, and technology. The Performance Marketing Team also fosters a great learning environment. You will be able to learn and grow by working closely with experts from a variety of backgrounds from all over the world.\nIn this Role, you\u201a\u00c4\u00f4ll get\nto:\nSearch: Experiment with text ads, bidding, and campaign structures on Google, Bing, Baidu, Naver, and other search engines. Adapt to new product features and roll out changes from successful tests\nDisplay: Test, analyze, and optimize campaigns on Facebook, Twitter, Instagram, and others\nModeling: Analyze the vast amounts of data generated by experiments, develop models we can use for optimization, and build dashboards for account managers\nWhat you\u201a\u00c4\u00f4ll Need to\nSucceed:\nBachelor\u201a\u00c4\u00f4s Degree or higher from top university in a quantitative subject (computer science, mathematics, engineering, statistics or science)\nAbility to communicate fluently in English\nExposure to one or more data analysis packages or databases, e.g., SAS, R, SPSS, Python, VBA, SQL, Tableau\nGood numerical reasoning skills\nProficiency in Excel\nIntellectual curiosity and analytical skills\nIt\u201a\u00c4\u00f4s Great if you\nHave:\nExperience in digital marketing\nAcademic research experience\n#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz  #baku #minsk #brussels #antwerp #ghent #charleroi  #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra  #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester  #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner\nEqual Opportunity Employer\nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u201a\u00c4\u00f4s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\nShow more\nShow less",
      "job_skills":"SQL, Data analysis, Data analytics, Data mining, Data science, Data visualization, Business analysis, Business intelligence (BI), Machine learning, Statistics, Python (programming language), Java, Pandas (software), Tableau, Microsoft SQL Server, R (programming language), Artificial intelligence (AI), Google, Facebook, Microsoft",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Analyst (Product Team) (Bangkok Based, relocation provided)",
      "company":"Agoda",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-product-team-bangkok-based-relocation-provided-at-agoda-3750113015",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"About Agoda\nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u201a\u00c4\u00d8enhancing the ability for our customers to experience the world.\nGet to Know our Team:\nIn Product, ideas come alive. The world is moving fast so our culture empowers ownership and minimal bureaucracy. That\u201a\u00c4\u00f4s the environment that enables you to do what you think is right \u201a\u00c4\u00ec and quickly. Product Operations is a large, multicultural team of diversely talented individuals that serve as the curators of Agoda\u201a\u00c4\u00f4s content. We manage all the content our customers and partners see on each of our products. As a part of our team,\u201a\u00c4\u00d8you will\u201a\u00c4\u00d8take ownership\u201a\u00c4\u00d8of\u201a\u00c4\u00d8processes that are critical to multiple other teams across the business.\u201a\u00c4\u00d8We are\u201a\u00c4\u00d8driving\u201a\u00c4\u00d8property-level\u201a\u00c4\u00d8content to map inventories\u201a\u00c4\u00d8from\u201a\u00c4\u00d83 rd \u201a\u00c4\u00d8party supplies\u201a\u00c4\u00d8which\u201a\u00c4\u00d8will enable our reach to span the globe. Content Operations is also keen on self-improvement and innovation. We run our own structured data and analyze\u201a\u00c4\u00d8it\u201a\u00c4\u00d8to make impactful decisions. With the support of state-of-the-art technology and an enriching work environment, we strengthen the bottom line and drive new business for Agoda.\nThe Opportunity:\nAs an Analyst\/Senior Analyst, you will report directly to either the Senior Manager or Associate Director within the Product Department and this will be an individual contributor role. You will be responsible and fully empowered to work with the partners on the ground. You will be supported by a team within the Product department and work closely with other Team members within Agoda. You will be instrumental in ensuring there is consistency in data being used for reporting, identifying value-added data to help the business grow as well as using data to make strategic business decisions. You will be expected to dig into data to provide business insights, guide decision-making and offer valuable inputs to further grow our business model.\nIn this Role, you\u201a\u00c4\u00f4ll get to\n:\nTranslate internal briefs into analytical projects (to include refining the initial brief and asking the \u201a\u00c4\u00f2right questions\u201a\u00c4\u00f4, working through potential hypotheses and storyboarding the output)\nUse and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders\nConducted an analysis of customer behavior and their path through the platform, guaranteeing that the conversion rates for each front-end page met the established benchmarks and continually pinpointed opportunities for enhancement\nPartnered with the Product Design and User Research team to generate fresh data-driven projects, one of which involved the development of a Dashboard designed for more efficient monitoring of user behavior and the measurement of novel business metrics\nDrive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply\nIdentify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence\nAutomate manual operational processes and present back on time savings gained through modernization of business operations\nWhat you\u201a\u00c4\u00f4ll Need to Succeed:\nBachelor\u201a\u00c4\u00f4s degree or higher in Mathematics, Business, Economics, Data Science, Information Technology or similar field\nBachelor\u201a\u00c4\u00f4s Degree or higher in computer sciences, engineering, mathematics, statistics, data science or a related degree program. Masters degree preferred\nAdvanced domain of data analysis and data visualization tools and software such as Excel, SQL, Tableau, Python or similar\nAnalytical mindset, with proven track record in using data to measure performance and make decisions\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written), with proven ability to convey complex messages clearly and with conviction\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\n#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz  #baku #minsk #brussels #antwerp #ghent #charleroi  #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra  #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester  #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server #productanalyst #product\nEqual Opportunity Employer\nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u201a\u00c4\u00f4s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\nShow more\nShow less",
      "job_skills":"Data analysis, SQL, Python, Data mining, Data science, R (programming language), Tableau, Analytical skills, Data visualization, Databases, Business analysis, Business intelligence, Microsoft SQL Server, Excel",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Visualization Analyst",
      "company":"System Soft Technologies",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-visualization-analyst-at-system-soft-technologies-3775094400",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are seeking a highly skilled and experienced data professional to join our team. The ideal\ncandidate should possess a strong background in data analytics, with proven expertise in statistical analysis, data modeling, and predictive analytics.\nLocation \u201a\u00c4\u00ec FWLab\nMust pass a Criminal Justice Information Systems (CJIS) fingerprint-based background check and maintain CJIS eligibility.\nTerm- 01\/02\/24 \u201a\u00c4\u00ec 06\/28\/24\nOn Site for 1st 2 month w\/possibility of hybrid (based on performance)\nIn-person interviews required\nKey skills:\nproficiency in programming languages such as Python, R, or SQL.\nextensive knowledge of working with data visualization tools like Power BI.\nsolid understanding of machine learning techniques and big data technologies.\nExcellent analytical skills\nattention to detail\nthe ability to derive meaningful insights from complex data sets.\nStrong communication skills for translating technical data findings into clear, actionable business insights.\nadept at managing multiple projects simultaneously\ndemonstrating both independent problem-solving abilities and teamwork skills.\n*The candidate must provide examples of previous work products, such as dashboards,\nautomated reports, and usage of advanced analytics tools. The candidate will work with client\ndepartments to produce a dashboard every 5-8 weeks.*\nExperience\n:\nWill need experience in leading projects and collaborating across various departments to support data-driven\ndecision-making is highly desirable.\nRequirements:\nData Visualization:\nTransform raw data into visually appealing and easily understandable reports and\ndashboards. Ability to create a variety of visualizations, including charts, graphs, and maps.\nData Integration:\nIntegrate with a vast array of data sources, including cloud-based and on-premises\ndata sources, Excel spreadsheets, and big data.\nReal-time Analytics:\nCreate real-time dashboard updates, allowing departments to monitor their\noperations as events unfold.\nAdvanced Analytics:\nPerform advanced analytics such as predictive modeling and machine learning,\nproviding deeper insights into data.\nAdvanced Knowledge of Excel\nShow more\nShow less",
      "job_skills":"Python, R, SQL, Power BI, Machine Learning, Big Data, Data Visualization, Data Modeling, Predictive Analytics, Statistical Analysis, Dashboard Creation, Data Integration, Realtime Analytics, Advanced Analytics, Excel",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Analyst, Digital Marketing",
      "company":"BSN SPORTS",
      "job_location":"Farmers Branch, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-digital-marketing-at-bsn-sports-3741437361",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"BSN SPORTS, A VARSITY BRANDS COMPANY - THE RECOGNIZED LEADER IN TEAM ATHLETIC GEAR\nFor over 50 years, BSN SPORTS has been the largest team sporting goods equipment and apparel distributor of choice in the United States. Our 3,000 BSN SPORTS employees strive to support the Heart of the Game by putting valuable time back into the day of coaches and administrators through excellent service platforms. Our company mission is simple: Save coaches and administrators time with everything they do off the field so they have more time to impact young lives on it.\nDIGITAL MARKETING \u201a\u00c4\u00ec SR. DATA ANALYST\nOverview:\nJoin us as our Senior Marketing Data Analyst and be the catalyst for transforming our digital marketing strategy. You'll be at the forefront of designing data-driven models and processes that ensure we reach the right people in the right way, fueling our qualified pipeline and revenue growth while reducing acquisition costs.\nYou'll dive deep into the data to help us answer questions at the heart of our demand generation and e-commerce strategies: How do different audience segments interact with BSN SPORTS? Which marketing channels are the most effective, what impact do our marketing campaigns have, and how can we optimize them?\nYou will be a thought partner for responsible growth initiatives, using advanced data skills to help marketing teams move away from opinion and toward data-informed, insight-led decisions.\nResponsibilities:\nShould possess expertise working in an analytical-type role, interpreting, manipulating, and transforming data.\nShould possess the ability to interpret insights from often complex and disparate business results into a cohesive and actionable business recommendation. These results are often derived across: primary site and lead metrics, sales data, market research, third-party syndicated data, and secondary marketing\/media performance data.\nShould possess strong intellectual curiosity and problem-solving skills to help business partners find adequate solutions to their questions.\nShould be self-driven, able to effectively work on projects independently, possess the ability to display good independent judgement and use strong time-management skills to meet project deadlines.\nEnsure marketing and sales data is regularly updated and analyze data to bring out key insights.\nUsing and promoting data-exploration techniques to discover new or unasked questions.\nTransform data into a digestible and presentable story based on the audience and confidently and effectively communicate that information with a wide range of audiences.\nDevelop deep expertise in our marketing data ecosystem, marketing metrics, data, and processes (e.g., website, CRM, paid media, marketing automation systems)\nIdentify gaps in data that prevent us from effectively generating demand across buying groups and pipeline.\nSupport the preparation of weekly, monthly, quarterly, and annual reporting for marketing leadership.\nDetermine, design, and implement automated reports and dashboards to help us understand the effectiveness of our global demand generation efforts while also focusing on improving marketing KPIs such as ROMI.\nHelp prepare presentations that summarize key insights tailored to specific marketing and sales audiences.\nEvaluate ongoing marketing performance against marketing targets.\nReport and analyze demand generation and e-commerce performance by campaign source, developing key metrics and goals across our revenue lifecycle to understand quality, conversion rates, and velocity.\nIdentify areas of underperformance in the revenue lifecycle and share insights and action plans with key stakeholders\nCollaborate and build credibility with marketing and sales teams, staying up to date on new initiatives and working to understand their data and reporting needs while managing expectations and providing guidance on best practices.\nFacilitate self-serve reporting and formulate roadmaps to prioritize projects; this includes development of content and enablement.\nCollaborate with the immediate and broader marketing team to help provide holistic actionable insights.\nQualifications:\n5+ years of experience in similar roles and\/or responsibilities\nExcellent written and verbal communication skills.\nStrong analytical and data interpretation skills.\nBachelors in a quantitative discipline or similar experience\nDemonstrated experience with multi-touch attribution and AB Testing.\nExpertise with CRM platforms, data warehouses, and leading BI analytics tools like Tableau. Ability to learn other tools and evaluate tools for suitability of implementation.\nDemonstrated experience in BI data architecture, including ETL and APIs, and DW concepts.\nStrong graphics and visualization. Ability to convey messages simply and advise on best possible graphics visualizations.\nFamiliarity with statistics and probability\nBackground in data science helpful but not required.\nIndependently exercises judgment within broadly defined practices and policies. Selects methods and techniques of obtaining solutions to problems of relatively routine to diverse scope and moderate to high complexity.\nExperience using SQL\/Python and\/or R\nJOIN THE BEST TEAM ON THE FIELD IN SPORT, SPIRIT & ACHIEVEMENT\nAt Varsity Brands, we believe every student deserves the opportunity to succeed and every educator wants to make a difference. It takes a team to make a real impact, and through our three distinct brands \u201a\u00c4\u00ec BSN SPORTS, Varsity Spirit and Herff Jones \u201a\u00c4\u00ec and our network of 9,000+ employees and independent representatives, we are proud to partner with schools, colleges and universities across the country to transform the student journey in SPORT, SPIRIT and ACHIEVEMENT.\nOUR VALUES\nService -\nWe lead with heart. We champion community.\nPassion -\nWe love what we do. It fuels our purpose.\nIntegrity -\nWe do what we promise. We own our actions and decisions.\nRespect -\nWe earn it by giving it. Because everyone deserves it.\nInnovation -\nWe never stop striving to be better. For ourselves and our community.\nTransparency -\nWe are committed to openness and honesty in everything we do.\nOur Benefits\nWe are committed to putting you and your families first. For benefits eligible roles, we offer a variety of choices and costs as well as program enhancements that align with our responsibility to elevate the employee experience. Some of our offerings include:\nComprehensive Health Care Benefits\nHSA Employer Contribution\/ FSA Opportunities\nWellbeing Program\n401(k) plan with company matching\nCompany paid Life, AD&D, and Short-Term Disability\nGenerous My Time Off & Paid Holidays\nEmployee Resource Groups\nSt. Jude Partnership & Volunteer Opportunities\nEmployee Perks including discounts on personal apparel and equipment!\nVarsity Brands companies are equal opportunity employers. Qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, citizenship, gender, sexual orientation, gender identity, veteran\u201a\u00c4\u00f4s status, age or disability.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Interpretation, Data Visualization, Marketing Analytics, MultiTouch Attribution, AB Testing, CRM Platforms, Data Warehousing, BI Analytics Tools (Tableau), ETL, APIs, DW Concepts, Graphics and Visualization, Statistics, Probability, Data Science, SQL, Python, R",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Analyst, Credit Risk Mgmt - Data Science and Modeling",
      "company":"T-Mobile",
      "job_location":"Frisco, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-analyst-credit-risk-mgmt-data-science-and-modeling-at-t-mobile-3786078082",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Be unstoppable with us!\nT-Mobile is synonymous with innovation\u201a\u00c4\u00ecand you could be part of the team that disrupted an entire industry! We reinvented customer service, brought real 5G to the nation, and now we\u201a\u00c4\u00f4re shaping the future of technology in wireless and beyond. Our work is as exciting as it is rewarding, so consider the career opportunity below as your invitation to grow with us, make big things happen with us, above all, #BEYOU with us. Together, we won\u201a\u00c4\u00f4t stop!\nAs a Senior Analyst within the Credit Risk Management team, you will be required to wear multiple hats. You must have a strong blend of analytical skills, project management, presentation skills, and ability to develop strong and effective working relationships.\nYou will be working independently and\/or in as part of a team of analysts to identify new credit segmentation opportunities using statistical methods leading to enhancements to our credit decision process and policies, collections strategies, and fraud strategies. You will be partnering within members of the Credit Risk Management team and other functional teams in T-Mobile for the deployment, analysis and tracking of new credit strategies to manage risk.\nYou must be able to manipulate large amounts of data, extract key insights from the data, and then clearly and concisely communicate actionable recommendations based upon your insights. In many cases, you will participate in projects at various stages from idea or hypothesis generation to development and\/or implementation. You will be expected to contribute as credit data expert, analytic methodology specialist and primary statistics analyst.\nDevelop, maintain, and monitor credit attributes from both external credit bureau data as well as internal customer behavior data\nDesign, develop, maintain, and monitor Credit Risk models emphasizing both prediction accuracy, and the impact to losses and profitability\nUtilize statistical segmentation techniques to identify new opportunities\nPerform complex qualitative and quantitative analysis of credit polices to ensure financial goals are being attained\nDevelop predictive financial and analytical models using the appropriate statistical methodologies, including trend and regression analysis\nParticipate and perform the analysis of new data and statistical products by external vendors\nPerform loss forecasting analysis\nExtract, process and transform data from multiple disparate sources\nAnalyze credit bureau and alternative credit data\nDeliver work output with full awareness and adherence to project timelines or agreed upon deadlines\nQualifications \u201a\u00c4\u00ec Minimum Required\n5+ years of quantitative analytic modeling experience or comparable process management experience\nBA\/BS in Finance, Economics, Mathematics, Industrial Engineering, Statistics or related degree required\nIntermediate or higher proficiency in SAS or other statistical\/analytical programming languages\nSuperior computer skills in Excel, Word, PowerPoint required\nSuperior communication (spoken and written), organization and presentation skills\nSuperior time management skills and awareness of project management methods\nRequires competency in customer focus, change & innovation, strategic thinking, relationship building & influencing, talent management, results focus and inspirational leadership.\nQualifications \u201a\u00c4\u00ec Desired\nGraduate degree in a quantitative discipline a plus\nBasic proficiency in SQL, C++, Python, R or other statistical software packages a plus\nPrior consumer risk management experience a plus\nWireless \/ Telecom experience a plus\nEducation \u201a\u00c4\u00ec Minimum Required\nBachelor\u201a\u00c4\u00f4s Degree in Finance, Economics, Mathematics, Industrial Engineering, Statistics or related degree\nAt least 18 years of age\nLegally authorized to work in the United States\nTravel\n:\nTravel Required (Yes\/No):No\nDOT Regulated\n:\nDOT Regulated Position (Yes\/No):No\nSafety Sensitive Position (Yes\/No):No\nNever stop growing!\nT-Mobile doesn\u201a\u00c4\u00f4t have a corporate ladder\u201a\u00c4\u00ecit\u201a\u00c4\u00f4s more like a jungle gym of possibilities! We love helping our employees grow in their careers, because it\u201a\u00c4\u00f4s that shared drive to aim high that drives our business and our culture forward.\nIf you\u201a\u00c4\u00f4d like to receive more information about careers at T-Mobile, sign up for the T-Mobile Talent Community today! https:\/\/www.tmobile.careers\/profile\/join\/\nT-Mobile USA, Inc. is an Equal Opportunity Employer. All decisions concerning the employment relationship will be made without regard to age, race, ethnicity, color, religion, creed, sex, sexual orientation, gender identity or expression, national origin, religious affiliation, marital status, citizenship status, veteran status, the presence of any physical or mental disability, or any other status or characteristic protected by federal, state, or local law. Discrimination, retaliation or harassment based upon any of these factors is wholly inconsistent with how we do business and will not be tolerated.\nTalent comes in all forms at the Un-carrier. If you are an individual with a disability and need reasonable accommodation at any point in the application or interview process, please let us know by emailing ApplicantAccommodation@t-mobile.com or calling 1-844-873-9500. Please note, this contact channel is not a means to apply for or inquire about a position and we are unable to respond to non-accommodation related requests.\nShow more\nShow less",
      "job_skills":"Statistical methods, Credit Segmentation, Credit Risk Management, Analytics, Modeling, SAS, Excel, PowerPoint, Data Mining, Data Manipulation, Data Visualization, SQL, C++, Python, R, Credit Risk Models, Predictive Modeling, Statistical Segmentation, Decision Making, Data Analysis, Data Interpretation, Credit Bureau Data, Customer Behavior Data, Trend Analysis, Regression Analysis, Time Management, Project Management, Communication, Presentation Skills, Team Work, Leadership, Change Management, Innovation, Talent Management, Customer Focus",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Programmer\/Analyst FD3DAa",
      "company":"iSphere",
      "job_location":"Rosenberg, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-programmer-analyst-fd3daa-at-isphere-3772237226",
      "search_city":"San Felipe",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Senior Programmer\/Analyst\nJOB SUMMARY:\niSphere, a leading IT\u00ac\u2020company in Texas, is seeking a highly skilled and experienced full-time Senior Programmer\/Analyst for a 50% remote opportunity. In this role, you will be responsible for all aspects of application design, development, and implementation. We are looking for a talented individual who can analyze customer needs, determine the impact and feasibility of computerizing procedures and processes, and participate in planning programs, policies, or objectives for our work group and department.\nResponsibilities:\n- Conduct thorough research, analysis, and evaluation to determine project feasibility.\n- Collaborate with the Programming Supervisor to develop accurate cost and benefits estimates, establishing the worth and resource requirements of each project.\n- Evaluate customer requirements, propose effective solutions, and make recommendations to ensure customer satisfaction.\n- Design and develop new computer applications while also maintaining and modifying existing applications to meet evolving customer needs.\n- Develop highly complex and critical software solutions, adhering to established software engineering processes.\n- Conduct comprehensive testing of applications, recommending and implementing modifications as necessary.\n- Develop enterprise-level custom integration solutions, utilizing programming solutions and complex middleware products.\n- Create custom interface solutions to facilitate extracted and electronic data interchange between local and external entities.\n- Gain proficiency in assigned vendor application development environments to effectively apply and support patches, upgrades, customizations, etc.\n- Apply vendor application patches and upgrades, establish regression testing, coordinate with relevant parties, and maintain communication with vendors to ensure optimal system integrity.\n- Develop component and data architecture design and performance monitoring standards.\n- Generate custom reports to provide necessary insights not offered by baseline vendor applications, utilizing vendor development\/reporting environment or department-standardized reporting tools.\n- Provide analysis and programming effort for data cleansing and extraction of data.\n- Offer support for multiple computer applications, acting as the primary contact for customer questions, problems, and change requests.\n- Serve as a backup support person for multiple applications, taking responsibility for problem resolution and modifications when the primary support person is unavailable.\n- Participate in evaluating the effectiveness of proposed vendor software products.\n- Contribute to the development of programming and development standards and procedures based on the long-term IT organization strategy.\n- Stay updated on emerging technologies applicable to the organization's environment.\n- Be available on-call 24\/7 for all supported applications.\n- Participate in activities related to emergency management during a local state of disaster, as directed by appropriate county managers.\nQualifications:\n- A bachelor's degree in computer science, information systems, or a related field is preferred. (High School Diploma\/GED and four years of relevant professional experience and five years of required experience may be substituted for the Bachelor's degree.)\n- Five years of relevant programming experience, including one year of management, supervisory, or team lead experience.\n- Strong experience in computer programming and systems design.\n- Thorough knowledge of programming and development standards, procedures, and architectures.\n- Expertise in programming languages and object-oriented approaches to designing, coding, testing, and debugging programs.\n- Proficiency in integration methodologies.\n- Excellent communication skills, capable of translating highly complex concepts for peers and customers.\n- Ability to design, debug, and maintain complex code, modules, or applications.\nSkills:\n- Proficient in ASP.Net and C#.\n- Familiarity with .Net core 6 is preferred.\nJoin iSphere, the leading IT consulting company in Texas, and take your career to new heights as a Senior Programmer\/Analyst. Apply now to be part of our dynamic team!\nShow more\nShow less",
      "job_skills":"ASP.Net, C#, Programming, Systems Design, ObjectOriented Programming, Integration Methodologies, Data Cleansing, Data Extraction, Data Architecture, Performance Monitoring, Vendor Software Products, Disaster Management, .Net Core 6",
      "Category":"Backend Development"
  },
  {
      "job_title":"Power BI Analyst",
      "company":"Workforce Opportunity Services",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/power-bi-analyst-at-workforce-opportunity-services-3681911002",
      "search_city":"Dallas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Summary\nThe Power BI Analyst will be responsible for designing, developing, and maintaining business intelligence solutions. Crafting and executing queries upon request for data, presenting information through reports and visualization. Your Power BI capability will focus on converting business and client reporting requirements to meet the overall needs of the organization.\nCandidate Profile\nBachelor's (Preferred)\nSQL: 1 year (Preferred)\nBusiness Analysis: 1 year (Preferred)\nCompetencies:\nBusiness Acumen\nCommunication\nConsultation\nCritical Evaluation\nRelationship Management\nEthical Practice\nDuties and Responsibilities:\nDesign, publish and maintain Power BI data models with over 45 interrelated tables connected\nImplementing a data model that works seamlessly in Direct Query or Import mode\nMerging\/Joining Queries (M Language) in order to filter useful data to make visuals on a high granular level\nEstablishing dynamic table relations with desired Cross filtering directions.\nImplementing measures in DAX that filter out values from different tables to display calculations\nVisuals with Level Filters that maintain data consistency across interactive\/dynamic pages\nSetup automated data refresh of dashboards to show the updated values from source data\nSlicer Selections and Syncing across report pages\nTranslate business needs to technical specifications\nConduct unit testing and troubleshooting\nEvaluate and improve existing BI systems\nCollaborate with teams to integrate systems\nDevelop and update technical documentation\nPerforms other duties as required\nQualifications:\nIn-depth understanding of the following:\nData Connections: Gateways, SSMS, Connection Types and their nuances\nData Modellng, Merging and Joining tables, Cross Filtering Techniques, PowerQuery (M language)\nVisualization: Power BI Desktop, Advanced Visual Interactions, Visual Level Filters, Measures (DAX), Action Buttons, Bookmarks and Custom Themes\nSharing\/Publishing: Power BI Service, Data Refresh Schedules, Embedded Power BI Reports\nDAX and Power Query M, implementing this for developing Power BI custom connectors for Language Detection\nProgramming Language: Python and R\nIndustry experience is preferred\nProven abilities to take initiative and be innovative\nAnalytical mind with a problem-solving aptitude\nJob Type:\nFull-Time\nSalary:\n$22.00\/Hour (Plus Benefits)\nLocation:\nDallas, TX\nBenefits:\nFree Individual Health Insurance\nFree Training (Program specific)\nPaid Vacation\nPaid Company Holidays\nEducation Assistance\/Reimbursement (Toward first degree - Bachelors\/Associates)\nIndividual Mentor\n401k Retirement Savings\nInterest free loans (Case basis)\nBenefits valued at up to $25,000.00 annually\nShow more\nShow less",
      "job_skills":"Power BI, SQL, Business Analysis, M Language, DAX, Python, R, PowerQuery, Data Connections, Gateways, SSMS, Data Modeling, Merging, Joining, Cross Filtering, Power BI Desktop, Visual Level Filters, Action Buttons, Bookmarks, Custom Themes, Power BI Service, Data Refresh Schedules, Embedded Power BI Reports",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Modeling Analyst",
      "company":"InfoVision Inc.",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-modeling-analyst-at-infovision-inc-3699237087",
      "search_city":"Dallas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Title: Sr Data Modeling Analyst\nLocation: Dallas, TX (Hybrid)\nDuration: Contract\nOnsite from Day 1 (Hybrid)\nThe role is Hybrid, the candidate will be required to go to Dallas Office for collaboration, workshops, meetings and sometimes may be asked to work in the office but can work remote other times.\nData Modeling, well-versed in any data modeling tool, Built Operation Data Store or OLTP database from scratch,\ngood SQL Skills, Exposure to Azure DevOps, good in problem solving and design\nEDUCATION \/ EXPERIENCE REQUIREMENTS\nMust have\n\u201a\u00c4\u00a2 12+ years of experience as a data modeler, developer, data warehouse consumer and \/ or data related operations\n\u201a\u00c4\u00a2 3+ Years of working experience or exposure to Azure, GCP or any other Cloud development and deployment practices.\n\u201a\u00c4\u00a2 4+ Years of Experience with data modeling tools such as ERwin, ER\/Studio, or PowerDesigner.\n\u201a\u00c4\u00a2 3+ years of experience with deployments via devops CI\/CD pipelines.\n\u201a\u00c4\u00a2 Graduation from a 4-year college or university with major course work in a discipline related to the requirements of the position is preferred.\n\u201a\u00c4\u00a2 Ability to astutely operate in the organization, and being able to emphasize methodology, modeling and (Data, Process and Application) governance.\n\u201a\u00c4\u00a2 Hands-On, working knowledge of .Net, Java and SQL language, (i.e. T-SQL (Microsoft)\n\u201a\u00c4\u00a2 Mid-level to expert knowledge in data integration concepts, source-to-target mapping techniques and requirements documentation for ETL team to follow\nPreferred\n\u201a\u00c4\u00a2 3+ years of people leadership skills will be a big plus\n\u201a\u00c4\u00a2 4+ Mortgage and\/or financial industry knowledge is strongly preferred\n\u201a\u00c4\u00a2 Working knowledge of Big Data concepts in organizing both structured and unstructured data is a big plus\nShow more\nShow less",
      "job_skills":"Data Modeling, SQL, Azure DevOps, ERwin, ER\/Studio, PowerDesigner, CI\/CD Pipelines, .Net, Java, TSQL, Data Integration, ETL, Big Data",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst - Product",
      "company":"Hunter Hamilton",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-product-at-hunter-hamilton-3784116305",
      "search_city":"Heber City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Hunter Hamilton and our Austin based HQ'd client is seeking a remote Data Analyst to join the team!\nCompany:\nHunter Hamilton\/Client\nType:\nFull Time, W2 - through Hunter Hamilton\nLocation:\nRemote, preferred Central Time Zone location\nBenefits:\nYes! Hunter Hamilton offers medical, dental, vision, 401k\nPay:\n$35 - $40\/hr.\nAbout this Position:\nYour core focus will be to deliver high-visibility, self-service, reports and visualizations that are used by the Product team to track progress against company-wide goals, and conduct analysis to identify key product growth levers which impact top-line objectives and key results (OKRs) by vetting, manipulating, and automating data extracts from multiple source systems into Tableau.\nTo accomplish this, analyze data with spreadsheet software (i.e. vlookups and pivot tables) and database query experience (e.g. SQL). Use Python to construct analyses and leverage disparate data sources to understand all aspects of strategic opportunities. Synthesize data sources into a strong business case that easily conveys recommendations alongside opportunity cost and impact. Pressure test and identify limitations of data sources, which requires ability to identify dependencies between different software products or different functionality within a software product. Analyses will recommend optimal approaches to drive improvements in processes and reduce customer and internal stakeholder efforts. Key to success is effective communication that is factually accurate, and the ability to articulate issues in a manner that is clear, concise and gives executives the necessary context to frame decisions.\nTo Be Successful in this Role:\n1+ years of experience using Tableau, PowerBI or similar data visualization software to create impactful reports and interactive dashboards\n1+ years of SQL. Must have the ability to write complex, highly-optimized queries including Common Table Expressions, and complex joins across large volumes of data.\n1+ years of solid Python programming skills to cleanse, manipulate, and present data, particularly using Pandas, Numpy, and Jupyter Notebooks\n2+ years of Industry experience in report development, data science, business analytics, business intelligence or comparable data analysis role, including data warehousing and business intelligence tools, techniques and technology\nExcellent oral and written communication skills, and comfort presenting to everyone from entry-level employees to senior vice presidents\nKnowledge of ETL and data warehouse concepts and processes\nAbility to explain complicated or technical information in a simple way to non-technical audiences\nCuriosity and passion about data, visualization and solving problems.\nCreativity to determine the best solution for a real-world problem with quantitative data\nExperience with reporting, descriptive statistics, probability, and cleaning big datasets\nWillingness to question the validity, accuracy of data and assumptions - and make recommendations to Engineering that improve our ability to make decisions\nEnjoyment from collaborating with others in a team environment\nEagerness to learn in a fast-paced environment\nDrive to own projects and be seen as the go-to expert for a subject area\nApplicants must be authorized to work for ANY employer in the U.S. We are unable to sponsor or take over sponsorship of an employment visa at this time\nAfter you have applied, download our Staffmark Group WorkNOW App to receive real-time job offers and apply for additional opportunities. You can download it from the App Store or get it on Google Play.\nAbout Hunter Hamilton\nHunter Hamilton is committed to providing equal employment opportunity for all persons regardless of race, color, religion (including religious dress and grooming practices), sex, sexual orientation, gender, gender identity, gender expression, age, marital status, national origin, ancestry, citizenship status, pregnancy, medical condition, genetic information, mental and physical disability, political affiliation, union membership, status as a parent, military or veteran status or other non-merit based factors. We will provide reasonable accommodations throughout the application, interviewing and employment process. If you require a reasonable accommodation, contact us. Hunter Hamilton is an E-Verify employer. This policy is applicable to all phases of the employment relationship, including hiring, transfers, promotions, training, terminations, working conditions, compensation, benefits, and other terms and conditions of employment.\nAll employees are directed to familiarize themselves with this policy and to act in accordance with it. All decisions with respect to employment matters and other phases of employer-temporary employee relationships will be in keeping with this policy and in accordance with all applicable laws and regulations.\nShow more\nShow less",
      "job_skills":"Tableau, SQL, Python, Pandas, Numpy, Jupyter Notebooks, Data visualization, Report development, Data science, Business analytics, Business intelligence, Data warehousing, ETL, Data warehouse, Statistics, Probability, Big data, Machine learning, Collaboration, Communication",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Analyst (San Antonio, TX\/ Huntsville, AL ) with Security Clearance",
      "company":"ClearanceJobs",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-san-antonio-tx-huntsville-al-with-security-clearance-at-clearancejobs-3770707900",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Senior Data Analyst\nSan Antonio, TX\/ Huntsville, AL Hybrid Job Summary\nWe are looking for a Senior Data Analyst to join a contract with a federal government client in support of an important mission. In this role, you will have the opportunity to work with a great team while supporting the team. Responsibilities\nThis role necessitates the employee to be based in the San Antonio area for on-site work at Fort Sam Houston. Conduct highly complex data mining, statistical analysis, trend analysis, and causal analysis.\nAct as a technical lead, responsible for monitoring and delivering monthly contract reports and deliverables.\nIntegrate multiple disciplines within an operations research team, translating methodologies into a language understandable by operational managers.\nReview and ensure quality control of products.\nDevelop and update training materials to educate newly assigned personnel on key analytic tools, procedures, and methodologies.\nTransform structured and unstructured data into cohesive analytical products for a contracting functional business area audience.\nUtilize pattern analysis methods to formulate recommendations for operational managers by identifying patterns in past, current, and anticipated operational environments. Education and Experience\nA minimum of 8 years of experience in a technical field.\nA Bachelor's degree in computer science, engineering, applied mathematics, statistics, or a related field is preferred. Required Skills\nExperience advising senior DoD decision makers on methodologies, results, and conclusions from applied operations research.\nProficiency in various research tools, including but not limited to Logistics Management Program, Vantage, Virtual Contracting Enterprise, General Fund Enterprise Business System (GFEBS), SAP Business Objects\/Web Intelligence Reports, Microsoft SharePoint, Army-specific contract writing systems (Procurement Desktop Defense (PD2) and Procurement Automated Data and Document System (PADDS)), and various Government and Commercial business process automation systems.\nStrong Data Manipulation And Problem-solving Skills. Desired Skills\nProficiency in statistics, programming languages like R or Python, SQL (Structured Query Language), data visualization, and data cleaning and preparation.\nEffective communication skills and strong problem-solving ability. Security Clearance\nEligibility to obtain a federal Security Clearance.\nShow more\nShow less",
      "job_skills":"Data mining, Statistical analysis, Trend analysis, Causal analysis, Data visualization, Data cleaning, Data preparation, Data manipulation, Problemsolving, R programming, Python programming, SQL, Logistics Management Program, Vantage, Virtual Contracting Enterprise, General Fund Enterprise Business System (GFEBS), SAP Business Objects\/Web Intelligence Reports, Microsoft SharePoint, Armyspecific contract writing systems (Procurement Desktop Defense (PD2) and Procurement Automated Data and Document System (PADDS)), Government and Commercial business process automation systems, Statistics, Effective communication",
      "Category":"Backend Development"
  },
  {
      "job_title":"Power BI Analyst",
      "company":"OmniForce Solutions",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/power-bi-analyst-at-omniforce-solutions-3787361162",
      "search_city":"Lorain",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Must be located in one of the following states:\nTexas\nColorado\nWashington\nNew Jersey\nPennsylvania\nOur client is a Fortune 200 leading retail energy company focused on bringing the power of energy to people and organizations. Putting customers at the center of everything they do, they provide energy solutions to millions of people through their diverse portfolio of retail brands across North America. Take your career to the next level by working on a dynamic, innovative team that moves our world towards a sustainable energy future.\nPosition Overview:\nAs a Data Analyst specializing in Power BI, you will play a pivotal role in transforming raw data into actionable insights that drive informed decision-making within our supply chain operations. The ideal candidate will possess a strong analytical mindset, attention to detail, and the ability to work independently. This is a project-based role with the potential for long-term engagement based on performance.\nKey Responsibilities:\nData Analysis: Analyze large datasets to extract meaningful trends, patterns, and insights.\nUtilize Power BI to create interactive and visually appealing dashboards for reporting purposes.\nReport Generation: Develop and maintain reports that provide key performance indicators (KPIs) to support supply chain decision-making.\nCollaborate with cross-functional teams to understand reporting requirements and deliver timely, accurate reports.\nPower BI Expertise: Demonstrate proficiency in Power BI, including data modeling, DAX calculations, and dashboard design.\nExtract, transform, and load (ETL) data from various sources into Power BI for analysis and reporting purposes.\nDesign and implement robust data models and relationships to ensure accurate and efficient data analysis.\nPerform data cleansing, validation, and manipulation to maintain data accuracy and consistency.\nStay current with industry best practices and advancements in Power BI functionality.\nData Visualization: Design visually compelling and user-friendly dashboards that effectively communicate complex data insights to stakeholders.\nEnsure data visualizations align with business objectives and enhance overall decision-making processes.\nPower BI Asset Management: Manage Power BI assets, including reports, dashboards, workspaces, semantic models, and other components.\nOversee the sharing and distribution of Power BI items, ensuring accessibility and collaboration among team members.\nImplement and maintain security measures to safeguard Power BI assets and sensitive data.\nQualifications:\nProven experience as a Data Analyst focusing on Power BI, including Power Query and Power Pivot.\nProficiency in SQL for data manipulation, extraction, and querying.\nProficiency in a range of other sources of data ingestion.\nAbility to translate complex business requirements into technical specifications for data visualization.\nProficiency in data visualization techniques and best practices.\nStrong analytical and problem-solving skills.\nExcellent communication skills, with the ability to convey complex findings to non-technical stakeholders.\nDemonstrated ability to work independently and manage multiple tasks and priorities effectively.\nProficiency in Python is preferred.\nEducation and Experience:\nBachelor's degree in Data Science, Business Analytics, or related field.\nMinimum of 2-4 years of relevant experience in data analysis with a focus on Power BI.\nShow more\nShow less",
      "job_skills":"Power BI, DAX, ETL, SQL, Python, Power Query, Power Pivot, Data Analysis, Data Visualization, Data Modeling, Data Manipulation, Business Analytics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst\/Report Writer 2",
      "company":"ALIS Software LLC",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-report-writer-2-at-alis-software-llc-3680075966",
      "search_city":"Virginia Beach",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"The Department of Public Safety (DPS) requires the services of a Data Analyst\/Report Writer, hereafter referred to as Worker, who meets the general qualification of i3 emerging, and the specifications outlined in this document for Texas Department of Public Safety.\nThe candiate will perform complex (Journey-level) data analysis and data research work. Work involves conducting detailed analysis of and extensive research on data, providing results, and monitoring and implementing data quality. Develop and implement customer-centric metrics and reporting. Support performance, quality, and improvement efforts to help streamline processes through data analysis and visualization. Manage the analysis of data and embrace evaluative thinking that includes posing thoughtful questions about data, getting feedback from key stakeholders, and using data to support staff, programs, and operations. May provide guidance to others. Works under limited supervision, with moderate latitude for the use of initiative and independent judgment.\nTeleworking option is available but up the discretion of DPS.\nMinimum Requirements\nII. CANDIDATE SKILLS AND QUALIFICATIONS\nCandidates that do not meet or exceed the\nminimum\nstated requirements (skills\/experience) will be displayed to customers but may not be chosen for this opportunity. Years Required\/Preferred Experience 4 Required Working with data visualization tools. 4 Required Experience manipulating large data sets through statistical software or other methods. 4 Required Strong functional expertise developing front-end reporting solutions. 4 Required Demonstrated proficiency with Microsoft Office Suite (Word, Excel, PowerPoint, and Outlook). Able to learn new software\/systems. Considerable knowledge in Excel, including creating pivot tables, conditional formulas and formatting, VLOOKUPS, etc 4 Required Considerable knowledge in Tableau Desktop and Tableau Prep. 4 Required Considerable knowledge with SQL, Python, or similar language. 1 Preferred Graduation from an accredited four-year college or university with major course work in Computer Science, Data Analysis, Data Science, Statistics or a related field. 1 Preferred Tableau Desktop certification is highly preferred.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Visualization, Statistical Software, Microsoft Office Suite, Excel, Pivot Tables, Conditional Formulas, VLOOKUPs, Tableau Desktop, Tableau Prep, SQL, Python, Computer Science, Data Science, Statistics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Analyst II, Credit",
      "company":"Affirm",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/analyst-ii-credit-at-affirm-3777168973",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Affirm is reinventing credit to make it more honest and friendly, giving consumers the flexibility to buy now and pay later without any hidden fees or compounding interest.\nThe Credit team works cross-functionally with Machine Learning, Product, Engineering, Capital Markets, and Commercial teams to responsibly manage the risk profile of the business. We\u201a\u00c4\u00f4re looking for a thoughtful, driven individual who wants to learn, grow, and solve hard problems.\nThe team\u201a\u00c4\u00f4s mandate is to enable sustainable growth while closely managing the profitability and resilience of our portfolio. As Affirm continues on an exciting growth trajectory, thinking through credit strategies for new initiatives and products, shaping ongoing testing and experimentation, and being ready for navigating through any exogenous changes will be important problems to tackle.\nThis role requires extensive use of data analytics to derive insights and develop credit strategies. It also requires a lot of cross-functional partnership. Working with the Machine Learning and Engineering team to develop new underwriting models, with the Product teams to develop new products and features, with the Merchant Pricing team to value different merchants, with the Finance team to help facilitate discussions with debt and equity investors are some parts of the role.\nCome join us in our mission to change consumer finance through better data and technology, lower costs, and increased transparency while providing the best customer experience!\nWhat You'll Do\nLeverage experimentation and advanced data analytics to derive insights. Dissect complex data and translate it into actionable strategies to help optimize credit underwriting\nDetermine and optimize user limit assignments, ensuring they are set optimally to balance risk and growth, driving healthy user engagement\nPlay a pivotal role in optimizing the portfolio, managing risk and ensuring the health and profitability of credit offerings\nDesign and implement inclusive credit strategies by leveraging alternative data, expanding credit to more users while managing the risk strategically\nPartner with Machine Learning and Engineering teams on building effective credit risk capabilities\nWhat we look for\n2-4 years of work experience as a data analyst\/data scientist (consumer credit risk management strongly preferred but not required)\nCurious and passionate to learn new things and think outside the box\nExtensive experience with SQL and Python, or other scripting languages. Experience with Spark is a plus\nAbility to collaborate and influence across different teams in the organization\nPay Grade\n- USA29\nEmployees new to Affirm or promoted into a new role, typically begin in the min to mid range.\nUSA base pay range (CA, WA, NY, NJ, CT) per year:\nMin: $138,800\nMid: $173,500\nMax: $208,200\nUSA base pay range (all other U.S. states) per year:\nMin: $124,900\nMid: $156,100\nMax: $187,300\nAffirm is proud to be a remote-first company! The majority of our roles are remote and you can work almost anywhere within the country of employment. Affirmers in proximal roles have the flexibility to work remotely, but will occasionally be required to work out of their assigned Affirm office. A limited number of roles remain office-based due to the nature of their job responsibilities.\nBenefits\nWe\u201a\u00c4\u00f4re extremely proud to offer competitive benefits that are anchored to our core value of people come first. Some key highlights of our benefits package include:\nHealth care coverage - Affirm covers all premiums for all levels of coverage for you and your dependents\nFlexible Spending Wallets - generous stipends for spending on Technology, Food, various Lifestyle needs, and family forming expenses\nTime off - competitive vacation and holiday schedules allowing you to take time off to rest and recharge\nESPP - An employee stock purchase plan enabling you to buy shares of Affirm at a discount\nWe believe It\u201a\u00c4\u00f4s On Us to provide an inclusive interview experience for all, including people with disabilities. We are happy to provide reasonable accommodations to candidates in need of individualized support during the hiring process.\nBy clicking \"Submit Application,\" you acknowledge that you have read the Affirm Employment Privacy Policy for applicants within the United States, the EU Employee Notice Regarding Use of Personal Data (Poland) for applicants applying from Poland, the EU Employee Notice Regarding Use of Personal Data (Spain) for applicants applying from Spain, or the Affirm U.K. Limited Employee Notice Regarding Use of Personal Data for applicants applying from the United Kingdom, and hereby freely and unambiguously give informed consent to the collection, processing, use, and storage of your personal information as described therein.\nShow more\nShow less",
      "job_skills":"Machine Learning, Product, Engineering, Capital Markets, Commercial, SQL, Python, Spark, Experimentation, Data Analytics, Credit Strategies, Underwriting Models, Risk Management, Portfolio Optimization, Financial Analysis",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst Staff - Level 4 with Security Clearance",
      "company":"ClearanceJobs",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-staff-level-4-with-security-clearance-at-clearancejobs-3790465227",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description:We are Lockheed Martin The position is on the Performance & Decision Analytics Data Staging team within the F-35 Sustainment DSA organization. Responsibilities to include: Perform in the role of Product Owner and Technical Lead to drive the execution\/creation and deliver of the D005 Contract Deliverable: 1) Aid in the Assessment of Data Model Elements\/Attributes 2) Construct and deliver contractually obligated data set 3) compare and contrast historical changes\/performance over time of data elements\/attributes 4) Document processes and procedures to construct data model attributes & attributes 5) Delivery of Data Set and GR&A Documentation. Perform Modeling, Simulation & Analysis (MS&A) in support of F-35 Sustainment. 1) Operate in a big data (high volume, high velocity, high complexity) environment and apply modeling & simulation technical principles, concepts and techniques to assess Performance Based Logistics (PBL) metrics using commercial, government, and LM developed tools\nSupport coordination and development of problem statements, modeling approaches and ground rules and assumptions (GR&A)\nWork as a technical lead and provide guidance to perform analysis to establish data sets that would be used to perform sustainment modeling activities.\nAnalyze F-35 fielded performance developing solutions to assigned problems for the purpose of forecasting, root cause analysis, evaluation of potential solutions, and assessment of corrective actions. Must be a US Citizen; This position is located at a facility that requires special access. A level 4 employee Typically has 9 - 15 years of professional experience. What's In It For You\nBenefits\nOur employees play an active role in strengthening the quality of life where we live and work by volunteering more than 850,000 hours annually. Here are some of the benefits you can enjoy:\nMedical\nDental\n401k\nPaid time off\nWork\/life balance\nCareer development\nMentorship opportunities\nRewards & recognition Learn more about Lockheed Martin's comprehensive benefits package here. This position is in Fort Worth, TX Discover Fort Worth. Basic Qualifications:\nBasic Qualifications\nExperience with part configurations, including part attribute data; i.e. failure rates, repair times, etc. - Experience with reconciling disparate datasets, demand forecasting, inventory optimization and supply planning methods.\nBachelors degree from an accredited college in a related discipline, or equivalent experience\/combined education, with 9 years of professional experience; or 7 years of professional experience with a related Masters degree. Considered an emerging authority.\nEducation should include use of stochastic and deterministic data models or related technical disciplines with an heavy emphasis in modeling, data manipulation, and\/or the application of mathematical and statistical methods to apply to business and risk management problems.\nDesired Skills\nPreferred STEM degree however not required. We recognize other majors incorporate the skills in their curriculum.\nExperience leading diverse teams to delivery complex contracted data sets and documentation. - Experience documenting complex processes and procedures. - Experience interacting with US DoD Customers and understanding their needs.\nExperience with data systems associated SAP or equivalent ERP system, aircraft fielded demand data (ALIS\/ODIN) or engineering failure source data (FRACAS) as a data sources for system optimization. - Experience deconstructing complex operations into component data problems for distributed work across teams. - Experience with readiness based sparing models, multi-echelon, multi indentured for aircraft or defense supply chain systems. - Experience with application of scientific methods for testing and debugging, problem resolution, root-cause analysis. - Knowledge of scripting (one or more common languages e.g., Python and R), statistics (descriptive and inferential), data munging, and data visualization\nExperienced in data structures and hierarchies\nExperience collecting and compiling datasets from disparate data sources into the required data structure. Ability to perform analysis via multi-criteria decision modeling including discrete event simulations, statistical & risk analysis, life-cycle cost analysis, performance & cost trade-offs, and business case analysis\nProficiency with MS Office tool suite.\nExperience managing data quality and configuration control.\nCoursework or previous experience analyzing supply chain networks.\nStrong analytical skills and understanding of system databases, data elements and application software solutions to optimize data gathering and analysis.\nSecurity Clearance Statement: This position requires a government security clearance, you must be a US Citizen for consideration.\nClearance Level: Secret\nOther Important Information You Should Know\nExpression of Interest: By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.\nAbility to Work Remotely: Part-time Remote Telework: The employee selected for this position will work part of their work schedule remotely and part of their work schedule at a designated Lockheed Martin facility. The specific weekly schedule will be discussed during the hiring process.\nWork Schedules: Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.\nSchedule for this Position: 4x10 hour day, 3 days off per week\nLockheed Martin is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nThe application window will close in 90 days; applicants are encouraged to apply within 5 - 30 days of the requisition posting date in order to receive optimal consideration.\nJoin us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They're dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about. As a leading technology innovation company, Lockheed Martin's vast team works with partners around the world to bring proven performance to our customers' toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.\nExperience Level: Experienced Professional\nBusiness Unit: AERONAUTICS COMPANY\nRelocation Available: Possible\nCareer Area: Product Support\nType: Full-Time\nShift: First\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Staging, Product Owner, Technical Lead, Data Modeling, Data Set Construction, Performance Based Logistics (PBL), Modeling & Simulation (MS&A), Big Data, Stochastic and Deterministic Data Models, SAP, ALIS\/ODIN, FRACAS, Python, R, Statistics, Data Munging, Data Visualization, MS Office, Data Quality Management, Configuration Control, Multicriteria Decision Modeling, Discrete Event Simulations, Statistical & Risk Analysis, LifeCycle Cost Analysis, Performance & Cost Tradeoffs, Business Case Analysis",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Insights Analyst III - Remote | WFH",
      "company":"Get It Recruit - Information Technology",
      "job_location":"Manchaca, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-insights-analyst-iii-remote-wfh-at-get-it-recruit-information-technology-3780601839",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"We are seeking a talented Data Insights Analyst III to join our dynamic Analytics & Data Insights team. As a key contributor, you will play a crucial role in supporting our core consumer business. If you are passionate about leveraging data, technology, and analytics to provide valuable insights that drive critical business decisions, we want to hear from you. This is a remote position, but for those living near our Austin, TX or NYC offices, it can be a hybrid role with two days per week in the office.\nResponsibilities\nCollaborate with product managers, marketing leaders, and internal teams to address complex business questions, offering insightful analysis and strategic recommendations.\nTransform data-based observations into hypotheses through analytical rigor, leading to A\/B tests that enhance the performance of our sites.\nTake ownership of metrics related to the functional area you support, from definition to reporting.\nMonitor engagement and conversion trends across the platform, identifying opportunities and threats.\nDevelop advanced metrics and visuals by collecting and integrating data from various sources, including web analytics tools and internal databases.\nAct as the go-to person for all data questions and insights, becoming a Care data expert.\nRequirements\nMinimum 3 years of professional experience in business intelligence or data analysis.\nProven ability to take initiative in solving business questions using data-driven solutions.\nStrong product development mindset with a focus on actionable analytics.\nExperience with relational databases and proficiency in writing performant SQL queries against large datasets.\nUnderstanding of Clickstream data and ability to extract and analyze event data.\nProficiency in data visualization tools, particularly Tableau, and experience in R or Python for ETL and complex analyses.\nStrong teamwork and communication skills, with a creative and global mindset.\nStatistical knowledge and modeling experience is a plus.\nPerks + Benefits:\n[Include link to the Perks + Benefits page]\nOur Commitment\nWe support diverse families and communities and seek employees who reflect that diversity. As an equal opportunity employer, we value a diverse and inclusive workforce. We encourage applications from individuals with varied experiences, perspectives, and backgrounds. We are committed to providing reasonable accommodations for qualified individuals with disabilities.\nEmployment Type: Full-Time\nShow more\nShow less",
      "job_skills":"Data Analytics, A\/B Testing, SQL, Tableau, R, Python, ETL, Clickstream Data, Event Data, Relational Databases, Product Development, Business Intelligence",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Insights Analyst - Remote | WFH",
      "company":"Get It Recruit - Information Technology",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-insights-analyst-remote-wfh-at-get-it-recruit-information-technology-3779348326",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"We are a dynamic consumer tech company with a mission close to our hearts. At our core, we're dedicated to solving a universal challenge: finding exceptional care for our loved ones. We are a diverse team of parents, pet owners, entrepreneurs, and individuals who understand the importance of a helping hand. Our culture and products reflect our commitment to making a positive impact on people's lives.\nOpportunity\nWe are currently seeking a Data Insights Analyst III to join our Analytics & Data Insights team, supporting our core consumer business. This role requires a passion for understanding the business, utilizing data, technology, and analytics to provide valuable insights that drive critical business decisions. If you enjoy autonomy, collaboration, and leveraging your talents for good, this could be the perfect opportunity for you.\nKey Responsibilities\nCollaborate with product managers, marketing leaders, and internal teams to address complex business questions, providing insightful analysis and strategic recommendations through compelling storytelling.\nTranslate data-based observations into hypotheses, leading to A\/B tests that enhance the performance of our sites.\nTake ownership of metrics related to your functional area, from definition to reporting.\nMonitor engagement and conversion trends, identifying opportunities and threats.\nDevelop advanced metrics and visuals by collecting and integrating data from various sources.\nAct as the go-to person for all data-related questions and insights.\nQualifications\nMinimum 3+ years of professional experience in business intelligence or data analysis.\nProven initiative in solving business questions through top-down, data-driven solutions.\nStrong product development mindset with a focus on actionable analytics.\nProficient in SQL, with experience using relational databases and big data environments.\nFamiliarity with Clickstream data and ability to extract and analyze event data.\nCreative, global thinker with strong teamwork skills.\nExperience with data visualization tools (Tableau) and proficiency in R or Python for ETL and complex analyses.\nKnowledge of statistical modeling is a plus.\nPerks + Benefits:\nFor a comprehensive list of our perks and benefits, please refer to our Perks + Benefits page.\nOur Commitment\nWe embrace diversity and inclusion, recognizing the strength it brings to our workforce. As an equal opportunity employer, we encourage applications from individuals with varied experiences, perspectives, and backgrounds. We are dedicated to providing reasonable accommodations for qualified individuals with disabilities.\nCompany Overview\nOperating in over 20 countries, we are the world's leading platform for finding and managing high-quality family care. Our services cover a broad spectrum, from household tax and payroll services to customized corporate benefits packages. Since 2007, families have relied on our industry-leading products for child and elder care, pet care, and home care.\nSalary Range: $115,000 to $150,000\nThe salary range represents the anticipated national range for this position. Actual salaries may vary based on factors such as work location, experience, and performance. Additional components of our total compensation package include annual bonuses, short- and long-term incentives, health insurance coverage, life and disability insurance, a generous 401K employer matching program, paid holidays, and paid time off (PTO).\nEmployment Type: Full-Time\nShow more\nShow less",
      "job_skills":"Data analysis, Business intelligence, SQL, Relational databases, Big data environments, Clickstream data, Event data, Tableau, R, Python, ETL, Statistical modeling, Data visualization",
      "Category":"Backend Development"
  },
  {
      "job_title":"Senior Data Analyst (Product Team) (Bangkok Based, relocation provided)",
      "company":"Agoda",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-product-team-bangkok-based-relocation-provided-at-agoda-3750111537",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"About Agoda\nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u201a\u00c4\u00d8enhancing the ability for our customers to experience the world.\nGet to Know our Team:\nIn Product, ideas come alive. The world is moving fast so our culture empowers ownership and minimal bureaucracy. That\u201a\u00c4\u00f4s the environment that enables you to do what you think is right \u201a\u00c4\u00ec and quickly. Product Operations is a large, multicultural team of diversely talented individuals that serve as the curators of Agoda\u201a\u00c4\u00f4s content. We manage all the content our customers and partners see on each of our products. As a part of our team,\u201a\u00c4\u00d8you will\u201a\u00c4\u00d8take ownership\u201a\u00c4\u00d8of\u201a\u00c4\u00d8processes that are critical to multiple other teams across the business.\u201a\u00c4\u00d8We are\u201a\u00c4\u00d8driving\u201a\u00c4\u00d8property-level\u201a\u00c4\u00d8content to map inventories\u201a\u00c4\u00d8from\u201a\u00c4\u00d83 rd \u201a\u00c4\u00d8party supplies\u201a\u00c4\u00d8which\u201a\u00c4\u00d8will enable our reach to span the globe. Content Operations is also keen on self-improvement and innovation. We run our own structured data and analyze\u201a\u00c4\u00d8it\u201a\u00c4\u00d8to make impactful decisions. With the support of state-of-the-art technology and an enriching work environment, we strengthen the bottom line and drive new business for Agoda.\nThe Opportunity:\nAs an Analyst\/Senior Analyst, you will report directly to either the Senior Manager or Associate Director within the Product Department and this will be an individual contributor role. You will be responsible and fully empowered to work with the partners on the ground. You will be supported by a team within the Product department and work closely with other Team members within Agoda. You will be instrumental in ensuring there is consistency in data being used for reporting, identifying value-added data to help the business grow as well as using data to make strategic business decisions. You will be expected to dig into data to provide business insights, guide decision-making and offer valuable inputs to further grow our business model.\nIn this Role, you\u201a\u00c4\u00f4ll get to\n:\nTranslate internal briefs into analytical projects (to include refining the initial brief and asking the \u201a\u00c4\u00f2right questions\u201a\u00c4\u00f4, working through potential hypotheses and storyboarding the output)\nUse and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders\nConducted an analysis of customer behavior and their path through the platform, guaranteeing that the conversion rates for each front-end page met the established benchmarks and continually pinpointed opportunities for enhancement\nPartnered with the Product Design and User Research team to generate fresh data-driven projects, one of which involved the development of a Dashboard designed for more efficient monitoring of user behavior and the measurement of novel business metrics\nDrive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply\nIdentify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence\nAutomate manual operational processes and present back on time savings gained through modernization of business operations\nWhat you\u201a\u00c4\u00f4ll Need to Succeed:\nBachelor\u201a\u00c4\u00f4s degree or higher in Mathematics, Business, Economics, Data Science, Information Technology or similar field\nBachelor\u201a\u00c4\u00f4s Degree or higher in computer sciences, engineering, mathematics, statistics, data science or a related degree program. Masters degree preferred\nAdvanced domain of data analysis and data visualization tools and software such as Excel, SQL, Tableau, Python or similar\nAnalytical mindset, with proven track record in using data to measure performance and make decisions\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written), with proven ability to convey complex messages clearly and with conviction\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\n#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz  #baku #minsk #brussels #antwerp #ghent #charleroi  #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra  #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester  #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server #productanalyst #product\nEqual Opportunity Employer\nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u201a\u00c4\u00f4s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\nShow more\nShow less",
      "job_skills":"Data analysis, Data mining, Data science, SQL, Python, R, Tableau, Analytical skills, Data visualization, Databases, Business analysis, Business intelligence (BI), Microsoft SQL Server, Data representation",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst V",
      "company":"Texas Health and Human Services",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-v-at-texas-health-and-human-services-3713339045",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nTexas Health and Human Services (HHS) Provider Finance department(PFD) seeks a highly qualified candidate to fill the position of Data Analyst V. in the Quality Review Unit (QRU). PFD is driven by its mission to deliver quality, cost-effective services to Texans. This position makes a significant contribution to PFD\u201a\u00c4\u00f4s mission by assisting with quality reporting activities.\nThe Data Analyst V performs highly complex (senior-level) data collection, reporting and analysis to monitor, evaluate and increase efficiencies for PFD. The position acts as a liaison between PFD, HHS policy, and program areas. This position oversees, plans, directs and monitors key analytic functions relating to the QRU team\u201a\u00c4\u00f4s day-to-day activities. The Data Analyst works with various teams to explore different aspects of a system (people, policy, and processes) to determine why particular areas are performing well or have opportunities for improvement.\nThe ideal candidate thrives in an environment that emphasizes: teamwork to achieve goals, excellence through high professional standards and personal accountability, curiosity to continuously grow and learn, critical thinking for effective execution, and integrity to do things right even when what is right is not easy.\nEssential Job Functions\nData Analysis and Visualization: Work involves conducting detailed analysis of data sets, including monitoring and ensuring data quality, to be used as input for performance dashboards and reports. Compiles, queries, and loads data points using SQL, and other query languages, into databases from a variety of source formats to support complex analyses. Cleans and prepares data, as necessary, to produce data required for data visualization software products and develops dashboards as a result. 25%\nReporting: Oversees development and develops high quality written project updates and reports; guides the selection of data management tools, the development of standards, usage guidelines, and procedures for those tools. Defines, develops, and implements data standards. Determines trends and resolves operational problems related to performance and quality measure data across multiple programs. Coordinates with others who collect, organize, analyze, and prepare materials in response to requests for information and reports specific to performance measure data. Analyzes performance measure data using standard tools, methods, and techniques. Prepares concise, comprehensive technical reports to present and interpret data; makes recommendations on revisions to data collection methodologies. Develops software applications or programming to use for statistical modeling and graphic analysis. 25%\nCoordination: Utilizes strong communication skills to explain PFD and QRU business processes and negotiate for information and resources needed to ensure successful Program initiatives. Consults with internal and external stakeholders regarding program performance measures. Coordinates with Program subject matter experts to ensure accuracy of reporting tools, workflows and reporting procedures. Provides direction to other areas providing data support; may supervise the work of others 10%\nData Quality\/Integrity: Establishes and updates data quality metrics, recommending and implementing improvements to data quality associated with processes. Ensures data integrity by identifying data gaps, errors, anomalies, inconsistencies, and redundancies in the content, structure, and relationships within data; coordinates with stakeholders to improve data quality. Interprets results to identify significant differences in data. Identifies and interprets data patterns and trends and assesses data quality 10%\nIdentifies and Implements Improvements: Provides suggestions regarding systematic changes to improve data collection and align data infrastructure with business needs. Provides routine updates on the status of projects and initiatives. 10%\nInfrastructure Support: Oversees, plans, directs and monitors key analytic functions relating to the day-to-day activities of the QRU team. Consults and provides requirements for developing and implementing databases, data collection systems, data analytics and other strategies to optimize statistical efficiency and quality. Oversees the evaluation of performance measure reporting activities to ensure program reporting requirements are met. May perform quality assurance and serve as a subject matter expert on data integrity, extraction, and compilation. 10%\nPerforms other related work as assigned. 10%\nKnowledge Skills Abilities\nAbility to work collaboratively across PFD to accomplish objectives.\nA keen attention to detail and the ability to implement creative solutions to problems.\nAble to balance team and individual responsibilities.\nKnowledge of data analysis techniques and best practices.\nKnowledge of PFD and other areas within HHS.\nKnowledge of data quality and integrity processes.\nKnowledge of the principles, practices and techniques of database and application design, development and structure.\nSkill in complex analytic work, identifying trends, concerns, recommending opportunities for improvement as well as areas of excellence.\nSkill in using SQL, SAS, SPSS, Python, and other query languages.\nSkill in using Extract, Transform and Load tools.\nKnowledge of and experience with reporting and visualization tools.\nSkill in communicating to both technical and non-technical audiences.\nAbility to work on a team, and to be flexible and creative with data demands.\nAbility to plan, organize and conduct data analytic projects.\nAbility to develop and interpret data charts, maps, and tables.\nAbility to interpret and publish data analytic findings.\nAbility to exercise independent judgment and show initiative.\nAbility to maintain detailed and organized documentation of data analytic projects.\nAbility to compile, review, and analyze data; to prepare reports; to maintain accuracy and attention to detail; to communicate effectively; and to supervise the work of others.\nRegistration Or Licensure Requirements\nInitial Selection Criteria:\nGraduation from an accredited 4-year college or university with major coursework in a social science, business, statistical or related field. Master\u201a\u00c4\u00f4s Degree preferred. At least five years of work and deep experience with data analytics. Experience with Health and Human Services data is preferred.\nAdditional Information\nExperience and education may be substituted for one another.\nRequisition Number 581174\nMOS Code\nNA\nTop 10 Tips for Success when Applying to Jobs at HHSC and DSHS\nHHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work.\nI-9 Form - Click here to download the I-9 form.\nIn compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Visualization, SQL, ETL tools, Reporting, SAS, SPSS, Python, Database Design, Data Structures, Data Quality, Data Integrity, Statistical Analysis, Data Analytics, Project Management, Data Communication, Data Documentation",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst IV",
      "company":"Texas Health and Human Services",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-iv-at-texas-health-and-human-services-3721811115",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nTexas Health and Human Services (HHS) Provider Finance department(PFD) seeks a highly qualified candidate to fill the position of Data Analyst IV. in the Quality Review Unit (QRU). PFD is driven by its mission to deliver quality, cost-effective services to Texans. This position makes a significant contribution to PFD\u201a\u00c4\u00f4s mission by assisting with quality reporting activities.\nThe Data Analyst IV performs highly complex (senior-level) data collection, reporting and analysis to monitor, evaluate and increase efficiencies for PFD. The position acts as a liaison between PFD, HHS policy, and program areas. This position oversees, plans, directs and monitors key analytic functions relating to the QRU team\u201a\u00c4\u00f4s day-to-day activities. The Data Analyst works with various teams to explore different aspects of a system (people, policy, and processes) to determine why particular areas are performing well or have opportunities for improvement.\nThe ideal candidate thrives in an environment that emphasizes: teamwork to achieve goals, excellence through high professional standards and personal accountability, curiosity to continuously grow and learn, critical thinking for effective execution, and integrity to do things right even when what is right is not easy.\nEssential Job Functions\nData Analysis and Visualization: Work involves conducting detailed analysis of data sets, including monitoring and ensuring data quality, to be used as input for performance dashboards and reports. Compiles, queries, and loads data points using SQL, and other query languages, into databases from a variety of source formats to support complex analyses. Cleans and prepares data, as necessary, to produce data required for data visualization software products and develops dashboards as a result. 25%\nReporting: Oversees development and develops high quality written project updates and reports; guides the selection of data management tools, the development of standards, usage guidelines, and procedures for those tools. Defines, develops, and implements data standards. Determines trends and resolves operational problems related to performance and quality measure data across multiple programs. Coordinates with others who collect, organize, analyze, and prepare materials in response to requests for information and reports specific to performance measure data. Analyzes performance measure data using standard tools, methods, and techniques. Prepares concise, comprehensive technical reports to present and interpret data; makes recommendations on revisions to data collection methodologies. Develops software applications or programming to use for statistical modeling and graphic analysis. 25%\nCoordination: Utilizes strong communication skills to explain PFD and QRU business processes and negotiate for information and resources needed to ensure successful Program initiatives. Consults with internal and external stakeholders regarding program performance measures. Coordinates with Program subject matter experts to ensure accuracy of reporting tools, workflows and reporting procedures. Provides direction to other areas providing data support; may supervise the work of others 10%\nData Quality\/Integrity: Establishes and updates data quality metrics, recommending and implementing improvements to data quality associated with processes. Ensures data integrity by identifying data gaps, errors, anomalies, inconsistencies, and redundancies in the content, structure, and relationships within data; coordinates with stakeholders to improve data quality. Interprets results to identify significant differences in data. Identifies and interprets data patterns and trends and assesses data quality 10%\nIdentifies and Implements Improvements: Provides suggestions regarding systematic changes to improve data collection and align data infrastructure with business needs. Provides routine updates on the status of projects and initiatives. 10%\nInfrastructure Support: Oversees, plans, directs and monitors key analytic functions relating to the day-to-day activities of the QRU team. Consults and provides requirements for developing and implementing databases, data collection systems, data analytics and other strategies to optimize statistical efficiency and quality. Oversees the evaluation of performance measure reporting activities to ensure program reporting requirements are met. May perform quality assurance and serve as a subject matter expert on data integrity, extraction, and compilation. 10%\nPerforms other related work as assigned. 10%\nKnowledge Skills Abilities\nAbility to work collaboratively across PFD to accomplish objectives.\nA keen attention to detail and the ability to implement creative solutions to problems.\nAble to balance team and individual responsibilities.\nKnowledge of data analysis techniques and best practices.\nKnowledge of PFD and other areas within HHS.\nKnowledge of data quality and integrity processes.\nKnowledge of the principles, practices and techniques of database and application design, development and structure.\nSkill in complex analytic work, identifying trends, concerns, recommending opportunities for improvement as well as areas of excellence.\nSkill in using SQL, SAS, SPSS, Python, and other query languages.\nSkill in using Extract, Transform and Load tools.\nKnowledge of and experience with reporting and visualization tools.\nSkill in communicating to both technical and non-technical audiences.\nAbility to work on a team, and to be flexible and creative with data demands.\nAbility to plan, organize and conduct data analytic projects.\nAbility to develop and interpret data charts, maps, and tables.\nAbility to interpret and publish data analytic findings.\nAbility to exercise independent judgment and show initiative.\nAbility to maintain detailed and organized documentation of data analytic projects.\nAbility to compile, review, and analyze data; to prepare reports; to maintain accuracy and attention to detail; to communicate effectively; and to supervise the work of others.\nRegistration Or Licensure Requirements\nInitial Selection Criteria:\nMaster\u201a\u00c4\u00f4s Degree preferred. At least five years of work and deep experience with data analytics. Experience with Health and Human Services data is preferred. Experience counts year-for-year of education.\nExperience in the management of a business function, division, or department relevant to the assignment. Graduation from an accredited four-year college or university with major course work in a field relevant to the assignment is generally preferred. Experience and education may be substituted for one another.\nAdditional Information\nRequisition Number 581176\nMOS Code\nNA\nTop 10 Tips for Success when Applying to Jobs at HHSC and DSHS\nHHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work.\nI-9 Form - Click here to download the I-9 form.\nIn compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.\nShow more\nShow less",
      "job_skills":"SQL, SAS, SPSS, Python, Data Analysis, Data Visualization, Data Quality, Data Integrity, Data Standards, Performance Measure Data, Data Management Tools, Data Analytics, Statistical Modeling, Graphic Analysis, Reporting, Communication, Teamwork, Collaboration, Problem Solving, Attention to Detail, Initiative, Independent Judgment, Documentation, Database Design, Application Design, Data Extraction, Data Compilation, Project Management, Project Planning, Project Execution, Project Reporting, Data Charts, Data Maps, Data Tables, Data Interpretation, Data Publication, Supervision, Extract Transform Load (ETL) tools, Reporting and visualization tools",
      "Category":"Backend Development"
  },
  {
      "job_title":"Production Engineering Analyst",
      "company":"ConocoPhillips",
      "job_location":"Midland, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/production-engineering-analyst-at-conocophillips-3784040603",
      "search_city":"Midland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"World\u201a\u00c4\u00f4s largest independent upstream oil and gas business\nSPIRIT values - Safety People Integrity Responsibility Innovation Teamwork\nOperations in 13 countries\nWelcome to ConocoPhillips, where innovation and excellence create a platform for opportunity and growth. Come realize your full potential here.\nWho We Are\nWe are one of the world\u201a\u00c4\u00f4s largest independent exploration and production companies, based on proved reserves and production of liquids and natural gas. With operations and activities in 13 countries, we explore for, develop, and produce crude oil and natural gas globally. We are challenged with an important job to safely find and deliver energy to the world. Our employees are critical to our success, and with them we power civilization.\nWe\u201a\u00c4\u00f4re grounded by our SPIRIT Values \u201a\u00c4\u00ec safety, people, integrity, responsibility, innovation, and teamwork. These values position us to deliver strong performance in a dynamic business \u201a\u00c4\u00ec but not at all costs. We believe it\u201a\u00c4\u00f4s not just what we do \u201a\u00c4\u00ec it\u201a\u00c4\u00f4s how we do it \u201a\u00c4\u00ec that sets us apart.\nWe strive to make a significant difference in the communities where we live and operate. We create an inclusive environment that values all voices and opinions. Together, the different backgrounds, experiences, ideas, and perspectives of our employees drive our success.\nJob Summary\nJob Description\nPermian Basin Overview\nConocoPhillips and its heritage companies have operated in the Permian Basin for almost 100 years. Across New Mexico and Texas, the company holds conventional positions in the Northwest Shelf and Central Basin Platform, and an unconventional position in the Delaware Basin. Permian saw significant growth in 2021 with the acquisition of Concho Resources Inc. in January 2021 and the addition of Shell\u201a\u00c4\u00f4s Permian acreage in December 2021. At year-end, the company held approximately 1.5 million net acres in the Permian Basin.\nNet production for the Permian in 2022 was 461 MBOED.\nClick here to learn more about Living and Working in Midland.\nDescription\nIf you are selected as a Production Engineering Analyst, you will report to the Production Engineering Supervisor. You will take an active role in developing and maintaining analytical tools to support production surveillance while working with multiple disciplines among the asset team.\nYou may be eligible for the voluntary hybrid office work (HOW) program that is designed to provide employees with flexibility while maintaining the advantages of in-person engagement.\nResponsibilities may include:\nSchedule\/Coordinate day-to-day Well Intervention activities based on guidance from Production Engineering Team and Well Intervention Superintendent, track cost and compile daily report for Asset Team and Support groups\nCapture and track downhole equipment failure trends and artificial lift failure rates\nManage and update field wide databases\nReview Artificial Lift Design and make recommendation to Engineering team\nTake pro-active approach in well production analysis and optimization\nCreate and maintain PowerBI or Spotfire dashboards to drive production surveillance activities by leveraging corporate datastore\nAct as liaison between Asset Team and supporting functions such as Land, Reservoir and Production Accounting to assure quality production data flow\nRespond with appropriate urgency to ad-hoc requests\nProactively identify workflow and\/or continuous improvement opportunities, including opportunities for automation where possible\nDesign and implement data analytics solutions in partnership with the Permian Integrated Operations and IT teams for use by asset team\nBasic\/Required:\nMust be legally authorized to work in the United States on a full-time basis for anyone other than current employer\n3 + years of direct experience in oil & gas industry\n3 + years of experience as an Engineering Technician \/ Analyst \u201a\u00c4\u00ec or related Artificial Lift Technician \/ Analyst experience\nAdvanced proficiency with Microsoft O365 applications: Excel, Outlook, PowerPoint, SharePoint, Teams, and Word\nPreferred:\nBachelor's degree or higher in Computer Engineering, Computer Science, other related technical field, or foreign equivalent\nAdvanced knowledge of Artificial Lift Equipment (Rod Pump, ESP, Gas Lift) equipment and design\nAdvanced knowledge of Production, Surveillance and Optimization\nFamiliarity with the Production Engineering discipline and key workflows such as production data management, surveillance, well intervention and well integrity\nFamiliarity with oil & gas production data and allocation tools\nIntermediate skills in PowerBI report construction and management\nFamiliarity with analytical and data visualization tools such as Spotfire, PowerBI, SQL, R, Python, etc\nFamiliarity with Well View and Access\nAwareness of Snowflake (preferred) or other data warehouse platforms\nAwareness of Power Automate (Flow) and Power Apps\nAbility and willingness to integrate across teams to identify and drive business needs\nEfficient written and verbal communication, interpersonal and collaboration skills\nDrives thoughtful and pragmatic change, inspires innovative thinking and continuous improvement, and models adaptability through resourcefulness, flexibility, and positivity\nTakes ownership of actions and follows through on commitments by holding others accountable and standing up for what is right\nDelivers positive results through realistic planning to accomplish goals\nBuilds effective solutions based on available information and makes timely decisions that are safe and ethical\nApply Before:\nJanuary 5, 2024\nSponsorship:\nConocoPhillips\u201a\u00c4\u00f4 sponsorship for employment authorization in the U.S. is NOT available for this position.\nEEO:\nIn the US, ConocoPhillips is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, national origin, age, disability, veteran status, gender identity or expression, genetic information, or any other legally protected status.\nShow more\nShow less",
      "job_skills":"Production Engineering, Microsoft O365, Excel, Outlook, PowerPoint, SharePoint, Teams, Word, PowerBI, Spotfire, SQL, R, Python, Well View, Access, Snowflake, Power Automate, Power Apps, Artificial Lift Equipment, Rod Pump, ESP, Gas Lift, Production Data Management, Surveillance, Well Intervention, Well Integrity, Oil & Gas Production Data, Allocation Tools",
      "Category":"Backend Development"
  },
  {
      "job_title":"Power BI Data Analyst",
      "company":"Propper International",
      "job_location":"St Charles, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/power-bi-data-analyst-at-propper-international-3763854966",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Title:\nPower BI Data Analyst:\nPropper International is looking for a forward-thinking and innovative Power BI Data Analyst to provide business insights that drive improvements. The Power BI Data Analyst will play a key role by capturing, processing, and transforming datasets into clear summaries to fuel data-driven business decisions and solutions. The Data analyst will be heavily involved in the integration of different data sources, the use of ETL, SQL databases, and Power BI to successfully deliver BI solutions on a periodic basis.\nResponsibilities\nWork closely with business stakeholders to understand their requirements and use multiple data sources and Power BI to deliver data-driven insights and informed decisions.\nUse Power BI to create customized reports, dashboards, and KPIs to monitor key performance indicators.\nProvide live Power BI data through development of dynamic reporting, dashboarding, drill-down capabilities, and visualization solutions.\nDevelop processes for data mining, data modeling, and data production.\nCreate test plans and scenarios to ensure quality and requirement traceability for final deliverable.\nProvide Power BI training on various levels of expertise to companywide users and executives as needed.\nImplement data security measures to protect sensitive information and ensure compliance with data protection regulations.\nActively identify solutions to enhance the existing Business Intelligence infrastructure, processes, and technology.\nPerform other duties as assigned.\nRequirements (Must Have)\n4-year bachelor's degree in IT or related fields\n5+ years in Data Analysis using Microsoft Business Intelligence Stack (Power BI, SSAS, SSRS, SSIS, Data Factory, Power Query, MDX, DAX, etc.)\nSolid knowledge of SQL Data Warehousing and database fundamentals such as multidimensional database and relational database design.\nStrong programming skills in SQL. Knowledge of Python is a plus.\nProficiency with data science techniques and in manipulating data through data cleansing, data transformation, and data modeling.\nStrong analytical and problem-solving skills.\nSolid project management skills using Agile methodologies to meet project deadlines, budgets, and business requirements.\nGood communication and presentation skills\nExcellent Customer Service Orientation is a MUST.\nPosition Details\nOn-Site, Monday thru Friday 8am-5pm\n1099 Contract position. Contract duration is 6 months to 12 months, with possibility of direct hire\nHourly range of $39.00\/hr to $43.00\/hr depending upon experience.\nWho Is Propper\nWe got our start in 1967 with a contract for the U.S. Navy, manufacturing the iconic \"Dixie Cup\" hat worn by U.S. sailors. Over the decades, we've supplied more than 120 million garments to the U.S. Department of Defense, law enforcement agencies, and the public safety community.\nYou may not have heard of us, but you've definitely seen our work.\nOur heritage informs how we operate. We are a retail brand, but we still think like a contract manufacturer. Contracts aren't won by selling a particular lifestyle, telling unique stories, or appealing to emotion. They are won with features, quality, and demonstrable value. Contracts are won on the concrete.\nThis mentality drives every aspect of our production. Make it Work. Make it Last. Make it Real. Or don't make it at all.\nEqual opportunity Employer\nShow more\nShow less",
      "job_skills":"Power BI, Data Analysis, Microsoft Business Intelligence Stack, SQL Data Warehousing, SQL, Python, Data Science, Data Cleansing, Data Transformation, Data Modeling, Analytical Skills, ProblemSolving Skills, Project Management, Agile Methodologies, Communication Skills, Presentation Skills, Customer Service Orientation",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr Data Analyst",
      "company":"Cushman & Wakefield",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-cushman-wakefield-3779636196",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title\nSr Data Analyst\nJob Description Summary\nThe role is for a Senior Data Analyst as part of a team collecting and analyzing data supporting ad hoc and strategic client projects primarily involving architectural building design.\nThe candidate will provide advanced expertise in data analysis, collaborate with key client partners, support the data team with identifying project requirements, refining project work, and providing recommendations on optimizing data management and workflows.\nJob Description\nCore Responsibilities\nCollect, clean, study, transform, load, and visualize data for ad hoc and strategic projects\nIdentify trends and provide insights from data that contribute to solving business problems\nCode programs, as needed, to help capture and organize relevant data\nCollaborate directly with internal and external partners to satisfy project needs\nClearly communicate useful information to business partners derived from data analysis\nAssist in managing completion of team data analysis tasks\nLead problem-solving and refinement of project activities and tasks\nLead project identifying requirements from analysis of current state versus desired future state\nIdentify opportunities for workflow optimization\nQualifications\nThree or more years of experience in data analytics, data management, or related roles\nAdvanced knowledge of data analytics, cleaning, preparation, and visualization techniques\nAdvanced experience with data analytics tools and programs (Microsoft Excel, Microsoft Power BI, Python, SQL, Tableau)\nAdvanced understanding of best practices in data management and visualization\nStrong critical thinking and problem solving skills\nStrong focus on solutions serving client\/end user\nAbility to write and speak clearly to both technical and non-technical audiences\nKeen attention to both technical detail and quality of work acceptable to client\/end user\nDemonstrated ability to collaborate effectively with partners across multiple teams\nStrong ability to prioritize work tasks in alignment with changing project and team needs\nPreferred candidate will have experience managing\/analyzing architectural design data\nCushman & Wakefield provides equal employment opportunity. Discrimination of any type will not be tolerated. Cushman & Wakefield is an Equal Opportunity \/ Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other characteristic protected by state, federal, or local law.\nIn compliance with the Americans with Disabilities Act Amendments Act (ADAAA), if you have a disability and would like to request an accommodation in order to apply for a position at Cushman & Wakefield, please call the ADA line at\n1-888-365-5406\nor email\nHRServices@cushwake.com\n. Please refer to the job title and job location when you contact us.\nShow more\nShow less",
      "job_skills":"Data analytics, Data management, Data visualization, Data cleansing, Data preparation, Microsoft Excel, Microsoft Power BI, Python, SQL, Tableau, Problem solving, Critical thinking, Communication, Collaboration, Project management, Team work, Attention to detail, Quality assurance, Architectural design data",
      "Category":"Backend Development"
  },
  {
      "job_title":"Analyst II, Credit",
      "company":"Affirm",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/analyst-ii-credit-at-affirm-3777169716",
      "search_city":"Collinsville",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Affirm is reinventing credit to make it more honest and friendly, giving consumers the flexibility to buy now and pay later without any hidden fees or compounding interest.\nThe Credit team works cross-functionally with Machine Learning, Product, Engineering, Capital Markets, and Commercial teams to responsibly manage the risk profile of the business. We\u201a\u00c4\u00f4re looking for a thoughtful, driven individual who wants to learn, grow, and solve hard problems.\nThe team\u201a\u00c4\u00f4s mandate is to enable sustainable growth while closely managing the profitability and resilience of our portfolio. As Affirm continues on an exciting growth trajectory, thinking through credit strategies for new initiatives and products, shaping ongoing testing and experimentation, and being ready for navigating through any exogenous changes will be important problems to tackle.\nThis role requires extensive use of data analytics to derive insights and develop credit strategies. It also requires a lot of cross-functional partnership. Working with the Machine Learning and Engineering team to develop new underwriting models, with the Product teams to develop new products and features, with the Merchant Pricing team to value different merchants, with the Finance team to help facilitate discussions with debt and equity investors are some parts of the role.\nCome join us in our mission to change consumer finance through better data and technology, lower costs, and increased transparency while providing the best customer experience!\nWhat You'll Do\nLeverage experimentation and advanced data analytics to derive insights. Dissect complex data and translate it into actionable strategies to help optimize credit underwriting\nDetermine and optimize user limit assignments, ensuring they are set optimally to balance risk and growth, driving healthy user engagement\nPlay a pivotal role in optimizing the portfolio, managing risk and ensuring the health and profitability of credit offerings\nDesign and implement inclusive credit strategies by leveraging alternative data, expanding credit to more users while managing the risk strategically\nPartner with Machine Learning and Engineering teams on building effective credit risk capabilities\nWhat we look for\n2-4 years of work experience as a data analyst\/data scientist (consumer credit risk management strongly preferred but not required)\nCurious and passionate to learn new things and think outside the box\nExtensive experience with SQL and Python, or other scripting languages. Experience with Spark is a plus\nAbility to collaborate and influence across different teams in the organization\nPay Grade\n- USA29\nEmployees new to Affirm or promoted into a new role, typically begin in the min to mid range.\nUSA base pay range (CA, WA, NY, NJ, CT) per year:\nMin: $138,800\nMid: $173,500\nMax: $208,200\nUSA base pay range (all other U.S. states) per year:\nMin: $124,900\nMid: $156,100\nMax: $187,300\nAffirm is proud to be a remote-first company! The majority of our roles are remote and you can work almost anywhere within the country of employment. Affirmers in proximal roles have the flexibility to work remotely, but will occasionally be required to work out of their assigned Affirm office. A limited number of roles remain office-based due to the nature of their job responsibilities.\nBenefits\nWe\u201a\u00c4\u00f4re extremely proud to offer competitive benefits that are anchored to our core value of people come first. Some key highlights of our benefits package include:\nHealth care coverage - Affirm covers all premiums for all levels of coverage for you and your dependents\nFlexible Spending Wallets - generous stipends for spending on Technology, Food, various Lifestyle needs, and family forming expenses\nTime off - competitive vacation and holiday schedules allowing you to take time off to rest and recharge\nESPP - An employee stock purchase plan enabling you to buy shares of Affirm at a discount\nWe believe It\u201a\u00c4\u00f4s On Us to provide an inclusive interview experience for all, including people with disabilities. We are happy to provide reasonable accommodations to candidates in need of individualized support during the hiring process.\nBy clicking \"Submit Application,\" you acknowledge that you have read the Affirm Employment Privacy Policy for applicants within the United States, the EU Employee Notice Regarding Use of Personal Data (Poland) for applicants applying from Poland, the EU Employee Notice Regarding Use of Personal Data (Spain) for applicants applying from Spain, or the Affirm U.K. Limited Employee Notice Regarding Use of Personal Data for applicants applying from the United Kingdom, and hereby freely and unambiguously give informed consent to the collection, processing, use, and storage of your personal information as described therein.\nShow more\nShow less",
      "job_skills":"SQL, Machine Learning, Python, Spark, Credit Risk Management, Underwriting Models, Data Analytics",
      "Category":"Backend Development"
  },
  {
      "job_title":"Sr. Data Analyst",
      "company":"Barkley",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-barkley-3784882135",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Our Data Management & Measurement (DMM) team lives at the center of marketing results and business impacts. We assess how our clients can best optimize their marketing efforts to maximize the direct impact on business results.\nWe are looking for a Sr. Data Analyst, who will work on the front lines of our practice - delivering impactful and inspiring reporting for our internal media teams and our clients. This person will ideally become a trusted expert regarding their clients' marketing performance data and its impact on business results. As a member of the DMM team, you will play an important role in discovering, analyzing and presenting findings and reports related to all media channels. You will be at the heart of uncovering and measuring the connections between marketing results and business objectives.\nResponsibilities\nHave a passion for data analysis, critical thinking and storytelling\nBe able to work with internal media and reporting teams to develop measurement solutions for client campaigns.\nAnalyze campaign performance and other marketing efforts to assess their impact on client KPIs and make recommendations for improvements.\nParticipate in the creation of our clients' measurement strategies, including KPI selection, data capture requirements, measurement frameworks and data visualization\nBecome a trusted expert regarding clients' marketing performance data and will assist team members across departments in accessing and interpreting results.\nHave experience with digital tracking, including tagging, mobile and social limitations\nExcellent verbal and written communication skills to interpret and present business value to clients.\nWork with client internal analytics and IT teams to implement custom tracking parameters\nImplement and maintain media performance dashboard reporting across platforms like Excel, Sheets, Data Studio, PowerPoint, Slides, Datorama, Tableau and Power BI\nDemonstrate problem-solving ability with emphasis on drawing inferences with data\nPersonal characteristics:\nIntellectual curiosity, problem solving skills and determination\nDetail-oriented and thorough\nEffective communications verbally and in writing\nAbility to listen to stakeholders, process feedback and provide solutions\nStrong work ethic and integrity\nQualifications\n2+ years of marketing analytics and business intelligence experience with an emphasis on media and marketing measurement\nExperience with data visualization tools, especially Power BI, is a plus. This includes both the data visualization component of dashboard development and backend data preparation and aggregation.\nStrong working knowledge of spreadsheet platforms (i.e. Excel, Sheets, etc)\nExperience with advertising planning, buying and performance metrics\nExperience with media reporting platform(s) (Doubleclick, Adwords, etc)\nExperience with web analytics platform(s) (Adobe, Google Analytics,etc.)\nData analysis experience including spreadsheet (Excel) and SQL platforms\nRelational database programming languages (e.g. SQL) and statistical tools (e.g. SAS, SPSS, Python) is a plus\nEffectiveness in managing multiple projects across multiple clients and stakeholders\nExperience in analysis, research and presentation creation\nBarkley's Commitment to Diversity & Inclusion\nWe believe being radically diverse and inclusive is the key to becoming one of the world's great creative idea companies. By embracing everything that makes our partners who they are and what makes them unique to the world around them, we create the conditions and capacity to help creative, original thinking thrive.\nBarkley is committed to Diversity, Equity, Inclusion and Belonging as part of our corporate strategic goals, supported by a formal DEI+B program, Employee Resource Groups, Director of Diversity leadership and agency commitment to The Brand Lab.\nShow more\nShow less",
      "job_skills":"Data analysis, Critical thinking, Storytelling, Marketing analytics, Business intelligence, Data visualization, Power BI, Spreadsheet platforms (Excel Sheets), Advertising planning, Advertising buying, Performance metrics, Media reporting platforms (Doubleclick Adwords), Web analytics platforms (Adobe Google Analytics), SQL, SAS, SPSS, Python, Project management, Research, Presentation creation, Relational database programming languages, Statistical tools",
      "Category":"Backend Development"
  },
  {
      "job_title":"Data Analyst",
      "company":"SBS Creatix",
      "job_location":"Greater St. Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-sbs-creatix-3770505264",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"**Must be US Citizen\"\n** No C2C Possibility**\nData Analyst opportunity in the Greater St. Louis Metropolitan Area.\n**Onsite and required that you be able to obtain a Top-Secret clearance. **\nRequirements\n:\nMinimum 2 years of related experience and must be eligible to obtain Top Secret clearance.\nProficiency in using scripting languages like Python for data analysis tasks such as data cleaning and visualization.\nExperience with SQL to accomplish data retrieval, manipulation, joining, and reporting tasks.\nKnowledge of Business Intelligence systems like Tableau, PowerBI, and\/or Qlik Sense for data analysis and visualization.\nPreferred\n:\nExperience with Advana or Palantir tools.\nBachelor of Science in STEM-related (Science, Technology, Engineering, Math, etc.) major.\nPrior experience with Geospatial tools, Python, PySpark, Databricks, and\/or Qlik.\nExperience leveraging statistical concepts in basic data analysis tasks (e.g., hypothesis testing, regression).\nResponsibilities\n:\nPerform data analysis, generate insights, and create interactive data visualizations.\nWork closely with business stakeholders to understand their requirements and deliver data-driven insights to drive informed decisions.\nCollaborate with data engineers to access, clean, and transform data for analysis, ensuring data quality and accuracy.\nCollaborate closely with cross-functional teams, including data scientists, analysts, and business stakeholders, to understand their data needs and provide timely support.\nShow more\nShow less",
      "job_skills":"Python, SQL, Data Cleaning, Data Visualization, Tableau, PowerBI, Qlik Sense, Advana, Palantir, Geospatial Tools, PySpark, Databricks, Qlik, Hypothesis Testing, Regression, Interactive Data Visualizations, DataDriven Insights, Data Quality, Data Accuracy, CrossFunctional Teams, Data Scientists, Business Stakeholders",
      "Category":"Backend Development"
  },
  {
      "job_title":"Manager, Data Loss Prevention (DLP) Engineer (Symantec)",
      "company":"Jobs for Humanity",
      "job_location":"Paris, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/manager-data-loss-prevention-dlp-engineer-symantec-at-jobs-for-humanity-3788480431",
      "search_city":"Hugo",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Description\nJobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.\nCompany Name: Capital One\nJob Description\nJob Advertisement: Manager, Data Loss Prevention (DLP) Engineer (Symantec) Location: McLean, Virginia, United States of America Capital One is looking for a data protection expert to join our team and help us build game-changing cybersecurity solutions. We believe in Excellence and Doing the Right Thing, and as a technology-driven company, we strive to deliver financial products through modern technology and constant innovation. One area of innovation is in cybersecurity, where we leverage technology to create the best solutions for our business. As a candidate for this role, you will be part of a team of cyber technicians and engineers. You will design, implement, and maintain DLP Controls using SaaS and IaaS solutions to reduce risk and enforce Capital One's Information Security Policy and Standards. Your role will involve staying up-to-date with emerging trends and threats, questioning existing processes and solutions, and prioritizing business value. You will collaborate with different teams, thrive in ambiguity, and ensure that the solutions you create meet the needs of our developer community and business partners. What you'll do: - Use your expertise in data loss prevention to design and implement tools that protect data from cyber risks at every stage. - Analyze the problem space, document your approach, and work with architecture to develop a target state architecture. - Collaborate with cross-functional teams across the organization to execute technical resolutions. - Maintain close relationships with stakeholders, developers, and engineers to ensure that our services meet evolving needs. - Communicate extensively with Data Protection Product and engineering teams. - Collaborate with different teams to resolve dependencies with data loss prevention products. - Design, build, and maintain cloud-based infrastructure that meets organizational requirements and ensures high availability. About You: - You are an expert in data loss prevention tools. - You have a strong understanding of web proxy, email, and endpoint solutions. - You pay attention to detail and can clearly articulate important details in both conversations and technical writing. - You can drive complex technical initiatives to full delivery, using your knowledge of cybersecurity practices, software engineering principles, agile frameworks, and customer engagement. - You can foster collaborative relationships with technology groups and stakeholders, including vendors. - You have excellent communication skills and can effectively interact with individuals at all levels of the organization. - You have experience managing multiple high-impact cybersecurity projects with cross-functional teams. - You have a passion for technical delivery, product security, software development practices, or platform engineering. - You have hands-on knowledge and expertise in building secure technology. - You are capable of troubleshooting, investigating, configuring, and supporting data loss prevention products. Basic Qualifications: - High School Diploma, GED, or equivalent certification. - At least 6 years of experience in cybersecurity or information technology. - At least 5 years of experience in data protection. - At least 3 years of experience with Symantec Data Loss Prevention (DLP) infrastructure engineering. - At least 3 years of experience with URL filtering, proxy, or Network DLP. Preferred Qualifications: - Bachelor's Degree in Cybersecurity, Systems Engineering, or Computer Science. - 4+ years of experience in scripting and solving cyber technical challenges. - 4+ years of experience in the Agile delivery model. - 4+ years of experience in public cloud security and multi-cloud environments. - 3+ years of experience in IT Delivery projects and technical writing. - 3+ years of hands-on JIRA experience. - 2 or more professional cybersecurity certifications: CISSP, GIAC, CISM, CCSP, CISA, or Security+. - 1 or more professional cloud certifications: AWS Cloud Practitioner, AWS Solution Architect - Associate, AWS Developer - Associate, AWS Security - Specialty, or AWS Solution Architect - Professional. At Capital One, we offer a comprehensive and competitive set of health, financial, and other benefits to support your total well-being. Visit the Capital One Careers website to learn more about our benefits eligibility. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We value individuals from all backgrounds and prohibit discrimination based on various protected characteristics. If you require accommodations during the application process, please contact Capital One Recruiting at 1-800-304-9102 or recruitingaccommodation@capitalone.com. We will ensure that your information is kept confidential and used only to provide the necessary accommodations. Please note that this role is eligible for performance-based incentive compensation, which may include cash bonuses and\/or long-term incentives. We appreciate your interest in Capital One and encourage you to apply within 5 business days. We do not accept applications from agencies. Thank you for considering Capital One as an employer. We look forward to reviewing your application. Sincerely, [Your Name] Bullet Points: - We're seeking a data protection expert to join our team and help us create innovative cybersecurity solutions. - As a Manager, Data Loss Prevention (DLP) Engineer, you will design, implement, and maintain DLP Controls. - Your role will involve reducing risk and enforcing Capital One's Information Security Policy and Standards. - You'll collaborate with diverse teams, stay up-to-date with emerging trends, and prioritize business value. - Basic qualifications include at least 6 years of experience in cybersecurity or information technology. - Preferred qualifications include hands-on experience with Symantec Data Loss Prevention (DLP) infrastructure engineering and professional certifications in cybersecurity and cloud technology. - At Capital One, we value diversity and inclusion, and we are an equal opportunity employer. - We offer a comprehensive set of benefits to support your total well-being. - If you require accommodations during the application process, please contact our Recruiting team. - We appreciate your interest in Capital One and encourage you to apply within 5 business days. - No agency applications, please.\nShow more\nShow less",
      "job_skills":"Data Loss Prevention, Cybersecurity, Agile, Symantec DLP, URL filtering, Proxy, Network DLP, AWS, Cloud security, Multicloud environments, Jira, CISSP, GIAC, CISM, CCSP, CISA, Security+, AWS Cloud Practitioner, AWS Solution Architect, AWS Developer, AWS Security, Software engineering, Customer engagement, IT Delivery, Technical writing",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Center Building Operating Engineer",
      "company":"JLL",
      "job_location":"Carrollton, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-building-operating-engineer-at-jll-3676746043",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"What This Job Involves \u201a\u00c4\u00ec\nThe Sr. Operating Engineer will perform and\/or direct various preventative maintenance and repairs within a given geographic territory. This will include hands-on work to complete the necessary work within JLL standards and guidelines. This role will perform and assist in identification and implementation of OM&F strategies to ensure safe, reliable, and efficient Buildings, Building Systems, and equipment within a geographic territory.\nWhat is your day to day?\nComprehensive knowledge of Safe Work practices especially regarding energized work, working at heights and confined spaces.\nAbility to recognize, assess and mitigate or eliminate risk.\nAbility to understand and use proper PPE for associated tasks.\nEvaluate, train, teach and coach a work force of Engineers and Maintenance Technicians as requested by supervisors.\nPossess hands-on skills and knowledge to complete required repairs and maintenance on commercial buildings and building systems (including, but not limited to: HVAC, Electrical, Plumbing, Vertical Transportation, Life Safety, Roofs, Structure, Parking Lots and Roads) using industry standard tools and in accordance with all codes, laws, and regulations.\nPerform preventative maintenance and repair service work on HVAC, mechanical, plumbing, electrical, and various other building systems to maintain the properties in peak operational conditions\nRequired to bend, sit, kneel, squat, stand, reach, and lay as required to access equipment components for extended periods of time; lift up to 50 lbs.\nMay be required to work exposed to heat, sunlight, rain, cold, daylight and night-time hours\nRequired\nDesired experience and technical skills\n5-7 years of Skilled Trades experience\nEPA 608 Universal Certification\nAbility to analyze the operation of various Commercial or Industrial Mechanical, Electrical, Plumbing and HVAC systems, determine the cause of any problems\/malfunctions and take corrective action\nAbility to effectively us computers and computer programs; including Excel, Word, Outlook\nHigh School diploma or GED equivalent\nPreferred\nPossess excellent communications skills both written and verbal.\nTwo years of trades schooling in electrical system design, refrigeration and HVAC\nShow more\nShow less",
      "job_skills":"Maintenance, Repair, HVAC, Electrical, Plumbing, Vertical Transportation, Life Safety, Roofs, Structure, Parking Lots, Roads, Industry Standard Tools, Codes, Laws, Regulations, Excel, Word, Outlook, EPA 608 Universal Certification, Commercial or Industrial Mechanical, High School Diploma or GED, Trades Schooling, Electrical System Design, Refrigeration",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"Mitchell Martin Inc.",
      "job_location":"Grapevine, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-mitchell-martin-inc-3762681379",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Our direct hiring manager is looking for a DataCenter Engineer who has Hvac and racking \/Stacking experience. Please review the details below and let me know if you are qualified and interested.\nPrimary point of contact for Data Center technologies and related mechanical devices. Participates in projects to design and implement mechanical and electrical improvements to data centers. Develops procedures to outline data center processes, and related tasks. Participates and leads in the design and engineering data center technologies and future datacenter related initiatives. Mentors Data Center Operations team members and helps increase their effectiveness and skillset.\nHVAC and Racking\/Stacking. Have to have both (Electrical and Network Knowledge)\nHands on data center\nMust be flexible with work schedule and hours\nBachelors degree and 4 years related experience\nKnowledge of:\nDatacenter HVAC, CRAC, CRAH cooling technologies\nDatacenter power, UPS, generator operations, etc\nDatacenter fire suppression systems (FM200, HFC125, etc)\nGeneral knowledge of datacenter design and construction\nLAN\/WAN\nEmerging Technology Trends\nDatacenter Best Practice and Industry Standard Methodology\nSkills\/Abilities:\nEvaluate critical systems, prioritize workflow and determine solutions\nExcellent written and verbal communication skills\nInterpret and apply laws, regulations and policies\nRead and understand technical manuals\nWork for extended time at keyboard\/terminal\nMaintain effective working relationships with supervisor and coworkers\nWork flexible hours, including weekends and evenings\nValue open, honest communication\nEager to be transparent and truthful as a primary matter of course\nShow more\nShow less",
      "job_skills":"HVAC, Racking, Stacking, Data center design, Data center construction, LAN, WAN, UPS, Generator operations, Fire suppression systems, Electrical knowledge, Network knowledge, CRAC, CRAH, FM200, HFC125, Data center best practices, Industry standard methodology, Communication skills, Laws, Regulations, Policies, Technical manuals, Keyboard, Terminal, Teamwork, Open communication, Honesty, Transparency, Truthfulness",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Engineer 2",
      "company":"Daikin Comfort",
      "job_location":"Waller, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-2-at-daikin-comfort-3781959618",
      "search_city":"San Felipe",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"The Opportunity\nDaikin Comfort Technologies Manufacturing, L.P. is seeking a skilled individual for our Data Engineer 2 position at our DTTP - Waller, TX location. The Data Engineer is responsible to put in place the framework for a Modern, Simple, Accurate and Secure Data Environment that connects data across the company and sets data up as an asset to the company. Data Engineers will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Data engineers implement methods to improve data reliability and quality If you meet the qualifications listed below, then we invite you to apply for our open position by visiting our website at http\/\/careers.daikincomfort.com and submit your resume.\nAbout DTTP\nDaikin Texas Technology Park- has a footprint of 4.23 million square feet under a single roof, and is the third largest factory in the United States. Opened in 2017 as the manufacturing, logistics, and engineering center for Daikin's American subsidiary Goodman, the plant makes heating and air conditioning products sold under the Goodman, Amana, and Daikin brands.\nWhy work with us?\n>\nBenefits are effective on day one for all full-time direct hires\n>\nTraining programs are available to help guide team members and develop new skills\n>\nGrowth Opportunities - there are immense opportunities to grow your career\n>\nYou will be part of a Global Company - our family brands are backed by Daikin Industries, Ltd.\nMay include\nIdentify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS \u201a\u00c4\u00f2big data\u201a\u00c4\u00f4 technologies\nWork with stakeholders including the Executive, Manufacturing, Sales and Marketing teams to assist with data-related technical issues and support their data infrastructure needs\nWork with data and analytics experts to strive for greater functionality in our data systems\nDevelop ways to improve data quality, reliability, and efficiency\nPerform additional projects\/duties to support ongoing business needs\nNature & Scope\nWorks within knowledge\nReceives general objectives from the supervisor, consisting of work assignments, goals desired, and recommends sources of information that may assist in task completion\nWorks under the general supervision of the Director of IT receiving instructions as to the nature and scope of assignments and objectives to be achieved and receives advice on unusual or complex problems which deviate from basic policy\nKnowledge & Skills\nWorking knowledge of programming languages and applications & database apps and toolsAbility to apply good judgement, decision making skills including strong work ethics & integrity on the job\nAbility to work independently on multiple tasks and projects, with various teams including Engineering, Sales, IT, Finance, Marketing, Manufacturing, Logistics, etc.\nSolid collaboration abilities; professional & diplomatic team builder\nEffective organizational & time management skills including prioritization\nEffective written & verbal communication skills\nDemonstrated analytical, quantitative & creative problem solving skills\nExperience or specialization within Data Management \/ Data Science preferred but not necessary\nAbility to apply good judgement, decision making skills including strong work ethics & integrity on the job\nExperience\n3+ years\nEducation\nBachelor\u201a\u00c4\u00f4s degree in Engineering, Data Science, Computer Science or may consider equivalent & relevant work experience with formal training and certifications\nPhysical Requirements\/Work Environment\nMust be able to perform essential responsibilities with or without reasonable accommodations\nQualified Applicants must be legally authorized for employment in the United States. Qualified applicants will not require employer sponsored work authorization now or in the future for employment in the United States.\nThe Company provides equal employment opportunity to all employees and applicants regardless of a person\u201a\u00c4\u00f4s race, color, religion (including religious dress or grooming practices), creed, national origin (including language use restrictions), citizenship, uniform service member or veteran status, ancestry, disability, physical or mental disability (including HIV\/AIDS), medical condition (including cancer and genetic characteristics), genetic information, request for protected leave, marital status, sex, pregnancy, age (over 40), sexual orientation, gender, gender identity or expression, political affiliation, or any other characteristic protected by law. The Company will comply with all federal and state regulations and statutes pertaining to individuals with disabilities.\nShow more\nShow less",
      "job_skills":"Data Engineering, Big Data, AWS, SQL, Programming Languages, Database Applications, Data Management, Data Science, Analytics, Problem Solving, Communication Skills, Teamwork, Collaboration, Organizational Skills, Time Management, Engineering, Computer Science",
      "Category":"Cloud Security"
  },
  {
      "job_title":"BigData Scala & AWS Developer Richardson, TX(Hybrid)",
      "company":"The Dignify Solutions, LLC",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/bigdata-scala-aws-developer-richardson-tx-hybrid-at-the-dignify-solutions-llc-3769520887",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"8+ Years of Development Experience in Big Data Scala\/Spark\nExpert level Scala development skill is a must have!\n2+ Years of Experience in AWS native tools such as Lambda, Glue, EMR, Cloudwatch, SNS, S3, EC2, API Gateway and Terraform\nExpertise in large Data processing (Extract, Transform and Provisioning) in different file formats\nShow more\nShow less",
      "job_skills":"Scala, Spark, AWS, Lambda, Glue, EMR, Cloudwatch, SNS, S3, EC2, API Gateway, Terraform, Data processing, Data extraction, Data transformation, Data provisioning",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Scientist",
      "company":"InfoVision Inc.",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-infovision-inc-3783947096",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Requirement:\n10+ years of IT experience.\nIndependently create and\/or Assist lead data scientists in developing various kinds of machine learning models for personalized customer service domain using state of the art ML algorithms such as GBM, XGBoost, Deep Learning etc. on CPU and GPU environments\nConduct pre-modeling activities such as data clean up, exploratory data analysis, scaling\/normalization, feature engineering, etc. with data in Google Cloud Platform ecosystem, notebooks\nProficient with standard Data Science Libraries such as NumPy, Pandas and Deep learning. In addition, proficiency in libraries for GPUs is a huge plus\nKnowledge of Pytorch or Tensorflow and experience with modern neural NLP approaches is a plus.\nDeveloping test cases and executing test cases for developed ML models\nAssist in performance\/load testing\/monitoring of the deployed models\nDocumenting the models, features and any decisions made during modeling\nAssist ML engineers during solution deployment on on-prem and AWS for authoring\/making changes to API wrappers\nAbility to rapidly learn the current state of the project and independently work with minimal assistance after the initial ramp up time\nShow more\nShow less",
      "job_skills":"Machine Learning, Natural Language Processing, Data Science, GBM, XGBoost, Deep Learning, NumPy, Pandas, Pytorch, Tensorflow, AWS, API, Cloud Platform",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Advanced Hires",
      "job_location":"Creve Coeur, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-advanced-hires-3784368665",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Title:\nSenior Data Engineer\nLocation:\n100% Remote\nDuration:\nLong term contract\nWhat you will do is why you should join us:\nBe a critical senior member of a data engineering team focused on creating distributed analysis capabilities around a large variety of datasets\nTake pride in software craftsmanship, apply a deep knowledge of algorithms and data structures to continuously improve and innovate\nWork with other top-level talent solving a wide range of complex and unique challenges that have real world impact\nExplore relevant technology stacks to find the best fit for each dataset\nPursue opportunities to present our work at relevant technical conferences\nProject your talent into relevant projects. Strength of ideas trumps position on an org chart\nIf you share our values, you should have:\nAt least 7 years\u201a\u00c4\u00f4 experience in software engineering\nAt least 2 years\u201a\u00c4\u00f4 experience with Go\nProven experience (2 years) building and maintaining data-intensive APIs using a RESTful approach\nExperience with stream processing using Apache Kafka\nA level of comfort with Unit Testing and Test-Driven Development methodologies\nFamiliarity with creating and maintaining containerized application deployments with a platform like Docker\nA proven ability to build and maintain cloud-based infrastructure on a major cloud provider like AWS, Azure or Google Cloud Platform\nExperience data modeling for large scale databases, either relational or NoSQL\nBonus points for:\nExperience with protocol buffers and gRPC\nExperience with: Google Cloud Platform, Apache Beam and or Google Cloud Dataflow, Google Kubernetes Engine or Kubernetes\nExperience working with scientific datasets, or a background in the application of quantitative science to business problems\nBioinformatics experience, especially large-scale storage and data mining of variant data, variant annotation, and genotype to phenotype correlation\nThis is a remote position.\nShow more\nShow less",
      "job_skills":"Data Engineering, Software Craftsmanship, Algorithms, Data Structures, Go, RESTful APIs, Apache Kafka, Unit Testing, TestDriven Development, Containerized Applications, Docker, Cloud Infrastructure, AWS, Azure, Google Cloud Platform, Data Modeling, Relational Databases, NoSQL Databases, Protocol Buffers, gRPC, Google Cloud Platform, Apache Beam, Google Cloud Dataflow, Google Kubernetes Engine, Kubernetes, Scientific Datasets, Bioinformatics, Variant Data, Variant Annotation, Genotype to Phenotype Correlation",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Engineer - Scala(U.S. remote)",
      "company":"Railroad19",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-scala-u-s-remote-at-railroad19-3782294502",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Railroad19, Inc.\nis hiring\nremote\nSenior Data Engineers\nto be a solid technical resource on a dynamic and growing team of accomplished engineers.\nOur ideal candidate is passionate about creating well-architected solutions containing thoroughly tested code. The ability to communicate effectively and develop relationships by empathizing with client goals is a highly valued skill within our company culture.\nCore Responsibilities:\nDevelop new and enhance existing application services\nWriting tests to maintain code quality\nUnderstand and adapt to our client's evolving business requirements within the television advertising domain.\nParticipate in detailed technical design sessions to understand client needs and provide productive feedback\nIdentify new opportunities, tools, and services to enhance the software platform\nSupport and troubleshoot issues, identify the root cause, and proactively recommend corrective actions\nSkills & Experience:\nScala 2.12 + development experience\nPassionate about developing clean and maintainable code with little or no side-effects\nExperience building Restful APIs in Scala using Spark 2.4\nStrong hands-on experience with AWS running spark jobs on ephemeral EMR clusters on AWS and S3.\nExperience with relational and non-relational databases\nWillingness to learn new technologies and takes pride in keeping up with the latest technologies and practices within the Scala and Spark development community\nExcellent oral and written communication skills\nStrong analytical and problem-solving skills\nSelf-directed and can effectively deliver solutions with little oversight\nA bachelor's or master's degree in computer science, computer engineering, or other technical disciplines or equivalent work experience is preferred but not required.\n$120,000 - $160,000 a year\nSalary is commensurate with experience.\nWe are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal-opportunity workplace.\n#Hiringnow\nWe are actively hiring (Data Engineers)\n#remote #Scala #DataEngineering #ApacheSpark\nShow more\nShow less",
      "job_skills":"Scala, Spark, AWS, EMR, S3, Restful APIs, Relational databases, Nonrelational databases",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Engineer",
      "company":"Barry-Wehmiller Design Group",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-at-barry-wehmiller-design-group-3786849642",
      "search_city":"Collinsville",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Who You\u201a\u00c4\u00f4ll Work With\nYou will join one of our 45 offices in the US, be part of a committed team of over 1500 professionals, and work in teams and directly with our clients doing work that is shaping the world around us. You will be welcomed into a rapidly growing business and team and empowered to make an impact. You will be valued, cared for, and challenged on your path to becoming a world-class professional consultant and surrounded by leaders who are committed to creating an environment that enables you to realize your own success and fulfillment.\nWhen you join Design Group as a Data Engineer, you are joining a team that will challenge you and position you for growth. In this role, you will work with a team of industry experts to help the world\u201a\u00c4\u00f4s leading companies solve their most difficult problems. You will partner with seasoned leaders, technical specialists, and subject matter experts to deliver the highest quality solutions to our clients with consistency and accuracy.\nWhat You\u201a\u00c4\u00f4ll Do\nDesign, develop, and maintain cloud data infrastructure leveraging technologies like Azure SQL Database, Azure Data Lakes, and Azure Synapse Analytics to enable advanced analytics (AWS experience is acceptable)\nBuild scalable cloud data solutions and pipelines for big data sources and large datasets using services like Azure Synapse Spark Pools, Azure Data Pipelines, Azure Data Lakes, and Spark Notebooks.\nCreate optimized data models, efficient ETL\/ELT logic, transformations, and metadata to structure and relate data for business insights.\nAutomate and schedule regular data integrations from transactional systems, on-prem data warehouses, enterprise databases and SaaS applications into high performance cloud data platforms.\nImplement data quality checks, validation processes, error handling, partitioning, security, and resilience capabilities into data solutions based on requirements.\nSupport migration initiatives to move on-premises data and BI systems into cloud data lakehouses, data lakes and other cloud analytics services.\nWhat You\u201a\u00c4\u00f4ll Bring\n0-2 years\u201a\u00c4\u00f4 experience as a data engineer, ETL developer, or similar role (internships experience included).\nExperience with cloud data technologies (Azure preferred) such as Azure Synapse Analytics and Spark Pools.\nStrong expertise with SQL and Python. Exposure to DAX and M preferred.\nFamiliarity with PowerBI or Tableau is a plus.\nExperience utilizing structured and unstructured data.\nKnowledge of data modeling, warehousing principles, ETL\/ELT, and metadata standards.\nUnderstanding of CI\/CD pipelines and DevOps processes is a plus.\nAbility to relate data opportunities to business needs.\nStrong communication, collaboration, curiosity, and perseverance skills.\nAnalytical mindset with problem solving and troubleshooting skills.\nBachelor\u201a\u00c4\u00f4s degree in Computer Science, Analytics, Information Systems or similar field required.\nOur culture and commitment to our people is what sets us apart. We foster an environment of mutual respect, integrity, and unconditional interest in the individual and collective success of our professionals. Our model and entrepreneurial mindset offer a rewarding, challenging, and highly flexible path. As an Application Support Analyst, you will build a meaningful and fulfilling career with the support of professional development resources and mentorships including our First Year Experience program, Individual Development Plans, and Career Path resources and tools. You will be surrounded by exceptional talent who will support your development as both a world-class professional and a highly effective leader.\nShow more\nShow less",
      "job_skills":"Azure SQL Database, Azure Data Lakes, Azure Synapse Analytics, AWS, Azure Synapse Spark Pools, Azure Data Pipelines, Spark Notebooks, ETL, ELT, DAX, M, PowerBI, Tableau, CI\/CD, DevOps, Data Modeling, Warehousing, Metadata",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Advanced Hires",
      "job_location":"Creve Coeur, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-advanced-hires-3784368665",
      "search_city":"Collinsville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Title:\nSenior Data Engineer\nLocation:\n100% Remote\nDuration:\nLong term contract\nWhat you will do is why you should join us:\nBe a critical senior member of a data engineering team focused on creating distributed analysis capabilities around a large variety of datasets\nTake pride in software craftsmanship, apply a deep knowledge of algorithms and data structures to continuously improve and innovate\nWork with other top-level talent solving a wide range of complex and unique challenges that have real world impact\nExplore relevant technology stacks to find the best fit for each dataset\nPursue opportunities to present our work at relevant technical conferences\nProject your talent into relevant projects. Strength of ideas trumps position on an org chart\nIf you share our values, you should have:\nAt least 7 years\u201a\u00c4\u00f4 experience in software engineering\nAt least 2 years\u201a\u00c4\u00f4 experience with Go\nProven experience (2 years) building and maintaining data-intensive APIs using a RESTful approach\nExperience with stream processing using Apache Kafka\nA level of comfort with Unit Testing and Test-Driven Development methodologies\nFamiliarity with creating and maintaining containerized application deployments with a platform like Docker\nA proven ability to build and maintain cloud-based infrastructure on a major cloud provider like AWS, Azure or Google Cloud Platform\nExperience data modeling for large scale databases, either relational or NoSQL\nBonus points for:\nExperience with protocol buffers and gRPC\nExperience with: Google Cloud Platform, Apache Beam and or Google Cloud Dataflow, Google Kubernetes Engine or Kubernetes\nExperience working with scientific datasets, or a background in the application of quantitative science to business problems\nBioinformatics experience, especially large-scale storage and data mining of variant data, variant annotation, and genotype to phenotype correlation\nThis is a remote position.\nShow more\nShow less",
      "job_skills":"Data engineering, Software engineering, Go, RESTful API development, Apache Kafka, Unit testing, Testdriven development, Docker, Cloud infrastructure, AWS, Azure, Google Cloud Platform, Data modeling, Relational databases, NoSQL databases, Protocol buffers, gRPC, Google Cloud Platform, Apache Beam, Google Cloud Dataflow, Google Kubernetes Engine, Kubernetes, Scientific datasets, Quantitative science, Bioinformatics, Variant data, Variant annotation, Genotype to phenotype correlation",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"TekWissen \u00ac\u00c6",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-tekwissen-%C2%AE-3782890075",
      "search_city":"Cahokia",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Overview:\nTekwissen Group, is a workforce management provider throughout the USA and many other countries in the world. This client is a German multinational Pharmaceutical and biotechnology company and one of the largest pharmaceutical companies in the world, headquartered in Leverkusen, and areas of business include pharmaceuticals; consumer healthcare products, agricultural chemicals, seeds and biotechnology products.\nJob Title: Senior Data Engineer\nLocation: St Louis, MO, 63146\nDuration: 12 Months\nJob Type: Contract\nWork Type: Remote\nJob Description:\nWhat you will do is why you should join us:\nBe a critical senior member of a data engineering team focused on creating distributed analysis capabilities around a large variety of datasets\nTake pride in software craftsmanship, apply a deep knowledge of algorithms and data structures to continuously improve and innovate\nWork with other top-level talent solving a wide range of complex and unique challenges that have real world impact\nExplore relevant technology stacks to find the best fit for each dataset\nPursue opportunities to present our work at relevant technical conferences\nProject your talent into relevant projects. Strength of ideas trumps position on an org chart\nIf you share our values, you should have:\nAt least 7 years' experience in software engineering\nAt least 2 years' experience with Go\nProven experience (2 years) building and maintaining data-intensive APIs using a RESTful approach\nExperience with stream processing using Apache Kafka\nA level of comfort with Unit Testing and Test Driven Development methodologies\nFamiliarity with creating and maintaining containerized application deployments with a platform like Docker\nA proven ability to build and maintain cloud-based infrastructure on a major cloud provider like AWS, Azure or Google Cloud Platform\nExperience data modelling for large scale databases, either relational or NoSQL\nBonus points for:\nExperience with protocol buffers and gRPC\nExperience with: Google Cloud Platform, Apache Beam and or Google Cloud Dataflow, Google Kubernetes Engine or Kubernetes\nExperience working with scientific datasets, or a background in the application of quantitative science to business problems\nBioinformatics experience, especially large-scale storage and data mining of variant data, variant annotation, and genotype to phenotype correlation\nTekWissen Group is an equal opportunity employer supporting workforce diversity.\nShow more\nShow less",
      "job_skills":"Software Engineering, Go, RESTful APIs, Apache Kafka, Unit Testing, Test Driven Development, Docker, AWS, Azure, Google Cloud Platform, Data Modelling, Protocol buffers, gRPC, Google Cloud Dataflow, Google Kubernetes Engine, Kubernetes, Bioinformatics, Variant Annotation, Genotype Phenotype Correlation",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Sr Data Engineer",
      "company":"Diverse Lynx",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-at-diverse-lynx-3682304958",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Role - Sr Data Engineer\nLocation \u201a\u00c4\u00ec Houston, USA (Onsite, Hybrid)\nDuration \u201a\u00c4\u00ec Contract\nJob Description\nThe Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.\nResponsibilities for Data Engineer\nCreate and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional \/ non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data technologies.\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\nWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.\nCreate data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\nWork with data and analytics experts to strive for greater functionality in our data systems.\nQualifications For Data Engineer\nAdvanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing big data data pipelines, architectures and data sets.\nExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets.\nBuild processes supporting data transformation, data structures, metadata, dependency and workload management.\nA successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable big data data stores.\nStrong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment.\nDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\nShow more\nShow less",
      "job_skills":"SQL, Relational Databases, Data Pipelines, Big Data Technologies, AWS, Analytics Tools, Data Systems, Data Structures, Metadata, Dependency Management, Workload Management, Data Transformation, Data Extraction, Message Queuing, Stream Processing, Big Data Data Stores",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Principal Data Engineer North Dallas or Detroit Metro",
      "company":"Comerica Bank",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-data-engineer-north-dallas-or-detroit-metro-at-comerica-bank-3787966287",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Principal Data Engineer\nThe Principal Data Engineer will provide data engineering and architecture support for complex Data management activities related to system software, hardware, performance, problem determination or resource management requiring communication and coordination with vendors, technicians, clients, and management. Provide technical input to management decision making in the areas of software, hardware, and performance. Responsibilities include performing detailed analysis of various projects and requests; developing designs for projects that have medium to high complexity; formulating procedures; monitoring key performance indicators; and implementing advanced business solutions. This role may also integrate Data solutions or build via DevOps.\nThe Principal Data Engineer will develop strong collaborative relationships with key technology and data teams and will be responsible for data modeling, applying data quality rules & standards, leveraging the latest technologies, and performing proof-of-concept tasks to evaluate new data systems, products, and data source performance. This role will also assist development teams, troubleshoot with data ingestion, and manage ELT\/ETL extraction needs and issues.\nPosition Responsibilities\nDesign and Methodology\nWork closely with business units, application teams, infrastructure areas and vendors to identity, review and evaluate the solution requirements.\nInvestigate and propose strategic fits for virtualization, consolidation and rationalization solution opportunities within the infrastructure or business. Propose changes to the technical architecture and design solutions as applicable.\nEvaluate and align strategic fit solutions across infrastructure platforms and solutions specific to system hardware and software technologies.\nUnderstand, participate, review and influence long term capacity planning and technology investments.\nTechnical Consulting\nProvide Client consulting and planning guidance as applicable for moderate to large highly complex projects\/programs.\nProvide consultation and works closely with other functional infrastructure areas\/departments on multiple initiatives to meet common organizational \/ business goals and objectives.\nParticipate in and provides consulting to project teams on architectural, design development, integration opportunities, planning of highly complex systems and assures it is aligned to our established strategies, guiding principles, rationales and practices.\nPlanning and Organizing\nIdentify and evaluate projects\/programs\/initiatives and design processes that enhance and rationalize existing and upcoming solutions.\nMap requirements into standard services solution, identity opportunities for integrating to existing or reuse technology and provide cost effective solutions for moderate to large highly complex project\/programs\/initiatives.\nReview, identify and manage requirements for moderate to complex solutions and do a cost value, feasibility and risk analysis.\nRisk Management\nReview, participate, develop and update architectural standards, guiding principles, rationales and strategies.\nEvaluate, review and approve highly complex design solutions for business and Infrastructure project or programs or initiatives.\nPosition Qualifications\nBachelor's degree in computer science, engineering or in a technology related field, OR equivalent through a combination of education and\/or technology experience, OR 12 years of technology experience\n6 years of Technology experience\n7 years in identifying technical solutions for complex business problems, identifying the benefits and risks of the solutions and providing recommendations\n5 years of experience mentoring another technologist\n4 years of experience working in enterprise data warehouse solutions and platforms, and working knowledge of different databases (e.g., SQL & NoSQL), S3 Datalake, CICD, Jenkins and AWS cloud technologies\n4 years of experience independently administering, managing compute & storage, applying best practices for schema, table, DDL creations, querying, evaluating load operations & performance, monitoring, cost effective solutions for RDS and Snowflake database systems & tools\n4 years of data governance experience, including column-level data security using secure views and dynamic data masking features, define & implement RBAC secure access to objects\n4 years of experience supporting production database systems, CDC, scheduling backup & recovery, archiving, replication, and Disaster Recovery management\nThis position is not eligible for sponsorship. Must have indefinite employment authorization\nPlano8:00am - 5:00pm Monday - Friday\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Architecture, Data Management, System Software, Hardware, Performance, Problem Determination, Resource Management, DevOps, Data Modeling, Data Quality, ProofofConcept, Data Systems, Data Products, Data Source Performance, ELT\/ETL Extraction, Virtualization, Consolidation, Rationalization, Technical Consulting, Project Planning, Risk Management, AWS Cloud Technologies, RDS, Snowflake, Data Governance, Data Security, RBAC, CDC, Backup & Recovery, Archiving, Replication, Disaster Recovery",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Sr. Data Analyst || Hybrid Role (Smithfield, RI, Durham, NC, or Westlake, TX)",
      "company":"Steneral Consulting",
      "job_location":"Westlake, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-hybrid-role-smithfield-ri-durham-nc-or-westlake-tx-at-steneral-consulting-3647813123",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Title: Sr. Data Analyst\nLocation: hybrid 5 days onsite\/month. Smithfield, RI, Durham, NC, or Westlake, TX!\nDuration: Through end of 2023, possible extension\nWe are currently sourcing for a Sr. Data Analyst to work at Fidelity's location in Smithfield, RI, Durham, NC, or Westlake, TX!\nMust Have\n7+ years experience with Data Modeling\n5+ years experience working with Data Warehouse\nExperience working with AWS\nNice To Have\nFinancial industry exposure would be really nice to have since this would really help when talking to our business stakeholders\nExperience working with Data Lakes within Snowflake\nShow more\nShow less",
      "job_skills":"Data Modeling, Data Warehouse, AWS, Data Lakes, Snowflake",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Engineer 2",
      "company":"Daikin Comfort",
      "job_location":"Waller, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-2-at-daikin-comfort-3781959618",
      "search_city":"San Felipe",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"The Opportunity\nDaikin Comfort Technologies Manufacturing, L.P. is seeking a skilled individual for our Data Engineer 2 position at our DTTP - Waller, TX location. The Data Engineer is responsible to put in place the framework for a Modern, Simple, Accurate and Secure Data Environment that connects data across the company and sets data up as an asset to the company. Data Engineers will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Data engineers implement methods to improve data reliability and quality If you meet the qualifications listed below, then we invite you to apply for our open position by visiting our website at http\/\/careers.daikincomfort.com and submit your resume.\nAbout DTTP\nDaikin Texas Technology Park- has a footprint of 4.23 million square feet under a single roof, and is the third largest factory in the United States. Opened in 2017 as the manufacturing, logistics, and engineering center for Daikin's American subsidiary Goodman, the plant makes heating and air conditioning products sold under the Goodman, Amana, and Daikin brands.\nWhy work with us?\n>\nBenefits are effective on day one for all full-time direct hires\n>\nTraining programs are available to help guide team members and develop new skills\n>\nGrowth Opportunities - there are immense opportunities to grow your career\n>\nYou will be part of a Global Company - our family brands are backed by Daikin Industries, Ltd.\nMay include\nIdentify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS \u201a\u00c4\u00f2big data\u201a\u00c4\u00f4 technologies\nWork with stakeholders including the Executive, Manufacturing, Sales and Marketing teams to assist with data-related technical issues and support their data infrastructure needs\nWork with data and analytics experts to strive for greater functionality in our data systems\nDevelop ways to improve data quality, reliability, and efficiency\nPerform additional projects\/duties to support ongoing business needs\nNature & Scope\nWorks within knowledge\nReceives general objectives from the supervisor, consisting of work assignments, goals desired, and recommends sources of information that may assist in task completion\nWorks under the general supervision of the Director of IT receiving instructions as to the nature and scope of assignments and objectives to be achieved and receives advice on unusual or complex problems which deviate from basic policy\nKnowledge & Skills\nWorking knowledge of programming languages and applications & database apps and toolsAbility to apply good judgement, decision making skills including strong work ethics & integrity on the job\nAbility to work independently on multiple tasks and projects, with various teams including Engineering, Sales, IT, Finance, Marketing, Manufacturing, Logistics, etc.\nSolid collaboration abilities; professional & diplomatic team builder\nEffective organizational & time management skills including prioritization\nEffective written & verbal communication skills\nDemonstrated analytical, quantitative & creative problem solving skills\nExperience or specialization within Data Management \/ Data Science preferred but not necessary\nAbility to apply good judgement, decision making skills including strong work ethics & integrity on the job\nExperience\n3+ years\nEducation\nBachelor\u201a\u00c4\u00f4s degree in Engineering, Data Science, Computer Science or may consider equivalent & relevant work experience with formal training and certifications\nPhysical Requirements\/Work Environment\nMust be able to perform essential responsibilities with or without reasonable accommodations\nQualified Applicants must be legally authorized for employment in the United States. Qualified applicants will not require employer sponsored work authorization now or in the future for employment in the United States.\nThe Company provides equal employment opportunity to all employees and applicants regardless of a person\u201a\u00c4\u00f4s race, color, religion (including religious dress or grooming practices), creed, national origin (including language use restrictions), citizenship, uniform service member or veteran status, ancestry, disability, physical or mental disability (including HIV\/AIDS), medical condition (including cancer and genetic characteristics), genetic information, request for protected leave, marital status, sex, pregnancy, age (over 40), sexual orientation, gender, gender identity or expression, political affiliation, or any other characteristic protected by law. The Company will comply with all federal and state regulations and statutes pertaining to individuals with disabilities.\nShow more\nShow less",
      "job_skills":"Data Engineering, SQL, AWS, Big Data, Data Quality, Data Extraction, Data Transformation, Data Loading, IT, Programming Languages, Database Applications & Tools, Decision Making, Problem Solving, Communication Skills, Collaboration, Data Science, Data Management, Analytics",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Engineer III",
      "company":"VRK IT Vision Inc.",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-iii-at-vrk-it-vision-inc-3677424570",
      "search_city":"Stroudsburg",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title:- Data Engineer III\nLocation:- Houston TX (Hybrid 3 Days\/week On-Site)\nJob Type:- Long Term Contract\nNeed Local and Senior 12+ Years\nNeed Oil & Gas Background\nSkills\nThe Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.\nResponsibilities for Data Engineer Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional \/ non-functional business requirements.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data technologies.\nBuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\nWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.\nCreate data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\nWork with data and analytics experts to strive for greater functionality in our data systems.\nQualifications for Data Engineer Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\nExperience building and optimizing big data data pipelines, architectures and data sets.\nExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\nStrong analytic skills related to working with unstructured datasets.\nBuild processes supporting data transformation, data structures, metadata, dependency and workload management.\nA successful history of manipulating, processing and extracting value from large disconnected datasets.\nWorking knowledge of message queuing, stream processing, and highly scalable big data data stores.\nStrong project management and organizational skills.\nExperience supporting and working with cross-functional teams in a dynamic environment\nRequired Skills\nBasic Qualification :\nAdditional Skills\nBackground Check :Yes\nShow more\nShow less",
      "job_skills":"SQL, AWS, Big Data, Data Pipelines, Data Transformation, Data Extraction, Data Loading, Analytics, Data Architecture, Data Structures, Metadata, Dependency Management, Workload Management, Message Queuing, Stream Processing, Scalable Data Stores, Project Management, CrossFunctional Teams",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Big Data Engineer",
      "company":"Optomi",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-engineer-at-optomi-3766938892",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Big-Data Engineer:\nOptomi, in partnership with a leader in Automotive Technology, is looking for a creative problem solver who enjoys collaborating with other software engineers, ML Engineers, and Data Scientists. This role is remote but candidates need to be in the DFW area. The ideal candidate will have Data Engineering experience with heavy software engineering skills and experience using Spark, Scala, Terraform, and AWS cloud tools.\nSummary:\nWe are inviting applications for software\/big-data engineering professionals with proven experience building big-data solutions leveraging cutting edge technologies such as AWS (EMR, Redshift, Glue, Athena, Lamda, CloudFormation), Terraform, GraphQL, Spark, Databricks, and Kubernetes.\nResponsibilities:\nLead the design of scalable big data platforms\/solutions used to ingest and process large volumes of financial\/capital markets data\nDevelop and automate large scale, high-performance, scalable platform (batch and\/or streaming) to drive faster analytics.\nBuild and maintain custom frameworks to support engineering\/analytics needs.\nPartner with analytic consumers and data scientists to build and improve new\/existing constructs and solve data engineering problems at scale.\nDeploy inclusive data quality checks to ensure high quality of data.\nEvangelize high quality software engineering practices towards building data infrastructure and pipelines at scale.\nQualifications:\n4+ years of experience as a Data Engineer or in a similar role working with large petabyte size data sets.\nExperience writing clean, concise, tested & maintainable code in Spark Scala.\nExperience with SQL, data modeling, data warehousing, and building ETL pipelines.\nExperience building and deploying applications in AWS.\nProven track record of independently delivering big data solutions.\nKnowledge of continuous integration, testing methodologies, TDD and agile development methodologies.\nExposure to structured or unstructured storage and distributed caching.\nExperience in open-source technologies is plus.\nStructured thinking with ability to easily break down ambiguous problems and propose impactful solutions.\nYou can manage ambiguity and are comfortable being set loose without a lot of direction\nBenefits:\nRemote work environment\nAdvanced team using advanced tech\nCool industry and competitive pay\nShow more\nShow less",
      "job_skills":"Data Engineering, Spark, Scala, Terraform, AWS, EMR, Redshift, Glue, Athena, Lamda, CloudFormation, GraphQL, Databricks, Kubernetes, SQL, Structured Query Language (SQL), Data Warehousing, ETL Pipelines, Continuous Integration, Testing Methodologies, TDD, Agile Development, Structured Storage, Unstructured Storage, Distributed Caching, OpenSource Technologies",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Sr. Data & ETL Platform Engineer",
      "company":"Corebridge Financial",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-etl-platform-engineer-at-corebridge-financial-3706383620",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Who We Are\nCorebridge Financial helps people make some of the most meaningful decisions they\u201a\u00c4\u00f4re ever going to make. We help them plan and take action to protect the future they envision, and respond to some of life\u201a\u00c4\u00f4s most difficult moments through the solutions and services we provide. We do this through our broad portfolio of life insurance, retirement and institutional products, offered through an extensive, multichannel distribution network. We provide solutions for a brighter future through our client centered service, breadth of product expertise, deep distribution relationships, and outstanding team of hardworking and passionate employees.\nAbout The Role\nAs a Sr. Data & ETL Platform Engineer you will be responsible for leading, influencing AIG\u201a\u00c4\u00f4s Datahub platform to address needs of all enterprise datasets at AIG. You will engineer for reliability, scalability, performance, observability and supportability of enterprise Datahub environment.\nIn this role, you will be responsible for administering, supporting, monitoring the entire technology stacks of Datahub environment. This involves the management and administration of enterprise Datahubs, including IT Data Lake and Worker Datahub. You will be responsible for maturing implementation of Datahub services, and to maintain a highly secure and reliable operational environment. You will be current in Datahub best practices and apply them to the environment to continuously improve performance, scalability, and proactively manage capacity of the environment.\nThis role provides an opportunity to make a significant impact across L&R and to define Datahub technology roadmaps. This senior leadership role requires extensive experience and is hands-on along with requiring the candidate to lead and influence a small team. The candidate will act as Datahub thought leader and interface with Architecture and Engineering teams, IT Security, and Production Operations to design and implement transformational improvements. The technologies you will manage include but are not limited to the following: Data Stage, Talend, AWS EMR, Snowflake, Oracle, SQL Server and AWS database services.\nPlease note:\nThe job can only be performed in the State locations listed: Houston, TX and Remote-TX.\nThe Senior Datahub Engineer\nis expected to perform the following duties:\nLeading the engineering, design, development, and launch of high available, low latency, flexible and scalable Datahub services.\nSignificantly influence overall strategy by helping define features, drive the system architecture, and spearhead the best practices that enable quality product and services.\nDesign and implement service data models, ETL process, caching models and APIs.\nPromoting infrastructure as code and helping teams to shift to an automated deployment process\nResponsible for improving the performance, reliability, and observability of the Datahub platform\nDesign, build, and maintain highly scalable and reliable data integration layer\nContribute to the design and documentation of the Datahub system architecture\nTroubleshoot and resolve production issues across services and multiple layers of the stack\nMaintain a high level of code quality and testing\nExtending service monitoring capabilities and publicly available data such as uptime and performance metrics\nExpanding the Datahub application and services for availability and redundancy\nMaintaining back end services and data stores to power the Datahub application\nDevelop and oversee monitoring systems to measure usage and ensure operational stability.\nMonitor the process during the entire lifecycle for adherence and updating or creating new process for improvement and cost effectiveness.\nExcellent communication, conceptual, critical thinking, analytical, problem-solving abilities, and organizational skills.\nComplex Problem Solving \u201a\u00c4\u00ec Identifying complex problems and reviewing related information to develop and evaluate options and implement solutions.\nPrimary Technical Skills\nETL Tools: Talend, IBM DataStage, AWS EMR\nCloud: AWS\nSecondary Technical Skills\nData: SQL (Snowflake, Oracle)\nPosition Requirements\n10+ years\nHands-on Administration experience with ETL tools like Talend, DataStage and AWS EMR or Hadoop\nTechnical experience in troubleshooting and ITIL process and practices\n7+ years\nAdministration expertise in Talend, IBM DataStage and AWS EMR or Hadoop\nExperience supporting infrastructure and applications hosted in AWS or Azure\nExperience establishing and maturing ETL and High availability best practices\nStrong proficiency in AWS services, particularly EMR and related big data technologies (Hadoop, Hive, Spark, etc.)\nSound knowledge of database management, SQL querying, data modeling, data warehousing, business intelligence, and OLAP (Online Analytical Processing)\nExperience managing\/working with Windows \/ Linux infrastructure teams\nExperience in creating disaster recovery plans for both on-premise and cloud infrastructures\nExcellent communication, conceptual, critical thinking, analytical, problem-solving abilities, and organizational skills\nComplex Problem Solving \u201a\u00c4\u00ec Identifying complex problems and reviewing related information to develop and evaluate options and implement solutions.\nComfortable leading discussions with leadership and have experience tailoring the level of technical details to suit the audience\nExperience with leading a team\nPreferred\/Plus Experience\nBatchelor\u201a\u00c4\u00f4s degree in Computer Science, Information Technology, or related\n5 years Proven experience as a Platform Engineer or similar role with a focus on ETL tools and big data technologies.\nFamiliarity with Administering reporting tools is a plus.\nStrong background with Public Cloud Infrastructure management\nExcellent problem-solving skills and the ability to work in a dynamic, collaborative environment\nExperience with Cloud Cost Management, Demand Forecasting, Budget forecasting, Capacity management, Chargeback mechanism\nWhat our employees like most about working for Corebridge Financial\nWe care about your professional development. Our career progression program will provide you with the opportunity to develop your skills, strengthen your productivity and be eligible to progressively advance to positions with an increased responsibility and increased compensation.\nOur \u201a\u00c4\u00faGiving Back\u201a\u00c4\u00f9 policy is at the core of our daily operations and guides our future progress. Don\u201a\u00c4\u00f4t believe us? We put our money where our mouth is! Corebridge Financial will give you up to 16 hours a year paid time off to volunteer in the community.\nOur people are our most important asset therefore we provide a generous benefits plan and competitive pay. Benefit package includes:\nPaid Time Off (Corebridge Financial recognizes the importance of work life balance). We offer 24 PTO days to start. YES, 24! 17 paid holidays per calendar year.\nA 401(k) Retirement Plan which will be HARD TO BEAT. Our 401K - $1 for $1 match up to 6% with immediate vesting, plus Corebridge Financial automatically contributes an additional 3% into your 401K regardless of if you enroll or not.\nWe are an Equal Opportunity Employer\nCorebridge Financial, Inc., its subsidiaries and affiliates are committed to be an Equal Opportunity Employer and its policies and procedures reflect this commitment. We provide equal opportunity to all qualified individuals regardless of race, color, religion, age, gender, gender expression, national origin, veteran status, disability or any other legally protected categories such as sexual orientation. At Corebridge Financial, we believe that diversity and inclusion are critical to our future and our mission \u201a\u00c4\u00ec creating a foundation for a creative workplace that leads to innovation, growth, and profitability. Through a wide variety of programs and initiatives, we invest in each employee, seeking to ensure that our people are not only respected as individuals, but also truly valued for their unique perspectives.\nTo learn more please visit: www.corebridgefinancial.com\nCorebridge Financial is committed to working with and providing reasonable accommodations to job applicants and employees with physical or mental disabilities. If you believe you need a reasonable accommodation in order to search for a job opening or to complete any part of the application or hiring process, please send an email to TalentandInclusion@corebridgefinancial.com. Reasonable accommodations will be determined on a case-by-case basis.\nFunctional Area\nIT - Information Technology\nEstimated Travel Percentage (%): No Travel\nRelocation Provided: No\nAmerican General Life Insurance Company\nShow more\nShow less",
      "job_skills":"ETL, Talend, DataStage, AWS EMR, SQL, Snowflake, Oracle, AWS, Hadoop, Hive, Spark, OLAP, Linux, Windows, Cloud Cost Management, Demand Forecasting, Budget forecasting, Capacity management, Chargeback mechanism",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"Brookwood Search & Selection",
      "job_location":"Texas, United States",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-brookwood-search-selection-3782726725",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Lead Data Engineer - Up to $230k + bonus (depending on experience)\nLocation: Texas (Remote)\nJoin a robust and growing consultancy that offers end-to-end solutions for their clients, digitally transforming their business, solving IT challenges, and improving ROI on data and technology.\nYou will be part of a cross functional team, leading engineering practices in implementing new technologies and delivering end-to-end solutions. As a leader on projects, you will engage with internal and external stakeholders, understanding requirements and long-term strategy to increase value gained from data. Be part of commercial element of the business ensuring project success through risk analysis and mitigation strategies.\nRequirements:\n5+ years' experience in a data engineering position\nMasters in data, maths, physics, computer science or related degree\nStrong track record of working with various data platforms (SQL, SSIS, Postgres, Oracle, etc)\nExperience as a project lead to completion\n3+ years' experience with commercial experience with Azure, GCP, or AWS\nExperienced with data visualisation tools\nApply now!\nShow more\nShow less",
      "job_skills":"Data Engineering, SQL, SSIS, Postgres, Oracle, Azure, GCP, AWS, Data Visualization",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Business Analyst",
      "company":"Kforce Inc",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-business-analyst-at-kforce-inc-3785040955",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nKforce has a client that is seeking a Data Business Analyst in Irving, TX. Responsibilities:\nData Business Analyst will design and develop the data ingestion architecture for all incoming data from various sources into a single warehouse solution\nAutomate data infrastructure and pipelines\nDesign our data warehouse solution for scale with a keen eye on optimizing data infrastructure\nBuild and maintain scalable ETL pipelines to efficiently process and maintain large data volumes\nWork with our engineering teams to ensure robust implementation across all areas of product\nAs a Data Business Analyst, you will partner with business stakeholders to gather and synthesize data requirements\nImplement monitoring tools and practices to ensure high data quality and stability\nArticulate and implement best practices around data ingestion frameworks and pipeline development\nRequirements\nBachelor's degree or equivalent experience required; Preferred Major: MIS or Computer Science\nData Engineer that has at least 4-6 years of experience in managing large complex data sources\nMinimum 4-6 years of experience in a Data Engineering role, managing large volumes of data\nBackground in Data Engineering, 4+ years of experience building and maintaining scalable data infrastructure, including distributed processing solutions (e.g., Spark), ETL tools (e.g., Alteryx), cloud-based data lakes and warehouses (e.g., Databricks, Snowflake, Big Query), workflow management (e.g., Airflow)\nDemonstrate strong ETL skills to integrate multiple data sources into a single data warehouse solution that is used for reporting, analytics and for building machine learning applications\nExperience with various data sources, formats, and systems, such as relational databases, NoSQL databases, data warehouses, data lakes, cloud platforms, streaming platforms, and ETL tools is required\nExperience proactively identifying opportunities to improve ETL & dashboard performance\nFamiliarity with cloud computing tools such as AWS, Azure, and GCP\nExperience with data transformation tools, automation, and scripting\nKnowledge of basic data visualization in Excel and Tableau\nExperience with SQL Server\nExcellent communication, organizational and interpersonal skills, and the ability to research and resolve issues\nStrong facilitation skills for requirement elicitation and management communications\nQuantitative rigor, good problem-solving skills, and a growth mindset\nExperience with Azure stack a plus\nThe pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.\nWe offer comprehensive benefits including medical\/dental\/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.\nNote: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.\nThis job is not eligible for bonuses, incentives or commissions.\nKforce is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nSalary: $48 - $55 per hour\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Business Analyst, ETL, Data Warehousing, Data Infrastructure, Data Quality, Data Integration, Data Analytics, Machine Learning, Spark, Alteryx, Databricks, Snowflake, Big Query, Airflow, SQL, Excel, Tableau, AWS, Azure, GCP, Cloud Computing, Data Visualization, Data Transformation, Automation, Scripting",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Security Track Specialist (Control Design Analyst)",
      "company":"Datum Technologies Group",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/security-track-specialist-control-design-analyst-at-datum-technologies-group-3779376339",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_skills":"Tech Audit, GRC, Access Governance, Access Management, App Security, Archer, BCPDR, Data Analytics, BSM, Checkpoint, Content Management, Siteminder, Identity and Access Management, DLP Management, Endpoint Protection, Enterprise SSO, F5, Firewall Management, Forensic Analysis, Identity Management, IDS\/IPS Management, Information Security, Information Governance, IT Governance, Managed Authentication Service, Oracle Access Manager, Oracle Identity Manager, Privileged Access Management, Quest Password Manager, Sec Analytics, Security Architecture, Security Operation Centre, Security Ops Management, Service Management, Solution Architecture, Technical Project Management, Tivoli Access Manager, Tivoli Identity Manager, Web App Firewall Management, Web Malware Protection",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Reporting Analyst",
      "company":"Soho Square Solutions",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-reporting-analyst-at-soho-square-solutions-3654422085",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description\nRole: Tableau\/Cognos\nRequired Skills: Reporting & Data Visualization(Tableau \/ Cognos)\nIndustry : Financial Services;FS - Banking & Capital Markets\nOther Information: Advanced (8-12 yrs exp)\nLocation: Houston, TX\nKey Responsibilities\nAs a seasoned IT developer with 8 to 12 years of experience in Tableau and Cognos, the job duties would involve a range of responsibilities related to data analysis, reporting, and visualization.\nHere is an overview of potential duties it might be undertaken:\nData Analysis: Analyze business requirements, data sources, and data structures to understand and define data integration and modeling strategies. Perform data profiling, cleansing, and transformation tasks to ensure data accuracy and consistency.\nReport and Dashboard Development: Design, develop, and maintain reports, dashboards, and scorecards using Tableau and Cognos. Collaborate with business users and stakeholders to gather requirements and create visually appealing and interactive data visualizations that effectively communicate insights.\nData Integration: Integrate data from various sources, including databases, spreadsheets, and APIs, into Tableau and Cognos environments. Design and implement data extraction, transformation, and loading (ETL) processes to ensure data is available for reporting and analysis.\nPerformance Optimization: Optimize queries, data models, and reports to improve performance and ensure efficient utilization of system resources. Monitor and tune the performance of Tableau and Cognos environments to ensure smooth and responsive user experience.\nData Governance and Security: Implement data governance policies and procedures to ensure data quality, consistency, and security. Define and enforce data access controls, authentication mechanisms, and data encryption measures to protect sensitive information.\nTroubleshooting and Issue Resolution: Investigate and resolve issues related to data connectivity, report performance, and data inconsistencies. Collaborate with IT teams and vendors to troubleshoot and resolve technical problems in Tableau and Cognos environments.\nTraining and Support: Provide training and support to end users, enabling them to effectively utilize Tableau and Cognos features and functionalities. Create documentation, user guides, and knowledge base articles to facilitate self-service analytics and reporting.\nStay Updated with Technology: Stay abreast of the latest advancements and best practices in Tableau, Cognos, and the broader data analytics field. Continuously enhance your skills and knowledge through professional development, training, and certification programs.\nShow more\nShow less",
      "job_skills":"Tableau, Cognos, Reporting, Data Visualization, Data Analysis, Data Profiling, Data Cleansing, Data Transformation, Report Development, Dashboard Development, Scorecard Development, Data Integration, ETL, Data Extraction, Data Transformation, Data Loading, Performance Optimization, Data Governance, Data Security, Data Access Control, Authentication, Data Encryption, Troubleshooting, Issue Resolution, Training, Support, User Documentation, Knowledge Base, Professional Development, Certification",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Security Track Specialist (Control Design Analyst)",
      "company":"Dice",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/security-track-specialist-control-design-analyst-at-dice-3785501358",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Dice is the leading career destination",
      "job_skills":"Tech Audit and Assessment, Access Governance, Access Management, App Security Threat Assessment, Application Security Testing, Archer, BCPDR, Big Data Security Analytics, BSM Architecture, Checkpoint, Checkpoint_ESS, Content Management, Curion, Data Classification, DLP Management, Domain Architect, Endpoint Protection Service, Enterprise Single Signon, F5, Firewall Management, Forensic Analysis, Identity Management, IDS\/IPS Management, Information Security, IT Governance, Managed Authentication Service, MS AD Federation, Oracle Access Manager, Oracle Identity Manager, Platform Architect, Privileged Access Management, Quest Password Manager, Secure Data Migration, Security Architect, Security Operation Centre, Security Product Manager, Service Management Architect, Solution Architect, Technical Project Management, Tivoli Access Manager, Tivoli Identity Manager, Web App Firewall Management, Web Malware Protection, Wireless Security Assessment",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Sr. Data Analyst || Hybrid Role (Smithfield, RI, Durham, NC, or Westlake, TX)",
      "company":"Steneral Consulting",
      "job_location":"Westlake, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-hybrid-role-smithfield-ri-durham-nc-or-westlake-tx-at-steneral-consulting-3647813123",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Title: Sr. Data Analyst\nLocation: hybrid 5 days onsite\/month. Smithfield, RI, Durham, NC, or Westlake, TX!\nDuration: Through end of 2023, possible extension\nWe are currently sourcing for a Sr. Data Analyst to work at Fidelity's location in Smithfield, RI, Durham, NC, or Westlake, TX!\nMust Have\n7+ years experience with Data Modeling\n5+ years experience working with Data Warehouse\nExperience working with AWS\nNice To Have\nFinancial industry exposure would be really nice to have since this would really help when talking to our business stakeholders\nExperience working with Data Lakes within Snowflake\nShow more\nShow less",
      "job_skills":"Data Modeling, Data Warehouse, AWS, Snowflake, Data Lakes",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Security Analyst",
      "company":"Wingstop Restaurants Inc.",
      "job_location":"Addison, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/security-analyst-at-wingstop-restaurants-inc-3737106501",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"SECURITY ANALYST (GRC)\nWINGSTOP RESTAURANTS, INC.\nRole Profile Overview\nROLE LOCATION\nGlobal Support Center\nREPORTS TO NAME\nTEAM\nIT\nREPORTS TO TITLE\nIT Controls Manager\nRole Profile Description\nX FULL-TIME\n\u221a\u221e PART-TIME\n40+\nHOURS PER WEEK\n\u221a\u221e CONTRACTOR\n\u221a\u221e INTERN\nX EXEMPT\n\u221a\u221e NON-EXEMPT\nWho We Are\nWe\u201a\u00c4\u00f4re not in the wing business. We\u201a\u00c4\u00f4re in the flavor business. It\u201a\u00c4\u00f4s been our mission To Serve the World Flavor since we first opened in 1994, and we\u201a\u00c4\u00f4re just getting started. 1997 saw the opening of our first brand partner operated Wingstop location, and by 2002 we had served the world one billion wings. It\u201a\u00c4\u00f4s flavor that defines us and has made Wingstop one of the fastest growing brands in the restaurant industry.\nAbove all else \u201a\u00c4\u00ec our success is largely due to our people and our core values, or what we call The Wingstop Way, of being entrepreneurial, service-minded, fun and authentic. We believe having a strong people foundation centered on these collective values creates a crave-worthy culture and talented team, as well as ensures our brand is poised for accelerated growth. We all win together.\nYOUR IMPACT\nThe Security Analyst, GRC will play a key role is helping to plan, organize, and manage governance, risk, and compliance efforts in alignment with the company\u201a\u00c4\u00f4s overall security and data privacy programs.\nThis includes managing our Information Security Policies and Standards to ensure they remain current with NIST-CSF and that they are accessible and understood by all impacted users.\nThe Security Analyst, GRC will also work to perform risk assessments on current internal systems, as well as assess the security controls of current and proposed vendors in alignment with Wingstops\u201a\u00c4\u00f4 security policies and standards.\nThe Security Analyst GRC will have the opportunity to lead PCI compliance program of our corporate owned restaurants and ecommerce (Web & Mobile) platform.\nWhat You\u201a\u00c4\u00f4ll Do\nManage all existing Information Security Policies and Standards, ensure they stay relevant and are available to all impacted teams. Identify and help to create new information security policies and standards that align with NIST-CSF and relevant compliance requirements.\nConduct information security risk assessments and assist in documenting identified risks and treatment plans in Wingstop\u201a\u00c4\u00f4s Risk Register.\nParticipate in enhancing compliance programs (PCI, SOX, etc..) ensuring all quarterly and annual requirements are successfully completed, documented, and communicated as appropriate. Identify opportunities to automate or simplify compliance where possible.\nIdentify and establish key metrics to indicate the health and status of Wingstop\u201a\u00c4\u00f4s Information Security Governance, Risk, and Compliance activities to be shared with Sr. Leadership.\nWork with cross functional teams to drive security related initiatives\nHelp to identify, develop, and execute security awareness opportunities to the Wingstop organization.\nWho You Are\nHUMBLE:\nYou feel there is always opportunity to further your personal and professional growth.\nB.S. degree in a computer science, information technology, computer related discipline or 5+ years IT work experience in the area of Governance, Risk and Compliance.\nTeam Player with proven leadership, communication, organizational, and relationship management skills.\nSelf-motivated, with keen attention to detail and excellent judgment skills.\nDemonstrated success implementing Information Security control frameworks and standards such as ITIL, CIS, Soc2, GDPR, NIST CSF \/ 800-53\nManagement, alignment, mapping, continuous improvement of internal security controls framework and control owner relationships. Integration expertise of vendor risk reviews, customer engagement surveys, control exceptions, risk assessments, audit readiness coordination, or security control requirement services.\nCompliance in alignment with security strategy and regulatory or legal obligations\nParticipate in Payment Card Industry Data Security Standards (PCI DSS) audits.\nExperience with GRC, IAM, and Risk Management Tools and solutions\nExperience with information security tools and solutions\nReport key operational, and program metrics designed to provide transparency of key attributes such as compliance readiness, security framework alignment, program maturity and operations.\nAbility to write and present articulated documentation and processes.\nKnowledge of hybrid IT systems, networking, co-locations, and cloud environments (AWS, Azure, etc.).\nCISA, CRISC, GIAC, CISM, or CISSP Certification is a plus\nHUNGRY:\nYou have a fire in you to keep pursuing excellence. You have strong business knowledge and an analytical mindset, easily managing tasks and projects across business lines, and building relationships.\nSMART:\nYou have a high degree of emotional intelligence and a thirst for knowledge. You have the aptitude to work both independently and collaboratively, the talent to apply sound, strategic thinking and analysis to address a variety of business circumstances, and the capability to produce high-quality, detail-oriented work within a fast-paced environment.\nSERVICE-MINDED:\nYou consider others at every turn by exercising your responsibilities in an energetic, proactive and organized way.\nENTREPRENEURIAL:\nYou work with an owner\u201a\u00c4\u00f4s mentality when collaborating cross-functionally as you manage multiple concurrent tasks and projects from inception through execution.\nA DAY IN THE LIFE\nRole\nSo, what does \u201a\u00c4\u00f2all in a day\u201a\u00c4\u00f4s work\u201a\u00c4\u00f4 look like to a Wing Expert in this role? Your day could shape up somewhat like this:\nFrequent use of a computer and other technology essential to the successful completion of your everyday role responsibilities, often in a seated position.\nFrequent use of mental energy while gathering, documenting, analyzing, and communicating information with cross-functional colleagues, vendors, and extended Wingstop team.\nRoutine need to shift priorities among simultaneous tasks and projects, while upholding quality and sense of urgency.\nWingstop provides equal opportunities for everyone that works for us and everyone that applies to join our team, without regard to sex or gender, gender identity, gender expression, age, race, religious creed, color, national origin, ancestry, pregnancy, physical or mental disability, medical condition, genetic information, marital status, sexual orientation, any service, past, present, or future, in the uniformed services of the United States (military or veteran status), or any other consideration protected by federal, state, or local law.\nShow more\nShow less",
      "job_skills":"Information security, NISTCSF, PCI compliance, Risk assessments, Security awareness, ITIL, CIS, Soc2, GDPR, NIST CSF \/ 80053, GRC, IAM, Risk Management Tools, CISA, CRISC, GIAC, CISM, CISSP, AWS, Azure",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Workday Reporting & HR Data Analyst",
      "company":"Flowserve Corporation",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/workday-reporting-hr-data-analyst-at-flowserve-corporation-3765339587",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Overview:\nIf a culture of excellence, innovation and ownership is what you\u201a\u00c4\u00f4re searching for, consider putting your experience in motion at Flowserve. As an individual contributor, or as a leader of people, your enterprise mindset will ensure Flowserve\u201a\u00c4\u00f4s position as the global standard in comprehensive flow control solutions. Here, your opportunity for professional development and industry leading rewards will be supported by our foundational commitments to the values of people first, integrity and safety. Thinking beyond opportunity and reward, at Flowserve, we are inspired by working together to create extraordinary flow control solutions to make the world better for everyone!\nWorkday Reporting and HR Data Analytics Analyst\nFlowserve is looking for a Workday Reporting and Data Analytics Analyst who will be part of a team tasked with balancing people, process, and technology to help enable HR make informed decisions and deliver results. The HR Data Reporting and Analytics team takes HR fundamentals and metrics and innovates to improve efficiencies, create data to support decisions, enable leadership effectiveness, and enhance the experience of our stakeholders. You\u201a\u00c4\u00f4ll partner with stakeholders across the business to design and implement scalable HR analytics and define opportunities for improvement.\nRequirements:\nExperience aggregating and analyzing data spanning multiple sources and reporting tools\nExperience developing and implementing new ideas and creative solutions for improved efficiency and effectiveness.\nWorking knowledge of business intelligence reporting tools (e.g., BI Tools like Power BI, QlikView, Tableau) and Data Management tools\/platforms (e.g., AWS, GCP, Azure, SQL, etc.)\nStrength in People\/Data Analytics, Statistics and Data Science.\nExperience Participating In Cross-functional, Multi-geographic Teams.\n3-5+ years of experience in quantitative or process improvement roles, using data analytics, mining, and\/or visualization to solve problems.\nProficiency in Excel (formulas, pivots, macros) and experience performing ad-hoc analysis\n3-5 years of experience in Workday Reporting including experience with Prism, Discovery Boards, Worksheets and Slides\nKnowledge and hands-on experience of Workday HCM and other Workday HR capabilities like Learning, Recruiting, Compensation, Payroll, etc.\nWorking knowledge of continuous improvement methodologies such as Lean Six-Sigma, DMAIC\/Agile, or root-cause analysis a plus\nBachelor\u201a\u00c4\u00f4s degree in Business, Analytics, Mathematics, Economics, or equivalent experience\nSkills:\nStrong Business Communication, Presentation And Writing Skills.\nAbility to communicate technical information and data to a non-technical audience in a logical, concise manner.\nStrong Problem Formulation And Creative Problem-solving Skills.\nSuperior learning agility; able to learn independently from a variety of sources; ability to thrive in ambiguous situations.\nCollaboration skills to develop buy-in and consensus that drives progress and results.\nStrong interpersonal skills with the ability to communicate with all levels of management through diplomacy and tact.\nAbility To Handle Multiple Tasks And Responsibilities.\nResponsibilities:\nExplore people data and evaluate trends to help develop core people metrics and identify opportunities to create meaningful, actionable insights and recommendations.\nEffectively partner with cross-functional teams & business partners with intent to build strong relationships that ultimately lead to identification of ways the reporting and analytics team can engage and improve business value.\nAbility to assess, capture, and translate complex business questions into metrics that can be evaluated to help measure the effectiveness of various HR work streams.\nAnalytical ability around data retrieval, manipulation, and performance analysis from data management systems; further turn this data into useful information\nChampion data quality processes and consistent use and adoption of measures, hierarchies, tools and reporting standards.\nDevelop reporting to help measure effectiveness of HR initiatives using data from the core HR systems: Human Capital Management, Talent\/Performance management, Learning Management, Recruiting\/Applicant Tracking, and Employee Engagement\nPreferred Experience:\nAbility to leverage HR data to support business partnering conversations.\nPrevious experience in coaching and driving change management programs.\nPredictive modeling experience with employee retention, employee performance, and other relevant workforce function\nExperience In Working With Manufacturing, Engineering, Or Sales Teams.\nAbility to influence others on proposed courses of action, be firm but be diplomatic at the same time.\nAbility to travel as needed.\nFlowserve offers competitive pay, annual bonuses, medical benefits on day 1, generous paid vacation time, paid holidays, 401(k) and many other excellent benefits!\nReq ID\n: R-6913\nJob Family Group\n: Human Resources\nJob Family\n: HR HR Information Systems\nEOE including Disability\/Protected Veterans. Flowserve will also not discriminate against an applicant or employee for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co-workers. Pay Transparency Nondiscrimination Provision\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access flowservecareers.com as result of your disability. You can request a reasonable accommodation by sending an email to employment@flowserve.com. In order to quickly respond to your request, please use the words \"Accommodation Request\" as your subject line of your email. For more information, read the Accessibility Process.\nShow more\nShow less",
      "job_skills":"Workday, Power BI, QlikView, Tableau, AWS, GCP, Azure, SQL, People\/Data Analytics, Statistics, Data Science, Lean SixSigma, DMAIC, Agile, Excel, Business Communication, Presentation, Writing, Problem Formulation, Problemsolving, Collaboration, Interpersonal Skills, Task Management, Data Exploration, Trend Analysis, Data Retrieval, Data Manipulation, Data Analysis, Data Quality, Reporting, Predictive Modeling, Employee Retention, Employee Performance, Manufacturing, Engineering, Sales",
      "Category":"Cloud Security"
  },
  {
      "job_title":"BI Analyst II",
      "company":"Spectrum",
      "job_location":"Maryland Heights, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/bi-analyst-ii-at-spectrum-3785387057",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Do you have a knack for identifying patterns and trends? Looking for a BI Analyst job that values insights from their data to use information to drive growth and success? If so, you\u201a\u00c4\u00f4ll fit right in with Spectrum\u201a\u00c4\u00f4s Business Intelligence team!\nSpectrum maintains our 32 million customers by offering trailblazing products and services. Our goal is not only to exceed the expectations of our users, but our employees too! In today\u201a\u00c4\u00f4s data-driven world, having access to accurate and timely information is crucial to stay competitive and relevant.\nSpectrum\u201a\u00c4\u00f4s Business Intelligence team plays a vital role in not only working towards the company\u201a\u00c4\u00f4s goals but improving our decision making through insights and analysis of data. It\u201a\u00c4\u00f4s a high-energy job that allows you to focus on all aspects of Spectrum: business and people! You\u201a\u00c4\u00f4d be joining a competent team with quality expectations that values partnership, long-term career growth, and great work-life balance.\nBE PART OF THE CONNECTION\nAs a\nBI Analyst II\n, you will be an integral part of the Business Intelligence Data Governance team that will help plan, design, maintain, and implement the governance framework. This role will be responsible for establishment and management of best practices, processes, and tools related to Data Governance and will report to the Manager of BI Data Governance. It requires cross functional coordination with stakeholders and partners within Business Intelligence and across the Charter organization.\nThe candidate should have prior experience with project management, policy writing, and creating high quality documentation with succinct and tailored messaging for a multitude of audiences. The role requires excellent time management, a proactive attitude and the ability to function effectively in a matrixed environment. The role will support initiatives from ideation through completion and work with Business Intelligence, IT, and internal Charter business units on the following work streams:\nBI Data Assets Governance including Data Catalog\nBusiness Intelligence Data Access & Audit\nBI Environment Access Process Governance\nDue to the nature of the initiative and visibility this team has, it requires a strong performer who is process oriented and can support building\/enhancing processes and controls around the overarching goal of ensuring Data Governance policies are consistently applied to the benefit of the organization and company.\nWHAT OUR BI Analyst II ENJOY MOST\nUtilize Project Management skills to prioritize, track, manage, and complete projects\nGather, create, and maintain requirements for governance framework operating models, RACI, and processes\nAssist in implementing Data Governance best practices and repeatable processes\nIdentify, capture, and report on metrics related to benefits realized due to Data Governance initiatives\nAuthor policies and procedures related to Data Governance that will be distributed across the organization\nCreate visual representations of workflows, procedures and processes\nAssist in creating executive level presentations and documents as needed\nInteract with senior management or executive level customers and provide support as needed\nDevelop partnerships with internal and external groups to gather feedback, collaborate on initiatives, and influence planning and decision making\nWork with the BI Data Governance team to implement\/enhance the data catalog, workflow automation, and other data governance related tools\nAnalyze how data is being accessed and make recommendations to further refine controls\nEvaluate requests to understand the business needs and determine best delivery that benefits the company as a whole\nPartner with BI teams to craft governance controls and processes around new technologies\/tools\nRequired Qualifications\nWHAT YOU\u201a\u00c4\u00f4LL BRING TO SPECTRUM\nSQL and Analytics \u201a\u00c4\u00ec 4+ years\nData Management and Reporting \u201a\u00c4\u00ec 4+ years\nExperience performing business analysis across a variety of industries, business functions and technologies - 4+\nProven ability in creating high quality documentation\nExperience in drafting, creating and maintaining policies and procedures\nExcellent listening, written and verbal communication skills\nStrong knowledge of MS Office applications (Visio, PowerPoint and Excel)\nLiaise between business users and technical teams for successful implementation of requirements\nAbility to analyze, simplify and summarize complex information accurately\nUnderstanding of business uses of data for reporting and analytics\nEagerness to learn new concepts\nFunctional and technical experience in a large-scale data environment, e.g. developing business requirements, mapping out process flows, Testing, etc.\nStrong Project Management skills\nDetail oriented with strong time management and organizational skills\nAbility to work independently with minimal guidance, prioritize and organize effectively and manage multiple projects\/assignments\nKnowledge of data governance methodologies, principles and tools is a plus\nExperience with\/knowledge of SQL databases, dimensional and relational data models, BI reporting tools and data integration tools\/methodologies\nRequired Education\nBachelor\u201a\u00c4\u00f4s degree or foreign equivalent in Information Technology or business-related field, or equivalent experience\nPreferred Qualifications\nKnowledge of Cable\/Telecom products and services\nConsulting background\nExperience with relational databases and unstructured databases\nExperience with MicroStrategy, Tableau, Teradata, Cloud Governance, Snowflake, Data Catalog, AWS\nProject Management\nData Governance\nWorking Conditions\nOnsite 5 days\nSPECTRUM CONNECTS YOU TO MORE\nDynamic Growth: The growth of our industry and evolving technology powers our employees\u201a\u00c4\u00f4 careers as they move up or around the company\nSupportive Teams: Who you are matters here. And, we aim to foster an inclusive workplace where every person is empowered to bring their best ideas\nLearning Culture: With a dedicated focus on training and development, employees can have confidence that day one is truly just the beginning of a dynamic career\nTotal Rewards: See all the ways we invest in you\u201a\u00c4\u00eeat work and in life\nApply now, connect a friend to this opportunity or sign up for job alerts!\nBBL317 2023-26593 2023\nHere, employees don\u201a\u00c4\u00f4t just have jobs, they build careers. That\u201a\u00c4\u00f4s why we believe in offering a comprehensive pay and benefits package that rewards employees for their contributions to our success, supports all aspects of their well-being, and delivers real value at every stage of life.\nA qualified applicant\u201a\u00c4\u00f4s criminal history, if any, will be considered in a manner consistent with applicable laws, including local ordinances.\nGet to Know Us\nCharter Communications is known in the United States by our Spectrum brands, including: Spectrum Internet\u00ac\u00c6, TV, Mobile and Voice, Spectrum Networks, Spectrum Enterprise and Spectrum Reach. When you join us, you\u201a\u00c4\u00f4re joining a strong community of more than 101,000 individuals working together to serve more than 32 million customers in 41 states and keep them connected to what matters most. Watch this video to learn more.\nWho You Are Matters Here\nWe\u201a\u00c4\u00f4re committed to growing a workforce that reflects our communities, and providing equal opportunities for employment and advancement. EOE, including disability\/vets. Learn about our inclusive culture.\nShow more\nShow less",
      "job_skills":"SQL, Analytics, Data Management, Reporting, Business Analysis, Documentation, Policies and Procedures, Communication, MS Office, Visio, PowerPoint, Excel, Project Management, Time Management, Organizational Skills, Independent Work, Data Governance Methodologies, Principles, Tools, SQL Databases, Dimensional Data Models, Relational Data Models, BI Reporting Tools, Data Integration Tools\/Methodologies, Information Technology, BusinessRelated Field, Consulting, Relational Databases, Unstructured Databases, MicroStrategy, Tableau, Teradata, Cloud Governance, Snowflake, Data Catalog, AWS, Data Governance",
      "Category":"Cloud Security"
  },
  {
      "job_title":"BI Analyst II, Data Governance",
      "company":"Spectrum",
      "job_location":"Maryland Heights, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/bi-analyst-ii-data-governance-at-spectrum-3778757173",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Summary\nThis position is an integral part of the Business Intelligence Data Governance team that will help plan, design, maintain, and implement the governance framework. This role will be responsible for establishment and management of best practices, processes, and tools related to Data Governance and will report to the Manager of BI Data Governance. It requires cross functional coordination with stakeholders and partners within Business Intelligence and across the Charter organization.\nThe candidate should have prior experience with project management, policy writing, and creating high quality documentation with succinct and tailored messaging for a multitude of audiences. The role requires excellent time management, a proactive attitude and the ability to function effectively in a matrixed environment. The role will support initiatives from ideation through completion and work with Business Intelligence, IT, and internal Charter business units on the following work streams:\nBI Data Assets Governance including Data Catalog\nBusiness Intelligence Data Access & Audit\nBI Environment Access Process Governance\nDue to the nature of the initiative and visibility this team has, it requires a strong performer who is process oriented and can support building\/enhancing processes and controls around the overarching goal of ensuring Data Governance policies are consistently applied to the benefit of the organization and company.\nMajor Duties And Responsibilities\nUtilize Project Management skills to prioritize, track, manage, and complete projects\nGather, create, and maintain requirements for governance framework operating models, RACI, and processes\nAssist in implementing Data Governance best practices and repeatable processes\nIdentify, capture, and report on metrics related to benefits realized due to Data Governance initiatives\nAuthor policies and procedures related to Data Governance that will be distributed across the organization\nCreate visual representations of workflows, procedures and processes\nAssist in creating executive level presentations and documents as needed\nInteract with senior management or executive level customers and provide support as needed\nDevelop partnerships with internal and external groups to gather feedback, collaborate on initiatives, and influence planning and decision making\nWork with the BI Data Governance team to implement\/enhance the data catalog, workflow automation, and other data governance related tools\nAnalyze how data is being accessed and make recommendations to further refine controls\nEvaluate requests to understand the business needs and determine best delivery that benefits the company as a whole\nPartner with BI teams to craft governance controls and processes around new technologies\/tools\nRequired Qualifications\nProven ability in creating high quality documentation\nExperience in drafting, creating and maintaining policies and procedures\nExcellent listening, written and verbal communication skills\nStrong knowledge of MS Office applications (Visio, PowerPoint and Excel)\nLiaise between business users and technical teams for successful implementation of requirements\nAbility to analyze, simplify and summarize complex information accurately\nUnderstanding of business uses of data for reporting and analytics\nEagerness to learn new concepts\nFunctional and technical experience in a large-scale data environment, e.g. developing business requirements, mapping out process flows, Testing, etc.\nStrong Project Management skills\nDetail oriented with strong time management and organizational skills\nAbility to work independently with minimal guidance, prioritize and organize effectively and manage multiple projects\/assignments\nKnowledge of data governance methodologies, principles and tools is a plus\nExperience with\/knowledge of SQL databases, dimensional and relational data models, BI reporting tools and data integration tools\/methodologies\nRequired Education\nBachelor\u201a\u00c4\u00f4s degree in Business, Information Systems, or business-related experience\nRequired Related Work Experience And Number Of Years\nSQL and Analytics \u201a\u00c4\u00ec 4+ years\nData Management and Reporting \u201a\u00c4\u00ec 4+ years\nExperience performing business analysis across a variety of industries, business functions and technologies - 4+\nPreferred Qualifications\nKnowledge of Cable\/Telecom products and services\nConsulting background\nExperience with relational databases and unstructured databases\nExperience with MicroStrategy, Tableau, Teradata, Cloud Governance, Snowflake, Data Catalog, AWS\nProject Management\nData Governance\nWORKING CONDITIONS\nOffice environment\nBBL317 2023-17814 2023\nHere, employees don\u201a\u00c4\u00f4t just have jobs, they build careers. That\u201a\u00c4\u00f4s why we believe in offering a comprehensive pay and benefits package that rewards employees for their contributions to our success, supports all aspects of their well-being, and delivers real value at every stage of life.\nA qualified applicant\u201a\u00c4\u00f4s criminal history, if any, will be considered in a manner consistent with applicable laws, including local ordinances.\nGet to Know Us\nCharter Communications is known in the United States by our Spectrum brands, including: Spectrum Internet\u00ac\u00c6, TV, Mobile and Voice, Spectrum Networks, Spectrum Enterprise and Spectrum Reach. When you join us, you\u201a\u00c4\u00f4re joining a strong community of more than 101,000 individuals working together to serve more than 32 million customers in 41 states and keep them connected to what matters most. Watch this video to learn more.\nWho You Are Matters Here\nWe\u201a\u00c4\u00f4re committed to growing a workforce that reflects our communities, and providing equal opportunities for employment and advancement. EOE, including disability\/vets. Learn about our inclusive culture.\nShow more\nShow less",
      "job_skills":"Data Governance, Project Management, Policies and Procedures, Data Catalog, Business Intelligence, RACI, SQL, Data Management, Reporting, Analytics, Business Analysis, MicroStrategy, Tableau, Teradata, Cloud Governance, Snowflake, AWS",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"World Wide Technology",
      "job_location":"Roanoke, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-world-wide-technology-3776646730",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"World Wide Technology Holding Co, LLC. (WWT) has an opportunity available for a\nData Center Engineer\nto support our client in an ongoing Data Center refresh project.\nData Center Engineer\nLocation:\nRoanoke, TX\nAvailable Shifts:\n(2 Openings) 7 PM \u201a\u00c4\u00ec 7 AM CST Thursday, Friday, Saturday, and Alternating Wednesdays.\n(1 Opening) 7 AM \u201a\u00c4\u00ec 7 PM CST Thursday, Friday, Saturday, and Alternating Wednesdays.\nDuration:\n12 Months\nContract Designation:\nFull-Time Contingent \u201a\u00c4\u00ec Contractors will be eligible for WWT\u201a\u00c4\u00f4s Full Time Employee Benefits Package including Medical, Vision, Dental, PTO, Paid Holidays, and more.\nResponsibilities:\nInstalling\/de-installing\/relocating all distributed systems and network hardware (CSUs, DSUs, routers, switches, encryptors, firewalls, etc.) in the Americas Data Centers within the internal service level mandates\nInstalling\/de-installing \/extending\/relocating\/testing all carrier circuits to the network hardware\nInstalling\/de-installing\/relocating all patch cabling for systems and network hardware\nInstalling\/de-installing\/relocating all Data Center hardware\nAssist with the coordination of cabinet power, circuit, and patch infrastructure installations w\/various facilities, electrical and communications vendors\nAssist with the coordination of network component configurations\nCoordinate and Install SAN cabling infrastructure\nManaging network ports and assist with the management of all consumable items (cables, labels, tie wraps, rail kits, etc.)\nMaintaining the integrity of the data center facilities, systems and communications environments through general housekeeping and best operations practices\nProvide hands-on, break\/fix level 2 support for the data center systems and communications environments\nCoordinating and approving data center infrastructure change controls\nEnsuring compliance with data center standards, policies and processes for all non-DCSD sponsored changes\nCoordinate activities in support of all projects and technical requests within the Americas Data Centers\nManage CTI-approved third-party vendors in support of local\/regional business service commitments and to assure adherence to Corporate and CTI standards\nProvide clear and detailed turnover to next shift workers for continuity\nMedia Management duties including the following:\nPerforming daily tape ejects to increase current day processing capacity.\nMonitoring of tape related console messages.\nManaging all daily ad-hoc tape\/job requests and scratch activity.\nManaging all physical and electronic vaulting activity.\nManage tape destruction process, ensuring all proper documentation has been recorded and approved.\nMonitoring scratch levels on display screens, on-line library web specialist or visually monitoring panel on libraries.\nReplacing any\/all damaged media.\nMonitoring of tape related console messages, working with the global command center and the on-site hardware teams.\nSupporting all physical off-site vaulting activities.\nEnsure destruction procedures are followed.\nSupporting all site and application specific disaster recovery\/COB tests\/exercises.\nAssisting in supporting all reconciliation and QA efforts including: Year End, Physical Inventory, Vertices. Hard-drive inventory levels, Other duties as assigned by management.\nQualifications:\nRequired skills include 3+ years of experience in the implementation, maintenance and analysis of data center facilities, hardware, communications infrastructure, strategies, tools and effective troubleshooting techniques.\nBasic background on enterprise data center facilities and infrastructure environments such as PDUs, RPPs, network and SAN infrastructures. In depth knowledge on complex, Enterprise class inter-networked environments involving a combination of switched\/routed\/shared Ethernet, TwinAx (100GigE, 25GigE,10GigE, GigE, 100M, and 10M), token ring, SAN, and wide area connectivity.\nStrong knowledge of WAN technologies (OC-x, DS-x), subnetting and TCP\/IP protocol a must.\nExcellent communication and writing skills a must.\nKnowledge of trouble ticketing systems, change control, Project processes and associated tools.\nLogical problem- solving techniques and associated experience in system, data center facilities, and telecommunications.\nExperience with project management.\nFinancial Services industry knowledge a plus\nShow more\nShow less",
      "job_skills":"Network engineering, Data center operations, SAN cabling, Tape management, Media management, Data destruction, Disaster recovery, Network troubleshooting, Cisco routers and switches, Firewalls, Enterprise data center facilities, PDUs, RPPs, Subnetting, TCP\/IP, WAN technologies, Project management",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Center Engineer - Houston",
      "company":"DeRisk Technologies",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-houston-at-derisk-technologies-3766680531",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Job Responsibilities:\nDeployment \/ In-Scope Configuration Items\nServers (Virtual & Physical)\nStorage & Backup Devices\nServer Appliances\nHyper Converged Infrastructure (E.g. Nutanix, Cisco UCS)\nTape Storage Units\nPower Distribution Units rated 3KVA and below\nSAN Fabric Switches\nNetwork Switches\nKVM Units\nWAN Optimization Devices\nFirewalls\nAccess Points\nRouters\nPhysical Cabling\nCable Management\nCables which connect the device to itself, a peripheral, or a power\/network port Break-fix \/ Technical Tasks List\nPower Cycling\nRunning Diagnostics Commands\nConducting whole unit replacement\nInserting\/Removing Media\nReplacing Defective Components\nAssist with fault diagnosis and investigation\nConfiguring Remote Access\nBasic Storage Array Configuration\nReplacing faulty cables\nTape Management and Maintenance\nRebooting routers, servers, storage devices or other equipment\nOperations Tasks List\nUpdating and Recording of activities in relevant IT Ticket Management System\nCoordinating and agreeing attendance time and date with key stakeholders\nProvide support either through phone, remote tools, or in person at onsite\nPerform installation as needed either through physical or network medium\nCoordinate actual activity date and timings including arrival and departure times\nCarry all necessary tools, laptops etc. which might be needed to support issues in the infrastructure environment\nLabelling, Patching and Asset Tagging activities\nFollowing specific task instructions and provision necessary reporting as necessary\nRequirements\nJob Requirements:\nTechnical Skills\nGood general understanding of IT principles such as Networks, Hardware and Domains\nKnowledge of Infrastructure (Data Center and Network) hardware architecture as to understand the procedure shared by L3 teams during troubleshooting,H&E support\nKnowledge of server\/client operations in a domain environment including Active Directory\nUnderstanding of current and legacy hardware Infrastructure platforms\nHands-on experience in installation and troubleshooting Infrastructure (DC & Network) equipment's, Rack and Stack of the equipment\/cable\nGood Hands-on Experience in IMAC and Break-fix activities related to Infrastructure environment\nAbility to identify Excellent the right defective spares and replace them with provided good spares as instructed and by physical observations\nKnowledge of TCP\/I P standards and networking\nExperience with Tape Management activities\nExcellent knowledge of best practices around management, control, and monitoring of server infrastructure\nFamiliarity with backup and recovery software and methodologies\nLanguage skills needed\nEnglish Soft Skills\nExceptional customer facing skills\nAble to communicate clearly and effectively both with Client and the Customer\nLogical and analytical approach to work\nAccurate record keeping\nAble to work unsupervised\nGood timekeeper\nIntense focus on quality work\nProductive and Efficient Academic Background\nBachelor of Engineering \/ Technology \/ Science or Equivalent Work Experience Overall Experience (in yrs.)\n5 - 7 years (min\nBenefits\nSalary and Benefits as per market standard\nShow more\nShow less",
      "job_skills":"Network Hardware, Server Hardware, Storage Hardware, Hyper Converged Infrastructure, Tape Storage, Power Distribution Units, SAN Fabric Switches, Network Switches, KVM Units, WAN Optimization Devices, Firewalls, Access Points, Routers, Cabling, Cable Management, BreakFix, Diagnostics, Troubleshooting, Remote Access, Storage Configuration, Network Configuration, Active Directory, Tape Management, Backup and Recovery, TCP\/IP, Server Infrastructure Management, English, Customer Service, Communication, Logical Thinking, Analytical Thinking, Record Keeping, Time Management, Quality Control, Productivity, Bachelor's Degree in Engineering Technology or Science",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Center Engineer - McAllen",
      "company":"DeRisk Technologies",
      "job_location":"McAllen, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-mcallen-at-derisk-technologies-3766682609",
      "search_city":"Alton",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Job Responsibilities:\nDeployment \/ In-Scope Configuration Items\nServers (Virtual & Physical)\nStorage & Backup Devices\nServer Appliances\nHyper Converged Infrastructure (E.g. Nutanix, Cisco UCS)\nTape Storage Units\nPower Distribution Units rated 3KVA and below\nSAN Fabric Switches\nNetwork Switches\nKVM Units\nWAN Optimization Devices\nFirewalls\nAccess Points\nRouters\nPhysical Cabling\nCable Management\nCables which connect the device to itself, a peripheral, or a power\/network port Break-fix \/ Technical Tasks List\nPower Cycling\nRunning Diagnostics Commands\nConducting whole unit replacement\nInserting\/Removing Media\nReplacing Defective Components\nAssist with fault diagnosis and investigation\nConfiguring Remote Access\nBasic Storage Array Configuration\nReplacing faulty cables\nTape Management and Maintenance\nRebooting routers, servers, storage devices or other equipment\nOperations Tasks List\nUpdating and Recording of activities in relevant IT Ticket Management System\nCoordinating and agreeing attendance time and date with key stakeholders\nProvide support either through phone, remote tools, or in person at onsite\nPerform installation as needed either through physical or network medium\nCoordinate actual activity date and timings including arrival and departure times\nCarry all necessary tools, laptops etc. which might be needed to support issues in the infrastructure environment\nLabelling, Patching and Asset Tagging activities\nFollowing specific task instructions and provision necessary reporting as necessary\nRequirements\nJob Requirements:\nTechnical Skills\nGood general understanding of IT principles such as Networks, Hardware and Domains\nKnowledge of Infrastructure (Data Center and Network) hardware architecture as to understand the procedure shared by L3 teams during troubleshooting,H&E support\nKnowledge of server\/client operations in a domain environment including Active Directory\nUnderstanding of current and legacy hardware Infrastructure platforms\nHands-on experience in installation and troubleshooting Infrastructure (DC & Network) equipment's, Rack and Stack of the equipment\/cable\nGood Hands-on Experience in IMAC and Break-fix activities related to Infrastructure environment\nAbility to identify Excellent the right defective spares and replace them with provided good spares as instructed and by physical observations\nKnowledge of TCP\/I P standards and networking\nExperience with Tape Management activities\nExcellent knowledge of best practices around management, control, and monitoring of server infrastructure\nFamiliarity with backup and recovery software and methodologies\nLanguage skills needed\nEnglish Soft Skills\nExceptional customer facing skills\nAble to communicate clearly and effectively both with Client and the Customer\nLogical and analytical approach to work\nAccurate record keeping\nAble to work unsupervised\nGood timekeeper\nIntense focus on quality work\nProductive and Efficient Academic Background\nBachelor of Engineering \/ Technology \/ Science or Equivalent Work Experience Overall Experience (in yrs.)\n5 - 7 years (min\nBenefits\nSalary and Benefits as per market standard\nShow more\nShow less",
      "job_skills":"Server Maintenance, Storage and Backup, Hyperconverged Infrastructure, Server Appliances, Virtual and Physical Servers, Network Switches, KVM Units, WAN Optimization Devices, Firewalls, Access Points, Routers, Physical Cabling, Cable Management, Troubleshooting, Power Cycling, Diagnostics Commands, Whole Unit Replacement, Media Insertion\/Removal, Component Replacement, Fault Diagnosis, Remote Access Configuration, Storage Array Configuration, Cable Replacement, Tape Management, Equipment Rebooting, Updating and Recording, Activity Coordination, Troubleshooting, Installation, Equipment Support, Labelling, Patching, Asset Tagging, Task Instructions, Reporting, Networking, Hardware, Domains, Data Center, Active Directory, Server\/Client Operations, Infrastructure Platforms, Equipment Installation, Troubleshooting, IMAC, BreakFix Activities, Spares Identification, TCP\/IP Standards, Backup and Recovery, English, Customer Service, Communication, Analytical Thinking, Record Keeping, Unsupervised Work, Time Management, Quality Focus, Productivity, Bachelor's Degree, Engineering, Technology, Science",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Center Engineer - W2 Contract",
      "company":"Promantis, Inc.",
      "job_location":"O'Fallon, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-w2-contract-at-promantis-inc-3784056310",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Title:\nData Center Engineer\nDuration\n: 1+ years (W2 Contract)\nLocation:\nO'Fallon, Missouri (Hybrid)\n1 round of interview Only\nExperience in below area is needed :\n-\nElectrical Engineering background is a must.\n-Power Alignment\n-Data Center experience is a must\n-Building Data Center\n-Designing\/Support\n-Fiber\/Copper alignment\n-Firewall\/Server\n-Split Circuit in Data Center\nShow more\nShow less",
      "job_skills":"Electrical Engineering, Power Alignment, Data Center experience, Building Data Center, Designing, Support, Fiber Alignment, Copper Alignment, Firewall, Server, Split Circuit",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Center Engineer - St. Louis",
      "company":"DeRisk Technologies",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-st-louis-at-derisk-technologies-3766684640",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Job Responsibilities:\nDeployment \/ In-Scope Configuration Items\nServers (Virtual & Physical)\nStorage & Backup Devices\nServer Appliances\nHyper Converged Infrastructure (E.g. Nutanix, Cisco UCS)\nTape Storage Units\nPower Distribution Units rated 3KVA and below\nSAN Fabric Switches\nNetwork Switches\nKVM Units\nWAN Optimization Devices\nFirewalls\nAccess Points\nRouters\nPhysical Cabling\nCable Management\nCables which connect the device to itself, a peripheral, or a power\/network port Break-fix \/ Technical Tasks List\nPower Cycling\nRunning Diagnostics Commands\nConducting whole unit replacement\nInserting\/Removing Media\nReplacing Defective Components\nAssist with fault diagnosis and investigation\nConfiguring Remote Access\nBasic Storage Array Configuration\nReplacing faulty cables\nTape Management and Maintenance\nRebooting routers, servers, storage devices or other equipment\nOperations Tasks List\nUpdating and Recording of activities in relevant IT Ticket Management System\nCoordinating and agreeing attendance time and date with key stakeholders\nProvide support either through phone, remote tools, or in person at onsite\nPerform installation as needed either through physical or network medium\nCoordinate actual activity date and timings including arrival and departure times\nCarry all necessary tools, laptops etc. which might be needed to support issues in the infrastructure environment\nLabelling, Patching and Asset Tagging activities\nFollowing specific task instructions and provision necessary reporting as necessary\nRequirements\nJob Requirements:\nTechnical Skills\nGood general understanding of IT principles such as Networks, Hardware and Domains\nKnowledge of Infrastructure (Data Center and Network) hardware architecture as to understand the procedure shared by L3 teams during troubleshooting,H&E support\nKnowledge of server\/client operations in a domain environment including Active Directory\nUnderstanding of current and legacy hardware Infrastructure platforms\nHands-on experience in installation and troubleshooting Infrastructure (DC & Network) equipment's, Rack and Stack of the equipment\/cable\nGood Hands-on Experience in IMAC and Break-fix activities related to Infrastructure environment\nAbility to identify Excellent the right defective spares and replace them with provided good spares as instructed and by physical observations\nKnowledge of TCP\/I P standards and networking\nExperience with Tape Management activities\nExcellent knowledge of best practices around management, control, and monitoring of server infrastructure\nFamiliarity with backup and recovery software and methodologies\nLanguage skills needed\nEnglish Soft Skills\nExceptional customer facing skills\nAble to communicate clearly and effectively both with Client and the Customer\nLogical and analytical approach to work\nAccurate record keeping\nAble to work unsupervised\nGood timekeeper\nIntense focus on quality work\nProductive and Efficient Academic Background\nBachelor of Engineering \/ Technology \/ Science or Equivalent Work Experience Overall Experience (in yrs.)\n5 - 7 years (min\nBenefits\nSalary and Benefits as per market standard\nShow more\nShow less",
      "job_skills":"Servers, Storage, Backup, Hyper Converged Infrastructure, Tape Storage, Power Distribution Units, SAN Fabric Switches, Network Switches, KVM Units, WAN Optimization Devices, Firewalls, Access Points, Routers, Cabling, Power Cycling, Diagnostics, Replacement, Maintenance, Remote Access, Storage Configuration, Installation, Troubleshooting, Labelling, Asset Tagging, IT Principles, Networks, Hardware, Active Directory, Infrastructure Platforms, Rack and Stack, IMAC, BreakFix, TCP\/IP, Tape Management, Backup and Recovery, English, Communication Skills, Analytical Thinking, Record Keeping, Time Management, Quality Control, Productivity",
      "Category":"Cloud Security"
  },
  {
      "job_title":"Data Scientist",
      "company":"Net2Source Inc.",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-net2source-inc-3784577725",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Max pay rate : $75-80\/hr. on C2C or $65-70\/hr. on W2\nSr. Data Scientist (Cyber Security is must)\nLocation : Onsite Charlotte, NC \/ Dallas, TX\nContract\nYears of Experience: 12+ Years of Experience\nJob Summary :\nWe are looking for a strong Sr. Data Scientist\nRoles & Responsibilities :\nCybersecurity is seeking a Sr Data Scientist to join the Cyber Analytics and Data Science team.\nThis position will use machine learning, data engineering, automation, and Data Science principles to solve enterprise problems and advance our Cyber Security mission.\nThis role is a key contributor to our practice and will be directly responsible for design, development, deployment, and automation.\nThe successful candidate will work closely with key stakeholders to rapidly advance the use of predictive and prescriptive analytics for cybersecurity as well as help the Cyber team with automation efforts.\nWe are seeking candidates with passion to lead the implementation of cutting-edge technology and methodologies while establishing strong partnerships with data owners and stakeholders across Cybersecurity.\nThe Sr Data Scientist will have demonstrated experience as a problem-solver, working alongside IT and business partners, and act as a trusted consultant.\nResponsibilities\nStructure business problems and drive viable, data-driven hypotheses in collaboration with business partners.\nAbility to skillfully enumerate a business problem, quantify its impact, size relevant data, and document applicable sources.\nDevise, develop and disseminate actionable intelligence from disparate data sources using advanced data analytics tools and techniques.\nAbility to identify needs and opportunities for advancements in innovations, processes and automation.\nAble to work proactively and take initiative without being specifically directed.\nAbility to extract & aggregate data from disparate data sources.\nAbility to perform in depth data analysis including but not limited to Machine Learning Classification Optimization Time Series analysis Pattern Recognition Establish and develop end-to-end automated processes (i.e.: data analyses, model development & implementation, manual processes, etc)Ability to communicate complex topics in an easy-to-understand manner when prese.\nShow more\nShow less",
      "job_skills":"Machine Learning, Data Engineering, Automation, Data Science, Predictive Analytics, Prescriptive Analytics, Cybersecurity, Data Analysis, Data Visualization, Data Mining, Data Aggregation, Time Series Analysis, Pattern Recognition, Data Warehousing, Data Mining, Data Integration, Data Governance",
      "Category":"Data Science"
  },
  {
      "job_title":"Manager, Data Loss Prevention (DLP) Engineer (Symantec)",
      "company":"Jobs for Humanity",
      "job_location":"Waco, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/manager-data-loss-prevention-dlp-engineer-symantec-at-jobs-for-humanity-3788485097",
      "search_city":"Waco",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Description\nJobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.\nCompany Name: Capital One\nJob Description\nManager, Data Loss Prevention (DLP) Engineer (Symantec) Capital One is looking for an expert in data protection to help us create innovative cybersecurity solutions. We believe in excellence and doing the right thing, and we use technology to deliver financial products at a large scale. As a DLP Engineer, you will be responsible for creating, implementing, and maintaining controls to protect our data and enforce our Information Security Policy. What you'll do: - Use your expertise in data protection technology to design and implement tools that safeguard data. - Analyze the problem space, document your approach, and work with our architecture team. - Collaborate with cross-functional teams to execute technical resolutions. - Communicate with stakeholders, developers, and engineers across the company. - Collaborate with different teams to resolve dependencies with data loss prevention products. - Design, build, and maintain cloud-based infrastructure. About You: - You are an expert in data loss prevention tools. - You have a strong understanding of web proxy, email, and endpoint solutions. - You pay attention to detail and can clearly articulate key details. - You can drive complex technical initiatives and engage with customers. - You can foster collaborative relationships with technology groups and other stakeholders. - You have excellent communication skills and can interact effectively with different levels of an organization. - You have experience managing enterprise cybersecurity projects. - You have expertise in technical delivery, product security, software development practices, or platform engineering. - You have knowledge of securing technology, including operating systems, databases, virtualization, cloud computing environments, and networks. - You can troubleshoot, investigate, configure, and support data loss prevention products. Preferred Qualifications: - Bachelor's Degree in Cybersecurity, Systems Engineering, or Computer Science. - Experience scripting and solving cyber technical challenges. - Experience in the Agile delivery model. - Experience in public cloud security and multi-cloud environments. - Experience in IT delivery projects and technical writing. - Hands-on experience with JIRA. - One or more professional cybersecurity certifications. - One or more professional cloud certifications. Basic Qualifications: - High School Diploma, GED, or equivalent certification. - At least 6 years of experience in cybersecurity or information technology. - At least 5 years of experience in the data protection field. - At least 3 years of experience with Symantec Data Loss Prevention (DLP) infrastructure engineering. - At least 3 years of experience with URL filtering, proxy, or Network DLP. We offer a comprehensive set of benefits that support your well-being. Learn more on our Careers website. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We promote a drug-free workplace and consider qualified applicants with a criminal history. If you need an accommodation during the application process, please contact us. Please note that any position posted in Canada is for Capital One Canada, and positions in the United Kingdom are for Capital One Europe. Positions in the Philippines are for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Data Loss Prevention, Web Proxy, Email Security, Endpoint Security, Cloud Computing, Symantec DLP Infrastructure, URL Filtering, Network DLP, Agile Methodology, Product Security, Software Development, Platform Engineering, Operating Systems, Databases, Virtualization, JIRA, Cybersecurity Certifications, Cloud Certifications",
      "Category":"Data Science"
  },
  {
      "job_title":"Business Intelligence Analyst \u201a\u00c4\u00ec Data Engineering Support",
      "company":"The University of Texas at Dallas",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/business-intelligence-analyst-%E2%80%93-data-engineering-support-at-the-university-of-texas-at-dallas-3785764107",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"The Business Intelligence Analyst position in OISDS will work collaboratively as a member of the team and will interact with internal and external stakeholders to support a variety of data management, training, analysis and benchmarking initiatives at The University of Texas at Dallas. The person in this role will assist with the ongoing development and implementation of tools to promote the development and use of analytic dashboards designed for wide distribution to UT Dallas campus stakeholders.\nThe primary functions of this role will be to\n1)\nassist OISDS with building relationships with campus constituents to develop analytic data resources and institutional research studies,\n2)\nassist with training and knowledge transfer activities related to OISDS tools, and\n3)\nconduct internal institutional research studies, assist with external data requests, perform data analysis, generate analytics, and communicate results involving internal data across numerous domains.\nIn this role, the Business Intelligence Analyst will provide direct support to internal and external stakeholders, manage relationships with data providers and end users. This role will also be tasked with enhancing existing and developing new analytics and data resources. The person in this role will report to the Senior Director of Institutional Reporting and Analytics.\nMinimum Education And Experience\nBachelors degree in related field.\nFour (4) years related professional experience.\nEquivalent combination of education and experience may be considered.\nPreferred Education And Experience\nMaster's Degree in a related field and two years of data analysis work experience.\nPossess a strong working knowledge of SQL and SAS programming.\nExperience in predictive analytics and machine learning.\nExperience working in an institutional research setting, a basic working knowledge of financial aid, admissions, and student data sources in a higher education setting (e.g., institutional, Federal (Integrated Post-Secondary Educational Data System), and the State via the Texas Higher Education Coordinating Board.\nBasic working knowledge of economic and accounting principles and practices, legal statutes, and analysis and reporting of financial data.\nExperience in designing business intelligence and\/or qualitative\/quantitative research studies to assist organizations in developing data-informed strategies.\nEssential Duties And Responsibilities\nReporting to the Senior Director, this Business Intelligence Analyst will focus on the data preparation processes for business intelligence solutions. The person in this role will work closely with the Data Warehouse Team to support the vision and delivery of optimized and accessible institutional data to deliver metrics capable of making data informed decisions across the University through reporting and analytics.\nWrites complex SQL and\/or DAX statements and scripts to support the development of business intelligence deliverables.\nDevelops and validates data models and schemas.\nDevelops and documents processes and procedures in collaboration with OISDS team members and other stakeholders for accessing data and for ensuring reliability of information retrieved.\nAutomates processes for ingesting, merging, and working with data from disparate sources using tools and applications.\nMaintains knowledge of best practices and emerging trends for infrastructure and processes (e.g., ETL, API) needed to collect, store, and analyze institutional data.\nAdditional Information\nRemote Work:\nThis role is eligible for a hybrid (partly remote\/partly in office) work schedule, subject to business need and manager approval. A UT Dallas Remote Work Agreement will be required within 14 days after approval. The Business Intelligence Analyst \u201a\u00c4\u00ec Data Visualizations must be located within the DFW Area and have the ability to be on campus within 24 hours of notice.\nWhat We Can Offer\nUT Dallas is an Equal Opportunity Employer. We offer an employee-friendly work environment with a comprehensive benefit package including:\nCompetitive Salary\nTuition Benefits\nInternal Training\nMedical insurance \u201a\u00c4\u00ec including\n100% paid\nemployee medical coverage for full-time employees\nDental Insurance\nVision Insurance\nLong and short-term disability\nRetirement Plan Options\nPaid time off\nPaid Holidays All UT Dallas employees have access to various\nprofessional development\nopportunities\n, including a membership to Academic Impressions, LinkedIn Learning, and UT Dallas Bright Leaders Program.\nVisit\nhttps:\/\/hr.utdallas.edu\/employees\/benefits\/\nfor more information.\nAbout Us:\nUT Dallas is a top public research university located in one of the nation's fastest-growing metropolitan regions. Our seven schools offer more than 140 undergraduate and graduate programs, plus professional certificates and fast-track programs. Our student body is 31,000 strong, reflecting students from over 100 countries and a multiplicity of identities and experiences. UT Dallas is committed to graduating well-rounded members of the global community whose education has prepared them for rewarding lives and productive careers in a constantly changing world. The University has a variety of programs and initiatives to support engagement and success for all members of the campus community. Employee benefits include a range of physical and mental wellness resources. \u201a\u00c4\u00faLilyPad\u201a\u00c4\u00f9 lactation facilities are located throughout the campus. There are several Employee Resource Groups (ERGs) comprised of individuals who share common interests to help build community among UT Dallas faculty and staff (e.g., Universal Access ERG, Military and Veteran ERG, UT Dallas Young Professionals). Rich with visual and performing arts venues, museum districts, professional and semi-professional athletics teams, botanical gardens, accessible trails and so much more, the Dallas-Fort Worth (DFW) metroplex has something for everyone to explore. UT Dallas partners with regional higher education institutions and school districts and with the\nRichardson Innovation Quarter\n(Richardson IQ), a major hub for innovation, entrepreneurship, and educational activities.\nImportant Message\nAll employees serve as a representative of the University and are expected to display respect, civility, professional courtesy, consideration of others and discretion in all interactions with members of the UT Dallas community and the general public.\nThe University of Texas at Dallas is committed to providing an educational, living, and working environment that is welcoming, respectful, and inclusive of all members of the university community. UT Dallas does not discriminate on the basis of race, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, national origin, disability, genetic information, or veteran status in its services, programs, activities, employment, and education, including in admission and enrollment. EOE, including disability\/veterans. The Universityis committed to providing access, equal opportunity, and reasonable accommodationfor individuals with disabilities.To request reasonable accommodation in the employment application and interview process, contact theADA Coordinator.For inquiries regarding nondiscrimination policies, contact theTitle IX Coordinator.\nShow more\nShow less",
      "job_skills":"SQL, DAX, Data Models, Schemas, ETL, API, Data Ingestion, Data Merging, Data Analysis, Predictive Analytics, Machine Learning, Institutional Research, Financial Aid, Admissions, Student Data Sources, Economic Principles, Accounting Principles, Legal Statutes, Business Intelligence, Qualitative Research, Quantitative Research, DataInformed Strategies, Data Visualizations, Data Warehousing, Data Preparation, Data Analytics, Data Reporting, Data Management, Data Mining, Data Integration, Data Governance, Data Security, Data Privacy, Big Data, Cloud Computing, Business Intelligence Tools, Data Visualization Tools, Data Analytics Tools, Data Mining Tools, Data Integration Tools, Data Governance Tools, Data Security Tools, Data Privacy Tools",
      "Category":"Data Science"
  },
  {
      "job_title":"Data & Progress Analyst (Ref ID: 230)",
      "company":"NextDecade",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-progress-analyst-ref-id-230-at-nextdecade-3718470080",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"ABOUT NEXTDECADE\nNextDecade Corporation\nis an energy company accelerating the path to a net-zero future and leading innovation in more sustainable LNG and carbon capture solutions, NextDecade is committed to providing the world access to cleaner energy. Through our subsidiaries Rio Grande LNG and NEXT Carbon Solutions, we are developing a 27 MTPA LNG export facility in South Texas along with one of the largest carbon capture and storage projects in North America. We are also working with third-party customers around the world to deploy our proprietary processes to lower the cost of carbon capture and storage and reduce CO2 emissions at their industrial-scale facilities. By combining emissions reduction associated with our carbon capture and storage project, responsibly sourced gas, and our pledge to use net-zero electricity, Rio Grande LNG is expected to produce\na lower carbon intensive LNG\nfor the world.\nNextDecade\u201a\u00c4\u00f4s common stock is listed on the Nasdaq Stock Market under the symbol \u201a\u00c4\u00faNEXT.\u201a\u00c4\u00f9 NextDecade is headquartered in Houston, Texas.\nSUMMARY OF THE ROLE:\nThis is a Data and Progress Analyst position within the Project Controls department to support execution of over 12 billion Dollar LNG Project. This role is responsible for designing, developing, and deploying project analytic dashboards using Microsoft BI technologies such as SQL, Power BI, etc.\nRESPONSIBILITIES:\n\u201a\u00c4\u00a2 Using Power BI, create dashboards and interactive visual reports.\n\u201a\u00c4\u00a2 Recognize project requirements in the context of BI and create data models to transform raw data into relevant insights.\n\u201a\u00c4\u00a2 Define key performance indicators (KPIs) with specific objectives and track them regularly.\n\u201a\u00c4\u00a2 Analyze data and display it in reports to aid decision-making.\n\u201a\u00c4\u00a2 Create, test, and deploy Power BI scripts, as well as execute efficient deep analysis.\n\u201a\u00c4\u00a2 Use Power BI to run DAX queries and functions.\n\u201a\u00c4\u00a2 Create charts and data documentation with explanations of algorithms, parameters, models, and relationships.\n\u201a\u00c4\u00a2 Construct a data warehouse.\n\u201a\u00c4\u00a2 Use SQL queries to get the best results.\n\u201a\u00c4\u00a2 Make technological adjustments to current BI systems to improve their performance.\n\u201a\u00c4\u00a2 For a better understanding of the data, use filters and visualizations.\n\u201a\u00c4\u00a2 Analyze current ETL procedures to define and create new systems.\nREQUIREMENTS:\nMinimum\/preferred experience required for the position:\n\u201a\u00c4\u00a2\n3+ years\nworking with Power BI and DAX.\n\u201a\u00c4\u00a2\n4+ years\nof experience working in an analyst role or related education.\n\u201a\u00c4\u00a2\n4+ years\nof experience in tools and systems on MS SQL Server BI Stack, including SSRS and TSQL, Power Query, MDX.\n\u201a\u00c4\u00a2 Strong experience in excel (pivots, formulas, and charts) to dissect preexisting stakeholder workflows.\n\u201a\u00c4\u00a2\n2+ years\nof experience in EPC (Engineering, Procurement and Construction) Project environment is preferred.\nMinimum\/preferred knowledge, skills and abilities required of the position:\n\u201a\u00c4\u00a2 Background with BI tools and systems such as Power BI.\n\u201a\u00c4\u00a2 Prior experience in data-related tasks.\n\u201a\u00c4\u00a2 Understanding of the Microsoft BI Stack.\n\u201a\u00c4\u00a2 Be familiar with MS SQL Server BI Stack tools and technologies, such as SSRS and TSQL, Power Query, MDX, Power BI, and DAX.\n\u201a\u00c4\u00a2 Analytical thinking for converting data into relevant reports and graphics.\n\u201a\u00c4\u00a2 Capable of enabling row-level data security.\n\u201a\u00c4\u00a2 Knowledge of Power BI application security layer models.\n\u201a\u00c4\u00a2 Ability to run DAX queries on Power BI desktop.\n\u201a\u00c4\u00a2 Proficient in doing advanced-level computations on the data set.\n\u201a\u00c4\u00a2 Good communication skills are required to communicate with project team.\n\u201a\u00c4\u00a2 Judgement, trust, and carefulness in handling sensitive and confidential information.\n\u201a\u00c4\u00a2 Strong organizational and time management skills to prioritize workload during peak periods.\n\u201a\u00c4\u00a2 Ability to identify and implement actions with minimum directions.\nRequired\/preferred education:\n\u201a\u00c4\u00a2 Bachelor\u201a\u00c4\u00f4s in computer science, or information system, or engineering, or construction management, or business.\nTRAVEL REQUIREMENTS:\nAssignment in Houston may need to visit to project site during construction phase.\nADDITIONAL INFORMATION:\nCommunicates effectively at all levels of the organization to ensure clarity in expectations requirements, and deliverables. Excellent analytical skills.\nTeam Player, good communication and reporting skills\nWelcomes working in a fast paced challenging and diverse entrepreneurial environment\nHands-on type of personality\nThis Position Description is not an exhaustive list of the duties and responsibilities, and the employee is expected to perform other duties as necessary and assigned. The duties and responsibilities of this position may be modified at any time to meet changing business needs.\n*In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\nNEXTDECADE VALUES\nSafety\n\u201a\u00c4\u00ec We make safety a priority. Everything we do relies on the safety of our people and the communities around us.\nIntegrity\n\u201a\u00c4\u00ec We do the right thing, and are open, ethical, and fair. We hold ourselves to the highest standards in all that we do.\nHonesty\n\u201a\u00c4\u00ec We value truth and honesty in ourselves and others. We honor our commitments and take responsibility for our actions.\nRespect\n\u201a\u00c4\u00ec We listen, and respect people, the environment, and the communities in which we live and work.\nTransparency\n\u201a\u00c4\u00ec Transparency builds trust. We promote open communication with our people, our customers, and all our stakeholders.\nDiversity\n\u201a\u00c4\u00ec We value diversity of people and thought. It takes people with different strengths, ideas, and cultural backgrounds to make our company succeed.\nShow more\nShow less",
      "job_skills":"Microsoft BI, SQL, Power BI, DAX, Power Query, Power BI scripts, SSRS, TSQL, ETL, Power BI application security layer models, Data warehouse",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Scientist, Product Growth",
      "company":"Jerry",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-product-growth-at-jerry-3789686108",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"We'd love to hear from you if you like:\nMaking a big impact with a Forbes Top Startup Employer\nWorking on products that have traction (40X revenue growth in 4 years | #1 rated app in the insurance comparison category)\nSolving problems in a huge market ($2T market size)\nWorking closely with serial entrepreneurs and seasoned leaders who have scaled companies like Robinhood, Amazon, LinkedIn, Wayfair, SoFi, Microsoft, etc.\nAbout the opportunity:\nWe are looking for a Senior Data Scientist to join our central data team and partner with one of our emerging product groups. Helping everyday, hard working Americans save time and money on their cars and creating a world class experience is what drives every decision we make as a company. Since launching our mobile app in 2019, we have amassed over 4M customers, expanded our product offerings to multiple categories and scaled our team 10X. Our data team fuels all of our business and product decisions through delivering analytical insights and building advanced models.\nWorking with a brilliant team of product managers, product designers, software engineers, and key business leaders, you will leverage data and insights to drive growth and retention for one of our emerging product groups (car repair marketplace or chatbot). You will perform analytical deep dives, develop and analyze experiments, build predictive models, and make recommendations that inform our product roadmap and new investment opportunities.\nHow you will make an impact:\nPartner closely with our product managers, software engineers, product designers, and key business leaders to drive user growth and retention for our core insurance product\nDesign, run, and analyze A\/B experiments on new and existing features; extract key insights, share learnings and make recommendations on next steps\nBuild key reports, dashboards, and predictive models to monitor the performance of our insurance business, and communicate analytical outcomes to our teams\nTransform and refine raw production data for analytical needs\nContinually improve our data governance and data consistency standards within our database\nWork with data engineering team on data tracking, integrity, and security as needed\nWork with other data scientists to evolve, optimize and integrate machine learning models\nWho you are:\nIntellectually curious: You're not satisfied with surface level insights. You dive deep to understand how systems work, why people behave in certain ways and are intrinsically motivated to uncover root causes for issues or underlying reasons behind decisions.\nCreative problem-solver: No challenge is too complex, no issue is too hard.\nData-driven: You're extremely analytical and live in data. At the same time, you're confident enough to make decisions when the data is limited.\nStrong communicator: Able to drive alignment and communicate effectively to different audiences.\nIdeal profile:\nBachelor\u201a\u00c4\u00f4s degree in Mathematics, Statistics, Economics, Computer Science or a related discipline\n2+ years of experience as a data scientist or product analyst in a consumer-facing web or mobile app environment\nExperience designing and implementing A\/B tests, and analyzing user experience\nHands-on experience with SQL (advanced proficiency)\nJerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.\nJerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at\nrecruiting@getjerry.com\nAbout Jerry:\nJerry is America\u201a\u00c4\u00f4s first and only AllCar\u201a\u00d1\u00a2 app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets.\nBacked by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all.\nWe are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 4 million customers \u201a\u00c4\u00ee and we\u201a\u00c4\u00f4re just getting started.\nJerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing.\nJoin our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that\u201a\u00c4\u00f4s disrupting a massive market.\nShow more\nShow less",
      "job_skills":"Data Science, Mathematics, Statistics, Economics, Computer Science, A\/B Testing, SQL, Machine Learning, Artificial Intelligence, App Development, Data Analysis, Data Governance, Data Consistency, Data Security, Data Engineering, Data Tracking, Data Integrity, Predictive Modeling, Product Management, Product Design, Software Engineering, Communication, Business Analytics, Business Intelligence",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Warehouse and BI Developer",
      "company":"Carriage Services",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-warehouse-and-bi-developer-at-carriage-services-3775030503",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"POWER BI DEVELOPER\nNo Agencies or 3RD Parties - Must be local to Houston\nAt\nCarriage Services\n, we believe in the concept of\n\u201a\u00c4\u00faFirst Who, Then What.\u201a\u00c4\u00f9\nWe have learned that leaders, who attract and surround themselves with the best people, achieve great things. Carriage Services is not for everyone. We believe in the Four E\u201a\u00c4\u00f4s of Leadership\u201a\u00c4\u00eeEnergy, Energize, Edge, and Execute. Our high-performance culture is demanding. If you can compete at this level, then our Company is for you!\nWe are looking for a Sr. Data warehouse and BI Developer to join our IT team in our Houston office. This person will be in charge of our Data warehouse, Dashboards and SQL and Power BI Reports.\nCompensation:\n$95,000 to $100,000 a year\nJob Type:\nFull-Time\n\"The What\"\nTroubleshoot and tune existing Data Warehouse, Dashboards and Reporting systems\nWrite and modify SSRS and Power BI reports\nCreate and Modify SSIS Packages as needed\nDesign and improve current ETL processes\nMaintain Azure Devops Pipelines\nCreate and update Power BI Data Models\nOwn and develop relationships with end-users, working with them to optimize and enhance existing reports and integrations\nHelp design, document and maintain system processes\nImprove systems by studying current practices and designing modifications.\nRecommend controls by identifying problems and writing improved procedures.\nMaintain professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; benchmarking state-of-the-art practices\n\"The Who\"\nBachelor\u201a\u00c4\u00f4s degree in Computer Science, Business or Information Science.\nMinimum of 5 to 10 years of experience in the field or in a related area.\nExperience with Microsoft SQL Server 2008 onwards, Transact-SQL, and Business Intelligence Development Studio (SSAS, SSIS, SSRS, Visual Studio).\nPower BI Experience\nKnowledge in Azure Data Factory and Pipelines\nFamiliarity with Essbase and MDX scripts a plus\nOperational Data Warehouse experience\nMust demonstrate basic knowledge or expertise in the following technology disciplines: Servers, Desktop\/Laptop\/Workstation Computing, Networking, Security, Programming, and\/or IT Operations\nAble to read, write and speak English fluently.\nProficient in Microsoft Office Suite (Outlook, Word, Excel, Access and PowerPoint) required.\nDetail oriented and ability to work in a team setting.\nAbility to be a self-starter and resolve issues with minimal supervision.\nMaintains a positive attitude\nAbility to handle multiple projects, prioritize tasks, and exercise good judgment.\nGood customer skills\nWilling to learn new systems and technology\nBenefits\n401(k)\n401(k) matching\nDental insurance\nEmployee assistance program\nEmployee discount\nHealth insurance\nHealth savings account\nLife insurance\nProfessional development assistance\nRetirement plan\nTuition reimbursement\nVision insurance\nShow more\nShow less",
      "job_skills":"Data Warehouse, Dashboards, SQL, Power BI, SSRS, Power BI Data Models, Azure Devops Pipelines, ETL, SSIS Packages, Relational Database, Microsoft SQL Server, TransactSQL, Business Intelligence Development Studio, SSAS, Visual Studio, MDX, Essbase, Server, Programming, Networking, Security, Microsoft Office Suite, Operational Data Warehouse, ETL",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Integration Engineer- EIT",
      "company":"HOLT CAT",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-integration-engineer-eit-at-holt-cat-3661328150",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"As the Lead Data Integration Engineer you will be part of a team responsible for delivering cloud data management solutions to our customers.\nIntegration engineers are an integral part of the Data Solutions team and primarily responsible for implementing solutions that integrate applications across an enterprise. They are the trusted advisor to client\u201a\u00c4\u00f4s technology teams and bring passion for solving complex business problems by designing and building reusable integrations.\nThe Lead Data Integration Engineer will support solution architects, business analysts and data engineers on system implementations and ensure optimal data delivery. They will work with stakeholders to define non-functional requirements and partner with solution architects to develop the solution architecture. This role will lead a team of onshore and offshore\/nearshore engineers responsible for building integrations and other required automation. They must be self-directed and comfortable supporting the integration needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of designing, optimizing or even re-designing our client\u201a\u00c4\u00f4s data architecture to support next generation of products and transformation initiatives.\nThe incumbent in this position is expected to model the following practices daily: 1) Demonstrate alignment with the company's mission and core business values; 2) Collaborate with key internal\/external resources; 3) Participate in ongoing self- development.\nEssential Functions:\nDevelops, evaluates, and influences effective and consistent productivity and teamwork to ensure the delivery of Legendary Customer Service (LCS)\nModels, promotes, reinforces, and rewards the consistent use of HOLT\u201a\u00c4\u00f4s Values Based Leadership (VBL) tools, models, and processes to ensure alignment with our Vision, Values, and Mission\nDefines systems integrations, design patterns and development standards to support cross-functional, multi-system solutions that are scalable and flexible to meet current and future needs of the organization\nAnalyzes and translates business requirements using frameworks into components of a modernized solution\nArchitects, designs, develops, and implements small to large scale integration solutions in MuleSoft platform based on functional and technical requirements\nCreates architectural deliverables that clearly communicate design and solution\nDesigns and develops automated solutions in accordance with MuleSoft and enterprise leading practices and design principles\nParticipates in design reviews to ensure they meet automation policies and design principles\nAuthors and maintains solution design documentation\nDevelops efficient, well-structured, reusable, and scalable automation processes and integrations\nPerforms thorough code-reviews based on high engineering standards and writes unit and integration tests based on chosen DevOps frameworks\nAnalyzes and resolves automation software issues whenever required\nIdentifies and communicates risks associated with integration solutions and process automation candidates\nProvides guidance to junior resources on best practices and development techniques for automated processes\nLeads one or more team members consisting of cross functional, global, and virtual groups; may need to supervise staff and assign responsibility to other team members.\nDevelop and maintain relationships with key client leadership\nWorks with Business Development Manager (BDM) (Salesperson) to identify new opportunities\nEngages in multiple short-term strategic consulting engagements and develop new opportunities\nManages the development of case studies and project summaries of each project delivered related to the service offering(s)\nActs as trusted advisor and expert on MuleSoft platform promoting security and performance\nWorks safely always and adheres to all applicable safety policies; complies with all company policies, procedures, and standards\nPerforms other duties as assigned\nKnowledge, Skills, and Abilities:\nExperience creating and maintaining domain diagrams, architecture frameworks, design patterns and standards to support various work streams\nStrong experience in the Application Integration Architecture, API and Microservices architecture, Solution Design, Development using SOA\/EAI solutions, API Led Architectures, creation of API design specifications, and RAML creation\nExperience integrating with Cloud\/SaaS applications, APIs, SDK of packaged applications and legacy Ideally have Salesforce, MS Dynamics, and Data warehouse integration experience\nHands on experience on MuleSoft's CloudHub, DataWeave, Anypoint MQ and deploying\/managing Mule flows to CloudHub\nExperience setting up and configuring on-premise\/cloud-based infrastructures\nExperience in implementing security aspects including API security, authentication, authorization, message & transport level security\nExperience in API Management tools using MuleSoft API Manager or others\nWell versed in configuring VPC and dedicated load balancer on Anypoint platform\nGood knowledge on DevOps stack (CI & CD) and other dependency management and build tools\nExperience working with API testing Tools like SOAPUI, postman\nExperience with High-Availability, Fault-Tolerance, Performance Testing and Tuning parameters\nWell versed with agile methodologies and source control (Bitbucket, GitHub, ADO)\nA desire to work as part of a growing, fast-paced, and highly flexible team\nBe comfortable working in a matrix environment and foster motivation within the project team to meet tight deadlines\nPossess the ability to manage workload, manage multiple priorities, and manage conflicts with customers\/employees\/managers, as applicable\nExcellent problem solving and project management skills; experienced in both Agile and waterfall methodologies\nEducation and Experience:\nHigh School diploma or equivalent required; Bachelor\u201a\u00c4\u00f4s degree in Information Technology, or related field preferred\n8+ years of experience in delivering enterprise complex systems integrations and intelligent automations required\n6+ years of demonstrated hands-on experience with ESB platforms such as Talend, Workato, Boomi, MuleSoft, Informatica or similar products required\nStrong working experience with SQL\/PLSQL and relational databases such as Oracle, MS SQL Server, and NoSQL databases required\nEstablished enterprise integration infrastructure, supporting ESB, messaging and SLA monitoring tools required\nExperience with messaging infrastructure, preferably Azure Service Bus and with Storage like Azure Blobs or Data Lake preferred\nExperience with ETL and Web Services based integrations with expert level knowledge of developing APIs using SOAP and REST architecture styles and data interchange formats like XML, JSON, etc. required\nExperience working in an Agile environment preferred\nPreferred Certifications\nActive MuleSoft, Salesforce or Azure\nMuleSoft Certified Developer and MuleSoft Certified Integration Architect\nSupervisory Responsibilities:\nThis position directs and manages the positions within assigned division. Responsibilities include, but are not limited to interviewing, hiring, and training employees; planning, assigning, and directing work; coaching and development; appraising performance; rewarding and educating employees; resolving conflicts.\nTravel:\nUp to 20% with occasionally overnight stay\nPhysical Requirements:\nThis position involves extended periods in a stationary position; additionally, occasional movement inside the office to access office machinery, file cabinets,\nThis role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines\nWork Environment\nThis job is generally performed in a professional office environment\nFrequently works at fast pace with unscheduled interruptions\nDisclaimer:\nPlease note that the above statements are intended to describe the general nature and level of work being performed by employees assigned to this classification. They are not to be interpreted as an exhaustive list of all responsibilities, duties, and skills required of the incumbents so classified. All incumbents may be required to perform duties outside of their normal responsibilities, as needed.\nShow more\nShow less",
      "job_skills":"Data Integration, Data Management, Data Engineering, Cloud Computing, MuleSoft, API Integration, Microservices, SOA\/EAI, Salesforce, MS Dynamics, Data Warehouse, DataWeave, Anypoint MQ, CloudHub, VPC, Load Balancer, DevOps, CI\/CD, SOAPUI, Postman, HighAvailability, FaultTolerance, Performance Testing, Tuning, Agile, Bitbucket, GitHub, ADO, SQL, PLSQL, Oracle, MS SQL Server, NoSQL, ESB, Messaging Infrastructure, Azure Service Bus, Azure Blobs, Data Lake, ETL, Web Services, SOAP, REST, XML, JSON",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Steneral Consulting",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-steneral-consulting-3741122848",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Hybrid role in either Chicago or Richardson (Must be local and undrer 60 mins to either location)\nNeed valid LinkedIn\nW2 candidates only\nDescription\nThis role requires the individual to have experience with collecting, organizing, and analyzing data from various resources. Primary tasks of this position are compilation and analysis of data definitions, meaning, usage, labelling standards and other source system information to produce IT consumable information. They may be required to take on other tasks as needed such as but not limited to: technical expertise with automatic data collection and reporting systems, including a capacity for program troubleshooting and system security measures\nRequired Qualification(s)\nShow more\nShow less",
      "job_skills":"Data Collection, Data Organization, Data Analysis, Data Compilation, Data Analysis, Data Definitions, Data Meaning, Data Usage, Labelling Standards, Source System Information, Program Troubleshooting, System Security",
      "Category":"Data Science"
  },
  {
      "job_title":"Labs - Data Scientist - Senior Associate",
      "company":"PwC",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/labs-data-scientist-senior-associate-at-pwc-3782251304",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Specialty\/Competency:\nData Science\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team designs, develops and programs the methods, processes, and systems that are used to collect all forms of data and develop models that serve predictions to applications, automated process flows, and stakeholders. A Data Scientist collects domain context from stakeholders, defines hypothesis and prediction tasks, identifies and creates supporting data sources, conducts experiments with various algorithms to model prediction tasks, undertakes validation and tests of models to improve performance, produces pipelines that can be used to automate training and predictions with unseen or production data, identifies meaningful insights from data sources, and contextualizes model outputs to communicate with stakeholders (product owners, process managers, and end consumers).\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nOur mandate is to quickly explore new technologies to determine what is relevant for our clients and Firm to invest in. Our work has a tremendous impact on how PwC and our clients do business. Our Data Scientists possess exceptional technical prowess matched by their ability to communicate results to other data scientists, clients, and internal stakeholders.\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nBachelor Degree\nAdditional Educational Requirements\nBachelor's degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and\/or progressively responsible work experience in technology for each missing year of college.\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nMaster Degree\nPreferred Fields Of Study\nComputer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management\/Research\nAdditional Educational Preferences\nPhD highly preferred\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success:\nExploring new analytical technologies and evaluate their technical and commercial viability;\nWorking across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications\/production ready tools;\nWorking across various data mediums: text, audio, imagery, sensory, and structured data;\nWorking in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients;\nTesting and rejecting hypotheses around data processing and ML model building;\nExperimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task;\nBuilding ML pipelines that ingest, clean data, and make predictions;\nFocusing on AI and ML techniques that are broadly applicable across all industries;\nStaying abreast of new AI research from leading labs by reading papers and experimenting with code;\nDeveloping innovative solutions and perspectives on AI that can be published in academic journals\/arXiv and shared with clients;\nApplying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.);\nUnderstanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique;\nUnderstanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow);\nUnderstanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application;\nBuilding ML models and systems, interpreting their output, and communicating the results; and,\nMoving models from development to production; conducting lab research and publishing work.\nDemonstrates thorough abilities and\/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:\nDemonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix;\nDemonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.);\nDemonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow;\nDemonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy;\nDemonstrating knowledge in NLU\/NLP domain: Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS;\nDemonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio); and,\nDemonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"Artificial Intelligence, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Robotics, Augmented Reality, Virtual Reality, Blockchain, Internet of Things, Drones, 3D Printing, Data Science, Product Management, Business Strategy, Software Engineering, Data Analysis, Data Visualization, Communication, Leadership, Problem Solving, Critical Thinking, Creativity, Innovation, Teamwork, Collaboration, Ethics, Research, Development, Production, Deployment, Maintenance, Support, Quality Assurance, Testing, Debugging, Documentation, Training, Education, Consulting, Mentoring, Coaching, Project Management, Agile Development, Scrum, Kanban, DevOps, Continuous Integration, Continuous Delivery, Continuous Deployment, Infrastructure as Code, Cloud Computing, Platform as a Service, Software as a Service, Infrastructure as a Service, Containers, Microservices, Serverless Computing, Function as a Service, EventDriven Architecture, Message Queuing, Data Streaming, Data Warehousing, Data Lake, Data Mining, Text Mining, Sentiment Analysis, Recommendation Systems, Fraud Detection, Anomaly Detection, Predictive Analytics, Forecasting, Optimization, Simulation, Modeling, Statistical Analysis, Data Visualization, Business Intelligence, Reporting, Dashboard, Data Storytelling, Communication, Presentation, Writing, Public Speaking, Negotiation, Conflict Resolution",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Scientist, Product Growth",
      "company":"Jerry",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-product-growth-at-jerry-3789682449",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"We'd love to hear from you if you like:\nMaking a big impact with a Forbes Top Startup Employer\nWorking on products that have traction (40X revenue growth in 4 years | #1 rated app in the insurance comparison category)\nSolving problems in a huge market ($2T market size)\nWorking closely with serial entrepreneurs and seasoned leaders who have scaled companies like Robinhood, Amazon, LinkedIn, Wayfair, SoFi, Microsoft, etc.\nAbout the opportunity:\nWe are looking for a Senior Data Scientist to join our central data team and partner with one of our emerging product groups. Helping everyday, hard working Americans save time and money on their cars and creating a world class experience is what drives every decision we make as a company. Since launching our mobile app in 2019, we have amassed over 4M customers, expanded our product offerings to multiple categories and scaled our team 10X. Our data team fuels all of our business and product decisions through delivering analytical insights and building advanced models.\nWorking with a brilliant team of product managers, product designers, software engineers, and key business leaders, you will leverage data and insights to drive growth and retention for one of our emerging product groups (car repair marketplace or chatbot). You will perform analytical deep dives, develop and analyze experiments, build predictive models, and make recommendations that inform our product roadmap and new investment opportunities.\nHow you will make an impact:\nPartner closely with our product managers, software engineers, product designers, and key business leaders to drive user growth and retention for our core insurance product\nDesign, run, and analyze A\/B experiments on new and existing features; extract key insights, share learnings and make recommendations on next steps\nBuild key reports, dashboards, and predictive models to monitor the performance of our insurance business, and communicate analytical outcomes to our teams\nTransform and refine raw production data for analytical needs\nContinually improve our data governance and data consistency standards within our database\nWork with data engineering team on data tracking, integrity, and security as needed\nWork with other data scientists to evolve, optimize and integrate machine learning models\nWho you are:\nIntellectually curious: You're not satisfied with surface level insights. You dive deep to understand how systems work, why people behave in certain ways and are intrinsically motivated to uncover root causes for issues or underlying reasons behind decisions.\nCreative problem-solver: No challenge is too complex, no issue is too hard.\nData-driven: You're extremely analytical and live in data. At the same time, you're confident enough to make decisions when the data is limited.\nStrong communicator: Able to drive alignment and communicate effectively to different audiences.\nIdeal profile:\nBachelor\u201a\u00c4\u00f4s degree in Mathematics, Statistics, Economics, Computer Science or a related discipline\n2+ years of experience as a data scientist or product analyst in a consumer-facing web or mobile app environment\nExperience designing and implementing A\/B tests, and analyzing user experience\nHands-on experience with SQL (advanced proficiency)\nJerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.\nJerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at\nrecruiting@getjerry.com\nAbout Jerry:\nJerry is America\u201a\u00c4\u00f4s first and only AllCar\u201a\u00d1\u00a2 app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets.\nBacked by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all.\nWe are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 4 million customers \u201a\u00c4\u00ee and we\u201a\u00c4\u00f4re just getting started.\nJerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing.\nJoin our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that\u201a\u00c4\u00f4s disrupting a massive market.\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Predictive Modeling, Product Analytics, A\/B Testing, SQL, Data Governance, Data Consistency, Data Integration, User Experience, Product Management, Software Engineering, Product Design, Business Intelligence, Data Visualization, Data Communication, Data Engineering, Data Tracking, Data Integrity, Data Security, Mathematics, Statistics, Economics, Computer Science, Artificial Intelligence",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Governance Analyst Specialist",
      "company":"Kforce Inc",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-governance-analyst-specialist-at-kforce-inc-3777073285",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nKforce has a client that is seeking a Data Governance Analyst Specialist in Kansas City, MO. Key Tasks:\nData Governance Analyst Specialist will execute the organization's data governance operating model and collaborate with various Company business and technical teams to implement enterprise data policies and standards for the organization\nMonitor progress of Data Domain teams with respect to the rollout of data governance practices and provide education, training, and support as needed\nEnsure data aligns with regulatory requirements as needed\nOversight and regular review of Data Domain Team deliverables related to data governance practices; Data maps; Data issue tracking; Metadata documentation; Data procedures documentation; Service Level Agreements; Access and security requirements; Audit and retention requirements\nPartner with Data Owners and Data Stewards to develop workflows, dashboards, and automation of data governance activities within our data governance tools\nAs a Data Governance Analyst Specialist, you will partner with HR's Learning and Development team to curate and deploy Data Governance, Data Stewardship, and Tool required training\nAct as a Collibra administrator and help train domain teams and consumers on the platform; Drive adoption of, and guide proper use of, features and functionality available within the tool\nWork closely with our tool vendors on roadmap items for implementation and provide feedback for additional improvements that would benefit Company\nManage internal data products, including reference data, metadata, data quality results, and SharePoint content\nRequirements\nBachelor's degree and\/or equivalent combination of education and work experience in related field; Finance, Accounting, or related education preferred\n2 or more years of confirmed experience working on a team engaged in data governance, data management, or data operations\nExperience with data governance, metadata, data mapping, and data lineage tools, such as Collibra, Informatica, IBM IGC, etc.\nFamiliarity with data security and protection methodologies\nComfortable with working in an agile work environment\nDemonstrated effectiveness working in a dynamic and high-paced environment\nValidated innovator and a strategic problem solver in the data governance space\nOutstanding interpersonal skills including the ability to communicate with individuals at all levels of the organization in both verbal and written form\nAbility to approach and solve problems in an analytical and methodical manner\nAbility to be proactive and collaborative in ambiguous situations\nPreferred\n2+ years of experience in the asset management industry, with strong domain knowledge of data management technology and operations\nExperience working with cloud technologies\nExperience in policy and standards development and maintenance\nExperience with MuleSoft Any point Studio or BPMN are a plus\nProject Management, Agile and\/or Six Sigma skills are a plus\nThe pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.\nWe offer comprehensive benefits including medical\/dental\/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.\nNote: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.\nThis job is not eligible for bonuses, incentives or commissions.\nKforce is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nSalary: $83,000 - $123,000 per year\nShow more\nShow less",
      "job_skills":"Data Governance, Data Stewardship, Collibra, Data Maps, Metadata Documentation, Data Procedures Documentation, Service Level Agreements, Access and Security Requirements, Audit and Retention Requirements, Data Quality, SharePoint, Informatica, IBM IGC, Data Security, Agile, BPMN, MuleSoft Any point Studio, Project Management, Six Sigma",
      "Category":"Data Science"
  },
  {
      "job_title":"Security Engineer III - Data Security",
      "company":"Stifel Financial Corp.",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/security-engineer-iii-data-security-at-stifel-financial-corp-3739533819",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Summary\nUnder minimal supervision, the Data Security Engineer III is a front-line member of the Data Security team that has responsibility for protecting corporate information assets. The Data Security Engineer III will be responsible for configuring and improving DLP policies on multiple tools, working towards increasing DLP Program coverage, crafting and maintaining DLP Program process documentation, defining new processes and controls to further mature the DLP Program, and addressing gaps that impact the DLP process.\nEssential Duties & Responsibilities\nDeploys and manages technology and process solutions to reduce the potential of data compromise\nDevelops technical requirements, evaluating vendor solutions, and testing of data security solutions\nUtilizes security tools to enhance data loss prevention capabilities across the Enterprise\nTune DLP policies on a continuous basis to maintain a mature set of policies within the scope of the DLP Program.\nImplement security policies to comply with data privacy, governance and regulatory requirements\nPerforms data protection monitoring and reporting, analyzes security alerts and escalates security alerts to local support teams.\nProposes improvements and assists in the implementation of enterprise wide security policies, procedures and standards to meet compliance responsibilities.\nPrepares status reports to develop security risk analysis scenarios.\nAssist in documenting standard operating procedures and protocols for the Data Security Pillar\nAssist in the development of technical solutions and processes to help mitigate security vulnerabilities and automate repeatable tasks.\nPartner with teams as needed to enhance DLP monitoring \/ response processes on an ongoing basis.\nQualifications\nStrong understand of how to identify and prioritize security incidents and\/or escalate to management or other team members.\nExperience translating data security questions into data analytical approaches\nHands-on experience in security systems, including data loss prevention, data classification, etc.\nUnderstanding of data classification frameworks and processes\nKnowledge of information security standards including CIS Critical controls and the NIST Cybersecurity Framework.\nAbility to systematically assess a problem or situation to accurately identify probable causes and solutions.\nUnderstanding of a broad range of IT disciplines that would impact overall security posture.\nProficiency in relating complex technical situations to non-technical customers.\nAbility to prioritize workload and consistently meet deadlines\nEducation & Experience\nBachelor's degree in Computer Science, Information Systems, Cybersecurity, or related field; or related combination of education and experience\n4+ years experience in an information technology or information security role\nCISSP, CISM, or Security+ certifications preferred\nAbout Stifel\nStifel is a more than 130 years old and still thinking like a start-up. We are a global wealth management and investment banking firm serious about innovation and fresh ideas. Built on a simple premise of safeguarding our clients\u201a\u00c4\u00f4 money as if it were our own, coined by our namesake, Herman Stifel, our success is intimately tied to our commitment to helping families, companies, and municipalities find their own success.\nWhile our headquarters is in St. Louis, we have offices in New York, San Francisco, Baltimore, London, Frankfurt, Toronto, and more than 400 other locations. Stifel is home to approximately 9,000 individuals who are currently building their careers as financial advisors, research analysts, project managers, marketing specialists, developers, bankers, operations associates, among hundreds more. Let\u201a\u00c4\u00f4s talk about how you can find your place here at Stifel, where success meets success.\nAt Stifel we offer an entrepreneurial environment, comprehensive benefits package to include health, dental and vision care, 401k, wellness initiatives, life insurance, and paid time off.\nStifel is an Equal Opportunity Employer.\nShow more\nShow less",
      "job_skills":"Data Security, DLP Tools, Data Loss Prevention, Security Policies, Security Alerts, Security Standards, Risk Analysis, Data Classification Frameworks, NIST Cybersecurity Framework, CIS Critical Controls, IT Disciplines, Technical Communication, Workload Prioritization, Computer Science, Information Systems, Cybersecurity, CISSP, CISM, Security+",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Database Engineer - SQL",
      "company":"Enterprise Mobility",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-database-engineer-sql-at-enterprise-mobility-3769040147",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Description\nEnterprise Mobility is the world\u201a\u00c4\u00f4s largest car rental operator and an industry leader in mobility and technology. We\u201a\u00c4\u00f4re one of the top global travel companies, ranking ahead of many airlines and most cruise lines and hotels. And no matter what transportation challenges our customers face, we have an innovative solution.\nWe operate the Enterprise Rent-A-Car National Car Rental and Alamo Rent A Car brands via more than 10,000 fully staffed neighborhood and airport offices, including franchisee branches, in over 90 countries and territories.\nThrough this robust global network, we operate a fleet of over 2.3 million vehicles and provide a comprehensive portfolio of transportation solutions, including car rental, carsharing, vanpooling, car sales, truck rental, vehicle-subscription and affiliated fleet management services. As a total mobility provider, we serve the needs of a wide variety of customers, businesses, government agencies and organizations every day.\nAt the center of it all, our dedicated IT teams innovate, design and develop the technology that is redefining how customers rent, buy and share vehicles from our family of brands. Here, you will be part of a diverse and talented team that creates and delivers powerful technology solutions for our customers and employees across the world with the resources and support to develop in a variety of career paths.\nAs an Enterprise employee, we offer an excellent package with market-competitive pay, comprehensive healthcare packages, 401k matching & profit sharing, schedule flexibility, work from home opportunities, paid time off, and organizational growth potential.\nThis position is open to candidates who wish to work from home (WFH). Employees who choose virtual \/ remote work should have an adequate space to serve as their home office.\nResponsibilties\nAs an\nSenior Database Engineer\n, you will be responsible for using your technical knowledge of professional concepts to solve business problems. We are looking for a talented individual that can work on a diverse work tasks and work with others in the department on complex assignments. You will be responsible for evaluating elements of technology's effectiveness through requirements gathering, testing, research and investigation and make recommendations for improvements that result in increased quality and effectiveness.\nIn this role, you will play a significant role in the implementation, migration, and maintenance of SQL Server On Prem and Azure SQL production databases. In addition, you will monitor daily database activities and overall performance, growth, and tuning configurations as well as the security patching of the databases. You will assist with process improvements and change activities, as well as participate in the teams on-call. We are looking for a self-starter that will maintain established service level agreements to meet customer expectations and quality standards.\nEqual Opportunity Employer\/Disability\/Veterans\nQualifications\nRequired:\nMust be presently authorized to work in the U.S. without a requirement for work authorization sponsorship by our company for this position now or in the future\nMust be committed to incorporating security into all decisions and daily job responsibilities\n3+ years of related experience\n3+ years of SQL Database engineering experience\n3+ years of experience with Microsoft and SQL scripting to automate tasks such as monitoring, patching, and generating reports\n2+ years of Azure Cloud Database experience\nStrong detail-oriented skills combined with sound problem solving and time management\nStrong verbal and written communication skills\nProven experience working in a fast-paced production environment\nMust be able to effectively collaborate and work with others in a remote work environment\nMust be able to work effectively in a change management environment\nPreferred\nBachelor's degree in Computer Science, Computer Information Systems, Management Information Systems, or related field preferred\nKnowledge on Microsoft cloud managed DBs\/Systems, e.g. Managed SQL Instance\nKnowledge of JIRA and Confluence a plus\nKnowledge of BitBucket and Git a plus\nKnowledge of Office 365 Windows environment\nKnowledge of Database Client software\nKnowledge of ServiceNow a plus\nKnowledge of SQL to Azure migration processes\n#IT\nShow more\nShow less",
      "job_skills":"SQL Server, Azure SQL, Microsoft SQL, JIRA, Confluence, BitBucket, Git, Office 365, Database Client software, ServiceNow, Azure Cloud Database, SQL to Azure migration processes",
      "Category":"Data Science"
  },
  {
      "job_title":"Data DevOps Engineer \/\/ St. Louis, MO",
      "company":"Motion Recruitment",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-devops-engineer-st-louis-mo-at-motion-recruitment-3785829212",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"A well-known brewing and beverage company is looking for a DevOps Engineer to join their team on a contract-to-hire basis. This will be a hybrid role working onsite in St. Louis, MO 2-3 days per week.\nAs a DevOps Engineer, you will be partnering up with Data Engineering and Data Science teams to architect data solutions. You will be using a DevOps approach to move data across their platforms and environments, so they are looking for someone who is knowledgeable on a variety of data systems.\nSkills & Experience\n4+ years of experience in DevOps\/Cloud Engineering\n2+ years of experience in an Azure cloud environment\nHands-on experience with Databricks, Snowflake, and\/or Apache Airflow\nCI\/CD experience using GitHub Actions is a plus\nPosted By:\nCarolyn Regimbal\nShow more\nShow less",
      "job_skills":"DevOps, Cloud Engineering, Azure, Databricks, Snowflake, Apache Airflow, GitHub Actions, CI\/CD",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Valorem Reply",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-valorem-reply-3754706155",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Note\nThis role requires candidates to be US Citizens.\nThis role requires individuals to be within driving distance from our office locations or willing to relocate (Atlanta, Chicago, Detroit, Kansas City and Philadelphia).\nValorem Reply is an award-winning digital transformation firm focused on delivering data-driven enterprise, IT modernization, customer experience, product transformation and digital workplace. Through the expertise of their people and power of Microsoft technologies, they provide hyper-scale and agile delivery of unique digital business services, strategic business models and design-led user experiences. Their innovative strategies and solutions securely and rapidly transform the way their clients do business.\nThe Senior Data Engineer will lead the creation of high-value data-driven solutions, leveraging Valorem Reply's proven implementation methodology and solutions for enterprise projects. They will also contribute to technical pre-sales activities as required. The responsibilities include designing solution architecture, defining requirements, and leading the project delivery team. There will be an opportunity to work with and learn about the latest cloud solutions in an exciting work environment. This position will work collaboratively across all of Valorem Reply's sales, service delivery, and account management organizations to serve Valorem Reply's customers.\nThis position will represent Valorem Reply's approach to advanced data engineering solutions and, as such, must demonstrate proficiency at the architecture level. It will require an understanding of how advanced analytics are positioned to meet business objectives and how data translates to business and enterprise value. The role will also involve implementing the Data Lakehouse solution through people, processes, and technology. This is a hands-on role, leading, coding, and delivering on the most advanced cloud data analytics platforms available. Projects will span from workshops to full enterprise production end-to-end solutions.\nThe ideal candidate will have extensive experience with Microsoft\/Azure data services and Databricks technology. Proficiency with the Databricks platform and the implementation of enterprise Data Lakehouse solutions will be required. Candidates will be expected to contribute to all stages of the data lifecycle, including data ingestion, data modeling, data profiling, data quality, data transformation, data movement, and data curation. The candidate should be familiar with market challenges in multiple industry verticals and have experience with both traditional and modern technologies across the Microsoft technology stack.\nResponsibilities\nLeading the development of data-driven solutions using Valorem Reply's methodology and enterprise project solutions.\nDesigning solution architecture and defining project requirements.\nStaying up to date with the latest cloud solutions and technologies.\nCollaborating across different teams to provide exceptional service to customers.\nDemonstrating expertise in data engineering and understanding how it aligns with business objectives.\nManaging the entire data lifecycle, from data ingestion to curation, and proficiency in Microsoft\/Azure data services and Databricks technology.\nMinimum Requirements\nBachelor's\/master\u201a\u00c4\u00f4s degree in computer science or equivalent with a focus on Azure data engineering solutions\n6+ years of data engineering delivery experience\n3+ years of Databricks engineering development experience\n2+ years of technical team leadership or technical management experience\nCandidates must be US Citizens\nShow more\nShow less",
      "job_skills":"Data Engineering, DataDriven Solutions, Solution Architecture, Project Requirements, Cloud Solutions, Microsoft Azure, Databricks, Data Lifecycle, Data Ingestion, Data Modeling, Data Profiling, Data Quality, Data Transformation, Data Movement, Data Curation, Data Analytics Platforms, Workshops, Full Enterprise Production, EndtoEnd Solutions, Microsoft Technology Stack, Technical Team Leadership, Technical Management",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"PRI Global",
      "job_location":"O'Fallon, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-pri-global-3780003357",
      "search_city":"Missouri",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"As per the client guidelines we are looking for only locals.\nThe requirement as follows\nJob title: Data Center Engineer\nDuration: 12+ months\nLocation: O'Fallon, MO\nMajor Accountabilities:\n\u201a\u00c4\u00a2Manage Data Center projects.\n\u201a\u00c4\u00a2Develop detailed requirements for upgrading existing corporate and MasterCard Data Centers, as well as re-architecting Data Centers to facilitate new requirements, technologies, and growth.\n\u201a\u00c4\u00a2Resolve Data Center operations problems impacting equipment performance globally.\n\u201a\u00c4\u00a2Participate in Data Center-related initiatives.\n\u201a\u00c4\u00a2Research and develop innovative solutions around Data Center technologies.\n\u201a\u00c4\u00a2Support assigned regional projects, which include responsibility for planning; time and cost control; resource utilization and implementation.\n\u201a\u00c4\u00a2Support Vendor management.\n\u201a\u00c4\u00a2Provide strategic technical direction on highly complex Data Center projects and activities involving the selection and recommendation of design approach and systems software technology.\n\u201a\u00c4\u00a2Serves as a point of escalation, resolving problems of diverse scopes where analysis of the situation requires in-depth technical evaluation and judgement\n\u201a\u00c4\u00a2Supports process improvement efforts to identify and test opportunities for automation and\/or reduction in time to deployment\n\u201a\u00c4\u00a2Performs security posture, which includes proactively identifying security risks and implementing both risk mitigation plans and control functions\n\u201a\u00c4\u00a2Mentors junior staff by providing training to develop technical skills and capabilities across the team\nShow more\nShow less",
      "job_skills":"Data Center management, Requirements analysis, Data Center architecture, Data Center operations, Problem resolution, Research and development, Vendor management, Technical direction, System software, Security posture, Risk mitigation, Process improvement, Automation, Deployment, Mentoring, Training",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Analyst",
      "company":"Proven Recruiting",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-at-proven-recruiting-3775130294",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"What you will be doing:\nWriting complex queries, joins, and stored procedures in SQL server\nCreating Power BI reports to present to the business\nAzure Cloud Migration\nRequirements:\n3 years experience in Data Analytics\n3 years of experience in SQL Server and Power BI\nStored Procedure experience in SQL\nBachelor's Degree\nLocation:\nHouston, TX\nSchedule:\nHybrid 4 days in Office, 1 day WFH\n#IND3\nWhat does this position pay?\nCompensation is determined by several factors which may include skillset, experience level, and geographic location.\nThe expected range for this role is $80,000 to $130,000 per year. Please note this range is an estimate and actual pay may vary based on qualifications and experience.\nShow more\nShow less",
      "job_skills":"SQL, Power BI, Azure Cloud, Stored Procedures, Data Analytics",
      "Category":"Data Science"
  },
  {
      "job_title":"Associate Data Engineer",
      "company":"48forty Solutions",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/associate-data-engineer-at-48forty-solutions-3737143441",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"48forty Solutions is the largest pallet management services company in North America. We provide end-to-end pallet solutions, from supply to retrieval, on-site services, reverse logistics, and packaging materials. 48forty Solutions is truly Pallet Management Made Simple. Our operations workforce is the heart and soul of our business. We are currently looking for an\nAssociate Data Engineer.\nSummary\nAs an Associate Data Engineer, you will be responsible for supporting the design, development, and maintenance of data pipelines and data processing systems using various technologies such as Azure, Spark SQL, SQL Server, Azure Data Factory, Azure Databricks, Azure DevOps, Git, Power BI, Azure Synapse Analytics, and Azure Databricks. You will work under the guidance of more senior data engineers and play a vital role in ensuring the availability, reliability, and scalability of data infrastructure and supporting data-driven initiatives within the organization.\nEssential Duties And Responsibilities\nData pipeline development: Collaborate with the data engineering team to develop and maintain data pipelines, ETL processes, and data integration workflows using Azure Data Factory, Azure Synapse Analytics, Spark SQL, and other relevant technologies. Ensure the timely and accurate movement of data between systems.\nData processing and transformation: Assist in implementing data processing and transformation logic using Azure Synapse Analytics, Spark SQL or Databricks. Extract insights from raw data and transform it into meaningful and structured formats in our data products.\nAzure service utilization: Work with Azure services such as SQL Server, Azure Data Factory, Azure Synapse and Azure Databricks to build and manage data infrastructure components. Leverage the capabilities of these services to ensure efficient and scalable data processing.\nVersion control and collaboration: Utilize Azure DevOps and Git for version control and collaborate effectively with the team to manage code repositories and ensure proper documentation and knowledge sharing.\nAzure DevOps integration: Assist in integrating data engineering workflows with Azure DevOps for continuous integration, continuous deployment, and automated testing. Contribute to the implementation of CI\/CD pipelines for data engineering projects.\nData visualization and reporting: Gain exposure to Power BI and support the team in developing insightful and visually appealing reports and dashboards to communicate data insights effectively to stakeholders.\nTroubleshooting and support: Assist in identifying and resolving data pipeline issues, bottlenecks, and data quality problems. Provide support in investigating and troubleshooting data-related incidents.\nContinuous learning and growth: Stay updated with the latest advancements in data engineering technologies and tools. Continuously enhance your knowledge of Azure services and data engineering best practices.\nQualifications And Skills\n2 years of experience in data engineering, data integration, or related roles.\nBachelor's Degree in Computer Science, Information Technology, or a related field preferred.\nHands-on experience with Azure services, including Azure Data Factory, Azure Synapse, and Azure Databricks.\nProficiency in SQL programming and experience working with SQL Server.\nFamiliarity with Spark SQL or Databricks for data processing and transformation.\nExposure to Git for version control and collaborative development.\nKnowledge of Azure DevOps practices for CI\/CD and automated testing.\nExperience with data visualization tools, such as Power BI, for developing reports and dashboards.\nUnderstanding of Azure Analysis Services and Azure Synapse Analytics is a plus.\nStrong problem-solving skills and attention to detail.\nGood communication and teamwork skills, with the ability to work effectively in a collaborative environment.\nSelf-motivated and eager to learn and grow in the field of data engineering.\nWork Environment\nThe work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential job functions.\nThe employee will be working at the corporate office and will be required to sit for long periods of time at a desk working on a laptop.\nThe noise level in the work environment is usually moderate.\nBenefits\nCompetitive Pay\nHoliday Pay\nReferral Bonuses\nLong-Term Career Advancement\nGreat Team Environment\nPTO\nFull-time employees eligible for Medical, Dental, Vision, Basic Life, AD&D and Short-Term & Long-Term Disability insurance on the 1st of the month following 60 days of employment\n48forty Solutions\nis an equal opportunity employer.\nPrivacy Policy\nCA Applicant\nCA Workforce\nShow more\nShow less",
      "job_skills":"Azure, Spark SQL, SQL Server, Azure Data Factory, Azure Databricks, Azure DevOps, Git, Power BI, Azure Synapse Analytics, ETL, Data pipelines, Data integration, Data processing, Data transformation, Data visualization, Data reporting, CI\/CD, Automated testing, Version control, Collaborative development, SQL programming, Data modeling, Data warehousing, Cloud computing, Big data",
      "Category":"Data Science"
  },
  {
      "job_title":"Database Engineer",
      "company":"Advanced Knowledge Tech LLC",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/database-engineer-at-advanced-knowledge-tech-llc-3673946387",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"For database engineer we have 2 roles.\nFor 1 we need SQL server and Sybase\nfor 2nd we need oracle and DB2.\nFor primary vs secondary out of both, we want 50-50 or even 60-40 is okay.\nOur largest DB platform is DB2 and SQL Server.\nOne should be familiar with installation of software, configuration and security - hardening the newly built host as per enterprise standards.\nAllocating SAN storage and mounts with DB restores and point-in-time recovery.\nJob Description\nManage SQL Server databases\nConfigure and maintain database servers and processes\nMonitor system's health and performance\nEnsure high levels of performance, availability, sustainability and security\nAnalyze, solve, and correct issues in real time\nProvide suggestions for solutions\nRefine and automate regular processes, track issues, and document changes\nAssist developers with query tuning and schema refinement\nPerform scheduled maintenance and support release deployment activities after hours\nQualifications\n5 years of experience as a SQL Server DBA\/Sybase\/DB2 or similar role\n4 years of experience with SQL Server DBA\/Sybase\/DB2 Administration experience required\nCritical thinker and problem-solving skills\nShow more\nShow less",
      "job_skills":"SQL Server, Sybase, Oracle, DB2, SAN, Enterprise standards, Database restores, Pointintime recovery, Monitoring, Performance tuning, Availability, Security, Troubleshooting, Problemsolving, Query tuning, Schema refinement, Maintenance, Deployment, DBA, Administration",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"InfoVision Inc.",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-infovision-inc-3774848104",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are looking for\nLead Data Engineer with\nAzure Synapse,\nAzure ADF, Power BI, ETL (SSIS) AND ITIL V4 Concepts\nExperience. It\u201a\u00c4\u00f4s an\nonsite\nposition in\nDallas, TX\n.\nQualifications:\n15+ years of experience in ETL & Data Warehousing\nShould have excellent leadership & communication skills\nShould have in depth knowledge on SSIS ETL Tool and good working knowledge on Power BI\nShould have worked on data sources such as SAP and Salesforce\nShould have very good knowledge of SSIS (ETL Tool), StreamSets (ETL Tool), Azure Cloud, ADF, Azure Synapse Analytics & Azure Hub Events\nShould have executed atleast 2 Azure Cloud Data Warehousing projects\nShould have worked atleast 4 projects using Agile\/SAFe methodology\nShould have demonstrated working knowledge on ITIL V4 concepts such as Incident Management, Problem Management, Change Management & Knowledge Management\nShould have working experience on any DevOps tools like GitHub, Jenkins, etc & on semi-structured data formats like JSON, Parquet and\/or XML files & written complex SQL queries for data analysis and extraction.\nShould have in depth understanding on Data Warehousing, Data Analysis, Data Profiling, Data Quality & Data Mapping\nShould have cross global location experience and led a team of atleast 15+ members in a global delivery model\nShould have experience in working with product managers, project managers, business users, applications development team members, DBA teams and Data Governance team on a daily basis to analyze requirements, design, development and deployment technical solutions\nResponsibilities:\nLead nearshore and offshore team to do production support of existing EDW, design, build & deploy enhancements and bug fixes to existing EDW\nSupport the existing EDW system built using Azure SQL, Microsoft SSIS, StreamSets & Power BI\nBe on call to support job incidents on rotational basis\nWork with business and technology stakeholders to communicate EDW incidents\/problems and manage their expectations\nLeverage ITIL concepts to circumvent incidents, manage problems and document knowledge\nAnalyze the different source systems, profile data, understand, document & fix Data Quality issues\nGather requirements and business process knowledge in order to transform the data in a way that is geared towards the needs of end users\nWrite complex SQLs to extract & format source data for ETL\/data pipeline\nCreate design documents, Source to Target Mapping documents and any supporting documents needed for deployment\/migration\nDesign, Develop and Test ETL\/Data pipelines\nWrite Unit Test cases, execute Unit Testing and document Unit Test results\nDeploy ETL\/Data pipelines\nUse DevOps tools to version, push\/pull code and deploy across environments\nSupport team during troubleshooting & debugging defects & bug fixes, business requests, environment migrations & other adhoc requests\nMaintain and improve already existing processes\nEnsure that the data pipelines are stable, secure, maintainable and highly available\n--\nAnjanna (ARJUN) Pallapu\nManager- Recruitment\nanjanna.pallapu@infovision.com\nwww.infovision.com\nShow more\nShow less",
      "job_skills":"Azure Synapse, Azure ADF, Power BI, ETL (SSIS), ITIL V4 Concepts, SSIS ETL tool, StreamSets ETL tool, Azure Cloud, Azure Hub Events, Agile\/SAFe methodology, GitHub, Jenkins, JSON, Parquet, XML files, Data Warehousing, Data Analysis, Data Profiling, Data Quality, Data Mapping, DevOps, Product Management, Project Management, Business User, Application Dev Team, DBA, Data Governance, EDW, SQL, Source to Target Mapping, ETL\/Data pipeline development, Unit Testing, Troubleshooting, Debugging",
      "Category":"Data Science"
  },
  {
      "job_title":"NETWORK\/DATA ENGINEER",
      "company":"ASK Consulting",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/network-data-engineer-at-ask-consulting-3778725589",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"\"All candidates must be directly contracted by ASK Consulting on their payroll and cannot be subcontracted. We are unable to provide sponsorship at this moment\".\nJob Title: NETWORK\/DATA ENGINEER\nLocation: Irving, TX, 75039\nDuration: 32 months\nPay Rate : $50 on W2\nIn office 3 days per week\nJob Description:\nRequired Skills:\nTOP 5 Skills Needed:\nProject based work in a team environment\nCisco CCNA certification\nExperience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena\nCloud computing \/ Whitebox\nEthernet\/L2 & L3 Troubleshooting\nResponsibilities:\nOverall Purpose: Responsible for providing custom data network operational support, design, engineering, and planning for complex global data network and communications projects involving TCP\/IP and related protocol connectivity for networks supporting AT&T customers in a 7x24 environment. Roles & Responsibilities: 1) Responsible for the management of the interoperability between Cisco and Juniper Layer 3 Platform, through the use of alarm and ticket systems, individual designed customized scripts, customer notification, and Business Partner escalations. 2) Responsible for deploying new routers, switches, and trunk capacity as well as configuring them. 3) Responsibilities include providing real time in-depth analysis and real time trouble resolution of incidents associated with the CISCO, Juniper, and associated Operations Support Systems, and Data Communications Network Technology platforms.\nAbout ASK:\nASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With 5 nationwide offices, two global delivery centers, and employees in 42 states-ASK Consulting connects people with amazing opportunities\nASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.\nShow more\nShow less",
      "job_skills":"Cisco CCNA, IOS, IOSXR, Arista EOS, Ciena, Cloud Computing, Whitebox, Ethernet, L2, L3, Troubleshooting, TCP\/IP, Juniper Layer 3 Platform, Scripts, Network Technology",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Engineer Sr Manager - Enterprise Data Foundation",
      "company":"PepsiCo",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-sr-manager-enterprise-data-foundation-at-pepsico-3754930775",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Overview\nLocation:\nMust be located within 90 miles of Plano TX, Purchase NY, or Chicago IL. This is a\nHybrid Position:\nTargeting 3 days in office per week\nData & Analytics at Pepsico:\nPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo\u201a\u00c4\u00f4s global business scale to enable business insights, advanced analytics and new product development.\nPepsiCo\u201a\u00c4\u00f4s\nEnterprise Data Operations (EDO)\nteam is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations, and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\nWhat PepsiCo Enterprise Data Operations (EDO) does:\nMaintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company\nResponsible for day-to-day data collection, transportation, maintenance\/curation and access to the PepsiCo corporate data asset\nWork cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders\nIncrease awareness about available data and democratize access to it across the company\nResponsibilities\nAs a Senior data engineering manager, you will be the key technical expert overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be empowered to create & lead a strong team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems. This role will lead a group of Senior Engineers working on Customer domain data.\nAssess and recommend architecture frameworks, design and implement high-performance solutions to support data and analytical products.\nAct as a subject matter expert across different digital projects.\nOversee\u201a\u00c4\u00d8work with internal clients and external partners to structure and store data into unified taxonomies and link them together with standard identifiers.\nManage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.\nBuild and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.\nExecute on a technical solution with minimal guidance, creating solution prototypes, providing top quality design, and create documentation for support and understanding of code created for each initiative\nEmpower the business by creating value through the increased adoption of data, data science and business intelligence landscape.\nCollaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.\nEvolve the architectural capabilities and maturity of the data platform by engaging with enterprise architects and strategic internal and external partners.\nStrong technical background in data science, business intelligence or data engineering and ETL best practices.\nDefine and manage SLA\u201a\u00c4\u00f4s for data products and processes running in production.\nContinue to improve code quality by tracking, reducing, and avoiding technical debt\nWork collaboratively with product managers, senior scientists, engineers, and other team members in an agile and scrum environment to fulfill modeling needs.\nWork closely with source data application teams and product owners to design, implement and support analytics solutions that provide insights to make better decisions\nCreate documentation for learnings and knowledge transfer.\nCreate and audit reusable packages or libraries.\nImplement Azure products and services, including Azure Data Lake Storage, Azure Data Factory, Azure Functions, Event Hub, Azure Stream Analytics, Azure Databricks, etc., as well as conventional data warehouse tools, to create data migration and data engineering solutions.\nQualifications\n10+ years of overall technology experience that includes at least 8+ years of hands-on software development, data engineering, and systems architecture.\n8+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.\n8+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).\n5+ years in cloud data engineering experience in at least one cloud (Azure, AWS, GCP).\nFluent with Azure cloud services. Azure Certification is a plus.\nExperience scaling and managing a team of 5+ engineers.\nExperience with integration of multi cloud services with on-premises technologies.\nExperience with data modeling, data warehousing, and building high-volume ETL\/ELT pipelines.\nExperience with data quality and data profiling tools like Apache Griffin, Deequ, and Great Expectations.\nExperience building\/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.\nExperience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.\nExperience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.\nExperience with version control systems like Github and deployment & CI tools.\nExperience with Azure Data Factory, Databricks and Mlflow is a plus.\nExperience with Statistical\/ML techniques is a plus.\nExperience with building solutions in the retail or in the supply chain space is a plus\nUnderstanding of metadata management, data lineage, and data glossaries is a plus.\nWorking knowledge of agile development, including DevOps and DataOps concepts.\nFamiliarity with business intelligence tools (such as PowerBI).\nBA\/BS in Computer Science, Math, Physics, or other technical fields.\nPreferably some experience in the CPG Industry\nSkills, Abilities, Knowledge\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nProven track record of leading, mentoring, hiring and scaling data teams.\nStrong change manager. Comfortable with change, especially that which arises through company growth. Able to lead a team effectively through times of change.\nAbility to understand and translate business requirements into data and technical requirements.\nHigh degree of organization and ability to manage multiple, competing projects and priorities simultaneously.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong leadership, organizational and interpersonal skills; comfortable managing trade-offs.\nFoster a team culture of accountability, communication, and self-management.\nProactively drives impact and engagement while bringing others along.\nConsistently attain\/exceed individual and team goals\nAbility to lead others without direct authority in a matrixed environment.\nUnderstands both the engineering and business side of the Data Products released.\nTeams up and collaborates for speed, agility, and innovation.\nStrong negotiation and decision-making skill.\nExperience managing and working with globally distributed teams.\nCompensation and Benefits:\nThe expected compensation range for this position is between $125,000 $190,600 based on a full-time schedule\nLocation, confirmed job-related skills and experience will be considered in setting actual starting salary\nBonus based on performance and eligibility; target payout is 15% of annual salary paid out Annually.\nPaid time off subject to eligibility, including paid parental leave, vacation, sick, and bereavement\nIn addition to salary, PepsiCo offers a comprehensive benefits package to support our employees and their families, subject to elections and eligibility: Medical, Dental, Vision, Disability, Health and Dependent Care Reimbursement Accounts, Employee Assistance Program (EAP), Insurance (Accident, Group Legal, Life), Defined Contribution Retirement Plan.\nEEO Statement\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.\nPepsiCo is an Equal Opportunity Employer: Female \/ Minority \/ Disability \/ Protected Veteran \/ Sexual Orientation \/ Gender Identity\nIf you'd like more information about your EEO rights as an applicant under the law, please download the availableEEO is the Law&EEO is the Law Supplementdocuments. ViewPepsiCo EEO Policy.\nPlease view ourPay Transparency Statement\nShow more\nShow less",
      "job_skills":"DataOps, Data Engineering, ETL\/ELT Pipelines, Data Warehousing, SQL, Data Quality and Profiling, Data Analytics, Data Modeling, Cloud Data Engineering, Azure Data Services, Cloud Infrastructure, Containerized Services, Kubernetes, Version Control Systems, DevOps and DataOps Concepts, Agile Development, Business Intelligence Tools, Hadoop, Data Lake Storage, Data Factory, Machine Learning, Statistical Techniques, Supply Chain Management, Metadata Management, Data Lineage, Data Glossaries, PowerBI, Tableau, Virtualization",
      "Category":"Data Science"
  },
  {
      "job_title":"Cloud Data Engineer\/Developer",
      "company":"Talener",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/cloud-data-engineer-developer-at-talener-3757621969",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Our client is a health-tec firm that provides a platform for claims management and an online pharmacy. They are looking to hire a Cloud Data Engineer\/Developer that is strong with Azure, Synapse and data lakes.\nTitle:\nCloud Data Engineer\/Developer\nLocation: Plano. TX\nRequired Skills And Responsibilities\nManage all aspects of database design, including implementation, maintenance, security, audits, performance, and the ability to generate reports\nAbility to consolidate date to Synapse\nDesign, architect, and build databases from business requirements\nManage and develop processes for Disaster recovery and HA with DevOps\nGenerate traces, execution plans, performance issues, deadlocks, and remediate\nDefine and implement storage, replication, partitioning, and archiving procedures\nMonitoring DB system performance and delivering reports to management\nSet up and database infrastructure supporting Analytics \/ BI processes\n4+ years of product or project development experience\nNice To Have Skills\nKnowledge of HIPAA and SOC2\nDB tools- Azure SQL DB,Azure SQL Managed Instance, ADF)\nExperience with ElasticSearch, Redshift, Snowflake, PostgreSQL\nAzure cloud technology stack (ARM, Bicep)\nTerraform Cloud\nCompensation\n$120,000-150,000\nAnnual bonus\nFor additional information, please reach out to Jed Pillion at jpillion@talener.com\nShow more\nShow less",
      "job_skills":"Azure, Synapse, Data lakes, Database design, Data consolidation, Business requirements, Disaster recovery, DevOps, Performance tuning, Storage procedures, Replication, Partitioning, Archiving, Database infrastructure, Analytics, BI processes, HIPAA, SOC2, Azure SQL DB, Azure SQL Managed Instance, Azure Data Factory (ADF), ElasticSearch, Redshift, Snowflake, PostgreSQL, Azure cloud technology stack, ARM, Bicep, Terraform Cloud",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr Data Solutions Analyst",
      "company":"National Life Group",
      "job_location":"Addison, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-solutions-analyst-at-national-life-group-3771069738",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Senior Data Solutions Analyst\nOverview\nAt National Life Group we are in the process of changing how we think about, organize, and use data. In order to get the most value from our data it is critical that we have timely, accurate, consistent and well-defined data throughout the organization. Success depends on strong commitment & collaboration from all areas of the organization. The Analytical Governance Team is key to enabling this transformation.\nThe Senior Data Solutions Analyst Is a Key Member Of Our Analytics Center Of Excellence, Which Provide Two Main Functions To The Organization\nFacilitation of enterprise reporting & analytics by administering tools, providing business ready data sets, & assisting in delivering high quality information to decision makers.\nSupport of data projects & the data governance framework through advising on deliverables related to new and existing analytical solutions.\nObviously, we are looking for someone who loves data! Beyond that, a successful candidate will embrace the type of work that comes with a transformative effort. They will also contribute to the culture of National Life \u201a\u00c4\u00ec where servant leadership, company values & applying learnings to performance are valued above all else.\nThe Senior Data Solutions Analyst role is a great opportunity to join a fast-growing team that is central to National Life\u201a\u00c4\u00f4s data transformation. You will be exposed to different teams who work as part of the data delivery chain. Through this work you will get exposure and guidance from senior and executive leaders across the enterprise and a chance to collaborate with peers from other departments.\nResponsibilities\nJob Responsibilities:\nAfter getting up to speed on National Life\u201a\u00c4\u00f4s processes they will support the two functions above, primarily through owning end-to-end one of our analytical applications and providing ad-hoc analysis for key stakeholders. A typical day-to-day experience will vary, but will be some combination of:\nOwning the end-to-end experience of one of our analytical applications, including user training, user experience, incidents, upgrade support, etc.\nProviding general support of data & analytics as a subject matter expert for a specific functional domain\nCreating, enhancing, enforcing & promoting data governance policies & practices\nOwning functions within the analytical governance processes to facilitate delivering data solutions to production environments\nRequirements & Qualifications\nBachelor's degree in Math, Economics, Engineering, or related quantitative field\n3-5 years of experience with data governance, data management or data analytics\nStrong communication skills, and the ability to explain technical solutions to non-technical audiences\nExperience with relational databases (e.g. Microsoft SQL) and writing queries\nAbility to learn data & technology as it relates to business functions\nAnalytical and critical thinking skills, i.e. a problem solver\u201a\u00c4\u00f4s mindset\nExperience administering Analytical tools, specifically Tableau & Alteryx, preferred\nThe base compensation range represents the low and high end of the range for this position. Actual compensation will vary and may be above or below the range based on various factors including but not limited to qualifications, skills, competencies, location, and experience. The range listed is just one component of our total compensation package for employees.\nOther rewards may include an annual bonus, quarterly bonuses, commissions, and other long-term incentive compensation, depending on the position. National Life offers a competitive total rewards package which includes: a 401(k) retirement plan match; medical, dental, and vision insurance; a company funded wellness account for director and below employees; 10 paid holidays; a generous paid time off plan (22 days of combined time-off for non-exempt employees and exempt employees have discretion in managing their time, including scheduling time off in the normal course of business, but in no event will exempt employees receive less sick time than required by state or local law); 6 weeks of paid parental leave; and 6 weeks of paid family leave after a year of full-time employment\nNational Life Group\u00ac\u00c6 is a trade name of National Life Insurance Company, Montpelier, VT \u201a\u00c4\u00ec founded in 1848, Life Insurance Company of the Southwest, Addison, TX \u201a\u00c4\u00ec chartered in 1955, and their affiliates. Each company of National Life Group is solely responsible for its own financial condition and contractual obligations. Life Insurance Company of the Southwest is not an authorized insurer in New York and does not conduct insurance business in New York. Equity Services, Inc., Member FINRA\/SIPC, is a Broker\/Dealer and Registered Investment Adviser affiliate of National Life Insurance Company. All other entities are independent of the companies of National Life Group.\nFortune 1000 status is based on the consolidated financial results of all National Life Group companies.\nNational Life Group\n1 National Life Dr\nMontpelier, VT 05604\nSocial Media Policy\nSite Disclosure and Privacy Policy\nShow more\nShow less",
      "job_skills":"Data governance, Data management, Data analytics, Data solutions, Data quality, Data modeling, Data integration, Data mining, Data visualization, Data warehousing, Data architecture, Data security, Relational databases, SQL, Tableau, Alteryx, Analytical tools, Communication skills, Problem solving skills, Analytical thinking, Critical thinking, Mathematics, Economics, Engineering",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Architect",
      "company":"Robert Half",
      "job_location":"League City, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-architect-at-robert-half-3776683525",
      "search_city":"Dickinson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are seeking a highly skilled Data Architect to join our dynamic IT team. The ideal candidate will have extensive experience in designing and implementing robust data architectures, with a strong focus on Microsoft Azure. As a Data Architect, you will play a pivotal role in shaping our data strategy, ensuring data integrity, and optimizing data solutions. The successful candidate will possess a deep understanding of database technologies and a proven track record in architecting scalable and efficient data systems.\nResponsibilities:\nData Architecture Design:\nDesign and implement scalable, secure, and efficient data architectures in alignment with organizational goals.\nCollaborate with stakeholders to understand data requirements and translate them into technical solutions.\nAzure Data Platform Expertise:\nLeverage Microsoft Azure services for data storage, processing, and analytics.\nDesign and implement data solutions using Azure SQL Database, Azure Synapse Analytics, and other Azure data services.\nDatabase Management:\nOversee database design, optimization, and performance tuning.\nEnsure data consistency, integrity, and security across various databases.\nData Integration and Migration:\nLead data integration initiatives, ensuring seamless connectivity between disparate systems.\nManage and execute data migration projects to Azure, ensuring minimal downtime and data loss.\nData Governance and Compliance:\nDevelop and implement data governance policies and procedures.\nEnsure compliance with data privacy regulations and industry standards.\nCollaboration and Communication:\nCollaborate with cross-functional teams, including developers, analysts, and business stakeholders.\nCommunicate complex technical concepts to non-technical audiences effectively.\nDocumentation:\nCreate and maintain comprehensive documentation of data architectures, standards, and processes.\nProvide training and support to internal teams on data-related best practices.\nQualifications:\nEducation:\nBachelor's degree in Information Technology, Computer Science, or a related field. Advanced degree preferred.\nExperience:\nMinimum of 5 years of experience as a Data Architect, with a strong emphasis on Azure data solutions.\nProven experience in designing and implementing data architectures in a complex environment.\nTechnical Skills:\nExpertise in Microsoft Azure data services (Azure SQL Database, Azure Synapse Analytics, Azure Data Factory, etc.).\nStrong database management skills, including experience with SQL Server and other relational databases.\nCertifications:\nRelevant certifications such as Microsoft Certified: Azure Data Engineer Associate or equivalent.\nSoft Skills:\nExcellent communication and interpersonal skills.\nStrong analytical and problem-solving abilities.\nAbility to work collaboratively in a team environment.\nShow more\nShow less",
      "job_skills":"Data architecture, Data modeling, Data integration, Data migration, Data governance, Data security, Data quality, Data warehousing, Big data, Cloud computing, Microsoft Azure, Azure SQL Database, Azure Synapse Analytics, Azure Data Factory, SQL Server, Relational databases, Microsoft Certified: Azure Data Engineer Associate",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior System Engineer - (Bryan\/College Station Data Center)",
      "company":"Kelsey-Seybold Clinic",
      "job_location":"Pearland, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-system-engineer-bryan-college-station-data-center-at-kelsey-seybold-clinic-3754678448",
      "search_city":"Dickinson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nJob Description\nPrimary responsibilities driving and owning projects and initiatives set out by leadership, ability to lead and set examples to non-senior staff on how to best optimize and create processes as well as document for more effective support. Technology vendor liaison and alignment with business objectives set forth by leadership as well as responding to critical situations. Staying up to date on any technology advancements and making recommendations to the business as to changes that align with business objectives. On-Call and ticket resolution as well as responsibility coverage from non-senior positions maybe required in specific instances.\nJob Title: Senior System Engineer - IT Systems\nClinic Location: Pearland Administrative Office\nDepartment:\nIT Systems\nJob Type: Full Time\nSalary Range: $122,247 - $151,015 (Pay is based on several factors including but not limited to education, work experience, certifications, etc.)\nQualifications\nEducation\nRequired: Technical Bachelor\u201a\u00c4\u00f4s degree or equivalent experience\nPreferred: Master\u201a\u00c4\u00f4s Degree\nExperience\nRequired: 7 years of System Administrator \/ Engineering experience\nPreferred: Prior experience in the health care industry including exposure to Epic Systems technologies.\nLicense(s)\nRequired: N\/A\nPreferred: CompTIA A+\nCompTIA Server+\nMicrosoft Certified Professional\nMicrosoft Certified IT Professional\nMicrosoft Certified Technology Specialist\nMicrosoft Certified Systems Administrator\nMicrosoft Certified Systems Engineer\nVMware Certified Professional\nSpecial Skills\nRequired: Excellent verbal and written communication skills; Strong analytical and problem-solving skills;\nSelf motivated and excels in team and individual environments; Implementation, support, and maintenance of Windows and Linux Server Operating Systems;\nImplementation, support, and maintenance of Microsoft Clustering or other HA solutions;\nStrong Directory Services Administration (Active Directory, LDAP, ADAM);\nStrong understanding of networking fundamentals and troubleshooting;\nStrong understanding of backup \/ recovery and other business continuity services;\nStrong understanding of alerting and monitoring;\nStrong understanding of architecture, security, and performance tuning;\nStrong understanding of storage technologies including SAN and NAS (Configuration, Zoning on Fiber Channel Switches, and multi-pathing);\nKnowledge of build automation, patch management, automated deployments and packaging;\nKnowledge of Cloud authentication 2FA\nPreferred: Linux Server Administration \/ Engineering\nMicrosoft SQL Server Administration \/ Engineering\nMicrosoft IIS Server Administration \/ Engineering\nMicrosoft SQL Server Administration \/ Engineering\nMicrosoft Exchange Administration \/ Engineering\nMicrosoft System Center Administration \/ Engineering\nM365 Admin Portal Administration\nAzure IaaS, Paas, Saas Administration \/ Engineering\nServer Virtualization (VMWare, Hyper-V) Administration \/ Engineering\nOn-Prem \/ Hybrid Cloud Orchestration and Automation\nOther\nRequired: N\/A\nPreferred: N\/A\nWorking Environment:\nOther\nAbout Us\nStart your career journey and become a part of a community of renowned Healthcare professionals. Kelsey-Seybold Clinic is Houston\u201a\u00c4\u00f4s fastest growing, multispecialty organization with more than 40 premier locations and over 65 specialties. Our clinics are comprised of more than 600 physicians and as we continue to grow, our focus is providing quality patient care by adding to our team of clinical and non-clinical professionals that work together in a convenient, coordinated, and collaborative manner. Enjoy the rewards of a successful career while maintaining a work\/life balance by joining our team today and changing the way health cares.\nWhy Kelsey-Seybold Clinic?\nMedical, Vision, and Dental\nTuition Reimbursement\nCompany Matching 401K\nEmployee Reward and Recognition Program\nPaid time off for vacation, sick, and holidays\nEmployee Assistance Program\nContinuing Medical Education allowance\nShow more\nShow less",
      "job_skills":"Leadership, Process Optimization, Documentation, Technology Vendor Liaison, Business Objectives Alignment, Technology Advancements, IT Systems, Windows Server Operating Systems, Linux Server Operating Systems, Microsoft Clustering, HA Solutions, Directory Services Administration, Active Directory, LDAP, ADAM, Networking Fundamentals, Troubleshooting, Backup \/ Recovery, Business Continuity Services, Alerting, Monitoring, Architecture, Security, Performance Tuning, Storage Technologies, SAN, NAS, Configuration, Zoning, Fiber Channel Switches, Multipathing, Build Automation, Patch Management, Automated Deployments, Packaging, Cloud Authentication 2FA, Linux Server Administration \/ Engineering, Microsoft SQL Server Administration \/ Engineering, Microsoft IIS Server Administration \/ Engineering, Microsoft Exchange Administration \/ Engineering, Microsoft System Center Administration \/ Engineering, M365 Admin Portal Administration, Azure IaaS, PaaS, SaaS Administration \/ Engineering, Server Virtualization, VMWare, HyperV, OnPrem \/ Hybrid Cloud Orchestration, Automation",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Integration Engineer",
      "company":"Jefferson Frank",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-integration-engineer-at-jefferson-frank-3785117346",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Role & Responsibilities\nArchitects, designs, and implements integration solutions on the MuleSoft platform based on functional and technical requirements.\nCreates and maintains solution design documentation.\nProvides guidance and leadership to junior team members.\nActs as a trusted advisor and expert on the MuleSoft platform, promoting security and performance.\nDevelops and evaluates productivity and teamwork to ensure Legendary Customer Service.\nModels and promotes the use of Values Based Leadership tools to align with company values.\nDefines systems integrations and design standards for scalable and flexible solutions.\nManages relationships with key clients and identifies new opportunities.\nPreferred Skills & Qualifications\nHands-on experience with MuleSoft's CloudHub, DataWeave, Anypoint MQ, and deploying\/managing Mule flows to CloudHub.\nStrong experience in Application Integration Architecture, API and Microservices architecture, and Solution Design using SOA\/EAI solutions.\nKnowledge of integrating with Cloud\/SaaS applications, APIs, SDK of packaged applications, and legacy systems, ideally including Salesforce, MS Dynamics, and Data warehouse integration.\nExperience in setting up and configuring on-premise\/cloud-based infrastructures.\nProficiency in implementing security aspects, including API security, authentication, authorization, message & transport level security.\nExperience working with API Management tools like MuleSoft API Manager.\nWell-versed in configuring VPC and dedicated load balancer on the Anypoint platform.\nFamiliarity with DevOps stack (CI & CD) and other dependency management and build tools.\nShow more\nShow less",
      "job_skills":"MuleSoft, CloudHub, DataWeave, Anypoint MQ, SOA\/EAI, Application Integration Architecture, API, Microservices, Cloud\/SaaS applications, Salesforce, MS Dynamics, Data warehouse, VPC, API Manager, DevOps, CI\/CD, Dependency management, Build tools",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Integration Engineer- EIT",
      "company":"HOLT CAT",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-integration-engineer-eit-at-holt-cat-3661328150",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"As the Lead Data Integration Engineer you will be part of a team responsible for delivering cloud data management solutions to our customers.\nIntegration engineers are an integral part of the Data Solutions team and primarily responsible for implementing solutions that integrate applications across an enterprise. They are the trusted advisor to client\u201a\u00c4\u00f4s technology teams and bring passion for solving complex business problems by designing and building reusable integrations.\nThe Lead Data Integration Engineer will support solution architects, business analysts and data engineers on system implementations and ensure optimal data delivery. They will work with stakeholders to define non-functional requirements and partner with solution architects to develop the solution architecture. This role will lead a team of onshore and offshore\/nearshore engineers responsible for building integrations and other required automation. They must be self-directed and comfortable supporting the integration needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of designing, optimizing or even re-designing our client\u201a\u00c4\u00f4s data architecture to support next generation of products and transformation initiatives.\nThe incumbent in this position is expected to model the following practices daily: 1) Demonstrate alignment with the company's mission and core business values; 2) Collaborate with key internal\/external resources; 3) Participate in ongoing self- development.\nEssential Functions:\nDevelops, evaluates, and influences effective and consistent productivity and teamwork to ensure the delivery of Legendary Customer Service (LCS)\nModels, promotes, reinforces, and rewards the consistent use of HOLT\u201a\u00c4\u00f4s Values Based Leadership (VBL) tools, models, and processes to ensure alignment with our Vision, Values, and Mission\nDefines systems integrations, design patterns and development standards to support cross-functional, multi-system solutions that are scalable and flexible to meet current and future needs of the organization\nAnalyzes and translates business requirements using frameworks into components of a modernized solution\nArchitects, designs, develops, and implements small to large scale integration solutions in MuleSoft platform based on functional and technical requirements\nCreates architectural deliverables that clearly communicate design and solution\nDesigns and develops automated solutions in accordance with MuleSoft and enterprise leading practices and design principles\nParticipates in design reviews to ensure they meet automation policies and design principles\nAuthors and maintains solution design documentation\nDevelops efficient, well-structured, reusable, and scalable automation processes and integrations\nPerforms thorough code-reviews based on high engineering standards and writes unit and integration tests based on chosen DevOps frameworks\nAnalyzes and resolves automation software issues whenever required\nIdentifies and communicates risks associated with integration solutions and process automation candidates\nProvides guidance to junior resources on best practices and development techniques for automated processes\nLeads one or more team members consisting of cross functional, global, and virtual groups; may need to supervise staff and assign responsibility to other team members.\nDevelop and maintain relationships with key client leadership\nWorks with Business Development Manager (BDM) (Salesperson) to identify new opportunities\nEngages in multiple short-term strategic consulting engagements and develop new opportunities\nManages the development of case studies and project summaries of each project delivered related to the service offering(s)\nActs as trusted advisor and expert on MuleSoft platform promoting security and performance\nWorks safely always and adheres to all applicable safety policies; complies with all company policies, procedures, and standards\nPerforms other duties as assigned\nKnowledge, Skills, and Abilities:\nExperience creating and maintaining domain diagrams, architecture frameworks, design patterns and standards to support various work streams\nStrong experience in the Application Integration Architecture, API and Microservices architecture, Solution Design, Development using SOA\/EAI solutions, API Led Architectures, creation of API design specifications, and RAML creation\nExperience integrating with Cloud\/SaaS applications, APIs, SDK of packaged applications and legacy Ideally have Salesforce, MS Dynamics, and Data warehouse integration experience\nHands on experience on MuleSoft's CloudHub, DataWeave, Anypoint MQ and deploying\/managing Mule flows to CloudHub\nExperience setting up and configuring on-premise\/cloud-based infrastructures\nExperience in implementing security aspects including API security, authentication, authorization, message & transport level security\nExperience in API Management tools using MuleSoft API Manager or others\nWell versed in configuring VPC and dedicated load balancer on Anypoint platform\nGood knowledge on DevOps stack (CI & CD) and other dependency management and build tools\nExperience working with API testing Tools like SOAPUI, postman\nExperience with High-Availability, Fault-Tolerance, Performance Testing and Tuning parameters\nWell versed with agile methodologies and source control (Bitbucket, GitHub, ADO)\nA desire to work as part of a growing, fast-paced, and highly flexible team\nBe comfortable working in a matrix environment and foster motivation within the project team to meet tight deadlines\nPossess the ability to manage workload, manage multiple priorities, and manage conflicts with customers\/employees\/managers, as applicable\nExcellent problem solving and project management skills; experienced in both Agile and waterfall methodologies\nEducation and Experience:\nHigh School diploma or equivalent required; Bachelor\u201a\u00c4\u00f4s degree in Information Technology, or related field preferred\n8+ years of experience in delivering enterprise complex systems integrations and intelligent automations required\n6+ years of demonstrated hands-on experience with ESB platforms such as Talend, Workato, Boomi, MuleSoft, Informatica or similar products required\nStrong working experience with SQL\/PLSQL and relational databases such as Oracle, MS SQL Server, and NoSQL databases required\nEstablished enterprise integration infrastructure, supporting ESB, messaging and SLA monitoring tools required\nExperience with messaging infrastructure, preferably Azure Service Bus and with Storage like Azure Blobs or Data Lake preferred\nExperience with ETL and Web Services based integrations with expert level knowledge of developing APIs using SOAP and REST architecture styles and data interchange formats like XML, JSON, etc. required\nExperience working in an Agile environment preferred\nPreferred Certifications\nActive MuleSoft, Salesforce or Azure\nMuleSoft Certified Developer and MuleSoft Certified Integration Architect\nSupervisory Responsibilities:\nThis position directs and manages the positions within assigned division. Responsibilities include, but are not limited to interviewing, hiring, and training employees; planning, assigning, and directing work; coaching and development; appraising performance; rewarding and educating employees; resolving conflicts.\nTravel:\nUp to 20% with occasionally overnight stay\nPhysical Requirements:\nThis position involves extended periods in a stationary position; additionally, occasional movement inside the office to access office machinery, file cabinets,\nThis role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines\nWork Environment\nThis job is generally performed in a professional office environment\nFrequently works at fast pace with unscheduled interruptions\nDisclaimer:\nPlease note that the above statements are intended to describe the general nature and level of work being performed by employees assigned to this classification. They are not to be interpreted as an exhaustive list of all responsibilities, duties, and skills required of the incumbents so classified. All incumbents may be required to perform duties outside of their normal responsibilities, as needed.\nShow more\nShow less",
      "job_skills":"Data Integration, MuleSoft, CloudHub, DataWeave, Anypoint MQ, VPC, API Manager, Bitbucket, GitHub, ADO, SOAPUI, High Availability, Fault Tolerance, Performance Testing, Agile, SQL, PLSQL, Oracle, MS SQL Server, NoSQL, Azure Service Bus, Azure Blobs, Azure Data Lake, REST, XML, JSON",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Engineer",
      "company":"Xoriant",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-at-xoriant-3775952368",
      "search_city":"Menlo Park",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Position Title: Data Engineer\nLocation: Sunnyvale, CA \/ Dallas, TX \/ REMOTE (need to work CST hours)\nDuration: 12 Months contract with possibility of extension\nPosition Description:\nSkill Set Required:\nSpark, Scala, Google Cloud, SQL, Hive, Hadoop and any scheduling tool.\nExperience level:\nMinimum 4-5 years of experience as Big Data Engineer\nShow more\nShow less",
      "job_skills":"Spark, Scala, Google Cloud, SQL, Hive, Hadoop, Scheduling tools, Big Data Engineering",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Governance Manager",
      "company":"Harnham",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-governance-manager-at-harnham-3786550637",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"DATA GOVERNANCE MANAGER\n$135,000 \u201a\u00c4\u00ec $145,000 + BONUS + BENEFITS\nHYBRID \u201a\u00c4\u00ec OFFICE LOCATED IN HOUSTON, TX\nThis automotive\/retail company is seeking a Data Governance Manager to implement, execute, and manage the data governance strategy for the organization. This is a pivotal role for the company and the strategy that is created by the Data Governance Manager will have high visibility across the company.\nROLE OVERVIEW:\nPartner closely with senior leadership within the Data and Analytics group to implement and manage the overall Data Governance strategy.\nLead critical initiatives, including intake and requirement processes, data and KPI standardization, Governance committee implementation, Master Data Management, Data Security, Data Quality, Data Retention, Data Glossary, and Self-Service reporting.\nRESPONSIBILITIES:\nCollaborate with stakeholders, IT teams, and various business units.\nUnderstand data quality and BI tools, particularly their interaction with data virtualization systems.\nDiscover and connect with data across different business units, focusing on KPI metrics and business acumen.\nDevelop and execute a comprehensive data governance strategy based on business unit needs.\nLay out a plan and roadmap for the implementation of the data governance strategy.\nSKILLS AND EXPERIENCE:\nProven experience building a data governance model and executing it from the ground up.\n5+ years of industry experience\nBackground in data (data analyst, engineer, or product manager) before transitioning to implementing data governance.\nStrong communication skills, and ability to influence and command a room.\nFamiliarity with master data, domains, transactions, data warehouses, and quality standards.\nBENEFITS\n$135,000 - 145,000 Base Salary + Bonus + Benefits\nHOW TO APPLY\nPlease register your interest by sending your Resume to Emma Spagnola via the Apply link on this page or at emmaspagnola@harnham.com.\nShow more\nShow less",
      "job_skills":"Data Governance, Data Analyst, Data Engineer, Data Product Manager, Data Quality, Data Retention, Data Security, Data Virtualization, Data Warehouse, Data Standardization, SelfService Reporting, Business Acumen, KPI Metrics, Master Data Management, Master Data, Domains, Transactions",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Governance Manager",
      "company":"Harnham",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-governance-manager-at-harnham-3787367814",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"DATA GOVERNANCE MANAGER\n$135,000 - $145,000 + BONUS + BENEFITS\nHYBRID - OFFICE LOCATED IN HOUSTON, TX\nThis automotive\/retail company is seeking a Data Governance Manager to implement, execute, and manage the data governance strategy for the organization. This is a pivotal role for the company and the strategy that is created by the Data Governance Manager will have high visibility across the company.\nROLE OVERVIEW:\nPartner closely with senior leadership within the Data and Analytics group to implement and manage the overall Data Governance strategy.\nLead critical initiatives, including intake and requirement processes, data and KPI standardization, Governance committee implementation, Master Data Management, Data Security, Data Quality, Data Retention, Data Glossary, and Self-Service reporting.\nRESPONSIBILITIES:\nCollaborate with stakeholders, IT teams, and various business units.\nUnderstand data quality and BI tools, particularly their interaction with data virtualization systems.\nDiscover and connect with data across different business units, focusing on KPI metrics and business acumen.\nDevelop and execute a comprehensive data governance strategy based on business unit needs.\nLay out a plan and roadmap for the implementation of the data governance strategy.\nSKILLS AND EXPERIENCE:\nProven experience building a data governance model and executing it from the ground up.\n5+ years of industry experience\nBackground in data (data analyst, engineer, or product manager) before transitioning to implementing data governance.\nStrong communication skills, and ability to influence and command a room.\nFamiliarity with master data, domains, transactions, data warehouses, and quality standards.\nBENEFITS\n$135,000 - 145,000 Base Salary + Bonus + Benefits\nShow more\nShow less",
      "job_skills":"Data Governance, Data Analyst, Data Quality, Data Retention, Master Data Management, Data Security, Data Virtualization, BI tools, KPI Metrics, Business Acumen, Data Warehouse, Quality Standards, Data Visualization, Data Engineering, Data Product Management, Data Strategy, Data Governance Model, Business Intelligence, Data Governance Committee, Data Glossary, SelfService Reporting",
      "Category":"Data Science"
  },
  {
      "job_title":"Big Data Developer - III (827754)",
      "company":"The Judge Group",
      "job_location":"Grand Prairie, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-developer-iii-827754-at-the-judge-group-3729749269",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Location:\nGrand Prairie, TX\nDescription:\nOur client is currently seeking a Big Data Developer - III\nJOB TITLE: GCP Senior Big Data Engineer\/Architect\nLooking for a Senior Big Data Engineer\/Architect on Google Cloud Platform to help strategize, architect and implement various solutions to migrate data hosted on our on-prem platform to Google cloud Platform (GCP).\nThe architect will design and implement enterprise infrastructure and platforms required for setting up data engineering pipelines utilizing the tools available on the GCP Platform.\nAs a GCP Platform Architect - You will work on Advanced Data Engineering products using Google Big Data technologies such as GCS, Data Proc, Airflow, Data Store and Big Query.\nVery strong leadership and communication skills exhibiting right negotiating posture with customer and program teams to make the right decisions.\nExperience leading one or more of the following areas of a Cloud transformation journey: strategy, design, application migration planning and implementation for any private and public cloud. Cloud foundation design and build\/implement Cloud Transformation & Migration Cloud Managed service (IaaS and PaaS) Cloud foundation design and build\/implement\nMUST HAVE SKILLS (Most Important)\nGoogle Cloud Certified Professional Cloud Architect Certification Bachelor?s degree with 3-5 years? experience on Google cloud with deep understanding, design and development experience with GCP products on Infrastructure, Data management, Application Development, Smart Analytics, Artificial Intelligence, Security and DevOps Extract, Transform and Load (ETL) & Big Data Tools: BigQuery, Cloud Dataflow, Cloud Proc, Cloud Pub\/Sub, Cloud Composer, Google Data Studio, Google Cloud Storage. NoSQL databases: Cloud Bigtable, Cloud Fire store, Firebase Realtime Database, Cloud Memory store. Search Technologies: Lucene and Elasticsearch Relational Databases: Cloud Spanner, Cloud SQL DESIRED SKILLS: Strong knowledge on Google cloud storage Data lifecycle management Strong knowledge on BIGQuery Slots management Cost optimization for Dataproc workload management Experience of designing, building, and deploying production-level data pipelines using tools from Hadoop stack (HDFS, Hive, Spark, HBase, Kafka, NiFi, Oozie, Splunk etc). Development and deployment technologies (e.g. JIRA, GitHub, Jenkins, Nexus, Artifactory) Software development background with solid understanding of and experience in Software development life cycle (SDLC), DevOps, CI\/CD. At least 2-year experience in architecting in enterprises using Agile methodologies - Experience in data visualization tools like Kibana, Grafana, Tableau and associated architectures. JOB DUTIES: Provide Subject Matter Expertise in cloud and hybrid-cloud computing with Google Cloud and related products; thereby becoming a trusted advisor to influential decision makers. Provide end-to-end technical guidance and expertise on how to effectively use Google Cloud to build solutions; creatively applying cloud infrastructure and platform services to help solve business problems; and communicating these approaches to different business users Design and implement Google solution architecture with the different products like Google App Engine, BigQuery, Kubernetes Engine, AutoML, assess architecture needs for projects, work with different development leads and managers to scope and craft proposals. Work to harvest best practices and document lessons learned as part of continuous improvement and aid in company-wide data governance. Periodically update senior management with the status of the project with excellent written and verbal communication skills. EDUCATION\/CERTIFICATIONS: Bachelor?s degree with 3-5+ years of experience on Google cloud with deep understanding, design and development experience with GCP products on Infrastructure, Data management, Application Development, Smart Analytics, Artificial Intelligence, Security and DevOps?\nContact:\nspandey02@judge.com\nThis job and many more are available through The Judge Group. Find us on the web at www.judge.com\nShow more\nShow less",
      "job_skills":"Google Cloud Certified Professional Cloud Architect Certification, Google Cloud Platform, Extract Transform and Load (ETL), Big Data Tools: BigQuery Cloud Dataflow Cloud Proc Cloud Pub\/Sub Cloud Composer Google Data Studio Google Cloud Storage., NoSQL databases: Cloud Bigtable Cloud Fire store Firebase Realtime Database Cloud Memory store., Search Technologies: Lucene and Elasticsearch, Relational Databases: Cloud Spanner Cloud SQL, Hadoop stack (HDFS Hive Spark HBase Kafka NiFi Oozie Splunk etc)., Software development life cycle (SDLC) DevOps CI\/CD., Kibana Grafana Tableau",
      "Category":"Data Science"
  },
  {
      "job_title":"Data & Progress Analyst (Ref ID: 230)",
      "company":"NextDecade",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-progress-analyst-ref-id-230-at-nextdecade-3718470080",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"ABOUT NEXTDECADE\nNextDecade Corporation\nis an energy company accelerating the path to a net-zero future and leading innovation in more sustainable LNG and carbon capture solutions, NextDecade is committed to providing the world access to cleaner energy. Through our subsidiaries Rio Grande LNG and NEXT Carbon Solutions, we are developing a 27 MTPA LNG export facility in South Texas along with one of the largest carbon capture and storage projects in North America. We are also working with third-party customers around the world to deploy our proprietary processes to lower the cost of carbon capture and storage and reduce CO2 emissions at their industrial-scale facilities. By combining emissions reduction associated with our carbon capture and storage project, responsibly sourced gas, and our pledge to use net-zero electricity, Rio Grande LNG is expected to produce\na lower carbon intensive LNG\nfor the world.\nNextDecade\u201a\u00c4\u00f4s common stock is listed on the Nasdaq Stock Market under the symbol \u201a\u00c4\u00faNEXT.\u201a\u00c4\u00f9 NextDecade is headquartered in Houston, Texas.\nSUMMARY OF THE ROLE:\nThis is a Data and Progress Analyst position within the Project Controls department to support execution of over 12 billion Dollar LNG Project. This role is responsible for designing, developing, and deploying project analytic dashboards using Microsoft BI technologies such as SQL, Power BI, etc.\nRESPONSIBILITIES:\n\u201a\u00c4\u00a2 Using Power BI, create dashboards and interactive visual reports.\n\u201a\u00c4\u00a2 Recognize project requirements in the context of BI and create data models to transform raw data into relevant insights.\n\u201a\u00c4\u00a2 Define key performance indicators (KPIs) with specific objectives and track them regularly.\n\u201a\u00c4\u00a2 Analyze data and display it in reports to aid decision-making.\n\u201a\u00c4\u00a2 Create, test, and deploy Power BI scripts, as well as execute efficient deep analysis.\n\u201a\u00c4\u00a2 Use Power BI to run DAX queries and functions.\n\u201a\u00c4\u00a2 Create charts and data documentation with explanations of algorithms, parameters, models, and relationships.\n\u201a\u00c4\u00a2 Construct a data warehouse.\n\u201a\u00c4\u00a2 Use SQL queries to get the best results.\n\u201a\u00c4\u00a2 Make technological adjustments to current BI systems to improve their performance.\n\u201a\u00c4\u00a2 For a better understanding of the data, use filters and visualizations.\n\u201a\u00c4\u00a2 Analyze current ETL procedures to define and create new systems.\nREQUIREMENTS:\nMinimum\/preferred experience required for the position:\n\u201a\u00c4\u00a2\n3+ years\nworking with Power BI and DAX.\n\u201a\u00c4\u00a2\n4+ years\nof experience working in an analyst role or related education.\n\u201a\u00c4\u00a2\n4+ years\nof experience in tools and systems on MS SQL Server BI Stack, including SSRS and TSQL, Power Query, MDX.\n\u201a\u00c4\u00a2 Strong experience in excel (pivots, formulas, and charts) to dissect preexisting stakeholder workflows.\n\u201a\u00c4\u00a2\n2+ years\nof experience in EPC (Engineering, Procurement and Construction) Project environment is preferred.\nMinimum\/preferred knowledge, skills and abilities required of the position:\n\u201a\u00c4\u00a2 Background with BI tools and systems such as Power BI.\n\u201a\u00c4\u00a2 Prior experience in data-related tasks.\n\u201a\u00c4\u00a2 Understanding of the Microsoft BI Stack.\n\u201a\u00c4\u00a2 Be familiar with MS SQL Server BI Stack tools and technologies, such as SSRS and TSQL, Power Query, MDX, Power BI, and DAX.\n\u201a\u00c4\u00a2 Analytical thinking for converting data into relevant reports and graphics.\n\u201a\u00c4\u00a2 Capable of enabling row-level data security.\n\u201a\u00c4\u00a2 Knowledge of Power BI application security layer models.\n\u201a\u00c4\u00a2 Ability to run DAX queries on Power BI desktop.\n\u201a\u00c4\u00a2 Proficient in doing advanced-level computations on the data set.\n\u201a\u00c4\u00a2 Good communication skills are required to communicate with project team.\n\u201a\u00c4\u00a2 Judgement, trust, and carefulness in handling sensitive and confidential information.\n\u201a\u00c4\u00a2 Strong organizational and time management skills to prioritize workload during peak periods.\n\u201a\u00c4\u00a2 Ability to identify and implement actions with minimum directions.\nRequired\/preferred education:\n\u201a\u00c4\u00a2 Bachelor\u201a\u00c4\u00f4s in computer science, or information system, or engineering, or construction management, or business.\nTRAVEL REQUIREMENTS:\nAssignment in Houston may need to visit to project site during construction phase.\nADDITIONAL INFORMATION:\nCommunicates effectively at all levels of the organization to ensure clarity in expectations requirements, and deliverables. Excellent analytical skills.\nTeam Player, good communication and reporting skills\nWelcomes working in a fast paced challenging and diverse entrepreneurial environment\nHands-on type of personality\nThis Position Description is not an exhaustive list of the duties and responsibilities, and the employee is expected to perform other duties as necessary and assigned. The duties and responsibilities of this position may be modified at any time to meet changing business needs.\n*In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\nNEXTDECADE VALUES\nSafety\n\u201a\u00c4\u00ec We make safety a priority. Everything we do relies on the safety of our people and the communities around us.\nIntegrity\n\u201a\u00c4\u00ec We do the right thing, and are open, ethical, and fair. We hold ourselves to the highest standards in all that we do.\nHonesty\n\u201a\u00c4\u00ec We value truth and honesty in ourselves and others. We honor our commitments and take responsibility for our actions.\nRespect\n\u201a\u00c4\u00ec We listen, and respect people, the environment, and the communities in which we live and work.\nTransparency\n\u201a\u00c4\u00ec Transparency builds trust. We promote open communication with our people, our customers, and all our stakeholders.\nDiversity\n\u201a\u00c4\u00ec We value diversity of people and thought. It takes people with different strengths, ideas, and cultural backgrounds to make our company succeed.\nShow more\nShow less",
      "job_skills":"Microsoft BI, SQL, Power BI, DAX, Data visualization, Dashboards, Reporting, Data analysis, KPI, ETL, Power Query, MDX, SSRS, TSQL, Data security, Data modeling, Data warehouse, Power BI desktop, Data computation, Communication, Analytical thinking, Problem solving, Teamwork, Project management, Time management, Prioritization, Attention to detail, Bachelor's degree in computer science information system engineering construction management or business",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Raft",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-raft-3690645958",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"This is a U.S. based position. All of the programs we support require\nU.S. citizenship to be eligible for employment. All work must be conducted within the continental U.S.\nWho we are:\nRaft ( https:\/\/TeamRaft.com ) is a customer-obsessed non-traditional small business with purposeful focus on Distributed Data Systems, Platforms at Scale, and Complex Application Development, with headquarters in Reston, VA. Our range of clients include innovative federal and public agencies leveraging design thinking, cutting edge tech stack, and cloud native ecosystem. We build digital solutions that impact the lives of millions of Americans.\nWe\u201a\u00c4\u00f4re looking for an experienced\nSenior Data Engineer\nto support our customer and join our passionate team of high-impact problem solvers.\nAbout the role:\nAs a Senior Data Engineer, you will be responsible for building and maintaining extract, transform, load (ETL) pipelines to enable comprehensive data operations, from ingest to query. You will use your in-depth understanding of data architecture, database management, and data processing workflows, ensuring efficient and secure handling of our data resources.\nWhat we are looking for:\nMinimum of 7 years of hands-on experience in data engineering or related field\nExtensive experience in building and managing ETL pipelines\nExperienced in building ETL pipelines for comprehensive data operations, meeting and exceeding business value requirements, potentially demonstrated through significant experiences or one exceptionally impactful event\nExperience with Cloud-based systems and\/or AI\/Machine Learning Development\nBachelor's degree in Statistics, Computer Science, Data Science, or a related field\nHighly preferred:\nUnderstanding of data security practices and policies, with the ability to design and implement security measures\nExceptional problem-solving abilities and strong analytical skills\nExcellent interpersonal and communication skills, able to effectively collaborate with team members and stakeholders\nAbility to adapt to changing business requirements and learn new technologies quickly\nAdvanced certification related to data management or data engineering would be a plus\nClearance Requirements:\nAbility to obtain\/maintain a Top Secret Security clearance\nWork Type:\nSan Antonio, TX (Local remote)\nMay require up to 10% travel\nWhat we will offer you:\nHighly competitive salary\nFully covered healthcare, dental, and vision coverage\n401(k) and company match\nUnlimited PTO + 11 paid holidays\nEducation & training benefits\nAnnual budget for your tech\/gadgets needs\nMonthly box of yummy snacks to eat while doing meaningful work\nRemote, hybrid, and flexible work options\nTeam off-site in fun places!\nGenerous Referral Bonuses\nAnd More!\nOur Vision Statement:\nWe bridge the gap between humans and data through radical transparency and our obsession with the mission.\nOur Customer Obsession:\nWe will approach every deliverable like it's a product. We will adopt a customer-obsessed mentality. As we grow, and our footprint becomes larger, teams and employees will treat each other not only as teammates but customers. We must live the customer-obsessed mindset, always. This will help us scale and it will translate to the interactions that our Rafters have with their clients and other product teams that they integrate with. Our culture will enable our success and set us apart from other companies.\nHow do we get there?\nPublic-sector modernization is critical for us to live in a better world. We, at Raft, want to innovate and solve complex problems. And, if we are successful, our generation and the ones that follow us will live in a delightful, efficient, and accessible world where out-of-box thinking, and collaboration is a norm.\nRaft\u201a\u00c4\u00f4s core philosophy is\nUbuntu: I Am, Because We are\n. We support our \u201a\u00c4\u00fanadi\u201a\u00c4\u00f9 by elevating the other Rafters. We work as a hyper collaborative team where each team member brings a unique perspective, adding value that did not exist before. People make Raft special. We celebrate each other and our cognitive and cultural diversity. We are devoted to our practice of innovation and collaboration.\nWe\u201a\u00c4\u00f4re an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\nShow more\nShow less",
      "job_skills":"Data Engineering, ETL Pipelines, Cloudbased Systems, AI\/Machine Learning, Data Security, Data Management, Data Processing, Data Architecture, Database Management, Statistics, Computer Science, Data Science",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Raft",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-raft-3731727301",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"This is a U.S. based position. All of the programs we support require\nU.S. citizenship to be eligible for employment. All work must be conducted within the continental U.S.\nWho we are:\nRaft ( https:\/\/TeamRaft.com ) is a customer-obsessed non-traditional small business with purposeful focus on Distributed Data Systems, Platforms at Scale, and Complex Application Development, with headquarters in Reston, VA. Our range of clients include innovative federal and public agencies leveraging design thinking, cutting edge tech stack, and cloud native ecosystem. We build digital solutions that impact the lives of millions of Americans.\nWe\u201a\u00c4\u00f4re looking for an experienced\nSenior Data Engineer\nto support our customer and join our passionate team of high-impact problem solvers.\nAbout the role:\nAs a Senior Data Engineer, you will be responsible for building and maintaining extract, transform, load (ETL) pipelines to enable comprehensive data operations, from ingest to query. You will use your in-depth understanding of data architecture, database management, and data processing workflows, ensuring efficient and secure handling of our data resources.\nWhat we are looking for:\nMinimum of 7 years of hands-on experience in data engineering or related field\nExtensive experience in building and managing ETL pipelines\nExperienced in building ETL pipelines for comprehensive data operations, meeting and exceeding business value requirements, potentially demonstrated through significant experiences or one exceptionally impactful event\nExperience with Cloud-based systems and\/or AI\/Machine Learning Development\nBachelor's degree in Statistics, Computer Science, Data Science, or a related field\nHighly preferred:\nUnderstanding of data security practices and policies, with the ability to design and implement security measures\nExceptional problem-solving abilities and strong analytical skills\nExcellent interpersonal and communication skills, able to effectively collaborate with team members and stakeholders\nAbility to adapt to changing business requirements and learn new technologies quickly\nAdvanced certification related to data management or data engineering would be a plus\nClearance Requirements:\nActive Top Secret\/SCI Security clearance\nWork Type:\nSan Antonio, TX (Local remote)\nMay require up to 10% travel\nWhat we will offer you:\nHighly competitive salary\nFully covered healthcare, dental, and vision coverage\n401(k) and company match\nUnlimited PTO + 11 paid holidays\nEducation & training benefits\nAnnual budget for your tech\/gadgets needs\nMonthly box of yummy snacks to eat while doing meaningful work\nRemote, hybrid, and flexible work options\nTeam off-site in fun places!\nGenerous Referral Bonuses\nAnd More!\nOur Vision Statement:\nWe bridge the gap between humans and data through radical transparency and our obsession with the mission.\nOur Customer Obsession:\nWe will approach every deliverable like it's a product. We will adopt a customer-obsessed mentality. As we grow, and our footprint becomes larger, teams and employees will treat each other not only as teammates but customers. We must live the customer-obsessed mindset, always. This will help us scale and it will translate to the interactions that our Rafters have with their clients and other product teams that they integrate with. Our culture will enable our success and set us apart from other companies.\nHow do we get there?\nPublic-sector modernization is critical for us to live in a better world. We, at Raft, want to innovate and solve complex problems. And, if we are successful, our generation and the ones that follow us will live in a delightful, efficient, and accessible world where out-of-box thinking, and collaboration is a norm.\nRaft\u201a\u00c4\u00f4s core philosophy is\nUbuntu: I Am, Because We are\n. We support our \u201a\u00c4\u00fanadi\u201a\u00c4\u00f9 by elevating the other Rafters. We work as a hyper collaborative team where each team member brings a unique perspective, adding value that did not exist before. People make Raft special. We celebrate each other and our cognitive and cultural diversity. We are devoted to our practice of innovation and collaboration.\nWe\u201a\u00c4\u00f4re an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\nShow more\nShow less",
      "job_skills":"Data Engineering, ETL Pipelines, Data Architecture, Database Management, Data Security, Cloudbased Systems, AI\/Machine Learning, Statistics, Computer Science, Data Science, Data Security Practices, Data Management, Data Engineering Certification, Top Secret\/SCI Security Clearance",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Raft",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-raft-3731774405",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"This is a U.S. based position. All of the programs we support require\nU.S. citizenship to be eligible for employment. All work must be conducted within the continental U.S.\nWho we are:\nRaft (https:\/\/goraft.tech) is a customer-obsessed non-traditional small business with purposeful focus on Distributed Data Systems, Platforms at Scale, and Complex Application Development, with headquarters in Reston, VA. Our range of clients include innovative federal and public agencies leveraging design thinking, cutting edge tech stack, and cloud native ecosystem. We build digital solutions that impact the lives of millions of Americans.\nOur team is rapidly growing and looking for an experienced\nSenior Data Engineer\nto support our customer and join our passionate team of high-impact problem solvers. We enjoy the challenges of human-centered design, security, and scale to create better outcomes for our federal agency partners. We are a remote-first and work completely in the\nopen source\n.\nAbout the role:\nSenior Data Engineers\non our\nDistributed Systems\nteam are focused on building data platforms that make it easy for different types of user personas to access data from a central control plane. This includes building backend services, connecting OSS projects in a repeatable and performant way, and extending feature sets.\nRequired Qualifications:\nExperience building data infrastructure and platforms using streaming frameworks\nExperience\/Interest in OSS projects like: Apache Flink, Apache Pulsar, Apache Kafka, Apache Beam, Apache Storm, Apache Airflow\nHands-on experience with Golang\nHands-on experience with Spark\nAbility to build cloud-native, scalable services\nHigher education degree or drop-out in Mathematics, CS, Statistics\nObtain Security+ within the first 90 days of employment with Raft\nHighly preferred:\nWork with the Platform team to run distributed OSS systems at scale on Kubernetes\nThink of ways to implement data security at the row and column levels\nContribute features back to the OSS projects in dedicated time\nBuild prototypes, gather\/implement feedback, delight users.\nDesign and develop data best practices using Kafka, ElasticSearch, Presto\/Trinio\nClearance Requirements:\nAbility to obtain\/maintain a Top Secret Security clearance\nPosition Type and Location:\nHybrid - San Antonio, TX\nMay require up to 10% travel\nWhat we will offer you:\nHighly competitive salary\nFully covered healthcare, dental, and vision coverage\n401(k) and company match\nUnlimited PTO + 11 paid holidays\nEducation & training benefits\nAnnual budget for your tech\/gadgets needs\nMonthly box of yummy snacks to eat while doing meaningful work\nRemote, hybrid, and flexible work options\nTeam off-site in fun places!\nGenerous Referral Bonuses\nAnd More!\nOur Vision Statement:\nWe bridge the gap between humans and data through radical transparency and our obsession with the mission.\nOur Customer Obsession:\nWe will approach every deliverable like it's a product. We will adopt a customer-obsessed mentality. As we grow, and our footprint becomes larger, teams and employees will treat each other not only as teammates but customers. We must live the customer-obsessed mindset, always. This will help us scale and it will translate to the interactions that our Rafters have with their clients and other product teams that they integrate with. Our culture will enable our success and set us apart from other companies.\nHow do we get there?\nPublic-sector modernization is critical for us to live in a better world. We, at Raft, want to innovate and solve complex problems. And, if we are successful, our generation and the ones that follow us will live in a delightful, efficient, and accessible world where out-of-box thinking, and collaboration is a norm.\nRaft\u201a\u00c4\u00f4s core philosophy is\nUbuntu: I Am, Because We are\n. We support our \u201a\u00c4\u00fanadi\u201a\u00c4\u00f9 by elevating the other Rafters. We work as a hyper collaborative team where each team member brings a unique perspective, adding value that did not exist before. People make Raft special. We celebrate each other and our cognitive and cultural diversity. We are devoted to our practice of innovation and collaboration.\nWe\u201a\u00c4\u00f4re an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\nShow more\nShow less",
      "job_skills":"Apache Flink, Apache Kafka, Apache Beam, Apache Storm, Apache Airflow, Golang, Spark, Kubernetes, Data Security, Kafka, ElasticSearch, Presto\/Trinio",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"InfoVision Inc.",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-infovision-inc-3773565680",
      "search_city":"Mansfield",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Lead Data Developer\nDallas, TX\nLong term contract\nQualifications:\n1. 15+ years of experience in ETL & Data Warehousing\n2. Should have excellent leadership & communication skills\n3. Should have in depth knowledge on SSIS ETL Tool and good working knowledge on Power BI\n4. Should have worked on data sources such as SAP and Salesforce\n5. Should have very good knowledge of SSIS (ETL Tool), StreamSets (ETL Tool), Azure Cloud, ADF, Azure Synapse Analytics & Azure Hub Events\n6. Should have executed atleast 2 Azure Cloud Data Warehousing projects\n7. Should have worked atleast 4 projects using Agile\/SAFe methodology\n8. Should have demonstrated working knowledge on ITIL V4 concepts such as Incident Management, Problem Management, Change Management & Knowledge Management\n9. Should have working experience on any DevOps tools like GitHub, Jenkins, etc & on semi-structured data formats like JSON, Parquet and\/or XML files & written complex SQL queries for data analysis and extraction\n10. Should have in depth understanding on Data Warehousing, Data Analysis, Data Profiling, Data Quality & Data Mapping\n11. Should have cross global location experience and led a team of atleast 15+ members in a global delivery model\n12. Should have experience in working with product managers, project managers, business users, applications development team members, DBA teams and Data Governance team on a daily basis to analyze requirements, design, development and deployment technical solutions\nResponsibilities:\n1. Lead nearshore and offshore team to do production support of existing EDW, design, build & deploy enhancements and bug fixes to existing EDW\n2. Support the existing EDW system built using Azure SQL, Microsoft SSIS, StreamSets & Power BI\n3. Be on call to support job incidents on rotational basis\n4. Work with business and technology stakeholders to communicate EDW incidents\/problems and manage their expectations\n5. Leverage ITIL concepts to circumvent incidents, manage problems and document knowledge\n6. Analyze the different source systems, profile data, understand, document & fix Data Quality issues\n7. Gather requirements and business process knowledge in order to transform the data in a way that is geared towards the needs of end users\n8. Write complex SQLs to extract & format source data for ETL\/data pipeline\n9. Create design documents, Source to Target Mapping documents and any supporting documents needed for deployment\/migration\n10. Design, Develop and Test ETL\/Data pipelines\n11. Write Unit Test cases, execute Unit Testing and document Unit Test results\n12. Deploy ETL\/Data pipelines\n13. Use DevOps tools to version, push\/pull code and deploy across environments\n14. Support team during troubleshooting & debugging defects & bug fixes, business requests, environment migrations & other adhoc requests\n15. Maintain and improve already existing processes\nEnsure that the data pipelines are stable, secure, maintainable and highly available\nLokesh Kumar\nlokesh.kumar@infovision.com\nShow more\nShow less",
      "job_skills":"ETL, Data Warehousing, SSIS ETL tool, Power BI, SAP, Salesforce, StreamSets ETL tool, Azure Cloud, ADF, Azure Synapse Analytics, Azure Hub Events, Agile, SAFe methodology, ITIL V4, Incident Management, Problem Management, Change Management, Knowledge Management, DevOps tools, GitHub, Jenkins, JSON, Parquet, XML, Data Analysis, Data Profiling, Data Quality, Data Mapping, SQL, Unit Testing, Data pipelines",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Electrical Engineer (Mission Critical\/Data Center)",
      "company":"WSP in the U.S.",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-electrical-engineer-mission-critical-data-center-at-wsp-in-the-u-s-3757438469",
      "search_city":"Cahokia",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who We Are\nAt WSP, we are driven by inspiring future-ready pioneers to innovate. We\u201a\u00c4\u00f4re looking to grow our teams with people who are ready to collaborate in building communities and expanding our skylines. To do this, we hire candidates of all experiences, skillsets, backgrounds and walks of life. We actively foster a work environment and culture where inclusion and diversity is part of our fundamental structure. This is delivered behaviorally, through our policies, trainings, local partnerships with professional diverse organizations, internal networks and most importantly with the support and sponsorship of our leaders who help drive our commitment to an inclusive, diverse, welcoming and equitable work environment. Anything is within our reach and yours as a WSP employee. Come join us and help shape the future!\nGreat people. Great places. Great projects. kW Mission Critical Engineering, a WSP company, is a high-performance, fast-paced consulting engineering firm designing data centers and mission critical environments across the globe. We hire smart, responsive, team players to work in collaborative and mentoring office settings. Our mechanical, electrical, plumbing, fire protection, controls, telecommunications, and security building system designs keep many of the world\u201a\u00c4\u00f4s top Fortune 100 financial, technology, enterprise, hyperscale, and colocation companies up and running 24 hours a day, 365 days a year.\nWe work on innovative, award-winning, large-scale projects. We travel to construction sites to see our designs being built. As part of WSP, we are able to offer our employees increased professional development and career opportunities in addition to kW MCE\u201a\u00c4\u00f4s office culture which is consistently recognized as one of the \u201a\u00c4\u00faBest Places to Work.\u201a\u00c4\u00f9 Join our great people at our great places designing great projects.\nThis Opportunity\nWhat You\u201a\u00c4\u00f4ll Do:\nkW Mission Critical Engineering\nis currently initiating a search for a\nLead Electrical Engineer\nthat can be located for our\nkW Tempe, Arizona office or our St. Louis, MO office.\nAs a Lead Electrical Engineer with us, you will design complex power and other building systems including generator plants, medium voltage distribution, uninterruptible power systems, lighting, fire alarm, and grounding while leading projects and a team of electrical engineers.\nYour Impact\nProduce high quality technical and professional deliverables for projects and proposals\nApply deep knowledge of engineering techniques across multiple technical functions\nUtilize advanced analytical and design techniques to solve technical problems\nExemplify well-developed advanced experience in electrical discipline\nLead the development of initial electrical system concepts\nPresent complex technical solutions to clients\nManage and coordinate project teams and projects\nDevelop work plans to address technical issues within project time and budget\nWork within multi-discipline project teams to develop drawing and specification documents for issuance to architects, contractors and building owners\nAttend and lead client meetings\nManage and mentor junior staff\nCollaborate and coordinate with internal project discipline team members, equipment vendors and manufacturers\nPerform project management activities including writing proposals, establishing budgets, and managing client interactions\nCoordinate activities concerned with technical development, scheduling, and resolving engineering design issues\nCoordinate the activities of technical staff from project award through project completion\nDesign complex and large electrical medium voltage and low voltage distribution systems and electrical building systems (i.e. general power, lighting, grounding, etc.)\nSurvey and evaluation of existing conditions\nDevelop project specifications\nPerform construction administration\nDevelop and maintain client relationships\nContribute and interact with team, develop and manage high quality technical and professional deliverables on projects and proposals\nParticipate in local professional organization (attend meetings\/lectures), i.e., poster sessions, participate in conference panel\nExercise responsible and ethical decision-making regarding company funds, resources and conduct and adhere to WSP\"s Code of Conduct and related policies and procedures\nProven track record of upholding workplace safety and ability to abide by WSP\"s health, safety and drug\/alcohol and harassment policies\nWho You Are\nThe ideal candidate has familiarity with Building Information Modeling using Revit, has strong communication skills, and an interest in liaising with internal and external design, client and construction team members. Candidate will have previous experience as a lead project electrical engineer capable of directing the project team.\nRequired Qualifications\nBachelor\u201a\u00c4\u00f4s degree in Electrical Engineering or Architectural Engineering with electrical building systems emphasis\n7+ years of experience in designing electrical systems for the high performing, commercial, industrial or mission critical\/data center buildings\nRegistered Professional Engineer (PE)\nExperience mentoring and training others in field\nStrong verbal and written communication skills\nAbility to interact well with others as well as develop and contribute to high quality technical and professional deliverables on projects and proposals\nStrong working knowledge of electrical systems and codes\nAttention to detail, highly organized, self-starter\nParticipate in conference programs including panels, lectures, poster sessions, papers and presentations\nPreferred Qualifications:\nEnhancing credentials (LEED, Uptime ATD, etc.) preferred\nExperience with the analysis and modeling of short circuit coordination and arc flash studies\nMission Critical\/Data Center experience\nExperience with international projects and knowledge of international codes and standards\nAdditional Requirements\nTo perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.\nAdditional Details\nTravel Required: 10%\nJob Status: Regular\nEmployee Type: Full\nPrimary Location: TEMPE - E RIO SALADO PKWY\nAll locations: US-AZ-Phoenix, US-AZ-Tempe, US-AZ-Tucson, US-MO-Creve Coeur, US-MO-St Louis\nAbout WSP\nWSP USA is the U.S. operating company of WSP, one of the world's leading engineering and professional services firms. Dedicated to serving local communities, we are engineers, planners, technical experts, strategic advisors and construction management professionals. WSP USA designs lasting solutions in the buildings, transportation, energy, water and environment markets. With more than 15,000 employees in over 300 offices across the U.S., we partner with our clients to help communities prosper. www.wsp.com\nWSP provides a flexible and agile workplace model while meeting client needs. Employees are also afforded a comprehensive suite of benefits including medical, dental, vision, disability, life, and retirement savings focused on providing health and financial stability throughout the employee\u201a\u00c4\u00f4s career.\nAt WSP, we want to give our employees the challenges they seek to grow their careers and knowledge base. Your daily contributions to your team will be essential in meeting client objectives, goals and challenges. Are you ready to get started?\nWSP USA (and all of its U.S. companies) is an Equal Opportunity Employer Race\/Age\/Color\/Religion\/Sex\/Sexual Orientation\/Gender Identity\/National Origin\/Disability or Protected Veteran Status.\nThe selected candidate must be authorized to work in the United States.\nNOTICE TO THIRD PARTY AGENCIES:\nWSP does not accept unsolicited resumes from recruiters, employment agencies, or other staffing services. Unsolicited resumes include any resume or hiring document sent to WSP in the absence of a signed Service Agreement where WSP has expressly requested recruitment\/staffing services specific to the position at hand. Any unsolicited resumes, including those submitted to hiring managers or other business leaders, will become the property of WSP and WSP will have the right to hire that candidate without reservation \u201a\u00c4\u00ec no fee or other compensation will be owed or paid to the recruiter, employment agency, or other staffing service.\nShow more\nShow less",
      "job_skills":"Revit, Building Information Modeling, Electrical Engineering, Architectural Engineering, LEED, Uptime ATD, Project Management, Construction Management, Telecommunications, Security, Fire Protection, Controls, Power Systems, Medium Voltage, Low Voltage, Arc Flash Studies, Short Circuit Coordination, AutoCAD",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Engineer\u201a\u00c4\u00eeData Modeling & Analytics",
      "company":"Curate Partners",
      "job_location":"Texas, United States",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer%E2%80%94data-modeling-analytics-at-curate-partners-3780185747",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"We are seeking a Data Engineer\u201a\u00c4\u00eeData Modeling & Analytics Solution Development to join the Network Operations team. The Network Operations team monitors and\nmaintains assets, supporting both frontline representation in the field and strategic\nprograms.\nAs a Data Engineer\u201a\u00c4\u00eeData Modeling & Analytics Solution Development, you\nwill partner cross-functionally to serve as the team\u201a\u00c4\u00f4s data modeling and analytics subject matter expert\nand provide user interface (\u201a\u00c4\u00faUI\u201a\u00c4\u00f9) experiences and workflows that lead to net cost reductions for the\nCompany.\nDescription % of Time Spent\n\u201a\u00c4\u00a2Provide technical expertise to and leadership for the Unmanned Aircraft System\n(\u201a\u00c4\u00faUAS\u201a\u00c4\u00f9) program by analyzing, designing, developing, and implementing UAS\ndata-driven UI and deliverables.\n\u201a\u00c4\u00a2Deliver cost effective, accurate, photo-realistic, interactive models of the\nCompany\u201a\u00c4\u00f4s U.S. assets.\n\u201a\u00c4\u00a2Lead UAS Team projects to develop analysis automation and UIs for\nemployees\/customers. Work with IT, Shared Services and cross functional\nteams to identify, develop and project manage system integrations to ensure\nUAS program delivers an integrated solution.\n\u201a\u00c4\u00a2Partner with business leaders and customers to identify opportunities for UAS data;\ndetermine scopes, evaluate requirements, manage implementations, and monitor quality during and post-production.\n\u201a\u00c4\u00a2Develop customer-facing data that can be generated using standard data collection\nand processing techniques.\n\u201a\u00c4\u00a2Collaborate with the Manager, UAS Operations to ensure collected data meet\nprocessing and analysis requirements; build quality and production metrics and\nensure requirements are scalable.\n\u201a\u00c4\u00a2Approximately 10% of the time the role will be performed outside of a conventional\noffice environment.\n\u201a\u00c4\u00a2Other duties as assigned.\nWhat You Need to Succeed\nEducation Education Level Description\nRequired 4 Year \/ Bachelors\nDegree\n\u00ac\u2211 Bachelor\u201a\u00c4\u00f4s degree in Computer Science,\nEngineering, Remote Sensing, Physics, or a\nrelated field required.\nPreferred Graduate Degree \u00ac\u2211 Master\u201a\u00c4\u00f4s degree in a related field preferred.\nExperience Description\nRequired \u00ac\u2211 A minimum of 3 years of relevant UAS, GIS, modeling, application design, or\nother quantitative industry experience required.\n\u00ac\u2211 A minimum of 5 years of professional work experience required.\n\u00ac\u2211 Experience transferring data from 3D modeling software or comparable\nrelevant projects required.\n\u00ac\u2211 Experience with point cloud manipulation, CAD, third-party GIS, or\nphotogrammetry software required.\nPreferred \u00ac\u2211 Experience with remote sensing, oblique imagery, LIDAR, or 3D point clouds\npreferred.\n\u00ac\u2211 UAS knowledge and capture from motion experience preferred.\n\u00ac\u2211 Photogrammetry and professional surveyor certificates preferred.\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Modeling, Analytics Solution Development, Unmanned Aircraft System (UAS), User Interface (UI) Development, 3D Modeling, Data Visualization, Cost Reduction, Data Collection, Data Processing, Data Validation, Data Quality Management, Requirements Gathering, Project Management, System Integration, Business Intelligence, Customer Relationship Management, GIS, Photogrammetry, Remote Sensing, CAD, Point Cloud Manipulation",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Steneral Consulting",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-steneral-consulting-3741122848",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Hybrid role in either Chicago or Richardson (Must be local and undrer 60 mins to either location)\nNeed valid LinkedIn\nW2 candidates only\nDescription\nThis role requires the individual to have experience with collecting, organizing, and analyzing data from various resources. Primary tasks of this position are compilation and analysis of data definitions, meaning, usage, labelling standards and other source system information to produce IT consumable information. They may be required to take on other tasks as needed such as but not limited to: technical expertise with automatic data collection and reporting systems, including a capacity for program troubleshooting and system security measures\nRequired Qualification(s)\nShow more\nShow less",
      "job_skills":"Data Collection, Data Analysis, Data Definition, Data Labeling, Data Compilation, Data Consumption, Automatic Data Collection, Automatic Data Reporting, Program Troubleshooting, System Security",
      "Category":"Data Science"
  },
  {
      "job_title":"Oracle Cloud Business Analyst",
      "company":"Sonitalent Corp",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/oracle-cloud-business-analyst-at-sonitalent-corp-3698383863",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Role: Oracle Cloud Business Analyst\nTerms: 6-Month Contract\nLocation: Hybrid (2-3 days onsite) Dallas, TX\nJob Description\nThe company went live with the Oracle Cloud deployment in April 2023. This position will be tasked with handling all stabilization and issue resolution for the Oracle Cloud system. This person's experience should be system first and business\/communication second. They will also be working with Warehouse Management Systems any experience with CPG or Pharmaceutical company is a huge plus.\nResponsible for working closely with internal customers (i.e., functional\/subject matter experts and\/or end users) in various Operations departments (Customer Service, DC) and to build knowledge regarding their specific business area, unique processes, and operational data needed to support business objectives.\nEnsure Warehouse Management \/Oracle Cloud ERP solutions align to business requirements.\nBe able to independently determine system behavior\nPerform ad-hoc data mining\nTroubleshoot defects\nReview solutions for missed requirements\nThink through potential scenario's and use cases to ensure comprehensive solution\nHelp execute test cases if necessary and smoke test implementations\nMust Have Skills\n4+ years of experience with Oracle Cloud (Oracle ERP) or other Cloud ERP\n2+ years of experience working with EDI (Electronic Data Interchange). Good working knowledge of EDI X12 format for retail customers\n2+ years of professional experience working with Middleware integration (Boomi or OIC preferred)\nPreferred Skills\nKnowledge of Customer Service and Warehousing processes preferably in\nCPG or Pharma\nenvironment\nGood personality - Will need to be able to effectively communicate to technical and Non-technical teams\nShow more\nShow less",
      "job_skills":"Oracle Cloud, Oracle ERP, EDI (Electronic Data Interchange), EDI X12, Middleware Integration, Boomi, OIC, Customer Service, Warehousing, CPG, Pharma",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst Assoc Manager - Enterprise Data Foundation",
      "company":"PepsiCo",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-assoc-manager-enterprise-data-foundation-at-pepsico-3757496123",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Overview\nPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo\u201a\u00c4\u00f4s global business scale to enable business insights, advanced analytics and new product development. PepsiCo\u201a\u00c4\u00f4s Enterprise Data Operations (EDO) team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations, and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\nWhat PepsiCo\u201a\u00c4\u00f4s Enterprise Data Operations (EDO) team does:\nMaintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company\nResponsible for day-to-day data collection, transportation, maintenance\/curation and access to the PepsiCo corporate data asset\nWork cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders\nIncrease awareness about available data and democratize access to it across the company\nJob Description\nAs a member of the data engineering team, you will be the key domain expert overseeing PepsiCo's business process and drive a strong discussion for how Supply Chain, Financial, Consumer, Channel, Category business needs to be defined and prioritize by working very closely with business leads, data science team and data engineering team. You'll develop an in-depth understanding of business processes in and translate business requirements to data engineering team in technical way\nResponsibilities\nAccountabilities:\nDiscover, analyze, and scope data requirements & representing them in conceptual and logical data models\nGather and analyze data pertaining to various business processes such as forecasts, capital requirements, inventory, logistic, manufacturing and production capacity to develop supply chain models. geographics, POS, pricing and promotion, store profile, e-commerce data to develop channel models.\nCreate high-level process models (system interface diagrams, workflow & swim lane diagrams, data flow diagrams) to represent processes for the area under analysis\nEmpower the business by creating value through the increased adoption of data, data science and business intelligence landscape.\nResponsible to improve the quality of data in relation to defined expectations\nPerform analysis of system data to identify patterns, exceptions, and erroneous data\nInterpret and explain complex data sets to non-technical stakeholders, translating data findings into actionable recommendations.\nDevelop metrics, storyboards, and dashboards by gathering data from various sources to tell a story about the data\nAbility to learn and adapt to new technologies, passion for continuous improvement.\nQualifications\n6+ years of experience with data analysis & data profiling in project, business requirements definition or data engineering in CPG or Manufacturing Industry.\n4+ years of strong Data Profiling experience & ability to identify trends and anomalies in the data to in-form data model build out.\n3+ years\u201a\u00c4\u00f4 work experience in the areas of Distribution Network Analysis, Manufacturing, Production Network Optimization, Transportation, Demand Planning, or other areas related to Supply Chain or other domains such as Financial, Consumer, Channel, Category etc.\nExperience working with structured\/unstructured datasets, ability to clearly document and communicate requirement to technical team members.\nExperience in working with third party datasets from different POS systems(IRI, Nielsen, Kantar, Fetch, 8451, Luminate etc) is a plus.\nA strong candidate will have proficient knowledge on 3-5 of the tools listed below. The list is indicative and not exhaustive.\nBusiness Process Modelling: Visio, Celonis, UML\nData Profiling: OpenRefine, Informatica, Ataccama, Apache Griffin, Talend, IBM InfoSphere\nBusiness Intelligence: Power BI, Tableau, Cognos, SAP BI, Qlik\nSQL: PostgreSQL, Azure SQL, PgAdmin, Oracle SQL Developer, Microsoft SQL, Datapine SQL Editor, Adminer\nERP : SAP, SAP BW SAP BO, JDA\nUnderstanding of MS Azure and Databricks\nStrong SQL,Excel and\/or Access skills\nEducation\nBachelor\u201a\u00c4\u00f4s Degree in Computer Science\/Operations Management\/Sustainability Studies, Masters Preferred.\nCompetencies\nStrong knowledge and understanding of Customer\/Sales data elements and processes\nAbility to translate business requirements into critical data dependencies and requirements\nAble to challenge and align various stakeholders to a common set of standards\nSelf-starter with excellent written & verbal communication skills.\nSelf-learner and eager to understand data, business processes, concepts, and technologies.\nEEO Statement\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.\nPepsiCo is an Equal Opportunity Employer: Female \/ Minority \/ Disability \/ Protected Veteran \/ Sexual Orientation \/ Gender Identity\nIf you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.\nPlease view our Pay Transparency Statement\nShow more\nShow less",
      "job_skills":"Data analysis, Data profiling, Data engineering, CPG, Manufacturing, Data modeling, Supply Chain Management, Financial, Consumer, Channel, Category, Structured datasets, Unstructured datasets, Data visualization, Data storytelling, ETL, Data integration, Data governance, Data quality, Business Intelligence, ERP, Cloud computing, Big data, Machine learning, Artificial intelligence, Data science, SQL, PostgreSQL, Azure SQL, PgAdmin, Oracle SQL Developer, Microsoft SQL, Datapine SQL Editor, Adminer, SAP, SAP BW, SAP BO, JDA, MS Azure, Databricks, Excel, Access, Visio, Celonis, UML, OpenRefine, Informatica, Ataccama, Apache Griffin, Talend, IBM InfoSphere, Power BI, Tableau, Cognos, SAP BI, Qlik",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr Business\/Data Analyst",
      "company":"DARBYTEK",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-business-data-analyst-at-darbytek-3772509680",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nAs a Sr. Business\/Data Analyst within Digital and Technology, the primary responsibility will be to define, design and implement complex integration solutions for the enterprise. You will have an opportunity to play a key role in data engineering space using state of the art technologies. You will have ample opportunity to learn from our experienced engineers.\nEducation & Experience:\nTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and\/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\nUniversity degree in Computer Science, Computer Engineering, Information technology or related field or relevant experience.\nAt least 10 years\u201a\u00c4\u00f4 experience in analysis, integration design involving P2P, E-Invoicing, CMMS & ERPs.\nRequirements Engineering, Project Management courses will be preferred.\nConsideration given to equivalent combination of education and experience.\nKey Responsibilities\n:\nAnalyze business and user needs, documenting requirements, and revising existing system logic difficulties.\nIdentify and document business rules, dependencies, assumptions, risks, supportability, performance, and training needs.\nCreate Integration technical design documents which includes process flow\/sequence diagrams, entity transformation mapping definitions (JSON, XML, CSV) and documentation for the engineering teams to be able to build.\nFacilitate application onboarding process, understand the technical challenges, and propose an optimal solution.\nCollaborate with Solution architects and engineering team to implement the solution following design principles.\nIntegrate multiple applications with middleware and derive mappings from source and target applications, using multiple technologies.\nProvide end user support for integration projects and translate needs into developing test plans.\nThis includes a coordinated effort with stakeholders by participating\/facilitating User Acceptance Testing for application signoff.\nCreate test plans, including definition of testing requirements; testing criteria, test data, scripts, user acceptance conditions and end-to end test requirements.\nFacilitate load and performance tests for applications.\nAct as a subject matter expert for integration customers, and answer queries for integrating applications, end users, developers, and architects.\nPerforms the investigation and resolution of complex and critical data integration issues in the production environment.\nWork with Product Managers and Scrum Master to estimate, design, and build efficient, long term business applications utilizing standards.\nBreak down tasks, estimate effort, identify, and raise blockers, issues, and risks.\nGenerate tables and\/or charts in excel to present meaningful data.\nAdhere to security, compliance and best-practices guidelines\nBasic Qualifications:\nAbility to complete tasks in a high-pressure environment.\nExcellent inter-personal and communication skills, both verbal and in writing\nExperience with enterprise information management, such as data modeling, data governance, reference data management, master data management, meta data management, data integration, etc.\nCritical thinking, problem solving, comfortable in making judgement call and able to clearly articulate the tradeoffs in proposed architecture design and solution.\nProficient with Databases and writing SQL queries against SQL server 2012, Oracle 11i, Postgres, MySQL.\nKnowledge of application lifecycle, design\/design patterns, tools, and methodologies.\nProven ability to work with software engineering teams and understand complex development systems, environments, and patterns.\nExperience with Word, Excel, SharePoint, JIRA, Confluence, SOAP UI, JMeter, Postman is desired.\nProficient in integration development using REST\/SOAP APIs, and asynchronous integrations leveraging Messaging patterns with Apache Kafka\/Active MQ\/IBM MQ.\nMust have good understanding of XML\/JSON\/CSV data structures.\nExperience with Agile software development processes and the development life cycle\nExperience with SOA and Micro services Architecture is preferable.\nKnowledge of ELK stack is desired.\nUnderstanding of Cloud patterns is a bonus.\nCompany Description\nAt Darbytek, our goal is to build a better future for people and business. We specialize in recruiting skilled individuals for both full-time direct hires and contract positions. Allow us to help you with your next opportunity.\nAt Darbytek, our goal is to build a better future for people and business. We specialize in recruiting skilled individuals for both full-time direct hires and contract positions. Allow us to help you with your next opportunity.\nShow more\nShow less",
      "job_skills":"Data Engineering, Integration Solutions, P2P, EInvoicing, CMMS, ERPs, Business Analysis, Data Analysis, Requirements Engineering, Project Management, Integration Design, Process Flow Diagrams, Sequence Diagrams, Entity Transformation Mapping, JSON, XML, CSV, Middleware, SOAP APIs, REST APIs, Messaging Patterns, Apache Kafka, Active MQ, IBM MQ, XML Data Structures, JSON Data Structures, CSV Data Structures, Agile Software Development, SOA, Micro services Architecture, ELK Stack, Cloud Patterns, SQL, Databases, SQL Server 2012, Oracle 11i, Postgres, MySQL, Word, Excel, SharePoint, JIRA, Confluence, SOAP UI, JMeter, Postman",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Quality Analyst",
      "company":"Wiliot",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-quality-analyst-at-wiliot-3777311351",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Wiliot was founded by the team that invented one of the technologies at the heart of 5G. Their next vision was to develop an IoT sticker, a computing element that can power itself by harvesting radio frequency energy, bringing connectivity and intelligence to everyday products and packaging, things previously disconnected from the IoT. This revolutionary mixture of cloud and semiconductor technology is being used by some of the world\u201a\u00c4\u00f4s largest consumer, retail, food, and pharmaceutical companies to change the way we make, distribute, sell, use, and recycle products. We\u201a\u00c4\u00f4re driven by our passion for sustainability, ESG and waste reduction.\nOur investors include Softbank, Amazon, Alibaba, Verizon, NTT DoCoMo, Qualcomm and PepsiCo.\nWe are growing fast and need people that want to be part of the journey, commercializing Sensing as a Service and enabling \u201a\u00c4\u00faIntelligence for Everyday Things\u201a\u00c4\u00f9.\nThis role is unique to Wiliot as generally data quality can be attributed only to bad data, however, sometimes drops in performance are key indicators for business values for our customers! It will be your responsibility to identify anomalies such as quality issues or business value utilizing your experience in Data Quality Frameworks. You will be responsible for ensuring the accuracy and completeness of our data, and for implementing and maintaining our data quality framework. You will work closely with our data engineering and data science teams to identify and resolve data quality issues, and to establish best practices for data quality management. You will also be responsible for monitoring data quality metrics and providing regular reports to our clients.\nResponsibilities:\nImplement and maintain our data quality framework, including data profiling, data quality rules, and data quality reports.\nCollaborate with data engineering and data science teams to identify and resolve data quality issues, and to establish best practices for data quality management.\nMonitor data quality metrics and provide regular reports to our clients.\nWork with the data engineering team to implement data quality checks and validations in our data pipelines.\nDevelop and maintain a comprehensive understanding of our data sources and the relationships between them.\nDevelop and implement data quality training programs for our clients.\nIdentify business value through data quality analytics.\nRequirements:\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\nAt least 3-5 years of experience in data quality analysis, with a track record of implementing and maintaining data quality frameworks.\nStrong knowledge of data quality best practices, including data profiling, data quality rules, and data quality reporting.\nExperience with data quality tools and platforms, such as Lightup, Talend, Trifacta, or Informatica.\nExperience with data storage technologies such as SQL and NoSQL databases, and proficiency in at least one of them.\nStrong problem-solving and communication skills.\nAbility to work independently and manage multiple priorities in a fast-paced environment.\nShow more\nShow less",
      "job_skills":"Data Quality, Data Profiling, Data Validation, Data Quality Metrics, Data Quality Reporting, Data Quality Management, Data Engineering, Data Science, Data Analytics, Data Quality Tools, SQL, NoSQL, Data Storage, Databases, Cloud Computing, Semiconductor Technology, Radio Frequency Energy Harvesting, IoT Platforms, Data Quality Frameworks",
      "Category":"Data Science"
  },
  {
      "job_title":"Data & Progress Analyst (Ref ID: 230)",
      "company":"NextDecade",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-progress-analyst-ref-id-230-at-nextdecade-3718470080",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"ABOUT NEXTDECADE\nNextDecade Corporation\nis an energy company accelerating the path to a net-zero future and leading innovation in more sustainable LNG and carbon capture solutions, NextDecade is committed to providing the world access to cleaner energy. Through our subsidiaries Rio Grande LNG and NEXT Carbon Solutions, we are developing a 27 MTPA LNG export facility in South Texas along with one of the largest carbon capture and storage projects in North America. We are also working with third-party customers around the world to deploy our proprietary processes to lower the cost of carbon capture and storage and reduce CO2 emissions at their industrial-scale facilities. By combining emissions reduction associated with our carbon capture and storage project, responsibly sourced gas, and our pledge to use net-zero electricity, Rio Grande LNG is expected to produce\na lower carbon intensive LNG\nfor the world.\nNextDecade\u201a\u00c4\u00f4s common stock is listed on the Nasdaq Stock Market under the symbol \u201a\u00c4\u00faNEXT.\u201a\u00c4\u00f9 NextDecade is headquartered in Houston, Texas.\nSUMMARY OF THE ROLE:\nThis is a Data and Progress Analyst position within the Project Controls department to support execution of over 12 billion Dollar LNG Project. This role is responsible for designing, developing, and deploying project analytic dashboards using Microsoft BI technologies such as SQL, Power BI, etc.\nRESPONSIBILITIES:\n\u201a\u00c4\u00a2 Using Power BI, create dashboards and interactive visual reports.\n\u201a\u00c4\u00a2 Recognize project requirements in the context of BI and create data models to transform raw data into relevant insights.\n\u201a\u00c4\u00a2 Define key performance indicators (KPIs) with specific objectives and track them regularly.\n\u201a\u00c4\u00a2 Analyze data and display it in reports to aid decision-making.\n\u201a\u00c4\u00a2 Create, test, and deploy Power BI scripts, as well as execute efficient deep analysis.\n\u201a\u00c4\u00a2 Use Power BI to run DAX queries and functions.\n\u201a\u00c4\u00a2 Create charts and data documentation with explanations of algorithms, parameters, models, and relationships.\n\u201a\u00c4\u00a2 Construct a data warehouse.\n\u201a\u00c4\u00a2 Use SQL queries to get the best results.\n\u201a\u00c4\u00a2 Make technological adjustments to current BI systems to improve their performance.\n\u201a\u00c4\u00a2 For a better understanding of the data, use filters and visualizations.\n\u201a\u00c4\u00a2 Analyze current ETL procedures to define and create new systems.\nREQUIREMENTS:\nMinimum\/preferred experience required for the position:\n\u201a\u00c4\u00a2\n3+ years\nworking with Power BI and DAX.\n\u201a\u00c4\u00a2\n4+ years\nof experience working in an analyst role or related education.\n\u201a\u00c4\u00a2\n4+ years\nof experience in tools and systems on MS SQL Server BI Stack, including SSRS and TSQL, Power Query, MDX.\n\u201a\u00c4\u00a2 Strong experience in excel (pivots, formulas, and charts) to dissect preexisting stakeholder workflows.\n\u201a\u00c4\u00a2\n2+ years\nof experience in EPC (Engineering, Procurement and Construction) Project environment is preferred.\nMinimum\/preferred knowledge, skills and abilities required of the position:\n\u201a\u00c4\u00a2 Background with BI tools and systems such as Power BI.\n\u201a\u00c4\u00a2 Prior experience in data-related tasks.\n\u201a\u00c4\u00a2 Understanding of the Microsoft BI Stack.\n\u201a\u00c4\u00a2 Be familiar with MS SQL Server BI Stack tools and technologies, such as SSRS and TSQL, Power Query, MDX, Power BI, and DAX.\n\u201a\u00c4\u00a2 Analytical thinking for converting data into relevant reports and graphics.\n\u201a\u00c4\u00a2 Capable of enabling row-level data security.\n\u201a\u00c4\u00a2 Knowledge of Power BI application security layer models.\n\u201a\u00c4\u00a2 Ability to run DAX queries on Power BI desktop.\n\u201a\u00c4\u00a2 Proficient in doing advanced-level computations on the data set.\n\u201a\u00c4\u00a2 Good communication skills are required to communicate with project team.\n\u201a\u00c4\u00a2 Judgement, trust, and carefulness in handling sensitive and confidential information.\n\u201a\u00c4\u00a2 Strong organizational and time management skills to prioritize workload during peak periods.\n\u201a\u00c4\u00a2 Ability to identify and implement actions with minimum directions.\nRequired\/preferred education:\n\u201a\u00c4\u00a2 Bachelor\u201a\u00c4\u00f4s in computer science, or information system, or engineering, or construction management, or business.\nTRAVEL REQUIREMENTS:\nAssignment in Houston may need to visit to project site during construction phase.\nADDITIONAL INFORMATION:\nCommunicates effectively at all levels of the organization to ensure clarity in expectations requirements, and deliverables. Excellent analytical skills.\nTeam Player, good communication and reporting skills\nWelcomes working in a fast paced challenging and diverse entrepreneurial environment\nHands-on type of personality\nThis Position Description is not an exhaustive list of the duties and responsibilities, and the employee is expected to perform other duties as necessary and assigned. The duties and responsibilities of this position may be modified at any time to meet changing business needs.\n*In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\nNEXTDECADE VALUES\nSafety\n\u201a\u00c4\u00ec We make safety a priority. Everything we do relies on the safety of our people and the communities around us.\nIntegrity\n\u201a\u00c4\u00ec We do the right thing, and are open, ethical, and fair. We hold ourselves to the highest standards in all that we do.\nHonesty\n\u201a\u00c4\u00ec We value truth and honesty in ourselves and others. We honor our commitments and take responsibility for our actions.\nRespect\n\u201a\u00c4\u00ec We listen, and respect people, the environment, and the communities in which we live and work.\nTransparency\n\u201a\u00c4\u00ec Transparency builds trust. We promote open communication with our people, our customers, and all our stakeholders.\nDiversity\n\u201a\u00c4\u00ec We value diversity of people and thought. It takes people with different strengths, ideas, and cultural backgrounds to make our company succeed.\nShow more\nShow less",
      "job_skills":"Data Analytics, Power BI, SQL, Dashboards, Data Visualization, Data Models, Key Performance Indicators (KPIs), DAX, ETL (Extract Transform Load), SSRS, TSQL, Power Query, MDX, Excel, EPC (Engineering Procurement and Construction), Communication Skills, Analytical Thinking, RowLevel Data Security, Power BI Application Security Layer Models, AdvancedLevel Computations, Computer Science, Information Systems, Engineering, Construction Management, Business",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr Data Analyst",
      "company":"Cornerstone Resources",
      "job_location":"Bedford, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-cornerstone-resources-3782324932",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Reporting to the VP-IT, this position designs and conducts primary market research projects, analyzes internal\nand external data, prepares reports, and supplies information for marketing and management decisions.\nCollaborates with department heads to develop reports (standard and custom) with analysis and\nrecommendations as requested.\nTrains department analysts in database and report creation, SQL, build and maintain\ndatabases that interface with CU databases (XP, Credit Card, Mortgage, etc.). Designs\nand develops custom in-house databases and reporting such as security protocols for\nelectronic wallets, adverse actions (regulatory), funding tracking for debit, credit and\nACH account openings and loan payments.\nManages and maintains in-branch video marketing including sourcing hardware and\nsoftware, on-site installation, troubleshooting and maintenance.\nPerforms research needed for branch expansion initiatives including mapping,\ndemographic analysis, profitability projections and competitive analysis.\nAssists Sr. VP - Finance with maintaining Profitstar database, gathers and analyzes data\nfrom internal and external sources.\nPerforms ROI analysis to track results, measure effectiveness, and make\nrecommendations for future campaigns, promotions and member relations.\nShow more\nShow less",
      "job_skills":"Market research, Data analysis, Report creation, SQL, Database design, Database maintenance, Security protocols, Inhouse databases, Video marketing, Hardware sourcing, Software installation, Troubleshooting, Mapping, Demographic analysis, Profitability projections, Competitive analysis, Profitstar database, ROI analysis",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Business Analyst - CPQ (Hybrid)",
      "company":"Stryker",
      "job_location":"Flower Mound, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-business-analyst-cpq-hybrid-at-stryker-3757949958",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Why join Stryker?\nWe are proud to be named one of the World\u201a\u00c4\u00f4s Best Workplaces and a Best Workplace for Diversity by Fortune Magazine! Learn more about our award-winning organization by visiting stryker.com\nAs the Senior Business Analyst - CPQ, you will form partnerships with business users across departments and build expertise that will help you prioritize, gather, and document Oracle CPQ requirements related to new configurable product launches, current configurable product updates, continuous improvement initiatives, and clarifying requirements to implement bug fixes.\nWho We Want\nCollaborative partners.\nPeople who build and leverage cross-functional relationships to bring together ideas, data and insights to drive continuous improvement in functions.\nAnalytical problem solvers.\nPeople who go beyond just fixing to identify root causes, evaluate optimal solutions, and recommend comprehensive upgrades to prevent future issues.\nEffective communicators.\nPeople who can interpret information clearly and accurately to concisely communicate results and recommendations to stakeholders, senior management, and their teams.\nWhat You Will Do\nRequirements gathering, testing, and documentation of Oracle CPQ Product Configuration, Commerce, Document Designer, and Pricing Functions focusing on the addition of new product lines to an existing Oracle CPQ Cloud implementation, documenting Sales Bill of Material requirements and Manufacturing Bill of Material requirements.\nWork with business department stakeholders, prioritizes enhancement requests related to Oracle CPQ and SAP Variant Configurator.\nConsult with Sales, Marketing, Production, and R&D Project managers on specific product line needs.\nLearn Stryker\u201a\u00c4\u00f4s implementation of Oracle CPQ and becomes a subject matter expert of CPQ end user functionality.\nReview upcoming Oracle CPQ Cloud version release notices and collaborates with the CPQ development team to document the required changes.\nCollaborate with internal developers and external consultants to create project plans and participate in unit testing and End User Testing.\nLead business process mapping and requirements gathering sessions with business stakeholders.\nWork with middleware teams to document interfaces in and out of CPQ in clear and concise business language.\nTrack CPQ project progress and reports status, issues, and roadblocks to the responsible R&D project manager for a new product launch.\nShare industry best practices around Configure-to-Order systems and business processes.\nDrive continuous process improvement activities and initiatives.\nWhat You Need\nBachelor\u201a\u00c4\u00f4s degree in Business Administration, Computer Information Systems, or equivalent required.\n2+ years of relevant experience.\nKnowledge of Product Configuration & Rules, Commerce Process, Document Designer and Pricing functionality of Oracle CPQ Cloud or other CPQ systems required.\nExperience developing Oracle CPQ Configurators is preferred but not required.\nExperience administering Oracle CPQ (formerly BigMachines) preferred.\nExperience building manufacturing bills of material using SAP Variant Configurator preferred.\nDemonstrated understanding of commercial processes and manufacturing processes including Assemble-to-Order and the differentiation between Sales BOMs and Manufacturing BOMs preferred.\nKnowledge of Oracle CPQ integrations with Salesforce.com, Model N and SAP S\/4 preferred.\nAbout Stryker\nOur benefits:\n12 paid holidays annually\nHealth benefits include: Medical and prescription drug insurance, dental insurance, vision insurance, critical illness insurance, accident insurance, hospital indemnity insurance, personalized healthcare support, wellbeing program and tobacco cessation program.\nFinancial benefits include Health Savings Account (HSA), Flexible Spending Accounts (FSAs), 401(k) plan, Employee Stock Purchase Plan (ESPP), basic life and AD&D insurance, and short-term disability insurance.\nFor a more detailed overview of our benefits or time off, please follow this link to learn more: US Stryker employee benefits\nAbout Stryker\nStryker is one of the world\u201a\u00c4\u00f4s leading medical technology companies and, together with its customers, is driven to make healthcare better. The company offers innovative products and services in Medical and Surgical, Neurotechnology, Orthopaedics and Spine that help improve patient and healthcare outcomes. Alongside its customers around the world, Stryker impacts more than 130 million patients annually. More information is available at stryker.com.\nKnow someone at Stryker?\nBe sure to have them submit you as a referral prior to applying for this position. Learn more about our employee referral program on our referral page\nStryker is driven to work together with our customers to make healthcare better. Employees and new hires in sales and field roles that require access to customer accounts as a function of the job may be required, depending on customer requirements, to obtain various vaccinations as an essential function of their role.\nR509190\nShow more\nShow less",
      "job_skills":"Oracle CPQ, SAP Variant Configurator, Salesforce.com, Model N, SAP S\/4, Product Configuration & Rules, Commerce Process, Document Designer, Pricing functionality, Oracle CPQ Cloud, Configurator, AssembletoOrder, Sales BOM, Manufacturing BOM",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst",
      "company":"LanceSoft, Inc.",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-at-lancesoft-inc-3782862539",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description:\nRequired Skills:\nSCCM Current Branch experience, Powershell\/Scripting, In-depth knowledge on Client OS (Windows 10).\nPreferred Skills:\nSCCM Image Deployment.\nCertificaiton:\nITIL Foundation (optional), Certification on SCCM 2007\/2012 (Optional in case of Good knowledge)\nCandidate with 6 to 8 Yrs.\nStrong experience in Software Distribution and Patch management using SCCM 2007\/2012.\nExecution of Enterprise support processes including Incident Management\/ Problem Management \/Change Management \/Service Request Management \/Asset & Configuration Management 6 to 8 years experience within engineering, building, and supporting a large heterogeneous multi-data centre computing environment.\nIn-depth work stream experience like Deployment, incident analysis, resolution, problem definition, analysis and resolution of Deployment failures.\nDetailed Infrastructure knowledge including Server troubleshooting, design, and implementation experience on Configuration manager versions 2007 and 2012.\nIn-depth understanding of all SCCM concepts like SCCM Roles, Boundary configuration, site assignment, Client installations etc.\nAwareness of recent technology changes of all System Center Products.\nAwareness of SCCM V-Next and windows 10 Servicing.\nDemonstrated proficiency with:\nDesigning and Deploying Microsoft products in an Enterprise environment.\nKnowledge &worked on manual build & imaging for unattended installation for various device models.\nKnowledge & worked on integrating MDT 2012 with SCCM.\nKnowledge on Light Touch Installation (LTI) by using MDT to make task sequence easier and automate.\nIn-depth knowledge of SCCM client installation, software distribution, remote control, and other SCCM issues.\nKnowledge &worked on SMS\/SCCM tools &utilities Day to day operational stability\nAbility to prioritise multiple tasks.\nWillingness to learn and support legacy applications Scripting experience like VB Script and PowerShell, .net etc.\nPackaging experience should include Wise Studio, but Install Shield experience may be substituted, along with VB script and SMS packaging Evaluate alternatives for deploying and supporting applications in a managed environment.\nExperience in Security Updates Deployment using SCCM 2007\/2012 and manage Patch Testing Deployments with change and Release Process.\nSoftware Deployment Process Knowledge on SCCM 2007\/SCCM2012 and with Good knowledge on Mass Software Distribution, Collection Creation and Managing Advertisements.\nTrouble Shooting on SCCM Distribution failures and Validating Packaged Applications for Deployment Readiness.\nAbility to prepare POC , creating RFC ,Implementing Service improvements etc. SCCM 2007\/2012 Reporting and Custom Reporting for Deployment Penetration Knowledge on SCCM SQL Database Schema.\nSCCM Asset Reporting and Reporting Software Usage, Maintain Deployment Calendar and License Validation process.\nIn-depth knowledge on Client OS (Windows 7\/8\/10) and Troubleshooting.\nKnowledge on Windows servers 2003\/2008\/2012, IIS, Active Directory, DNS, etc.\nITIL Foundation (optional), Certification on SCCM 2007\/2012 (Optional in case of Good knowledge) Responsible for proper escalation, communications, and management of production system problems.\nKnowledge on other deployment tools like Altiris, Landesk will be advantage.\nAbility to train less experienced staff is required.\nCommunication & Documentation:-\nExcellent communication & Documentation skills on penetration reporting and Patch Deployment penetration reporting\nShow more\nShow less",
      "job_skills":"SCCM, Powershell, Scripting, Windows 10, SCCM Image Deployment, ITIL Foundation, SCCM 2007\/2012, Software Distribution, Patch Management, Incident Management, Problem Management, Change Management, Service Request Management, Asset & Configuration Management, Deployment, Incident Analysis, Resolution, Problem Definition, Server Troubleshooting, Design, Implementation, Configuration Manager, SCCM Roles, Boundary Configuration, Site Assignment, Client Installations, SCCM VNext, Windows 10 Servicing, Microsoft Products, Manual Build, Imaging, Unattended Installation, MDT 2012, SCCM Integration, Light Touch Installation (LTI), MDT, Task Sequence, SCCM Client Installation, Software Distribution, Remote Control, Wise Studio, Install Shield, VB Script, SMS Packaging, Evaluating Alternatives, Security Updates Deployment, Patch Testing Deployments, Change and Release Process, Software Deployment Process, Mass Software Distribution, Collection Creation, Advertisements, SCCM Distribution Failures, Packaged Applications, Deployment Readiness, POC Preparation, RFC Creation, Service Improvements, SCCM 2007\/2012 Reporting, Custom Reporting, Deployment Penetration, SCCM SQL Database Schema, SCCM Asset Reporting, Software Usage Reporting, Deployment Calendar, License Validation, Windows 7, Windows 8, Windows Servers 2003\/2008\/2012, IIS, Active Directory, DNS, Altiris, Landesk, Training, Communication, Documentation, Penetration Reporting, Patch Deployment Penetration Reporting",
      "Category":"Data Science"
  },
  {
      "job_title":"Competitive Intelligence & Pricing Analyst",
      "company":"Lone Star Analysis",
      "job_location":"Addison, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/competitive-intelligence-pricing-analyst-at-lone-star-analysis-3781053781",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Company Overview\nLone Star Analysis is a rapidly growing company offering applied decision intelligence and engineering solutions to enhance innovation, create economic strength, and make the world safer. Since 2004, organizations have trusted Lone Star to deliver actionable answers to complex problems in manufacturing, aerospace, defense, energy, logistics, transportation, and communications.\nJob Description\nCompetitive Intelligence & Pricing Analyst is responsible for supporting full scale Price to Win (PTW) project engagements. This includes data collection, data synthesis, and model testing activities. The Price to Win Analyst works closely with Senior Price to Win Lead, Competitive Intelligence, and other project team members to ensure successful delivery of all client requirements on time and on budget. This position requires a unique blend of technical, business, and strategic thinking skills and the ability to work in a team environment to develop competitive solutions in support of client capture activities. This position's workload will be dynamic, engaging, and will directly impact the success of our clients.\nResponsibilities\nConduct Price to Win analysis in support of routine and strategic captures ranging in size and complexity from $500M\nCollect and analyze strategic and tactical competitive intelligence from open-source data\nLead data extraction engagements with Subject Matter Experts\nBuild predictive cost and offering models to develop PTW and design-to-cost recommendations, which predict competitor bids within 5% of their actual submittals\nDevelop strategy analysis and recommendations to maximize client probability of win\nUtilize excellent leadership and communication skills, present findings to clients\nOther duties as assigned\nKey Requirements\nMust be comfortable with the prospect of working across several industries (Aerospace, Defense, Manufacturing, Energy, Transportation, Logistics, and Telecom) and across several domains (Operations, Asset Management, Maintenance, Technology, and Others) as required.\nAbility to work in a fast-paced, collaborative team environment and comfortable in ambiguous and rapidly evolving situations.\nExcellent time and project management skills - including project structuring and managing multiple work streams independently.\nHighly driven with an execution focus and a strong sense of urgency.\nAbility to effectively deal with uncertainty.\nCreative problem-solving and analytical skills.\nExceptional organization skills and attention to detail.\nExcellent client relationship management skills.\nWork well with all levels of the organization.\nExceptional oral and written communication skills, including negotiation, presentation, and influence.\nSkilled in creating and presenting results to all levels of leadership.\nAbility to communicate effectively to facilitate client engagements and strategic discussions.\nAbility to effectively elicit information in a transparent, legal, and ethical manner.\nSomeone who is open to continuous improvement and can take constructive criticism well.\nStrong leadership skills and specific background in Federal Pricing - CAS environment, including knowledge of TINA and FAR Part 15.\nAbility to search and extract information from large databases and ability to analyze conflicting and incomplete data to reach analytically based conclusions.\nUnderstand basic business and marketplace activities, behavioral norms, and competitive pressures.\nProficient with Microsoft Office Suite (PowerPoint, Word, Excel, OneNote).\nAdvanced spreadsheet and modeling skills.\nAptitude for learning new software and procedures.\nMust be able to obtain a Department of Defense Security clearance.\nThis position may require up to 20% travel.\nEducation & Experience\nBachelor's degree in Engineering, Business, Mathematics, Finance, Accounting or other related fields which require significant analytical coursework.\nAt least 5 years of broad and varied experience that demonstrates a high level of business acumen, such as price to win, pricing analysis, working on competitive proposal teams, experience in a manufacturing environment, or assignments in business strategy, finance, or contracts.\nAdditional Qualities\nDemonstrated successful development of winning PTW strategy and offerings on >$50M\nBusiness Development or Capture experience preferred.\nDemonstrated PTW modeling techniques ,including expertise in Microsoft Excel.\nProven ability to influence capture and program management to implement winning PTW solutions.\nDetailed experience in cost modeling and Basis of Estimate preparation.\nMaster's Degree in a related field, preferably an MBA.\nExperience with the RFP\/GOV capture process.\nMinimum of a SECRET security clearance.\nExpectations Do Not Include\nAll of the desirable attribute within a single candidate.\nWhy Lone Star?\nHave you ever wanted to...Work on cutting edge issues? Experience what it feels like to have your work truly make a difference? Work in a high trust, high performance environment and feel valued? If the answer is 'yes' then Lone Star might be for you. There is one catch however, you can't hide in our culture. So, if we appeal to you, bring your 'A' game.\nWhat We Offer\nA great culture and work environment\nHeavily subsidized cafeteria style medical, dental & vision\nFlexible PTO and work hours\nSome remote work options\nCompany match 401(k)\nSubsidized HSA (w\/ HDHP election)\nCompany paid Life and AD&D\nCompany paid Short- & Long-term Disability\nProfessional Development Reimbursement\nVariable compensation and equity options\nCompany paid Medical Concierge Service\nCompany paid Identity Theft Protection\nLegal \/ Compliance Statements\nLone Star's normal requirements apply, in addition to these job specific attributes. This position is expected to span across level 1 - 4 position categories. Lone Star is committed to protecting your personal data and is an equal opportunities employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin or any other characteristic protected by law. See the company website for more information about Lone Star and how we hire; www.Lone-Star.com\nShow more\nShow less",
      "job_skills":"Price to Win (PTW) analysis, Data collection, Data synthesis, Model testing, Competitive intelligence, Project management, Predictive cost and offering models, Probability of win, Client relationship management, Microsoft Office Suite, Advanced spreadsheet and modeling skills, Data extraction, Cost modeling, Basis of Estimate preparation, RFP\/GOV capture process, SECRET security clearance, TINA, FAR Part 15",
      "Category":"Data Science"
  },
  {
      "job_title":"US Tech - Business Analyst",
      "company":"PwC",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/us-tech-business-analyst-at-pwc-3785064291",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nBusiness Analysis\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team are the general managers of commercial and internal products. They sit at the intersection of the business, user experience, and the technology that solve our customer and end-user problems. They design, develop and manage activities for a specific product or group of products from product definition and planning through production, release, and end of life. Product Management\u201a\u00c4\u00f4s involvement lasts throughout all stages of a product\u201a\u00c4\u00f4s lifecycle including modifications, upgrades, maintenance of the product or product line. For commercial products, it also includes commercialization, Go To Market planning, sales, and other key business support activities.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades\/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Manager, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nPursue opportunities to develop existing and new skills outside of comfort zone.\nAct to resolve issues which prevent effective team working, even during times of change and uncertainty.\nCoach others and encourage them to take ownership of their development.\nAnalyse complex ideas or proposals and build a range of meaningful recommendations.\nUse multiple sources of information including broader stakeholder views to develop solutions and recommendations.\nAddress sub-standard work or work that does not meet firm's\/client's expectations.\nDevelop a perspective on key global trends, including globalisation, and how they impact the firm and our clients.\nManage a variety of viewpoints to build consensus and create positive outcomes for all parties.\nFocus on building trusted relationships.\nUphold the firm's code of ethics and business conduct.\nBusiness Analysts apply analytical skills working with business and product owners to develop requirements and user stories stemming from product roadmaps. Analysts add value to the delivery team by working with the business and product owner to create clarity around business objectives through the development of and refinement of user stories. Our Business Analysts solve business problems working with delivery teams using Agile and scrum methodologies.\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n4 year(s) of progressive roles managing IT system\/software development and project management processes.\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nInformation Technology, Computer Systems Analysis, Management Information Systems\nCertification(s) Preferred\nIIBA\nPreferred Knowledge\/Skills\nDemonstrates extensive abilities and\/or a proven record of success as a team leader working on software development projects, preferably for a global network of professional services firms, including the following areas:\nPerforming all phases of applications systems analysis and a proven understanding of the SDLC development methodology (Waterfall\/Agile\/Scrum);\nPossessing business requirements understanding and translating them into the appropriate deliverables;\nPerforming SDLC activities expected to develop custom developed and packaged applications selecting and driving appropriate requirement Methods including Agile Requirements Methods; and,\nDemonstrating Vendor SOW, SLA measures and acceptance criteria for managing successful outcomes of projects leveraging vendors;\nWorking on software development projects, infrastructure, SaaS and\/or Cloud solutions;\nApplying analytical skills to determine business value and document accurate business requirements and present these requirements in a manner that is concise, measurable and flexible enough to meet project and stakeholder needs;\nConducting requirements elicitation, validation and analysis meetings with the business stakeholders; perform Fit\/Gap analysis; support testing activities; and produce deliverables related to the project or projects assigned;\nManaging the quality and acceptance of vendor analysis and testing SOW deliverables in a project setting;\nOverseeing the documentation of business requirements and test cases, so that requirements and test cases are unambiguous, aligned, consistent and not in contradiction with each other;\nWorking with vendor SOW project deliverables on their quality and meeting acceptance criteria;\nProviding modeling of the business processes; understand the business need and impacts of proposed solutions;\nProviding assistance for developing solution approach to deliver business value;\nDeveloping business and application domain knowledge for an assigned business portfolio and\/or line of service; and,\nDemonstrating prior knowledge of Adobe Experience Cloud stack (Adobe Experience Manager - AEM, Adobe Analytics, Adobe Target, etc.) is highly desirable.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechmanager\nShow more\nShow less",
      "job_skills":"Business Analysis, Scrum, Agile, Software Development, Project Management, SDLC, Requirements, Business Objectives, User Stories, Cloud, SaaS, Infrastructure, Quality Assurance, Business Strategy, Analytical Skills, Data Analysis, Product Management, Adobe Experience Cloud, Adobe Experience Manager, Adobe Analytics, Adobe Target",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Security Analyst 1 -529400704 (Cybersecurity, Network Security, Testing)",
      "company":"Five Cubes",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-security-analyst-1-529400704-cybersecurity-network-security-testing-at-five-cubes-3722206503",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Responsible for administering, operating data loss prevention tools to include incident response. Knowledge and experience with Digital Guardian DLP. Participate in incident response activities and 24\/7 on-call rotation as needed.\nRequirements\nRequired Knowledge of computer networking concepts and protocols, and network security methodologies\nRequired Knowledge of cybersecurity and privacy principles\nRequired Knowledge of systems administration concepts\nRequired Knowledge of critical infrastructure systems with information communication technology that were designed without system security considerations\nRequired Knowledge of Personally Identifiable Information (PII) data security standards\nRequired Knowledge of Payment Card Industry (PCI) data security standards\nRequired Knowledge of Personal Health Information (PHI) data security standards\nRequired Knowledge of an organization's information classification program and procedures for information compromise\nRequired Skill in conducting test events\nRequired Skill in systems integration testing\nRequired Skill in writing test plans\nRequired Develop test plans to address specifications and requirements\nRequired Make recommendations based on test results\nRequired Determine scope, infrastructure, resources, and data sample size to ensure system requirements are adequately demonstrated\nRequired Test, evaluate, and verify hardware and\/or software to determine compliance with defined specifications and requirements\nPreferred Test, evaluate, and verify hardware and\/or software to determine compliance with defined specifications and requirements\nBenefits\nRate: $51.19 - $61.19 DOE\nRemote role\nCandidates must be within the State of Texas. Out of State candidates will not be considered.\nShow more\nShow less",
      "job_skills":"Digital Guardian DLP, Network security methodologies, Cybersecurity, Privacy principles, Systems administration concepts, Critical infrastructure systems, Information communication technology, PII data security standards, PCI data security standards, PHI data security standards, Information classification program, Information compromise, Test events, Systems integration testing, Test plans, Test specifications, Test requirements, Test results, Test scope, Infrastructure, Resources, Data sample size, System requirements, Hardware testing, Software testing, Compliance verification, Specifications, Requirements",
      "Category":"Data Science"
  },
  {
      "job_title":"Technology Analyst - Business Intelligence",
      "company":"CapMetro",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/technology-analyst-business-intelligence-at-capmetro-3790402748",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nWHO WE'RE LOOKING FOR\nThe Business Intelligence Technology Analyst III, Information Technology is responsible for the data systems. The role will work with the departmental business system analysts and other users of the system, supporting the Business Intelligence (BI) tools, helping analyze reporting requirements, developing complex BI queries and reports, generate and schedule complex data outputs, develop and manage complex dashboards and troubleshoot data inconsistencies and issues.\nAbout Us\nCapMetro is Austin's regional public transportation provider. We've been around since 1985 and work every day to give residents, commuters, and visitors the best possible transit options available to match their busy everyday lives.\nWe're always on the move, connecting people with jobs, schools, restaurants, shops, festivals, and other great places to hang out. In fact, we have more than 31 million boardings each year.\nOrganization\nAt CapMetro, we work to empower, enhance, and serve the region and its communities through the responsible delivery of safe, reliable, high-quality transportation. We are driven by a culture of\nSafety, Equity, Transparency, Sustainability, and Innovation\n. These values guide us in our daily activities, and decision-making and position us to be a great community partner and to better serve our riders who trust us to get them where they\u201a\u00c4\u00f4re going!\nWhat\u201a\u00c4\u00f4s In It For You\nWork with a diverse, collaborative, and energetic workforce whose focus is to bring innovation into the industry and how we serve our customers and team members.\nUtilize our free and reduced-fare transit service to get to the office and then plan to hit the gym (for free) and work with our onsite trainers, before heading back home.\nIf you have children between the ages of 6 months and 6 years old, enroll them in the onsite award-winning Childcare and Learning Center.\n\u201a\u00c4\u00b6and much more!\nWhat You Should Know\nCapMetro is deeply committed to building a workplace where inclusion is not only valued but prioritized. We are proud to be an equal-opportunity employer and committed to creating a welcoming and diverse environment. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, pregnancy, age, or any other protected characteristic as outlined by federal, state, or local laws. CapMetro makes hiring decisions based solely on qualifications, merit, and organizational needs at the time.\nShow more\nShow less",
      "job_skills":"Business Intelligence, Data Analysis, Reporting, Data Warehousing, Data Mining, SQL, Tableau, Power BI, Data Visualization, Data Integration, Data Modeling, Data Governance, Data Quality, Data Security",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Project Analyst",
      "company":"Texas Health and Human Services",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-project-analyst-at-texas-health-and-human-services-3757491060",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nThe Fraud Analytics and Data Operations (FADO) division of the Office of Inspector General (OIG) is seeking a Data Project Analyst (Data Analyst III).\nThe Data Project Analyst performs moderately complex project management work, along with consultative and technical system and data support work related to the development and implementation of Data Operations data projects and strategic initiatives. This position will assist OIG business areas by supporting operations for the Medicaid Fraud and Abuse Detection System (MFADS) and analyzing Medicaid data, focusing on hospital and nursing facility data. The position will also support operations of the utilization review systems and coordinating system enhancements and issue management with the contracted vendor and HHSC IT.\nThe position reports to the Director of Data Research and Support and works under limited supervision, with considerable latitude for the use of initiative and independent judgment.\nThe work involves coordinating the planning and initiation of complex data support and operational projects and strategic initiatives throughout the project lifecycle; monitoring the progress and schedule of projects; and communicating with project stakeholders, management, and other relevant parties. In consultation with management, this position directs, assigns, and monitors the work of project and vendor staff, and will provide guidance to others during the project lifecycle.\n*** This position can telework 100% from locations within Texas consistent with HHS telework policies. May need to occasionally report to the office to attend in-person meetings.***\nEssential Job Functions\nAttends work on a regular and predictable schedule in accordance with agency leave policy and performs duties as assigned:\nCoordinates, plans, supports and evaluates the operation of Medicaid Fraud and Abuse Detection System (MFADS) system, and makes recommendations for system modifications and updates. Monitors and reports upon project and issue statues. Interprets historical, current, and projected data to identify problems, causes, and areas for which procedural or system changes are indicated for MFADS and other utilization review systems and processes. Provides support for OIG Sharepoint sites. (25%)\nEngages in external-facing collaboration and communication both inside and outside of the agency and across OIG units, including but not limited to: OIG program area customers, OIG executive team, contractors\/vendors, IT resources and other stakeholders. Will be the primary support for system operations and training related to MFADS and other utilization review systems and processes. (20%)\nManages and supports project management activities. Establishes project goals and objectives, exercises sound judgment in making critical decisions; analyzes complex information and develops plans to address identified issues. Identifies project risks and gaps and directs, assigns, and evaluates the work of project staff. (25%)\nProvides technical and operational support to OIG staff for the Medicaid Fraud and Abuse Detection System (MFADS) and assists in training related to business processes and utilization review systems used by OIG staff. (10%)\nResearches, reviews, and performs case-specific analytical work on large datasets involving cases of suspected fraud, waste, and abuse to support active reviews and investigations. (10%)\nEffectively communicates verbally and in writing data analysis and findings to internal customers by way of reports, visualizations, trainings, and presentations (5%)\nPerforms other duties necessary to achieve the mission of the Office of Inspector General. Keeps manager informed as required or as necessary. Statewide travel of about 5% may be required. (5%)\nKnowledge Skills Abilities\nKnowledge of project management theories and practices applicable to IT projects that are highly complex in scope.\nKnowledge of Agile project management practices.\nSkill in project management monitoring, addressing changes in scope and budget, and the use of a computer and applicable software, including Word, Excel, and PowerPoint.\nKnowledge of statistics and analyzing data sets, running queries, report writing, and presenting findings, data mining, and segmentation techniques; and of record keeping, including security procedures for handling, protecting, and distributing confidential data.\nSkill in using formulas and manipulating large databases in EXCEL, Access or other spreadsheet software.\nSkill in critical thinking, analyzing problems, and devising effective solutions.\nKnowledge of state health and human services programs and related data.\nSkill in verbal and written communication skills essential to effectively interacting with OIG customers, leadership, and stakeholders.\nAbility to manage project activities; to establish project goals and objectives; to exercise sound judgment in making critical decisions; to analyze complex information and develop plans to address identified issues; to demonstrate negotiation and facilitation skills; to identify project risks and gaps; to prepare reports; to communicate effectively; and to direct, assign, and evaluate the work of project staff.\nSkill utilizing Business Objects or similar software to complete research and to develop reports.\nAbility to work in teams that may cross functions, departments and\/or agencies.\nAbility to work independently, exercise independent judgment, prioritize tasks, and manage multiple projects\/assignments\/responsibilities in a fast-paced environment under time constraints.\nRegistration Or Licensure Requirements\nCertified Associate in Project Management (CAPM) or Project Management Professional (PMP) preferred but not required.\nInitial Selection Criteria\nMinimum Qualifications\nGraduation from a four-year college or university with major course work in a related field. Education and experience can be substituted on a year for year basis.\nMinimum of 2 years of experience as a project manager, project coordinator, or program specialist working on large, complex systems related projects.\nPreferred Qualifications\nExperience in managing technical, data-intensive projects and cross-functional project teams.\nExperience querying and analyzing healthcare data.\nAdditional Information\nA copy of college transcript may be required. Selected candidate must be able to pass a background check.\nThe OIG is responsible for preventing, detecting, auditing, inspecting, reviewing, and investigating fraud, waste, and abuse in the provision of HHS in Medicaid and other HHS programs. Potential employees of OIG are subject to criminal background checks in accordance with the HHS Human Resources policy. Selected applicants must complete a national fingerprint-based criminal background check through the Texas Department of Public Safety (TDPS) and Federal Bureau of Investigations (FBI) to determine if they have criminal history record information that constitutes a bar to employment.\nOIG will request that all applicants considered for an interview provide responses to essay questions. Failure to respond to the request could disqualify an applicant from the interview process.\nAny employment offer is contingent upon available budgeted funds. The offered salary will be determined in accordance with budgetary limits and the requirements of HHSC Human Resources Manual.\nHHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work.\nIn compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888\u201a\u00c4\u00ee894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.\nMOS Code\nNote: Military occupation(s) that relate to the initial selection criteria and registration or licensure requirements for this position may be found by viewing the Texas State Auditor\u201a\u00c4\u00f4s Military Crosswalk at http:\/\/www.hr.sao.state.tx.us\/Compensation\/JobDescriptions.aspx.stitutes a bar to employment.\nTop 10 Tips for Success when Applying to Jobs at HHSC and DSHS\nHHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work.\nI-9 Form - Click here to download the I-9 form.\nIn compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.\nShow more\nShow less",
      "job_skills":"Project management, Data analysis, Data mining, Statistical analysis, Microsoft Office Suite (Word Excel PowerPoint), SQL, Report writing, Business Objects, Agile, Medicaid, PMP or CAPM certification, Healthcare data, Data security, Critical thinking, Problemsolving, Communication, Teamwork, Time management, Prioritization",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Security Analyst",
      "company":"The Timberline Group, LLC",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-security-analyst-at-the-timberline-group-llc-3752666922",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Join our dynamic and thriving company as a\nData Security Analyst\nin\nSt. Louis, MO\nwhere you'll have the opportunity to make an impact and shape the future of our renowned brands. If you have a passion for fashion, eager to learn and have an eye for detail, this is the perfect role for you! As a member of our team, you'll be part of a company that values\nresults, caring and learning.\nWhat You\u201a\u00c4\u00f4ll Be Doing\nMonitor security service performance and availability: Provide recommendations on security equipment, software, and services\nOn-going investigation: Inspect information security alarms and events to determine vulnerability and impact\nImplement processes: Put forth structured risk assessment processes, conducting ongoing threat and vulnerability assessments, and evaluating controls and countermeasures to mitigate risk\nParticipate in architecture reviews: Ensure adherence to information security architecture\nDevelop processes: Create plans for preventing, detecting, identifying, analyzing and responding to information security incidents\nDesign and deliver programs: Create education and training programs on information security and privacy matters\nThe Timberline Group\nPhone: 636-209-5537\nPO Box 565, Sullivan, Mo 63080\nwww.timberlinegrp.com\nresumes@timberlinegrp.com\n\"Delivering quality solutions through quality people\"\nShow more\nShow less",
      "job_skills":"Data Security, Security Service, Security Equipment, Software, Risk Assessment, Threat Assessment, Vulnerability Assessment, Information Security Architecture, Incident Response, Education and Training",
      "Category":"Data Science"
  },
  {
      "job_title":"US Tech Sr. Business Analyst",
      "company":"PwC",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/us-tech-sr-business-analyst-at-pwc-3782846530",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nBusiness Analysis\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team are the general managers of commercial and internal products. They sit at the intersection of the business, user experience, and the technology that solve our customer and end-user problems. They design, develop and manage activities for a specific product or group of products from product definition and planning through production, release, and end of life. Product Management\u201a\u00c4\u00f4s involvement lasts throughout all stages of a product\u201a\u00c4\u00f4s lifecycle including modifications, upgrades, maintenance of the product or product line. For commercial products, it also includes commercialization, Go To Market planning, sales, and other key business support activities.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades\/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Manager, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nTake action to ensure everyone has a voice, inviting opinion from all.\nEstablish the root causes of issues and tackle them, rather than just the symptoms.\nInitiate open and honest coaching conversations at all levels.\nMove easily between big picture thinking and managing relevant detail.\nAnticipate stakeholder needs, and develop and discuss potential solutions, even before the stakeholder realises they are required.\nDevelop specialised expertise in one or more areas.\nAdvise stakeholders on relevant technical issues for their business area.\nNavigate the complexities of global teams and engagements.\nBuild trust with teams and stakeholders through open and honest conversation.\nUphold the firm's code of ethics and business conduct.\nBusiness Analysts apply analytical skills working with business and product owners to develop requirements and user stories stemming from product roadmaps. Analysts add value to the delivery team by working with the business and product owner to create clarity around business objectives through the development of and refinement of user stories. Our Business Analysts solve business problems working with delivery teams using Agile and scrum methodologies.\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n6 year(s) of relevant experience in progressive roles managing IT system\/software development and project management processes\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nInformation Technology, Computer Systems Analysis, Management Information Systems\nCertification(s) Preferred\nIIBA\nPreferred Knowledge\/Skills\nDemonstrates intimate knowledge of, and\/or proven record of success in, roles as a Business Analyst working on software development projects, preferably for a global network of professional services firms, including the following areas:\nUnderstanding of requirements from the business or stakeholder\u201a\u00c4\u00f4s perspective and translating the requirements into the appropriate deliverables in an Agile\/Scrum delivery model;\nLeading User Acceptance Testing;\nCollaborating and leading stakeholders through all phases of User Acceptance Testing, including review of User Acceptance Test cases for completeness;\nUnderstanding of the SDLC activities expected to deliver custom developed and packaged applications and Agile Requirements Methods; and,\nUnderstanding of all phases of applications systems analysis and the SDLC development methodology and Business Process Modeling. Demonstrates intimate ability, and\/or proven record of success, in roles considering the business implications of applying technology to the current business environment and preparing requirements from which applications can be developed including in the following areas:\nUnderstanding of requirements from the business or stakeholder\u201a\u00c4\u00f4s perspective and translating the requirements into the appropriate deliverables in an Agile\/Scrum delivery model;\nLeading User Acceptance Testing;\nCollaborating and leading stakeholders through all phases of User Acceptance Testing, including review of User Acceptance Test cases for completeness;\nUnderstanding of the SDLC activities expected to deliver custom developed and packaged applications and Agile Requirements Methods; and,\nUnderstanding of all phases of applications systems analysis and the SDLC development methodology and Business Process Modeling.\nAnalyzing business and user needs, establishing clear business value objectives, documenting requirements, and revising existing system logic or business process difficulties to select, build or modify large, complex or mission critical information systems to achieve business value;\nWorking with other Business Analysts to understand total testing scope to establish that the requested equals delivered functionality;\nSetting up testing suite test cases and assignment of testers;\nUsing Azure DevOps for reporting and metrics;\nPerforming Senior Business Analyst responsibilities working on large and complex software development, infrastructure, SaaS and\/or Cloud solutions;\nApplying analytical skills to evaluate and document accurate business requirements and present these requirements in a manner that is concise, measurable and flexible enough to meet project and stakeholder needs;\nManaging the quality and acceptance of vendor analysis and testing of SOW deliverables in a project setting;\nDeveloping and guiding the documentation of requirements and test cases so that the requirements and test cases are unambiguous, aligned, consistent and not in contradiction with each other;\nWorking collaboratively within a delivery team at all levels including stakeholder management, with considerate ability to take ownership of tasks and complete them with minimal direct supervision; and,\nDeveloping deep business and application domain knowledge for an assigned business portfolio and\/ or LoS to aid in critically evaluating the balance of both business needs and user requests.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniormanager\nShow more\nShow less",
      "job_skills":"Business Analysis, Product Management, Agile, Scrum, User Acceptance Testing, Software Development, Project Management, Azure DevOps, Data Science, Business Strategy, System Analysis, Cloud Solutions, SaaS, Information Systems, Requirements Gathering, Business Process Modeling, User Stories, User Experience, Stakeholder Management, Leadership, Communication, Problem Solving, Analytical Skills, IIBA Certification",
      "Category":"Data Science"
  },
  {
      "job_title":"Analyst of Cloud Platform Applications - ( Microsoft Azure, Power of BI platform, Cloud Applications, N-tier web-based applicat",
      "company":"The Timberline Group, LLC",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/analyst-of-cloud-platform-applications-microsoft-azure-power-of-bi-platform-cloud-applications-n-tier-web-based-applicat-at-the-timberline-group-llc-3578825956",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Analyst - Cloud Platform Applications - ( Microsoft Azure, Power of BI platform, Cloud Applications, N-tier web-based applications) responsible for architectural design and implementation of overall enterprise software solutions. This will include researching, identification, selection, and all steps related to drive solution delivery. Systems integration will be a key focus along with aligning teams (internal and vendor development teams) to our shared technical direction and partnering with multiple teams to elaborate the solution along with its architecture, interfaces, assumptions and context. The successful candidate will bring a demonstrated track record of success as a change agent as well as critical skills in developing partnerships, modeling behaviors and help drive future innovation of our software solutions.\nDesign, review, determine technology platform and maintain scalable and stable off the shelf applications or custom-built technology solutions to meet business needs. Act as a subject matter expert for Applications Group.\nImproved, maintain, monitor a collection of 3rd- party and custom developed applications from an infrastructure perspective.\nResponsible for overall design of solutions and architectural landscape\nConduct root cause analysis and advanced performance tuning for complex business processes and functionality\nCurator of the code repository and integration services\nParticipate in systems related integration issues to resolution\nEstablish architectural standards and direct external developers on adherence of those standards\nDemonstrate the broad expertise to integrate the technical vision for IT, integrating across technologies, systems, and organization\nCoordinate the identification and assessment of new and emerging hardware, software, products, methods, and techniques and evaluating likely relevance of these for the organization\nIs passionate about technology and has a breadth across multiple subject areas: Applications, Data, Security and Infrastructure\nKnowledge of Microsoft Azure, Power of BI platform, Cloud Applications, N-tier web-based applications experience\nThe Timberline Group\nPhone: 636-209-5537\n623 Missouri Ave #104, Sullivan, Mo 63080\nwww.timberlinegrp.com\nresumes@timberlinegrp.com\n\"Delivering quality solutions through quality people\"\nShow more\nShow less",
      "job_skills":"Microsoft Azure, Power BI, Cloud applications, Ntier web applications, Enterprise software solutions, System integration, Architectural design, Implementation, Scalable applications, Custombuilt solutions, Infrastructure management, Performance tuning, Code repository management, Integration services, Technical standards, Systems architecture, Technology identification, Technology evaluation, Technology integration, Hardware assessment, Software assessment, Product assessment, Method assessment, Technique assessment, Technology vision, Applications knowledge, Data knowledge, Security knowledge, Infrastructure knowledge",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst - Hybrid",
      "company":"FTL Finance",
      "job_location":"St Charles, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-hybrid-at-ftl-finance-3762338583",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Reporting to the President, the Data Analyst will be at the forefront of driving and influencing transformative change at FTL Finance by developing and implementing an analytical approach to address key business decisions. This new role will be responsible for collecting, processing, and analyzing data to provide valuable and actionable insights that support FTL\u201a\u00c4\u00f4s operational goals and strategic vision. The data analyst will collaborate closely with department leaders in operations, technology, marketing, and sales, and bring new perspectives to assist in solving complex problems.\nFTL Finance is a nationwide consumer financing company on a mission to help HVAC and home improvement contractors grow their businesses. We believe financing should be easy and accessible for everyone, and we\u201a\u00c4\u00f4re constantly innovating to make that vision a reality.\nOur team lives outside of the box and fosters a trusting, supportive culture where everyone feels valued as people first. We purposefully approach relationships with our customers, partners, and each other with a spirit of cooperation, sincerity, and fun.\nWould you like to be part of our success?\nResponsibilities\nData Collection and Integration:\nMaintain and optimize databases to ensure data accuracy and availability for analysis. Streamline data sources, identify new sources of data, and establish methods to improve data collection.\nData Cleaning:\nClean and preprocess data to ensure accuracy and consistency, including handling missing values, outliers, and data quality issues.\nData Analysis and Modeling:\nAnalyze data using statistical techniques, data mining, and data visualization tools to uncover trends, correlations, and insights to address department-specific questions and challenges. Utilize machine learning and data mining techniques when appropriate.\nData Visualization and Reporting:\nCreate interactive visualizations, charts, and dashboards to effectively communicate insights. Prepare reports and presentations for various departments, highlighting key findings in a way that is understandable and actionable for non-technical stakeholders.\nCross-Departmental Collaboration:\nWork closely with department heads and team members to understand their strategies, needs, and challenges. Provide data-driven insights and recommendations to improve processes and achieve goals.\nData Security and Compliance:\nEnsure that data handling and analysis adhere to data security and privacy regulations.\nDocumentation:\nMaintain comprehensive documentation of data sources, analysis methods, and results for transparency and reference.\nRequired Experience And Skills\nBachelor\u201a\u00c4\u00f4s Degree in a relevant field, such as statistics, mathematics, computer science, economics, finance, or a related discipline\nMinimum of 5 years of experience in data analysis\nStrong foundation in statistics and data analysis techniques\nProficiency in a programming language for data manipulation, analysis, and modeling\nKnowledge of databases and the ability to write SQL queries to extract and manipulate data\nCompetence in data visualization tools\nFamiliarity with machine learning algorithms and techniques for predictive modeling\nSkills in extracting, transforming, and loading (ETL) data from various sources\nAn understanding of data ethics and privacy regulations\nAbility to relate data analysis to business goals and make data-driven recommendations to solve business problems\nStrong verbal and written communication skills to convey findings\nDesired Traits\nIndependent\nResourceful\nCurious\nCollaborative\nAdaptable\nOrganized\nEfficient\nAt FTL Finance, we value diversity and the uniqueness of all people. We thrive in an inclusive environment, and we recruit, hire and promote without regard to race, gender, age, color, gender identity, gender expression, sexual orientation, ethnic or national origin, citizenship, religion, sexual preference, military or veteran status, marital status, family status, physical or mental disability - or any other legally protected categories as set forth in the applicable state, federal or local laws. This policy applies to all aspects of employment including training, compensation, benefits, and all other privileges of employment.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Mining, Machine Learning, Data Visualization, SQL, Programming Languages, Data Security, Data Ethics, Statistics, Databases, ETL, Predictive Modeling, Data Manipulation",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Governance Analyst Specialist",
      "company":"Kforce Inc",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-governance-analyst-specialist-at-kforce-inc-3777073285",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nKforce has a client that is seeking a Data Governance Analyst Specialist in Kansas City, MO. Key Tasks:\nData Governance Analyst Specialist will execute the organization's data governance operating model and collaborate with various Company business and technical teams to implement enterprise data policies and standards for the organization\nMonitor progress of Data Domain teams with respect to the rollout of data governance practices and provide education, training, and support as needed\nEnsure data aligns with regulatory requirements as needed\nOversight and regular review of Data Domain Team deliverables related to data governance practices; Data maps; Data issue tracking; Metadata documentation; Data procedures documentation; Service Level Agreements; Access and security requirements; Audit and retention requirements\nPartner with Data Owners and Data Stewards to develop workflows, dashboards, and automation of data governance activities within our data governance tools\nAs a Data Governance Analyst Specialist, you will partner with HR's Learning and Development team to curate and deploy Data Governance, Data Stewardship, and Tool required training\nAct as a Collibra administrator and help train domain teams and consumers on the platform; Drive adoption of, and guide proper use of, features and functionality available within the tool\nWork closely with our tool vendors on roadmap items for implementation and provide feedback for additional improvements that would benefit Company\nManage internal data products, including reference data, metadata, data quality results, and SharePoint content\nRequirements\nBachelor's degree and\/or equivalent combination of education and work experience in related field; Finance, Accounting, or related education preferred\n2 or more years of confirmed experience working on a team engaged in data governance, data management, or data operations\nExperience with data governance, metadata, data mapping, and data lineage tools, such as Collibra, Informatica, IBM IGC, etc.\nFamiliarity with data security and protection methodologies\nComfortable with working in an agile work environment\nDemonstrated effectiveness working in a dynamic and high-paced environment\nValidated innovator and a strategic problem solver in the data governance space\nOutstanding interpersonal skills including the ability to communicate with individuals at all levels of the organization in both verbal and written form\nAbility to approach and solve problems in an analytical and methodical manner\nAbility to be proactive and collaborative in ambiguous situations\nPreferred\n2+ years of experience in the asset management industry, with strong domain knowledge of data management technology and operations\nExperience working with cloud technologies\nExperience in policy and standards development and maintenance\nExperience with MuleSoft Any point Studio or BPMN are a plus\nProject Management, Agile and\/or Six Sigma skills are a plus\nThe pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.\nWe offer comprehensive benefits including medical\/dental\/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.\nNote: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.\nThis job is not eligible for bonuses, incentives or commissions.\nKforce is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nSalary: $83,000 - $123,000 per year\nShow more\nShow less",
      "job_skills":"Data Governance, Data Management, Data Operations, Collibra, Informatica, IBM IGC, Data Security, Data Protection, Agile, Project Management, Six Sigma, MuleSoft Any point Studio, BPMN",
      "Category":"Data Science"
  },
  {
      "job_title":"Hiring Fulltime - Senior Technical Analyst \u201a\u00c4\u00ec SAP - Kansas City, MO",
      "company":"Sonitalent Corp",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/hiring-fulltime-senior-technical-analyst-%E2%80%93-sap-kansas-city-mo-at-sonitalent-corp-3742866558",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Job title: Senior Technical Analyst \u201a\u00c4\u00ec SAP\nLocation: Kansas City, MO\nRate: $ 130-135k\/year\nInterview: Phone\/ Skype\nVisa: USC and GC Only\nJob Description\nTop 3-5 Non-negotiables:\nBachelor's or Master\u201a\u00c4\u00f4s degree in computer science, Information Technology, or 10+ years related experience or 5 end-to-end roll-outs.\nProven experience as a Technical Analyst with a focus on SAP S4\/HANA and other SAP modules as mentioned above.\nStrong knowledge of SAP installation, configuration, administration, and troubleshooting.\nExperience with both on-premises and cloud-based SAP deployments.\nProficient in implementing security measures and user administration within SAP systems.\nFamiliarity with network and infrastructure components relevant to SAP systems.\nExcellent problem-solving skills and ability to handle complex technical challenges.\nStrong communication and collaboration skills to work effectively with cross-functional teams.\nWorked in both Project as well as Support roles.\nExperience with BTP\nTop 3-5 Non-negotiables\nBachelor's or Master\u201a\u00c4\u00f4s degree in computer science, Information Technology, or 10+ years related experience or 5 end-to-end roll-outs.\nProven experience as a Technical Analyst with a focus on SAP S4\/HANA and other SAP modules as mentioned above.\nStrong knowledge of SAP installation, configuration, administration, and troubleshooting.\nExperience with both on-premises and cloud-based SAP deployments.\nProficient in implementing security measures and user administration within SAP systems.\nFamiliarity with network and infrastructure components relevant to SAP systems.\nExcellent problem-solving skills and ability to handle complex technical challenges.\nStrong communication and collaboration skills to work effectively with cross-functional teams.\nWorked in both Project as well as Support roles.\nAnswer these-\nDo you have any SAP Certification (S4 Hana)?\nDo you have experience with SAP Cloud?\nDo you have experience with BTP?\nDo you have consulting experience?\nHow many SAP end to end rollouts have you participated in (ideally, at least 5)?\nHow much support experience do you have, and what SAP modules\/technologies have you supported?\n3 Soft Skills\nAble to communicate with Business as well as technical users\nTeam Player, Collaborator\nExperience managing vendors\/contractors\nShow more\nShow less",
      "job_skills":"SAP S4\/HANA, SAP Modules, SAP Installation, SAP Configuration, SAP Administration, SAP Troubleshooting, SAP Security, SAP User Administration, Network Components, Infrastructure Components, Problem Solving, Communication, Collaboration, Project Management, Support, BTP, SAP Cloud",
      "Category":"Data Science"
  },
  {
      "job_title":"Security Business Analyst \u201a\u00c4\u00ec Senior Level.",
      "company":"Tantus Technologies, Inc.",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/security-business-analyst-%E2%80%93-senior-level-at-tantus-technologies-inc-3764331673",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Tantus Technologies, Inc., recognized by the Washington Post as a Top Workplace, is seeking a\nSecurity Business Analyst - Senior Level\nto provide security control and assessment as well as Risk Management Framework support for a Federal Client's information systems. This role is instrumental in enhancing our cybersecurity posture and impact in securing sensitive information. The ideal candidate will have a thorough knowledge and understanding of Federal Information Security Management Act (FISMA), including the NIST 800 series Special Publications (SP), FedRAMP, and Federal Information Processing Standards (FIPS) guidelines and regulations. Experience in a federal or high-compliance environment is highly preferred.\nDesign and advise on system security controls requirements, ensuring compliance with all Federal laws, standards, and guidelines.\nConduct comprehensive assessments of security controls, documenting, and reporting results with actionable insights.\nFacilitate cross-departmental understanding of IT security governance, regulations, and the application of current technologies.\nDevelop and refine security policies, processes, and techniques, including related training, to ensure the success of security-related projects.\nManage the scheduling and execution of security activities, including system categorization, control assessment, audit response preparation, and compliance material review.\nTrack and manage POA&Ms and other identified risks.\nMentor, and enhance the skillset of junior and mid-level team members.\nBachelor\u201a\u00c4\u00f4s degree in information technology or related field.\nAt least 5 years of Cyber Security experience with expertise in Contingency Plans, Risk Assessments, System Security Plans, Incident Response Plans, NIST 800-53, Assessing 800-53 controls, FedRAMP, A&A, POA&Ms, ATO process, and current security tools and technologies.\nProven ability to design and conduct security control assessments.\nExperience with Cloud Service Providers, FedRAMP vendors, CIO Annual FISMA, and FISCAM Metrics reporting.\nProficiency in utilizing electronic Governance, Risk Management, and Compliance (eGRC) applications (e.g., CSAM, Xacta, Archer, eMASS).\nAbility to develop and update comprehensive security policies.\nStrong understanding of network designs, protocols, and security tools.\nShow more\nShow less",
      "job_skills":"NIST 800 series Special Publications (SP), Federal Information Security Management Act (FISMA), FedRAMP, Federal Information Processing Standards (FIPS), Information technology, Contingency Plans, Risk Assessments, System Security Plans, Incident Response Plans, NIST 80053, FedRAMP, A&A, POA&Ms, ATO process, eGRC applications (CSAM Xacta Archer eMASS), Security policies, Network designs, Protocols, Security tools",
      "Category":"Data Science"
  },
  {
      "job_title":"US Tech - Business Analyst",
      "company":"PwC",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/us-tech-business-analyst-at-pwc-3785062764",
      "search_city":"Shawnee",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nBusiness Analysis\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team are the general managers of commercial and internal products. They sit at the intersection of the business, user experience, and the technology that solve our customer and end-user problems. They design, develop and manage activities for a specific product or group of products from product definition and planning through production, release, and end of life. Product Management\u201a\u00c4\u00f4s involvement lasts throughout all stages of a product\u201a\u00c4\u00f4s lifecycle including modifications, upgrades, maintenance of the product or product line. For commercial products, it also includes commercialization, Go To Market planning, sales, and other key business support activities.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades\/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Manager, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nPursue opportunities to develop existing and new skills outside of comfort zone.\nAct to resolve issues which prevent effective team working, even during times of change and uncertainty.\nCoach others and encourage them to take ownership of their development.\nAnalyse complex ideas or proposals and build a range of meaningful recommendations.\nUse multiple sources of information including broader stakeholder views to develop solutions and recommendations.\nAddress sub-standard work or work that does not meet firm's\/client's expectations.\nDevelop a perspective on key global trends, including globalisation, and how they impact the firm and our clients.\nManage a variety of viewpoints to build consensus and create positive outcomes for all parties.\nFocus on building trusted relationships.\nUphold the firm's code of ethics and business conduct.\nBusiness Analysts apply analytical skills working with business and product owners to develop requirements and user stories stemming from product roadmaps. Analysts add value to the delivery team by working with the business and product owner to create clarity around business objectives through the development of and refinement of user stories. Our Business Analysts solve business problems working with delivery teams using Agile and scrum methodologies.\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n4 year(s) of progressive roles managing IT system\/software development and project management processes.\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nInformation Technology, Computer Systems Analysis, Management Information Systems\nCertification(s) Preferred\nIIBA\nPreferred Knowledge\/Skills\nDemonstrates extensive abilities and\/or a proven record of success as a team leader working on software development projects, preferably for a global network of professional services firms, including the following areas:\nPerforming all phases of applications systems analysis and a proven understanding of the SDLC development methodology (Waterfall\/Agile\/Scrum);\nPossessing business requirements understanding and translating them into the appropriate deliverables;\nPerforming SDLC activities expected to develop custom developed and packaged applications selecting and driving appropriate requirement Methods including Agile Requirements Methods; and,\nDemonstrating Vendor SOW, SLA measures and acceptance criteria for managing successful outcomes of projects leveraging vendors;\nWorking on software development projects, infrastructure, SaaS and\/or Cloud solutions;\nApplying analytical skills to determine business value and document accurate business requirements and present these requirements in a manner that is concise, measurable and flexible enough to meet project and stakeholder needs;\nConducting requirements elicitation, validation and analysis meetings with the business stakeholders; perform Fit\/Gap analysis; support testing activities; and produce deliverables related to the project or projects assigned;\nManaging the quality and acceptance of vendor analysis and testing SOW deliverables in a project setting;\nOverseeing the documentation of business requirements and test cases, so that requirements and test cases are unambiguous, aligned, consistent and not in contradiction with each other;\nWorking with vendor SOW project deliverables on their quality and meeting acceptance criteria;\nProviding modeling of the business processes; understand the business need and impacts of proposed solutions;\nProviding assistance for developing solution approach to deliver business value;\nDeveloping business and application domain knowledge for an assigned business portfolio and\/or line of service; and,\nDemonstrating prior knowledge of Adobe Experience Cloud stack (Adobe Experience Manager - AEM, Adobe Analytics, Adobe Target, etc.) is highly desirable.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechmanager\nShow more\nShow less",
      "job_skills":"Business Analysis, Software Development, Agile, Scrum, Waterfall, SDLC, Adobe Experience Cloud, Requirements Elicitation, Requirements Validation, Requirements Analysis, User Stories, Use Case Diagrams, Business Process Modeling, Solution Architecture, Stakeholder Engagement, Quality Assurance, Testing, Vendor Management, Project Management, Communication, Teamwork, Leadership, Ethics",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Catalog and Lineage Central Governance Analyst",
      "company":"PwC",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-catalog-and-lineage-central-governance-analyst-at-pwc-3785060838",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nIFS - Information Technology (IT)\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data\/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nAdditional Responsibilities\nSupporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture.\nCustom Orgs\nGlobal LoS\n:\nInternal Firm Services\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nComputer and Information Science, Data Processing\/Analytics\/Science\nAdditional Educational Preferences\nOther related fields of study with relevant experience may be considered.\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success as a team leader:\nPossessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects;\nDisplaying knowledge of data management and governance policies, standards, metrics, controls, and processes;\nHaving knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers;\nPossessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies;\nShowcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture;\nExhibiting proven knowledge and working experience in Microsoft Purview;\nCreating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers;\nShowcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;\nDisplaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog;\nConducting periodic reviews of the data catalogue to corroborate compliance with the DG standards;\nFacilitating the capture of metadata as core change and operational deliverables;\nDemonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers;\nDesigning, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview;\nIdentifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports;\nPossessing ability to create and maintain automated workflows for periodic metadata refresh;\nComplete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR\/HIPPA\/SPI (as applicable);\nHelping manage the inventory of data-related controls on systems that support segment processes and customers;\nShowcasing thorough understanding of data steward\/data owner operating model;\nAbility in designing and rolling out training programs to train the trainer\/end-users;\nBeing a collaborative team player; and,\nHaving a business outcome focused problem-solving mindset.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"Data Governance, Azure Purview, Business Glossary, EndtoEnd Data Lineage, Data Management, Data Catalog, Data Ownership, Metadata Management, Data Asset Identification, Data Classification, Taxonomy and Hierarchies, Data Discovery, Data Lineage, Data Quality, Data Standards, Compliance, Regulations (GDPR\/HIPPA\/SPI), Data Privacy, Data Security, Analytics, Business Intelligence, Machine Learning, Artificial Intelligence, Cloud Computing, Software Development, Project Management, Problem Solving, Communication, Collaboration, Teamwork, Leadership, Ethics",
      "Category":"Data Science"
  },
  {
      "job_title":"US Tech - Business Analyst",
      "company":"PwC",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/us-tech-business-analyst-at-pwc-3785064304",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nBusiness Analysis\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team are the general managers of commercial and internal products. They sit at the intersection of the business, user experience, and the technology that solve our customer and end-user problems. They design, develop and manage activities for a specific product or group of products from product definition and planning through production, release, and end of life. Product Management\u201a\u00c4\u00f4s involvement lasts throughout all stages of a product\u201a\u00c4\u00f4s lifecycle including modifications, upgrades, maintenance of the product or product line. For commercial products, it also includes commercialization, Go To Market planning, sales, and other key business support activities.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades\/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Manager, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nPursue opportunities to develop existing and new skills outside of comfort zone.\nAct to resolve issues which prevent effective team working, even during times of change and uncertainty.\nCoach others and encourage them to take ownership of their development.\nAnalyse complex ideas or proposals and build a range of meaningful recommendations.\nUse multiple sources of information including broader stakeholder views to develop solutions and recommendations.\nAddress sub-standard work or work that does not meet firm's\/client's expectations.\nDevelop a perspective on key global trends, including globalisation, and how they impact the firm and our clients.\nManage a variety of viewpoints to build consensus and create positive outcomes for all parties.\nFocus on building trusted relationships.\nUphold the firm's code of ethics and business conduct.\nBusiness Analysts apply analytical skills working with business and product owners to develop requirements and user stories stemming from product roadmaps. Analysts add value to the delivery team by working with the business and product owner to create clarity around business objectives through the development of and refinement of user stories. Our Business Analysts solve business problems working with delivery teams using Agile and scrum methodologies.\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n4 year(s) of progressive roles managing IT system\/software development and project management processes.\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nInformation Technology, Computer Systems Analysis, Management Information Systems\nCertification(s) Preferred\nIIBA\nPreferred Knowledge\/Skills\nDemonstrates extensive abilities and\/or a proven record of success as a team leader working on software development projects, preferably for a global network of professional services firms, including the following areas:\nPerforming all phases of applications systems analysis and a proven understanding of the SDLC development methodology (Waterfall\/Agile\/Scrum);\nPossessing business requirements understanding and translating them into the appropriate deliverables;\nPerforming SDLC activities expected to develop custom developed and packaged applications selecting and driving appropriate requirement Methods including Agile Requirements Methods; and,\nDemonstrating Vendor SOW, SLA measures and acceptance criteria for managing successful outcomes of projects leveraging vendors;\nWorking on software development projects, infrastructure, SaaS and\/or Cloud solutions;\nApplying analytical skills to determine business value and document accurate business requirements and present these requirements in a manner that is concise, measurable and flexible enough to meet project and stakeholder needs;\nConducting requirements elicitation, validation and analysis meetings with the business stakeholders; perform Fit\/Gap analysis; support testing activities; and produce deliverables related to the project or projects assigned;\nManaging the quality and acceptance of vendor analysis and testing SOW deliverables in a project setting;\nOverseeing the documentation of business requirements and test cases, so that requirements and test cases are unambiguous, aligned, consistent and not in contradiction with each other;\nWorking with vendor SOW project deliverables on their quality and meeting acceptance criteria;\nProviding modeling of the business processes; understand the business need and impacts of proposed solutions;\nProviding assistance for developing solution approach to deliver business value;\nDeveloping business and application domain knowledge for an assigned business portfolio and\/or line of service; and,\nDemonstrating prior knowledge of Adobe Experience Cloud stack (Adobe Experience Manager - AEM, Adobe Analytics, Adobe Target, etc.) is highly desirable.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechmanager\nShow more\nShow less",
      "job_skills":"Business Analysis, Product Management, Agile, Scrum, Waterfall, SDLC, Vendor SOW, SLA, SaaS, Cloud, Adobe Experience Cloud, Adobe Experience Manager, Adobe Analytics, Adobe Target",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst - IT Supply Chain Support",
      "company":"World Wide Technology",
      "job_location":"Maryland Heights, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-it-supply-chain-support-at-world-wide-technology-3788689732",
      "search_city":"Saint Paul",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Why WWT?\nFueled by creativity and ideation, World Wide Technology strives to accelerate our growth and nurture future innovation. From our world-class culture to our generous benefits, to developing cutting-edge technology solutions, WWT constantly works towards its mission of creating a profitable growth company that is a great place to work. We encourage our employees to embrace collaboration, get creative, and think outside the box when it comes to delivering some of the most advanced technology solutions for our customers.\nWWT was founded in 1990 in St. Louis, Missouri. We employ approximately 10,000 individuals and closed nearly 17B in revenue. We have an inclusive culture and believe our core values are the key to company and employee success. WWT is proud to announce that it has been named on the FORTUNE \"100 Best Places to Work For\u00ac\u00c6\" list for the twelfth consecutive year!\nWant to work with highly motivated individuals that come together to form high-performance teams? Come join WWT today!\nAs part of the IT Supply Chain Support team, you will provide front-line support for our growing Supply Chain operations through Oracle Fusion Cloud apps, on-prem EBS, Custom applications, and more to help ensure our business partners' continued success.\nWhat will you be doing?\nThe individual we are looking to hire will work with the team of analysts and developers to support and enhance the on-prem and cloud Oracle systems. They will be required to learn our business processes and procedures, participate in meetings with business stakeholders globally, design meetings, and tech meetings, perform proof of concept as and when needed, and get fully involved in all aspects of delivering solutions to the business. Also, this person will be required to test various applications, conduct UAT as necessary, and work with the team to deploy the technical components in production.\nResponsibilities:\nParticipate and lead the support of existing Supply Chain applications.\nParticipate and lead in strategic improvements to operational resiliency and scalability.\nProvide Application solution design across different Oracle Application Technologies and custom platforms for supply chain operations.\nAnalyze data flow within the Oracle EBS, Oracle Cloud, and various boundary and custom web applications to identify solutions to problems.\nMentor and lead other team members.\nWork with their technical counterparts to provide functional details of the ask and work with them to deliver a technical solution.\nTest end-to-end solutions to ensure complete satisfaction of internal and external users.\nCreate training documents, QA flows, and work instructions so that the solutions developed can be used by end users.\nRelevant Skills:\n8+ years of experience in Oracle EBS\/Applications\nExperience in Oracle Fusion Cloud is excellent to have.\nWorking knowledge of supply chain processes: Warehouse Management, Inventory management, Order Management, Purchasing, and Planning processes.\nExperience with analysis, setup, configuration, and testing\nExperience managing a support queue.\nAbility to write complex SQL for data mining, analysis, and other purposes.\nUnderstanding Upstream and downstream integration with other modules and third-party and custom applications.\nAbility to work and collaborate with business and cross-functional teams.\nStrong analytical, troubleshooting, and debugging skills.\nExperience and or knowledge of Agile Methodology is a big plus.\nGood presentation and communication skills.\nAbility to be self-directed and self-motivated.\nAbility to be innovative, have outside-the-box creativity, and present alternative ideas.\nTo be a good active listener and communicator.\nThe well-being of WWT employees is essential. So, when it comes to our benefits package, WWT has one of the best. We offer the following benefits to all full-time employees:\nHealth and Well-being: Heath, Dental, and Vision Care, Onsite Health Centers, Employee Assistance Program, Wellness Program\nFinancial Benefits: Competitive pay, Profit Sharing, 401k Plan with Company Matching, Life and Disability Insurance, Tuition Reimbursement\nPaid Time Off PTO & Holidays, Parental Leave, Sick Leave, Military Leave, Bereavement\nAdditional Perks: Nursing Mothers\u201a\u00c4\u00f4 Benefits, Voluntary Legal, Pet Insurance, Employee Discount Program\nDiversity, Equity, and Inclusion are more than a commitment at WWT -- it is the foundation of what we do. Through diverse networks and pipelines, we have a clear vision: to create a Great Place to Work for All. We believe inclusion includes U. Be who U are at WWT!\nShow more\nShow less",
      "job_skills":"Oracle, Oracle EBS, Oracle Fusion Cloud, Agile Methodology, SQL, Supply Chain Management, Warehouse Management, Inventory Management, Order Management, Purchasing, Planning, Analysis, Setup, Configuration, Testing, Data Mining, Troubleshooting, Debugging, Presentation skills, Communication skills, Selfmotivation, Creativity, Active Listening",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Electrical Engineer - Data Center",
      "company":"Olsson",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-electrical-engineer-data-center-at-olsson-3772679012",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Company Description\nWe are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.\nOur most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u201a\u00c4\u00ee and will continue to allow us \u201a\u00c4\u00ee to grow. The result? Inspired people, amazing designs, and projects with purpose.\nJob Description\nAs an Electrical Engineer, you will work directly with some of the world\u201a\u00c4\u00f4s largest technology companies and other mission-critical clients. You will serve as an electrical engineer on projects, design calculations, write technical reports, and prepare documents. Experience in the Data Center industry is preferred. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients.\nQualifications\nYou are passionate about:\nWorking collaboratively with others\nHaving ownership in the work you do\nUsing your talents to positively affect communities\nYou bring to the team:\nStrong communication skills\nAbility to contribute and work well on a team\nBachelor's degree in electrical engineering\n8+ years of electrical engineering experience\nLicensed PE\nAbility to be a self-starter to take on a variety of tasks to best serve the client and their project work\nInvestigation and troubleshooting of problems to find solutions\nAdditional Information\nOlsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u201a\u00c4\u00f4re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.\nAs an Olsson employee, you\u201a\u00c4\u00f4ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u201a\u00c4\u00f4ll:\nBecome an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)\nEngage in work that has a positive impact in communities\nReceive an excellent 401(k) match\nParticipate in a wellness program promoting balanced lifestyles\nBenefit from a bonus system that rewards performance\nHave the possibility for flexible work arrangements\nOlsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.\nShow more\nShow less",
      "job_skills":"Electrical Engineering, Design Calculations, Technical Reports, Data Center Industry, Communication Skills, Teamwork, Bachelor's in Electrical Engineering, 8+ Years of Electrical Engineering Experience, Licensed PE, Troubleshooting, Project Management, Employee Stock Ownership Plan (ESOP), 401(k) Match, Wellness Program, Bonus System, Flexible Work Arrangements",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior SQL Database Developer (New Braunfels\/Hybrid):  $125-150K",
      "company":"Austin Fraser",
      "job_location":"New Braunfels, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-sql-database-developer-new-braunfels-hybrid-%24125-150k-at-austin-fraser-3786294530",
      "search_city":"New Braunfels",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Austin Fraser is working with a big name company headquartered in the New Braunfels area in their search for a Senior SQL Developer to add to their top notch Software Engineering team.\nThis is a Hybrid Position so You Must Live Within a Commutable Distance of New Braunfels, TX and be Willing to Work 2-3 Days in the Office.\nWhy the Senior SQL Engineer Role is For You:\nHighly Competitive Base Salary + Awesome Benefits\nVery Reputable Company Offering Stability and Work-Life Balance\nFlexible Hybrid Schedule\nGreat Leadership and Manager Who Truly Cares About Their People\nWhat We're Looking For in a Senior SQL Developer:\n8+ Years of Database and Software Development Industry Experience\n6+ Years of SQL Server Development Experience\nHeavy Experiences with the Microsoft SQL Server, BI Tools\nSSIS, SSRS, SSAS, ETL, OLAP\nPower BI, Cognos, Tableau and\/or Other Reporting Tools\nPlease apply today to be set up with an interview before the holidays!\nShow more\nShow less",
      "job_skills":"SQL, Microsoft SQL Server, BI Tools, Reporting Tools, SSIS, SSRS, SSAS, ETL, OLAP, Power BI, Cognos, Tableau",
      "Category":"Data Science"
  },
  {
      "job_title":"Business Intelligence Analyst \u201a\u00c4\u00ec Data Visualizations",
      "company":"The University of Texas at Dallas",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/business-intelligence-analyst-%E2%80%93-data-visualizations-at-the-university-of-texas-at-dallas-3785764105",
      "search_city":"McKinney",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"The Business Intelligence Analyst position in OISDS will work collaboratively as a member of the team and will interact with internal and external stakeholders to support a variety of data management, training, analysis and benchmarking initiatives at The University of Texas at Dallas. The person in this role will assist with the ongoing development and implementation of tools to promote the development and use of analytic dashboards designed for wide distribution to UT Dallas campus stakeholders.\nThe primary functions of this role will be to\n1)\nassist OISDS with building relationships with campus constituents to develop analytic data resources and institutional research studies,\n2)\nassist with training and knowledge transfer activities related to OISDS tools, and\n3)\nconduct internal institutional research studies, assist with external data requests, perform data analysis, generate analytics, and communicate results involving internal data across numerous domains.\nIn this role, the Business Intelligence Analyst will provide direct support to internal and external stakeholders, manage relationships with data providers and end users. This role will also be tasked with enhancing existing and developing new analytics and data resources. The person in this role will report to the Associate Director for Institutional Research and Analytics.\nMinimum Education And Experience\nBachelors degree in related field.\nFour (4) years related professional experience.\nEquivalent combination of education and experience may be considered.\nPreferred Education And Experience\nMaster's Degree in a related field and two years of data analysis work experience.\nPossess a strong working knowledge of SQL and SAS programming.\nExperience in predictive analytics and machine learning.\nExperience working in an institutional research setting, a basic working knowledge of financial aid, admissions, and student data sources in a higher education setting (e.g., institutional, Federal (Integrated Post-Secondary Educational Data System), and the State via the Texas Higher Education Coordinating Board.\nBasic working knowledge of economic and accounting principles and practices, legal statutes, and analysis and reporting of financial data.\nExperience in designing business intelligence and\/or qualitative\/quantitative research studies to assist organizations in developing data-informed strategies.\nEssential Duties And Responsibilities\nReporting to the Associate Director, this Business Intelligence Analyst will focus on the development of data visualizations for business intelligence solutions. The person in this role will work closely with the stakeholders to support the vision and delivery of optimized and accessible institutional data to deliver metrics capable of making data informed decisions across the University through reporting and analytics.\nDesigns and develops intuitive dashboards, reports, and interactive visualizations to present complex data in a clear and concise manner.\nUtilizes data visualization tools to create dynamic and interactive visualizations that allow end users to explore data and uncover patterns and trends.\nInterprets data and provides insights to stakeholders through visualizations, enabling them to make informed decisions and identify actionable items.\nConducts data analysis and validations to ensure the accuracy and integrity used for visualization.\nMaintains knowledge of best practices and emerging trends in data visualizations and provides recommendations for continuous improvement.\nAdditional Information\nRemote Work:\nThis role is eligible for a hybrid (partly remote\/partly in office) work schedule, subject to business need and manager approval. A UT Dallas Remote Work Agreement will be required within 14 days after approval. The Business Intelligence Analyst \u201a\u00c4\u00ec Data Visualizations must be located within the DFW Area and have the ability to be on campus within 24 hours of notice.\nWhat We Can Offer\nUT Dallas is an Equal Opportunity Employer. We offer an employee-friendly work environment with a comprehensive benefit package including:\nCompetitive Salary\nTuition Benefits\nInternal Training\nMedical insurance \u201a\u00c4\u00ec including\n100% paid\nemployee medical coverage for full-time employees\nDental Insurance\nVision Insurance\nLong and short-term disability\nRetirement Plan Options\nPaid time off\nPaid Holidays All UT Dallas employees have access to various\nprofessional development\nopportunities\n, including a membership to Academic Impressions, LinkedIn Learning, and UT Dallas Bright Leaders Program.\nVisit\nhttps:\/\/hr.utdallas.edu\/employees\/benefits\/\nfor more information.\nAbout Us\nUT Dallas is a top public research university located in one of the nation's fastest-growing metropolitan regions. Our seven schools offer more than 140 undergraduate and graduate programs, plus professional certificates and fast-track programs. Our student body is 31,000 strong, reflecting students from over 100 countries and a multiplicity of identities and experiences. UT Dallas is committed to graduating well-rounded members of the global community whose education has prepared them for rewarding lives and productive careers in a constantly changing world.\nThe University has a variety of programs and initiatives to support engagement and success for all members of the campus community. Employee benefits include a range of physical and mental wellness resources. \u201a\u00c4\u00faLilyPad\u201a\u00c4\u00f9 lactation facilities are located throughout the campus. There are several Employee Resource Groups (ERGs) comprised of individuals who share common interests to help build community among UT Dallas faculty and staff (e.g., Universal Access ERG, Military and Veteran ERG, UT Dallas Young Professionals).\nRich with visual and performing arts venues, museum districts, professional and semi-professional athletics teams, botanical gardens, accessible trails and so much more, the Dallas-Fort Worth (DFW) metroplex has something for everyone to explore. UT Dallas partners with regional higher education institutions and school districts and with the\nRichardson Innovation Quarter\n(Richardson IQ), a major hub for innovation, entrepreneurship, and educational activities.\nImportant Message\nAll employees serve as a representative of the University and are expected to display respect, civility, professional courtesy, consideration of others and discretion in all interactions with members of the UT Dallas community and the general public.\nThe University of Texas at Dallas is committed to providing an educational, living, and working environment that is welcoming, respectful, and inclusive of all members of the university community. UT Dallas does not discriminate on the basis of race, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, national origin, disability, genetic information, or veteran status in its services, programs, activities, employment, and education, including in admission and enrollment. EOE, including disability\/veterans. The Universityis committed to providing access, equal opportunity, and reasonable accommodationfor individuals with disabilities.To request reasonable accommodation in the employment application and interview process, contact theADA Coordinator.For inquiries regarding nondiscrimination policies, contact theTitle IX Coordinator.\nShow more\nShow less",
      "job_skills":"Data Management, Data Analysis, Data Visualization, Statistical Analysis, SAS Programming, SQL, Predictive Analytics, Machine Learning, Business Intelligence, Research Studies, Financial Analysis, Accounting, Economic Analysis",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Building Operating Engineer",
      "company":"JLL",
      "job_location":"Allen, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-building-operating-engineer-at-jll-3748261897",
      "search_city":"McKinney",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"General Description:\nThe Data Center Operations Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)\nPrincipal Duties and Responsibilities\nTask will include but not be limited to:\nResponsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire\/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.\nRequires the ability to analyze the operation of various systems, determine the cause of any problems\/malfunctions and take corrective action as required.\nComply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.\nLearn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.\nWork order management, including CMMS, Vendor Management, and Customer Facing Tickets.\nUnderstanding and complying with emergency escalation procedures.\nPerform additional job duties as required.\nMinimum Requirements:\nPreferred to have hands-on experience working in a data center\/critical facility, including UPS.\nSystems, emergency generators, and switchgears.\nHigh School diploma or GED equivalent\n2+ years related work experience.\nWorking knowledge of computer applications including Word and Excel.\nDemonstrated verbal\/written communication skills.\nPreferred Requirements:\nCorrigo Experience.\nMCIM \/ Salesforce Experience.\nZendesk Experience.\nService Now Experience.\nReceived EPA 608.\nTrained in NFPA70E.\nShow more\nShow less",
      "job_skills":"Data Center Operations, Electrical Systems, Mechanical Systems, HVAC, Chillers, CRAC, CRAH, Plumbing, Controls, UPS, ATS, STS, PDU, Generators, Primary Switchgear, Power Distribution, Transformers, Hot Water Systems, Refrigeration, Air Conditioning, Boilers, Ventilating, Water Heaters, Pumps, Valves, Piping, Filters, CMMS, Vendor Management, Customer Facing Tickets, Emergency Escalation Procedures, Word, Excel, Corrigo, MCIM, Salesforce, Zendesk, Service Now, EPA 608, NFPA70E",
      "Category":"Data Science"
  },
  {
      "job_title":"Data & Integration Analyst",
      "company":"Maxor National Pharmacy Services, LLC",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-integration-analyst-at-maxor-national-pharmacy-services-llc-3787392018",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Overview\nThe\nData & Integration Analyst\nis responsible for implementing, supporting, and maintaining inbound\/outbound data file exchanges. Enable and integrate clients and 3 rd party vendors onto Maxor\u201a\u00c4\u00f4s PBM platform. Assist in documenting and creating efficient\/automated solutions to promote operational capability while also improving client data integrity. Reporting to the Sr. Director of Eligibility and Accumulators the Data & Integration Analyst will meet all service standards to ensure client satisfaction.\nPosition Location\nThis is a remote-based position.\nOur Company\nWe're Maxor and we're building a different kind of pharmacy company. We're transforming the pharmacy industry to create healthier lives through purposeful engagement across Pharmacy Benefit Management, Pharmacy Management, Specialty Pharmacy, 340B, Rebate and Formulary Management, and Pharmacies. We put people first and are committed to providing outstanding service across all aspects of our business. We believe there's a better way to deliver pharmacy and healthcare services to people across the country, and we'd love for you to help us do it.\nOur Locations\nThe Maxor workforce brings robust experience, diverse perspectives and passion from over 1,000 employees working all over the US in pharmacies, hospitals, home offices, or corporate offices.\nResponsibilities\nSupport new and existing clients through implementation\/conversion\/integration processes working directly with clients, account managers and implementation teams though full data-life-cycle development.\nServe as a Subject Matter Expert (SME) on integration points with Maxor\u201a\u00c4\u00f4s PBM platform, application, file integration functions\/standards and back end data models.\nExecute advanced\/dynamic SQL scripts to generate flat files or reports to support backend file processing, reconciliation analysis, and internal\/external reporting.\nReview, analyze, and implement complex file mappings and data conversions to support standard and custom file integrations between Maxor and our clients.\nPlan, document, implement new or improved automated\/ETL solutions\nConduct system testing of new features, integrations and backend features\nWith a focus on quality and timeliness, maintain ownership for assigned goals\nEnsure quality, service level, productivity and customer standards are consistently met.\nHandle routine work stream assignments along with, but not limited to, member and file research, assisting with file processing\/data analysis, advise\/consult with our internal teams and clients\nComply with Maxor\u201a\u00c4\u00f4s Ethical Business Conduct policy and Maxor\u201a\u00c4\u00f4s Compliance Program.\nComplete required training, as assigned, within the established timeframes.\nMust be able to cope with the mental and emotional stress of the position.\nPromote teamwork and best practices\nMaintain regular attendance in accordance with established policies.\nPerform other job-related duties as assigned.\nQualifications\nEducation:\nBachelor\u201a\u00c4\u00f4s Degree in business, computer science, operations, engineering or related field required.\nExperience:\nExperience in data cleansing\/mapping\/formatting, ETL frameworks, and\/or database relational models. Previous experience with health care enrollment\/eligibility\/accumulator fundamentals and Pharmacy Benefits Managers (PBMs) data\/file\nExchange\/integration Experience Preferred.\nKnowledge, Skills, and Abilities:\n5+ years of experience in data exchange, integration, ETL frameworks, data visualization and\/or relational database models\/design.\n5+ years of experience as Data\/Integration\/EDI Analyst with relevant PBM\/Heath Benefit\/Health IT experience.\nStrong business acumen with healthcare and pharmacy benefit management industry knowledge preferred.\nA desire to problem solve, think critically, analyze and interpret data.\nWillingness to solution across business and technical domains.\nAbility to identify assumptions, be inquisitive and reach conclusions.\nAbility to communicate, document, share and acquire knowledge.\nAbility to adapt, continuously improve, enjoy building new tools and process.\nProven ability to develop effective working relationships with internal and external stakeholders.\nMotivated by goal oriented delivery, ability to understand overall business objectives and drive towards results.\nWHY CHOOSE A CAREER AT MAXOR?\nDid you know that patients see their pharmacist an average of 12 times a year? Pharmacy is at the heart of healthcare. Come join Maxor and make a direct impact on patients\u201a\u00c4\u00f4 lives. Improve your own wellbeing with our robust benefits and flexible work environment. At Maxor, you have a career with limitless possibilities and the charge to make a difference. A company of 1,000 diverse people and almost 100 years of pharmacy experience, we offer the stability of a Fortune 500 company with the energy and innovation of a startup. We provide services and technology that fuel the entire pharmacy ecosystem, but we are more than pharmacy services. We enable pharmacy care .\nWE OFFER\n: A diverse, progressive culture that supports a \u201a\u00c4\u00fadress for your day\u201a\u00c4\u00f9 attire and a collaborative, team oriented environment. Our industry leading compensation and health benefits include:\nComprehensive mental health and wellbeing resources\nNationwide Blue Cross Blue Shield PPO with employee friendly plan design, including $850 individual annual medical deductible, $25 office visit copays, Low biweekly premiums\nCompany paid basic life\/AD&D, Short-term and Long-term disability insurance\nRx, dental, vision, short-term disability, and FSA\nEmployer-matched 401k Plan\nIndustry leading PTO plan\nAnd MORE!\nApply today at :\nhttps:\/\/careers-maxor.icims.com\/\nMaxor is an EOE, including disability\/vets\nShow more\nShow less",
      "job_skills":"Data Exchange, Integration, ETL frameworks, Data Visualization, Relational Database Models, EDI Analyst, Business Acumen, Healthcare, Pharmacy Benefit Management, Problem Solving, Critical Thinking, Data Analysis, Communication, Documentation, Knowledge Sharing, Adaptation, Continuous Improvement, Stakeholder Relationship Building, Goal Oriented Delivery, SQL",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"World Wide Technology",
      "job_location":"Roanoke, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-world-wide-technology-3782269155",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Data Center Engineer\nCompany Overview\nWorld Wide Technology (WWT), a global technology solutions provider with $17 billion in annual revenue, combines the power of strategy, execution and partnership to accelerate transformational outcomes for large public and private organizations around the world. Through its Advanced Technology Center, a collaborative ecosystem of the world's most advanced hardware and software solutions, WWT helps customers and partners conceptualize, test and validate innovative technology solutions for the best business outcomes and then deploys them at scale through its 4 million square feet of global warehousing, distribution and integration space. With over 10,000 employees and more than 55 locations around the world, WWT's culture, built on a set of core values and established leadership philosophies, has been recognized 11 years in a row by Fortune and Great Place to Work\u00ac\u00c6 for its unique blend of determination, innovation and leadership for diversity and inclusion. With this culture at its foundation, WWT bridges the gap between business and technology to make a new world happen for its customers, partners and communities.\nWorld Wide Technology Holding Co, LLC. (WWT) has an opportunity available for a\nData Center Engineer\nto support our client in an ongoing Data Center refresh project.\nLocation:\nRoanoke, TX\nAvailable Shifts:\n(2 Openings) 7 PM \u201a\u00c4\u00ec 7 AM CST Thursday, Friday, Saturday, and Alternating Wednesdays.\nMUST BE OKAY WITH 12 HOUR NIGHT SHIFTS - Expectation is to have 80 hours of work in a 2 week period.\nDuration:\n12 Months (Expected to renew for up to 3 years, on an ongoing 12-month renewal)\nContract Designation:\nFull Time Contingent \u201a\u00c4\u00ec Contractors will be eligible for WWT\u201a\u00c4\u00f4s Full Time Employee Benefits Package including Medical, Vision, Dental, PTO, Paid Holidays, and more.\nResponsibilities:\nInstalling\/de-installing\/relocating all distributed systems and network hardware (CSUs, DSUs, routers, switches, encryptors, firewalls, etc.) in the Americas Data Centers within the internal service level mandates\nInstalling\/de-installing \/extending\/relocating\/testing all carrier circuits to the network hardware\nInstalling\/de-installing\/relocating all patch cabling for systems and network hardware\nInstalling\/de-installing\/relocating all Data Center hardware\nAssist with the coordination of cabinet power, circuit, and patch infrastructure installations w\/various facilities, electrical and communications vendors\nAssist with the coordination of network component configurations\nCoordinate and Install SAN cabling infrastructure\nManaging network ports and assist with the management of all consumable items (cables, labels, tie wraps, rail kits, etc.)\nMaintaining the integrity of the data center facilities, systems and communications environments through general housekeeping and best operations practices\nQualifications:\nRequired skills include 3+ years of experience in the implementation, maintenance and analysis of data center facilities, hardware, communications infrastructure, strategies, tools and effective troubleshooting techniques.\nBasic background on enterprise data center facilities and infrastructure environments such as PDUs, RPPs, network and SAN infrastructures. In depth knowledge on complex, Enterprise class inter-networked environments involving a combination of switched\/routed\/shared Ethernet, TwinAx (100GigE, 25GigE,10GigE, GigE, 100M, and 10M), token ring, SAN, and wide area connectivity.\nStrong knowledge of WAN technologies (OC-x, DS-x), subnetting and TCP\/IP protocol a must.\nExcellent communication and writing skills a must.\nKnowledge of trouble ticketing systems, change control, Project processes and associated tools.\nLogical problem- solving techniques and associated experience in system, data center facilities, and telecommunications.\nMust be Able to Lift up to 50lbs.\nEqual Opportunity Employer Minorities\/Women\/Veterans\/Disabled\nShow more\nShow less",
      "job_skills":"Data Center Engineering, Installation, Deinstallation, Relocation, Maintenance, Analysis, Troubleshooting, PDUs, RPPs, Ethernet, TwinAx, Token Ring, SAN, WAN, OCx, DSx, Subnetting, TCP\/IP, Change Control, Ticketing Systems, Project Processes, System Administration, Telecommunications",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Scientist",
      "company":"Boeing Distribution Services Inc.",
      "job_location":"Coppell, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-boeing-distribution-services-inc-3751416388",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We\u201a\u00c4\u00f4re committed to fostering an environment for every teammate that\u201a\u00c4\u00f4s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.\nTitle: Data Scientist 3\nCompany: BDSI\nJob ID: 98367\nLocation: Miami, FL or Dallas, TX (flexible locations)\nThis position allows telecommuting. The selected candidate will be required to perform some work onsite at one of the listed location options.\nExport Control\nThe position must meet Export Control compliance requirements, therefore a \u201a\u00c4\u00faUS Person\u201a\u00c4\u00f9 as defined by 22 C.F.R.\n120.15 is required. \u201a\u00c4\u00faUS Person\u201a\u00c4\u00f9 includes US Citizen, lawful permanent resident, refugee, or asylee.\nEmployer will not sponsor applicants for employment visa status.\nPosition Summary\nBoeing Distribution Services Inc. Supply Chain Planning Organization is currently looking for a Data Scientist to join the team. In this role, you will envision, develop and implement optimized supply chain solutions to enhance support and services under Boeing Global Services\u201a\u00c4\u00f4 (BGS) Distribution portfolio. You will use optimization techniques to evaluate Stocking Strategies, and Inventory optimization strategies including projects related t optimal part home to drive the right inventory at the right location.\nThis individual will lead cross-functional teams to determine, define and deploy complex predictive\/prescriptive analytic solutions to meet business objectives. Additional responsibilities include evaluating business objectives and determine stakeholder needs. You will choose best fit methods, define algorithms, validate and deploy models to achieve business results.\nEssential Job Duties And Responsibilities\nAnalyze data and development metrics\nDetermine, define, and deploy predictive\/prescriptive analytic solutions to meet business requirements in forecast accuracy, inventory health and stock transfer optimization, as well as other key processes\nDevelop supply chain metrics to track progress to plan over time and stress test the order pipeline for risks and opportunities\nAnalyze supply chain data to determine order, holding, and shortage costs for use with optimal Economic Order Quantity (EOQ) models with shortages\nSupport Sales, Inventory, and Operations Planning (SIOP) through improvements in data insights and dashboards\nCreate design requirements for evaluating low demand parts with zero demand in one or more months.\nConnect systems and large data sets across business units and functions to develop forecast models that support shifting business and market trends\nMine data using SQL skills from multiple source systems to support analysis required\nLeads and coaches developing analysts\nLeads special projects as required\nBasic Qualifications (Required Skills And Experience)\n4-6 years of related work experience\n2 or more years of experience performing Statistical Analysis\n2 or more years of experience using research tools and methods\n2 or more years of experience using SQL for data analytics\nAbility to read, analyze, and interpret the most complex data\nAbility to work define problems, collect data, develop metrics, and work with financial concepts to make effective wise decisions\nProficient with various inter-relational software programs (i.e. MS Excel, MS Word, MS Access, Tableau, SAP)\nDemonstrated ability to collaborate and work effectively cross-functionally\nAbility to communicate effectively and efficiently both written and verbally\nAbility to work in a fast-paced environment\nAbility to manage multiple and competing priorities\nPreferred Qualifications (Desired Skills\/Experience)\nEducation: Bachelor\u201a\u00c4\u00f4s Degree in Data Analytics, Industrial Engineering, Supply Chain, or related field of study\n6-8 years of related work experience preferred\nExperience working within the aviation industry, preferred\nAbility to manage multiple and competing priorities.\nDrug Free Workplace\nBoeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.\nExperience Level\nIndividual Contributor \u201a\u00c4\u00ec Level 3\nJob Type: Regular \u201a\u00c4\u00ec Full time\nJob Code:\nBEH7I3\nBoeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military\/veteran status or other characteristics protected by law .\nShow more\nShow less",
      "job_skills":"Data Analytics, SQL, Data Mining, Tableau, SAP, MS Excel, MS Word, MS Access, Predictive Analytics, Prescriptive Analytics, Crossfunctional Collaboration, Statistical Analysis, Economic Order Quantity (EOQ) Models, Supply Chain Metrics, Data Visualization",
      "Category":"Data Science"
  },
  {
      "job_title":"Labs - Data Scientist - Senior Associate",
      "company":"PwC",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/labs-data-scientist-senior-associate-at-pwc-3782252085",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Specialty\/Competency:\nData Science\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team designs, develops and programs the methods, processes, and systems that are used to collect all forms of data and develop models that serve predictions to applications, automated process flows, and stakeholders. A Data Scientist collects domain context from stakeholders, defines hypothesis and prediction tasks, identifies and creates supporting data sources, conducts experiments with various algorithms to model prediction tasks, undertakes validation and tests of models to improve performance, produces pipelines that can be used to automate training and predictions with unseen or production data, identifies meaningful insights from data sources, and contextualizes model outputs to communicate with stakeholders (product owners, process managers, and end consumers).\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nOur mandate is to quickly explore new technologies to determine what is relevant for our clients and Firm to invest in. Our work has a tremendous impact on how PwC and our clients do business. Our Data Scientists possess exceptional technical prowess matched by their ability to communicate results to other data scientists, clients, and internal stakeholders.\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nBachelor Degree\nAdditional Educational Requirements\nBachelor's degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and\/or progressively responsible work experience in technology for each missing year of college.\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nMaster Degree\nPreferred Fields Of Study\nComputer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management\/Research\nAdditional Educational Preferences\nPhD highly preferred\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success:\nExploring new analytical technologies and evaluate their technical and commercial viability;\nWorking across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications\/production ready tools;\nWorking across various data mediums: text, audio, imagery, sensory, and structured data;\nWorking in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients;\nTesting and rejecting hypotheses around data processing and ML model building;\nExperimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task;\nBuilding ML pipelines that ingest, clean data, and make predictions;\nFocusing on AI and ML techniques that are broadly applicable across all industries;\nStaying abreast of new AI research from leading labs by reading papers and experimenting with code;\nDeveloping innovative solutions and perspectives on AI that can be published in academic journals\/arXiv and shared with clients;\nApplying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.);\nUnderstanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique;\nUnderstanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow);\nUnderstanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application;\nBuilding ML models and systems, interpreting their output, and communicating the results; and,\nMoving models from development to production; conducting lab research and publishing work.\nDemonstrates thorough abilities and\/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:\nDemonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix;\nDemonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.);\nDemonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow;\nDemonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy;\nDemonstrating knowledge in NLU\/NLP domain: Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS;\nDemonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio); and,\nDemonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"Artificial Intelligence, Machine Learning, Natural Language Processing, Computer Vision, Deep Learning, Reinforcement Learning, Generative Adversarial Networks, Recommender Systems, Neural Networks, Robotics, Augmented Reality, Virtual Reality, Drones, Internet of Things, 3D Printing, Blockchain, Quantum Computing",
      "Category":"Data Science"
  },
  {
      "job_title":"Business Intelligence Data Analyst - ELP",
      "company":"Education at Work",
      "job_location":"El Paso, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/business-intelligence-data-analyst-elp-at-education-at-work-3779625206",
      "search_city":"Socorro",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Education at Work is an innovative, mission driven business process outsourcing (BPO) company putting college students at the forefront of our unique business model. As a rapidly growing company with a start-up mindset, we are committed to fostering a collaborative environment and entrepreneurial culture which values and progresses out of the box thinkers and savvy problem solvers.\nPosition Summary\nThe Data Analyst who is able to turn project requirements into custom-formatted data reports. The ideal candidate for this position is able to do complete life cycle data generation and outline critical information for the company. Ideally, the Data Analyst is able to analyze business procedures and recommend specific types of data that can be used to improve upon them. A data analyst's job is to take that data and use it to help the company make better business decisions.\nEssential Functions\nDevelopment and maintain various reports required to analyze call trends and historical patterns.\nSynthesize current business intelligence or trend data to support recommendations for action.\nManage timely flow of business intelligence information to users.\nGathering user requirements.\nProvide error free decision-making reports to management on a daily, weekly, monthly and annual basis.\nDesigning and automating reporting using Power BI.\nVarious performance related analysis as needed.\nOther duties as deemed by Management.\nMinimum Job Requirements\nProficient knowledge of Power BI \u201a\u00c4\u00ec including multiple data connections, visualizations, DAX, M.\nExpert knowledge of Excel- including graphs, pivot tables, formulas.\nExcellent communication skills.\nStrong organizational skills.\nDetail orientated.\nAbility to work effectively as an individual and in a team environment.\nAbility to meet company attendance and dependability guidelines.\nMust be able to sit for long periods of time and repeatedly use a computer or other operational hardware.\nEducation\nBachelor\u201a\u00c4\u00f4s degree, preferred. Equivalent level of work experience considered.\nWorking Conditions\nAbility to travel on occasion.\nAbility to function at a computer workstation for long periods of time.\nAbility to work independently.\nAbility to work with team members offsite.\n$50,000 - $60,000 a year\nExempt Position\nTHE AMERICANS WITH DISABILITIES ACT OF 1990 (ADA) PROHIBITS DISCRIMINATION IN COMPENSATION AND EMPLOYMENT OPPORTUNITIES AGAINST QUALIFIED INDIVIDUALS WITH DISABILITIES. TO DETERMINE WHETHER AN INDIVIDUAL IS QUALIFIED, THE ESSENTIAL FUNCTIONS OF EACH JOB MUST BE IDENTIFIED. ESSENTIAL FUNCTIONS ARE THOSE THAT ARE INTRINSIC TO THE POSITION, AND THAT THE INDIVIDUAL(S) WHO HOLDS THE JOBS MUST BE ABLE TO PERFORM WITH OR WITHOUT REASONABLE ACCOMMODATION.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Management, Data Reporting, Data Visualization, Power BI, Excel, DAX, M, Communication, Organization, Teamwork, Attendance, Dependability, Attention to Detail, Problem Solving",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Process Analyst with Security Clearance",
      "company":"ClearanceJobs",
      "job_location":"El Paso, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-process-analyst-with-security-clearance-at-clearancejobs-3753486308",
      "search_city":"Socorro",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Responsibilities PeopleTec is currently seeking a Data Process Analyst to support our El Paso, TX (Fort Bliss) location. Our team is looking for an exceptionally motivated self-starting professional with a background supporting front-end\/UI software development, intelligence analysis, and\/or big data projects . The candidate will support our growing team of cyber, space, and engineering professionals who design, implement, test, and deploy end-to-end 2D\/3D geospatial solutions. The Data Entry Analyst is responsible for ensuring the accurate entry of operational and intelligence data from operational reporting into collaboration environments like Command and Control of the Information Environment (C2IE). Th Data Entry Analyst supports an operational joint task force with a critical National defense mission in a fast-paced environment. This Data Entry Analyst is uniquely gifted to enjoy detailed data entry processes and solve different problems each day. This position involves collaborating with intelligence, operational, & data professionals across multiple echelons of Command. Qualifications Required Skills\/Experience :\nDevelop statistical material and reports\nBuild briefing products that provide situational awareness for the counter-narcotics mission\nTransfer data from various formats & locations (e.g., paper, storyboards, other databases) into a common collaboration environment like C2IE\nCreate spreadsheets and other products that are used to make data-driven decisions based on data trends & synthesis\nClean, process, and retrieve data from a variety of databases & sources to ingest into the collaboration environment\nPerform regular backups to ensure data preservation\nSort and organize paperwork after entering data to ensure it is not lost\nCollaborate with operational staff (e.g., intelligence, operations, IT, Command) to gain user requirements for data insights\nTravel: 0 %\nMust be a U.S. Citizen\nAn active DoD Secret clearance is required to perform this work. Candidates are required to have an active Secret clearance upon hire, and the ability to maintain this level of clearance during their employment. Education Requirements :\nHigh school degree or equivalent & proven experience as data entry professional Desired Skills :\nHave general knowledge and access to decision support systems (i.e., C2IE, Advana) and the experience working with data in the environment\nExposure to\/experience in USG organizations that have a counter-narcotics mission\nAS or BS in data, statistics, or another relevant subject Projected Timeframe to Employee :\nFeb 1, 2024 Overview People First. Technology Always. PeopleTec, Inc. is an employee-owned small business founded in Huntsville, AL that provides exceptional customer support by employing and retaining a highly skilled workforce. Culture: The name \"PeopleTec\" was deliberately chosen to remind us of our core value system - our people. Our company's foundation was built on placing our employees and customers first. With an award-winning atmosphere, we have matured into a company that boasts the best and brightest across multiple technical fields. Career: At PeopleTec, we value your long-term goals. Whether it's through our continuing-education opportunities, our robust training programs, or our \"People First\" benefits package, PeopleTec truly believes that our best investments are our people. Come Experience It. #cjpost #dpost EEO Statement PeopleTec, Inc. is an Equal Employment Opportunity employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in its job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may use the following email address, and\/or phone number (256.319.3800) to contact us about your interest in employment with PeopleTec, Inc. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, genetic information, citizenship, ancestry, marital status, protected veteran status, disability status or any other status protected by federal, state, or local law. PeopleTec, Inc. participates in E-Verify.\nShow more\nShow less",
      "job_skills":"Data Analysis, Statistics, Data Visualization, Data Entry, Spreadsheet Creation, Data Retrieval, Data Warehousing, Data Cleansing, Decision Support Systems, Command and Control of the Information Environment (C2IE), Advana, Microsoft Office Suite, Data Analytics, Data Mining, ETL Tools, Data Warehousing Tools, Data Visualization Tools",
      "Category":"Data Science"
  },
  {
      "job_title":"Computer Engineer, AST - Data Systems (Direct Hire)",
      "company":"NASA - National Aeronautics and Space Administration",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/computer-engineer-ast-data-systems-direct-hire-at-nasa-national-aeronautics-and-space-administration-3788122957",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Duties\nSummary\nThis position serves as a Senior Computer Systems Engineer with responsibility for the development, operations, and sustainment of Mission Control Center Systems (MCCS) at NASA's Johnson Space Center. The Mission Control Center supports the International Space Station (ISS), Artemis, and other human spaceflight programs.\nRequirements\nQualifications\nIn addition to the Basic Education Requirement (in the Education section below), to qualify for this position you must meet the requirements below. Specialized experience is experience that has equipped you with the particular ability, skill, and knowledge to successfully perform the duties of this position and is typically in or related to this line of work. NASA utilizes OPM-approved qualification and rating requirements specific for Aerospace Technology (AST) positions which recognizes NASA's unique aerospace work. The specific qualifications and minimum education requirements are further described below and within the education section of the job announcement. To qualify for GS-13, you must have one year of directly related specialized experience equivalent to the GS-12 level: Working with design, development, and operations teams in the cost, technical, and schedule performance of spacecraft control center systems. Assisting in designing and developing tools and capabilities for mission critical spacecraft control centers. Evaluating and making recommendations to the improvement in performance and availability of mission critical information technology systems.\nYour resume must include a clear and detailed narrative description, in your own words, of how you meet the required specialized experience. Experience statements copied from a position description, vacancy announcement or other reference material constitutes plagiarism and may result in disqualification and losing consideration for the job.\nExplore the Extraordinary Calling all the innovators, pioneers, visionaries, and adventurers! We are a diverse group of professionals united by a common purpose: to discover and expand knowledge for the benefit of humanity. We're building on our rich legacy by embarking on new and exciting missions, both on Earth and beyond and we're looking for fresh ideas to help us get there. Do you have a passion for exploration? Do you want your work to leave an enduring impact? Join us in a career that can take you farther than you can imagine. At NASA, our work is more than just a profession-it's a lifelong pursuit, a passion, and a chance to change the world. NASA is more than astronauts. We are scientists, engineers, IT specialists, human resources specialists, accountants, writers, technicians and many other kinds of people working together to break barriers to achieve the seemingly impossible. Explore the extraordinary, every day; explore a career at NASA!\nShow more\nShow less",
      "job_skills":"Spacecraft control center systems, Mission critical information technology systems, Spacecraft control centers, GS13, GS12, Mission Control Center Systems (MCCS), International Space Station (ISS), Artemis, Human spaceflight programs, NASA",
      "Category":"Data Science"
  },
  {
      "job_title":"Computer Engineer, AST - Data Systems (Direct Hire)",
      "company":"NASA - National Aeronautics and Space Administration",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/computer-engineer-ast-data-systems-direct-hire-at-nasa-national-aeronautics-and-space-administration-3788124737",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Duties\nSummary\nThis position serves as a Senior Computer Systems Engineer with responsibility for the development, operations, and sustainment of Mission Control Center Systems (MCCS) at NASA's Johnson Space Center. The Mission Control Center supports the International Space Station (ISS), Artemis, and other human spaceflight programs.\nRequirements\nQualifications\nIn addition to the Basic Education Requirement (in the Education section below), to qualify for this position you must meet the requirements below. Specialized experience is experience that has equipped you with the particular ability, skill, and knowledge to successfully perform the duties of this position and is typically in or related to this line of work. NASA utilizes OPM-approved qualification and rating requirements specific for Aerospace Technology (AST) positions which recognizes NASA's unique aerospace work. The specific qualifications and minimum education requirements are further described below and within the education section of the job announcement. To qualify for GS-13, you must have one year of directly related specialized experience equivalent to the GS-12 level: Working with design, development, and operations teams in the cost, technical, and schedule performance of spacecraft control center systems. Assisting in designing and developing tools and capabilities for mission critical spacecraft control centers. Evaluating and making recommendations to the improvement in performance and availability of mission critical information technology systems.\nYour resume must include a clear and detailed narrative description, in your own words, of how you meet the required specialized experience. Experience statements copied from a position description, vacancy announcement or other reference material constitutes plagiarism and may result in disqualification and losing consideration for the job.\nExplore the Extraordinary Calling all the innovators, pioneers, visionaries, and adventurers! We are a diverse group of professionals united by a common purpose: to discover and expand knowledge for the benefit of humanity. We're building on our rich legacy by embarking on new and exciting missions, both on Earth and beyond and we're looking for fresh ideas to help us get there. Do you have a passion for exploration? Do you want your work to leave an enduring impact? Join us in a career that can take you farther than you can imagine. At NASA, our work is more than just a profession-it's a lifelong pursuit, a passion, and a chance to change the world. NASA is more than astronauts. We are scientists, engineers, IT specialists, human resources specialists, accountants, writers, technicians and many other kinds of people working together to break barriers to achieve the seemingly impossible. Explore the extraordinary, every day; explore a career at NASA!\nShow more\nShow less",
      "job_skills":"IT, Aerospace Technology, Computer Systems Engineering, Mission Control Center Systems, Software Systems, Technical Writing, ProblemSolving Skills, Teamwork, Communication Skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Governance Analyst - Houston, TX",
      "company":"Talent Groups",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-governance-analyst-houston-tx-at-talent-groups-3790379044",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Note: This role is HYBRID (4\/1) in Houston, TX.\nTop Skills: MS Dynamics, Data Accuracy, Attention to Detail, large data experience. Power BI(user level), Excel.\nThe candidate will support the Sales Operations Data Governance initiatives maintaining accuracy and conformity of our system data. Data initiatives include, but not limited to account and location information within Microsoft Dynamics. All data is required to follow predefined standardization. Activities include working from dashboards or directly within systems addressing inaccuracies that need remediation.\nResponsibilities\n\u201a\u00c4\u00a2 Ability to self-diagnose challenges with clear decision making.\n\u201a\u00c4\u00a2 Cleanse and enrich data within Microsoft Dynamics\n\u201a\u00c4\u00a2 Utilize external data sources during review process.\n\u201a\u00c4\u00a2 Communicate with Sales as needed.\n\u201a\u00c4\u00a2 Provide additional administrative support as required.\nExpectations\n\u201a\u00c4\u00a2 Computer skills using Microsoft Office and ability to learn a variety of sales focused tools.\n\u201a\u00c4\u00a2 Excellent organizational\/administrative skills.\n\u201a\u00c4\u00a2 Can-do attitude \/ self-starter.\n\u201a\u00c4\u00a2 Ability to learn new tools and skills quickly.\n\u201a\u00c4\u00a2 Ability to multi-task in a fast-paced environment.\n\u201a\u00c4\u00a2 Customer service with a strong problem-solving approach.\n\u201a\u00c4\u00a2 A constant example of modeling Crown\u201a\u00c4\u00f4s purple values.\nEducation\/Certifications\n\u201a\u00c4\u00a2 College Degree preferred.\nExperience\/Minimum Requirements\n\u201a\u00c4\u00a2 3-5 years of relevant data governance and\/or data analytic experience.\n\u201a\u00c4\u00a2 Experience working with large data sets.\n\u201a\u00c4\u00a2 Working in office environment with strong attention to detail.\n\u201a\u00c4\u00a2 MS Dynamics\nWork Plans: This role falls into our hybrid work model working in your assigned office 4 days per week. There is an expectation of collaboration with teammates and stakeholders for moments that matter.\nShow more\nShow less",
      "job_skills":"Microsoft Dynamics, Data Accuracy, Attention to Detail, Large Data Experience, Power BI, Excel, Data Governance, Data Cleansing, Data Enrichment, External Data Sources, Sales Communication, Administrative Support, Microsoft Office, Various Sales Tools, Organizational Skills, Problem Solving, Crown's Purple Values, College Degree, Data Governance Experience, Data Analytic Experience, Large Data Sets, Office Environment",
      "Category":"Data Science"
  },
  {
      "job_title":"MAOP Data Analyst",
      "company":"Acadian Ambulance",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/maop-data-analyst-at-acadian-ambulance-3778734216",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nThe contract MAOP Data Analyst will work with a team of four to five other analysts under the supervision of a team lead. Duties and tasks would include:\nCompilation\nSorting and indexing of MAOP records for historic pipeline projects\nReviewing and conducting comparative analysis of MAOP records\nCorrelating technical documents against baseline GIS data to identify any gap between the two Following documented workflow and procedures.\nRequired Skills And Experience\nMust be familiar with pipe construction and MAOP validation work\nMAOP\/MOP records verification for pipelines, components, and facilities\nExperience with PHMSA Audits for pipelines\nAnalysis of MAOP\/MOP for high pressure pipeline segments\nProcurement process for pipeline materials and components\nAbility to read and interpret pipeline as built drawings\nWorking knowledge of pipeline data tools such PODS, GIS, etc.\nWorking knowledge of pipeline materials and yield strength calculation\nWorking knowledge of PHMSA 49 CFR Part 192\/195 regulations and fundamental knowledge of construction and operation of high-pressure pipelines\nStrong verbal and written communication and customer service skills to interact with other groups\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\nLiberty Energy Services, a division of Safety Management Systems, has extensive professional experience and expertise within the oil and gas industry. Our clients have come to realize that they receive phenomenal services from an elite group of highly skilled consultants that deliver every time.\nShow more\nShow less",
      "job_skills":"MAOP records compilation, MAOP records sorting and indexing, MAOP records review and comparative analysis, Correlating technical documents and GIS data, Document workflow and procedures, Pipe construction and MAOP validation, MAOP\/MOP records verification, PHMSA Audits for pipelines, MAOP\/MOP analysis for high pressure pipelines, Pipeline materials and components procurement, Pipeline as built drawings interpretation, Pipeline data tools such as PODS GIS, Pipeline materials and yield strength calculation, PHMSA 49 CFR Part 192\/195 regulations, Highpressure pipelines construction and operation, Verbal and written communication",
      "Category":"Data Science"
  },
  {
      "job_title":"Labs - Data Scientist - Senior Associate",
      "company":"PwC",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/labs-data-scientist-senior-associate-at-pwc-3782252106",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Specialty\/Competency:\nData Science\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team designs, develops and programs the methods, processes, and systems that are used to collect all forms of data and develop models that serve predictions to applications, automated process flows, and stakeholders. A Data Scientist collects domain context from stakeholders, defines hypothesis and prediction tasks, identifies and creates supporting data sources, conducts experiments with various algorithms to model prediction tasks, undertakes validation and tests of models to improve performance, produces pipelines that can be used to automate training and predictions with unseen or production data, identifies meaningful insights from data sources, and contextualizes model outputs to communicate with stakeholders (product owners, process managers, and end consumers).\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nOur mandate is to quickly explore new technologies to determine what is relevant for our clients and Firm to invest in. Our work has a tremendous impact on how PwC and our clients do business. Our Data Scientists possess exceptional technical prowess matched by their ability to communicate results to other data scientists, clients, and internal stakeholders.\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nBachelor Degree\nAdditional Educational Requirements\nBachelor's degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and\/or progressively responsible work experience in technology for each missing year of college.\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nMaster Degree\nPreferred Fields Of Study\nComputer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management\/Research\nAdditional Educational Preferences\nPhD highly preferred\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success:\nExploring new analytical technologies and evaluate their technical and commercial viability;\nWorking across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications\/production ready tools;\nWorking across various data mediums: text, audio, imagery, sensory, and structured data;\nWorking in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients;\nTesting and rejecting hypotheses around data processing and ML model building;\nExperimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task;\nBuilding ML pipelines that ingest, clean data, and make predictions;\nFocusing on AI and ML techniques that are broadly applicable across all industries;\nStaying abreast of new AI research from leading labs by reading papers and experimenting with code;\nDeveloping innovative solutions and perspectives on AI that can be published in academic journals\/arXiv and shared with clients;\nApplying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.);\nUnderstanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique;\nUnderstanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow);\nUnderstanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application;\nBuilding ML models and systems, interpreting their output, and communicating the results; and,\nMoving models from development to production; conducting lab research and publishing work.\nDemonstrates thorough abilities and\/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:\nDemonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix;\nDemonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.);\nDemonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow;\nDemonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy;\nDemonstrating knowledge in NLU\/NLP domain: Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS;\nDemonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio); and,\nDemonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"AI, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Augmented Reality, Virtual Reality, Robotics, Blockchain, Drones, Internet of Things, 3D Printing, Data Science",
      "Category":"Data Science"
  },
  {
      "job_title":"Global Market Leading Energy Firm - Staff Data Engineer",
      "company":"Xcede",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/global-market-leading-energy-firm-staff-data-engineer-at-xcede-3606685239",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Global Market Leading Energy Firm - Staff Data Engineer\nMy client is a Global Market Leading Energy Firm leading the global energy transition. They offer the opportunity to work with cutting-edge technologies with excellent professional growth. They have a great reputation across industry & offer an excellent work environment.\nThe role is paying $180,000 - $210,000 base plus a bonus & stock.\nNOTE: The role is flexible with 3 days in the Chicago office and 2 days working from home - this is non-negotiable.\n\u00ac\u2211\nMUST\nhave a Masters's degree or a relevant bachelor's degree - with a\nhigh GPA from college or university.\n\u00ac\u2211\nHands-on experience\ndesigning, planning, productionizing & maintaining reliable and scalable data infrastructure and data products in complex environments.\n\u00ac\u2211\nExperience\ndesigning and implementing large-scale distributed systems.\n\u00ac\u2211\nExperience\nwith different query languages\n\u00ac\u2211\nDemonstrable\ncoding expertise in one or more object-oriented programming languages.\nShow more\nShow less",
      "job_skills":"Data Engineering, Data Infrastructure, Data Products, Distributed Systems, Query Languages, ObjectOriented Programming",
      "Category":"Data Science"
  },
  {
      "job_title":"Well Data Specialist",
      "company":"Apex Systems",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/well-data-specialist-at-apex-systems-3784023463",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job ID #2007815\nLocation\n: Houston, TX (50% onsite\/50% remote)\nLength\n: 1 year contract (possible extension)\nKey Responsibilities:\nRequirement gathering in collaboration with Data Leads and Corporate Data Management team to define project scope and deliverables\nRefine list of wells for final scope of work and prioritize AOIs to be remediated in priority order aligning with BU critical needs.\nInventory and analysis of pre-existing datasets in SORs and databases to identify legacy datasets to be validated\nLiaise with BU technical staff on both Engineering and Geoscience side to identify legacy datasets that need to be considered for validation\nMentor technical staff on Perforation Data Management and best practices\nChair status meetings and provide weekly updates on project progress\nAssist in the roll out of validated perforation data into SOR \u201a\u00c4\u00ec EDM\nCollaborate with Subsurface Data Management team and IT to ensure backups of projects and repositories are available prior to validated data roll out.\nCollaborate with OpenWorks and Petrel Studio administrators to cleanup pre-existing perforation datasets for OpenWorks and Studio and roll out validated datasets\nAct as primary point of contact for Petrel Studio and OpenWorks technical data\nDrive compliance with approved perforation data standards, data loading policies, processes, and guidelines\nQualifications:\nEducation\nBachelor of Science degree in Geoscience, Engineering or related field or equivalent experience\n10+ years of experience managing oil and gas geoscience, drilling or engineering technical data required\n5 years of experience loading and managing technical data in Landmark R5000 OpenWorks\n3 years of experience loading and managing technical data in Petrel \/ Petrel Studio\nData Management\nStrong knowledge of well data generated during planning, drilling, logging and completion operations\nStrong knowledge of EDM\/OpenWells\/LOWIS Data Models is highly desirable\nGood Understanding of Well Drilling and Completions Operating\nStrong understanding and knowledge of geodetics and units of measure used in loading technical data\nStrong understanding of project and master data management concepts for technical data\nExperience working with diverse business groups and functions\nExperience working with technical data in a complex multi-platform federated environment\nBehavioral\nAbility to lead project work, influence stakeholder buy-in and drive change in support of Subsurface Data Management tactical and strategic work programs\nExcellent analytical and problem-solving skills\nExcellent written and verbal communication skills\nStrong leadership and organizational skills\nSelf-driven individual that can multi-task and deliver on commitments\nOpen-minded with ability to identify new methodologies and technologies for managing technical data\nExcellent team player that can work independently under minimal supervision when required\nAbility to establish and maintain win-win relationships\nShow more\nShow less",
      "job_skills":"Geoscience, Engineering, Data Management, Data Loading, Landmark R5000 OpenWorks, Petrel, Petrel Studio, EDM, OpenWells, LOWIS, Well Data, Geodetics, Units of Measure, Project Management, Master Data Management, MultiPlatform Federated Environment, Analytical Skills, ProblemSolving Skills, Communication Skills, Leadership Skills, Organizational Skills, Team Player",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Systems Engineer",
      "company":"CyberCoders",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-systems-engineer-at-cybercoders-3779627997",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Title\n: Data Systems Engineer\nJob Location\n: Baton Rouge, LA OR Houston, TX (mainly remote; however, candidates MUST be local to Baton Rouge or Houston)\nSalary\n: $70-100K DOE (benefits, time off, etc.)\nRequirements\nBachelor's degree in Computer Science, Engineering, or related field (or equivalent work experience).\n3+ years of recent professional experience developing SQL queries and ETL processes.\nExperience with Microsoft T-SQL, .NET, Visual Studio, and\/or Oracle is preferred, but not required.\nFor over 60 years, we have provided solutions for industrial valve\/instrumentation applications in the oil\/gas industry. Due to recent growth, we are seeking a talented Data Systems Engineer to join our team. This position requires a Bachelor's degree in Computer Science, Engineering, or related field (or equivalent work experience) and 3+ years of recent professional experience developing SQL queries and ETL processes. Experience with Microsoft T-SQL, .NET, Visual Studio, and\/or Oracle is preferred, but not required.\nWhat You Will Be Doing\nDeveloping solutions to support business analytics\/data processing needs.\nDesigning, developing, and maintaining data lake\/warehouse.\nImplementing reports\/data extracts and data sources for visualization tools (ex. Tableau).\nWhat You Need for this Position\nBachelor's degree in Computer Science, Engineering, or related field (or equivalent work experience).\n3+ years of recent professional experience developing SQL queries and ETL processes.\nPreferred Qualifications\nAzure\nT-SQL\n.NET, SSRS, SSIS, Excel\nVisual Studio, SQL Managment Studio\nOracle PL\/SQL\nWhat's In It for You\nCompetitive Base Salary ($70-100K DOE)\nMedical, Dental, Vision Insurance\nTime Off\nSo, if you are a Data Systems Engineer with SQL and ETL experience, please apply today!\nEmail Your Resume In Word To\nLooking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:\nBrittany.Owen@CyberCoders.com\nPlease do NOT change the email subject line in any way. You must keep the JobID: linkedin : BO4-1777444L440 -- in the email subject line for your application to be considered.***\nBrittany Owen - Executive Recruiter - CyberCoders\nApplicants must be authorized to work in the U.S.\nCyberCoders is proud to be an Equal Opportunity Employer\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\nYour Right to Work\n\u201a\u00c4\u00ec In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\nShow more\nShow less",
      "job_skills":"SQL, ETL, Data Lake, Data Warehouse, Tableau, Azure, .NET, SSRS, SSIS, Excel, Visual Studio, SQL Management Studio, PL\/SQL, TSQL",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst\/Scientist",
      "company":"VeeAR Projects Inc.",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-scientist-at-veear-projects-inc-3782205706",
      "search_city":"Skagway",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Job Description\nData analyst\/scientist with experience in web analytics using clickstream data analysis.\nTableau and SQL, but they need to also have worked with clickstream data in the web analytics space for 2+ years\nShow more\nShow less",
      "job_skills":"Data Analysis, Web Analytics, Clickstream Data Analysis, Tableau, SQL",
      "Category":"Data Science"
  },
  {
      "job_title":"Statistician\/Data Scientist Fellowship - Established Scientist",
      "company":"Oak Ridge Institute for Science and Education",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/statistician-data-scientist-fellowship-established-scientist-at-oak-ridge-institute-for-science-and-education-3751154237",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Organization\nU.S. Department of Defense (DOD)\nReference Code\nUSAISR-2023-0017-ES\nHow To Apply\nClick on Apply at the bottom of the opportunity to start your application.\nDescription\nThe U.S. Army Institute of Surgical Research (USAISR) is offering an Established Scientist opportunity at JBSA Fort Sam Houston, Texas.\nWhat will I be doing?\nAs an Oak Ridge Institute for Science and Education (ORISE) participant, you will join a community of scientists and researchers in an effort to apply principles of study design, data analysis, and clinical inference specific to conducting combat casualty care research.\nWhy should I apply?\nUnder the guidance of a mentor, you will gain hands-on experience to complement your education and support your academic and professional goals. Along the way, you will engage in activities and research in several areas. These include, but are not limited to,\nApplying statistical methods to biological processes in health research environment\nDeveloping relevant and testable trauma-related research questions and hypotheses\nDesigning both animal and human research studies\nAnalyzing data using a variety of statistical software programs (including but not limited to JMP, SigmaPlot, and GraphPad),\nApplying advanced statistical theories, techniques, and methods to human and animal research data\nInterpreting clinical research findings\nPreparing a variety of products including study protocols, abstracts, and peer-reviewed publications\nWhere will I be located?\nSan Antonio, Texas\nWhat is the anticipated start date?\nExact start dates will be determined at the time of selection and in coordination with the selected candidate. Applications are reviewed on an ongoing basis and fellowships will be filled as qualified candidates are identified.\nWhat is the appointment length?\nThis appointment is a twelve-month research appointment, with the possibility to be renewed for additional research periods. Appointments may be extended depending on funding availability, project assignment, program rules, and availability of the participant.\nWhat are the benefits?\nParticipants will receive a stipend to be determined by\nUSAISR.\nStipends are typically based on the participant\u201a\u00c4\u00f4s academic standing, discipline, experience, and research facility location. Other benefits may include the following:\nParticipants are eligible to purchase health insurance through ORISE.\nRelocation Allowance\nTraining and Travel Allowance\nAbout USAISR\nThe U.S. Army Institute of Surgical Research (USAISR) is one of six research laboratories within the U.S. Army Medical Research and Development Command of the U.S. Army Futures Command. The Institute is the Army's lead research laboratory for improving the care of combat casualties. The mission of the Institute is to \"Optimize Combat Casualty.\" For more information about USAISR: https:\/\/www.usaisr.amedd.army.mil .\nAbout ORISE\nThis program, administered by Oak Ridge Associated Universities (ORAU) through its contract with the U.S. Department of Energy (DOE) to manage the Oak Ridge Institute for Science and Education (ORISE), was established through an interagency agreement between DOE and DoD. Participants do not enter into an employee\/employer relationship with ORISE, ORAU, DoD or any other office or agency. Instead, you will be affiliated with ORISE for the administration of the appointment through the ORISE appointment letter and Terms of Appointment. Proof of health insurance is required for participation in this program. Health insurance can be obtained through ORISE. For more information, visit the ORISE Research Participation Program at the U.S. Department of Defense .\nQualifications\nThe qualified applicant should be an established scientist with a graduate degree in statistics, applied mathematics, or data science and 5+ years of work experience in a biomedical related field.\nHighly competitive applicants will have education and\/or experience in one or more of the following:\nTeaching advanced statistics or data science classes\nCalculating sample size\/power and preparing publication quality tables and figures\nKnowledge of the theory and techniques of applied statistical methods such as linear mixed models, generalized estimating equations, analysis of non-parametric data, and failure analysis.\nStrong data management skills as well as knowledge of SAS programming language\nApplication Requirements\nA complete application consists of:\nZintellect Profile\nEducational and Employment History\nEssay Questions (goals, experiences, and skills relevant to the opportunity)\nResume (PDF)\nTranscripts\/Academic Records - Please upload a copy of a transcript for your current or most recent degree program that meets the disciplinary qualifications of the opportunity. Click here for detailed information about acceptable transcripts .\nOne recommendation. Your application will be considered incomplete and will not be reviewed until one recommendation(s) is submitted. We encourage you to contact your recommender(s) as soon as you start your application to ensure they are able to complete the recommendation form and to let them know to expect a message from Zintellect. Recommenders will be asked to rate your scientific capabilities, personal characteristics, and describe how they know you. You can always log back in to your Zintellect account and check the status of your application.\nIf you have questions, send an email to ARMY-MRMC@orise.orau.gov. Please list the reference code of this opportunity [USAISR-2023-0017-ES] in the subject line of the email. Please understand that ORISE does not review applications or select applicants; selections are made by the sponsoring agency identified on this opportunity. All application materials should be submitted via the \u201a\u00c4\u00faApply\u201a\u00c4\u00f9 button at the bottom of this opportunity listing. Please do not send application materials to the email address above.\nConnect with ORISE...on the GO!\nDownload the new ORISE GO mobile app in the Apple App Store or Google Play Store to help you stay engaged, connected, and informed during your ORISE experience and beyond!\nEligibility Requirements\nCitizenship: U.S. Citizen Only\nDegree: Master's Degree or Doctoral Degree.\nDiscipline(s):\nChemistry and Materials Sciences ( 12 )\nCommunications and Graphics Design ( 2 )\nComputer, Information, and Data Sciences ( 16 )\nEarth and Geosciences ( 21 )\nEngineering ( 27 )\nEnvironmental and Marine Sciences ( 14 )\nLife Health and Medical Sciences ( 45 )\nMathematics and Statistics ( 10 )\nOther Non-Science & Engineering ( 2 )\nPhysics ( 16 )\nScience & Engineering-related ( 1 )\nSocial and Behavioral Sciences ( 27 )\nShow more\nShow less",
      "job_skills":"Statistics, Data Analysis, Clinical Research, Statistical Software (JMP SigmaPlot GraphPad), Statistical Methods, Data Management, SAS Programming, Teaching, Sample Size Calculation, NonParametric Data Analysis, Linear Mixed Models, Generalized Estimating Equations, Failure Analysis",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Analyst",
      "company":"Texas Tech University",
      "job_location":"Lubbock, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-analyst-at-texas-tech-university-3733827590",
      "search_city":"Lubbock",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Lubbock\nLead Data Analyst\n35349BR\nData Management Division\nPosition Description\nResponsibilities\nPerforms specialized analytical duties in the operation and maintenance of assigned area. Responsibilities include collecting, analyzing and developing data relative to area, making recommendations and assisting in implementation of projects. Work is performed under general supervision with latitude for independent judgment in accordance with established policies and procedures. While some management oversight may be expected for specific projects, this position is expected to exercise discretion and independent judgment in the performance of the following duties:\nPerforms data analysis and develops database actions defined in project plans to meet customer requirement and\/or marketing objectives.\nAbout The Department And\/or College\nThrough collaboration and coordination with campus partners, the Data Management Division will support all areas of Texas Tech University with the development, execution, and supervision of plans, policies, programs, and practices that deliver, control, protect, and enhance the value of data and information assets throughout their lifecycles.\nMajor\/Essential Functions\nOversight for Data Governance Projects (Data Quality and Audits).\nEvaluate\/understand high level data flow and data exchange between systems.\nEvaluate technical standards for critical systems.\nCoordinate with technical staff on metadata, data dictionaries, data protection, and data quality management.\nUnderstands data across systems and alignment with business processes.\nSupports change controls related to critical data.\nManages initial triage work for data related issues and projects before it is escalated to the Data Stewardship Council.\nIdentify and track critical dependencies between business requirements and data.\nRequired Qualifications\nBachelor's degree plus four years progressively responsible related experience; OR a combination of education and\/or experience to equal eight years\nPreferred Qualifications\nExperience developing data quality measures that align with business processes. Understanding of Master Data, Metadata, Reference Data, Data Warehousing, and BI principles and processes including technical architecture. Familiarly with enterprise information tools like SQL Server, Power BI, Oracle, etc. Excellent soft skills, including the ability to communicate well with various levels. Experience with Data Management Principles or Data Governance and Technical Writing.\nSafety Information\nAdherence to robust safety practices and compliance with all applicable health and safety regulations are responsibilities of all TTU employees.\nOccasional Duties\nOccasional work outside of normal hours required to meet project deadlines and travel to attend conferences or training.\nDoes this position work in a research laboratory?\nNo\nRequired Attachments\nCover Letter, Professional\/Personal References, Resume \/ CV\nOptional Attachments\nTranscript\nJob Type\nFull Time\nPay Basis\nHourly\nMinimum Hire Rate\n20.76\nPay Statement\nCompensation is commensurate upon the qualifications of the individual selected and budgetary guidelines of the hiring department, as well as the institutional pay plan. For additional information, please reference the institutional pay plan by visiting www.depts.ttu.edu\/hr\/payplan.\nTravel Required\nUp to 25%\nShift\nDay\nSchedule Details\nM-F, 8AM-5PM\nGrant Funded?\nNo\nJob Group\nInformation and Records Clerks\nEEO Statement\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, age, disability, genetic information or status as a protected veteran.\nShow more\nShow less",
      "job_skills":"Data Analysis, Database Development, Data Quality Management, Data Warehousing, BI, SQL Server, Power BI, Oracle, Master Data, Metadata, Reference Data, Technical Writing, Data Management Principles, Data Governance",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"Cloudflare",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-cloudflare-3732383582",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"About Us\nAt Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world\u201a\u00c4\u00f4s largest networks that powers approximately 25 million Internet properties, for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine\u201a\u00c4\u00f4s Top Company Cultures list and ranked among the World\u201a\u00c4\u00f4s Most Innovative Companies by Fast Company.\nWe realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!\nData Center Operations Engineer\nAbout the department\nIn this role, you will be focused on maintaining the Clou dflare global network. You 'll work closely with Cloudflare\u201a\u00c4\u00f4s SRE (Site Reliability Engineering) team, Network Engineering team, Network Deployment Engineering team and with various vendors and partners (including hardware vendors, datacenter and network providers, and ISPs) to maintain and improve our global infrastructure. You will further be responsible for the development and implementation of consistent processes and visibility measurements for consistent and effective management of our infrastructure. This is a highly visible position that requires deep technical understanding of datacenter infrastructure, networking (physical), and basic experience with data analysis and project management.\nTo be successful in this position, you should have excellent technical skills, communication skills, and be able to navigate a range of challenges and constraints (e.g. schedule adherence, time zones, and cultures). You will have the opportunity to (literally) build a faster, safer Internet for our millions of users and the billions of web surfers that visit their sites each month.\nWho You Are\nYou will thrive in a hypergrowth engineering environment and be self driven with a keen attention to detail. You will come with a deep technical understanding of Data Center colocation environments, network architecture and server technologies. You will be used to working through partners to support infrastructure delivery to a number of remote locations. You will have had experience managing operational environments, and used to developing new approaches to improve delivery efficiency or operational stability.\nWhat You'll Do\nCollaborating with internal teams (Infrastructure, Network Engineering and SRE). Create documentation and manage remote contractors to complete datacenter tasks, working with hardware manufacturers, datacenter and network providers, logistics partners and other service providers in support of our 300+ datacenter locations\nMaintain Data Center environment operational availability\nCreating and maintaining documentation, plans, SOP\u201a\u00c4\u00f4s, MOP\u201a\u00c4\u00f4s etc.\nSupport and configure network infrastructure where required\nProviding feedback to internal teams to support internal tools and external vendor partnerships\nRequired Experience\nMinimum of 5 yrs of Linux systems administration\nExperience with Juniper, Cisco and DWDM network equipment\nExperience managing and instructing remote contractors\nFamiliarity with work required to stand up infrastructure in remote colocation facilities\nExperience running and improving operational processes, including automation tooling, in a rapidly changing environment\nFamiliarity with day-to-day tasks and projects common to Data Center Operations (deployment, migration, decommissioning etc.)\nComfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA\nIncident management\nOther Responsibilities May Include\nAggressively seek opportunities to introduce cutting-edge technology and automation solutions that are effective, efficient and scalable in order to improve our ability to deploy and maintain our global infrastructure\nAssist with the definition, documentation and implementation of consistent processes across all region\nLimited travel\nExamples Of Desirable Skills, Knowledge And Experience\nBachelor\u201a\u00c4\u00f4s degree; technical background in engineering, computer science, or MIS\nDirect experience executing on complex data center\/infrastructure projects\nPrevious experience installing \/ maintaining data center (and other IT) infrastructure and DCIM tools\nExperience running and improving operational processes in a rapidly changing environment\nStrong verbal and written communication skills, problem-solving skills, attention to detail, and interpersonal skills\nMust be proactive with proven ability to learn fast and execute on multiple tasks simultaneously\nAbility to manage MS excel and Google spreadsheets\nComfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA\nMust be a team player\nBonus Points\nMulti-lingual; experience working with infrastructure in multiple countries\nComfortable with remote \u201a\u00c4\u00falights-out\u201a\u00c4\u00f9 and out-of-band access to data center resources\nLinux certifications (RHCSA etc.)\nNetwork certifications (CCNA, JNCIA or higher)\nCompensation\nCompensation may be adjusted depending on work location.\nFor Colorado-based hires: Estimated annual salary of $ 111,000 - $ 135,000 .\nFor New York City, Washington, and California (excluding Bay Area) based hires: Estimated annual salary of $ 135,000 - $ 165,000\nFor Bay Area-based hires: Estimated annual salary of $ 142,000 - $ 174,000 .\nEquity\nThis role is eligible to participate in Cloudflare\u201a\u00c4\u00f4s equity plan.\nBenefits\nCloudflare offers a complete package of benefits and programs to support you and your family. Our benefits programs can help you pay health care expenses, support caregiving, build capital for the future and make life a little easier and fun! The below is a description of our benefits for employees in the United States, and benefits may vary for employees based outside the U.S.\nHealth & Welfare Benefits\nMedical\/Rx Insurance\nDental Insurance\nVision Insurance\nFlexible Spending Accounts\nCommuter Spending Accounts\nFertility & Family Forming Benefits\nOn-demand mental health support and Employee Assistance Program\nGlobal Travel Medical Insurance\nFinancial Benefits\nShort and Long Term Disability Insurance\nLife & Accident Insurance\n401(k) Retirement Savings Plan\nEmployee Stock Participation Plan\nTime Off\nFlexible paid time off covering vacation and sick leave\nLeave programs, including parental, pregnancy health, medical, and bereavement leave\nWhat Makes Cloudflare Special?\nWe\u201a\u00c4\u00f4re not just a highly ambitious, large-scale technology company. We\u201a\u00c4\u00f4re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.\nProject Galileo\n: We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare\u201a\u00c4\u00f4s enterprise customers--at no cost.\nAthenian Project\n: We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.\nPath Forward Partnership\n: Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.\n1.1.1.1\n: We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here\u201a\u00c4\u00f4s the deal - we don\u201a\u00c4\u00f4t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.\nSound like something you\u201a\u00c4\u00f4d like to be a part of? We\u201a\u00c4\u00f4d love to hear from you!\nThis position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.\nCloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA\/Veterans\/Disabled Employer.\nCloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.\nShow more\nShow less",
      "job_skills":"Linux systems administration, Juniper Cisco and DWDM network equipment, Remote contractors management, Data center colocation facilities, Operational processes management, Automation tooling, JIRA, Incident management, IT infrastructure projects, DCIM tools, Communication skills, Problemsolving skills, Attention to detail, Interpersonal skills, MS excel, Google spreadsheets, RHCSA, CCNA, JNCIA",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer - Austin",
      "company":"DeRisk Technologies",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-austin-at-derisk-technologies-3766676856",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Job Responsibilities:\nDeployment \/ In-Scope Configuration Items\nServers (Virtual & Physical)\nStorage & Backup Devices\nServer Appliances\nHyper Converged Infrastructure (E.g. Nutanix, Cisco UCS)\nTape Storage Units\nPower Distribution Units rated 3KVA and below\nSAN Fabric Switches\nNetwork Switches\nKVM Units\nWAN Optimization Devices\nFirewalls\nAccess Points\nRouters\nPhysical Cabling\nCable Management\nCables which connect the device to itself, a peripheral, or a power\/network port Break-fix \/ Technical Tasks List\nPower Cycling\nRunning Diagnostics Commands\nConducting whole unit replacement\nInserting\/Removing Media\nReplacing Defective Components\nAssist with fault diagnosis and investigation\nConfiguring Remote Access\nBasic Storage Array Configuration\nReplacing faulty cables\nTape Management and Maintenance\nRebooting routers, servers, storage devices or other equipment\nOperations Tasks List\nUpdating and Recording of activities in relevant IT Ticket Management System\nCoordinating and agreeing attendance time and date with key stakeholders\nProvide support either through phone, remote tools, or in person at onsite\nPerform installation as needed either through physical or network medium\nCoordinate actual activity date and timings including arrival and departure times\nCarry all necessary tools, laptops etc. which might be needed to support issues in the infrastructure environment\nLabelling, Patching and Asset Tagging activities\nFollowing specific task instructions and provision necessary reporting as necessary\nRequirements\nJob Requirements:\nTechnical Skills\nGood general understanding of IT principles such as Networks, Hardware and Domains\nKnowledge of Infrastructure (Data Center and Network) hardware architecture as to understand the procedure shared by L3 teams during troubleshooting,H&E support\nKnowledge of server\/client operations in a domain environment including Active Directory\nUnderstanding of current and legacy hardware Infrastructure platforms\nHands-on experience in installation and troubleshooting Infrastructure (DC & Network) equipment's, Rack and Stack of the equipment\/cable\nGood Hands-on Experience in IMAC and Break-fix activities related to Infrastructure environment\nAbility to identify Excellent the right defective spares and replace them with provided good spares as instructed and by physical observations\nKnowledge of TCP\/I P standards and networking\nExperience with Tape Management activities\nExcellent knowledge of best practices around management, control, and monitoring of server infrastructure\nFamiliarity with backup and recovery software and methodologies\nLanguage skills needed\nEnglish Soft Skills\nExceptional customer facing skills\nAble to communicate clearly and effectively both with Client and the Customer\nLogical and analytical approach to work\nAccurate record keeping\nAble to work unsupervised\nGood timekeeper\nIntense focus on quality work\nProductive and Efficient Academic Background\nBachelor of Engineering \/ Technology \/ Science or Equivalent Work Experience Overall Experience (in yrs.)\n5 - 7 years (min\nBenefits\nSalary and Benefits as per market standard\nShow more\nShow less",
      "job_skills":"Data Center Hardware Architectures, Active Directory, Infrastructure Platforms, IMAC, TCP\/IP Standards, Tape Management, Server Infrastructure Management, Backup and Recovery Software, Troubleshooting, Installation, Rack and Stack, Cabling, Labelling, Patching, Asset Tagging, English, Communication, Logical Thinking, Analytical Thinking, Record Keeping, Time Management, Quality Focus, Productivity, Bachelor's Degree, Engineering, Technology, Science, 57 Years Work Experience",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Infotree Global Solutions",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-infotree-global-solutions-3693757332",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Collect, structure, and manage product content and data for eCommerce and web data collection projects. Extract content and data from different data sources and format in excel. Work with vendors to map websites for automated data collection. Organize and structure product data in different languages in files for automated data transfers. Review excel files with product data content, images, and videos for accuracy and structure.\nSkills:\nExcel, Box, Quip, Web Crawling, Data Extraction, Data Management, APIs, project management, eCommerce project management, international ecommerce, telco ecommerce\nAdditional Details\nLarge-scale data entry\nShow more\nShow less",
      "job_skills":"Excel, Data Extraction, Data Management, Web Crawling, APIs, Project Management, eCommerce Project Management, International eCommerce, Telco eCommerce",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Scientist",
      "company":"Excelon Solutions",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-at-excelon-solutions-3782240130",
      "search_city":"Hollywood",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position: Research Data Scientist\nLocation: Austin-Texas or Cupertino-CA, USA\nDuration: Long term\nJob Description:\nUnderstanding of user study research in consumer electronics with qualitative and quantitative data including appropriate sample sizing\nExpertise in statistical analysis using multiple data types and sources.\nAwareness of consumer electronic development process or phase gates methodology\nCreativity in data visualization to provide quick insights into results.\nClearly communicates complex activities or analysis.\nSkills\nResearch Data Scientist\nStatistical analysis using JMP or R\nMulti-database studies and demonstrated data integrity.\nData Visualization expertise in Tableau with export to Keynote\nSuccess Criteria\/Definition of Done\nConsult with multiple PM\u201a\u00c4\u00f4s during design to calculate sample size.\nAnalysis of data is done on time and with thoughtful data visualizations.\nAbility to join multiple data sets together to derive insights.\nCommunication with the team is clear, effective, and timely.\nProof Points\/ Expected Approach\nSolution\n: Description of approach, execution proposal\nCase study\n: proof of skills to meet deliverables on time and within budgets.\nShow more\nShow less",
      "job_skills":"Statistical analysis, Data visualization, Multidatabase studies, JMP, R, Tableau, Keynote, Data integrity, Sample size calculation, Data visualization expertise, Data sets, Communication, Research Data Scientist",
      "Category":"Data Science"
  },
  {
      "job_title":"sUAS Data Analyst",
      "company":"Percheron, LLC",
      "job_location":"Katy, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/suas-data-analyst-at-percheron-llc-3516746700",
      "search_city":"San Felipe",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"The sUAS Data Processor\/Analyst is responsible for the processing and analysis of remotely sensed data, including but not limited to LiDAR and aerial photography from all types of sensors or payload which could include terrestrial and\/or static platforms. The Data Analyst is responsible for the Quality Assurance\/Quality Control of post-acquisition Photogrammetry and LiDAR data in preparation for final product generation. The selected candidate will be primarily processing, validating, and manipulating low altitude LiDAR and digital aerial photography, extracting topographic and spatial information from point clouds, creating bare earth digital terrain models, preparing 3D visualizations and topographic and planimetric mapping.\nAble to prepare and review aerial LiDAR point cloud datasets\nManually clean\/classify\/filter aerial LiDAR point cloud data\nAble to prepare and review aerial Photogrammetric maps and datasets\nEnsure all aerial data is free of gross errors or anomalies\nEnsuring data meets required accuracy specifications and feature specifications\nFeature coding \u201a\u00c4\u00ec 2D \/ 3D feature coding of collected Photogrammetry and LiDAR datasets\nProduce final deliverables in various formats\nServe as a primary resource for LiDAR data processing on topographic and utility surveys\nProcess and QC aircraft trajectories using POSPac MMS\nProcess and QC calibrated LiDAR point clouds using Optech's LiDAR Mapping Suite\nClassify LiDAR data using Terrascan to meet customer requirements\nUtilize Autodesk Civil3D software to prepare initial project boundaries and final map deliverables\nUtilize GIS software to convert data, attribute features and produce maps\nIssue all project deliverables in a timely manner in order to support administrative, procurement and construction activities\nCommunicate and coordinate with internal and external departments to achieve resolution of project-related activities\nProvide internal daily status reports of activities\nOther special duties as assigned\nMinimum two years UAS related work experience (Required)\nMinimum of one year of experience LiDAR data classification and extraction (Required)\nPost-secondary educational in Land Surveying, Geography, GIS, Geomatics or other related discipline, or equivalent work experience (Required)\nBachelor\u201a\u00c4\u00f4s degree is a plus, but not required\nKnowledge of standard surveying and mapping practices (Required)\nsUAS part 107 (Required)\nLocal candidates strongly preferred\nSkilled use of Microsoft Office Software, Adobe Suite, MicroStation\/Terrascan, Pix4D, AutoCAD Civil3D, ArcGIS, Google Earth, Global Mapper, and other surveying and mapping software a plus\nServe as a primary resource for LiDAR data processing on topographic surveys\nProcess and QC aircraft trajectories using Spatial Explorer and\/or PosPAC\nProcess and QC calibrated LiDAR point clouds using\nClassify LiDAR data using TerraSolid to meet company and customer requirements\nUtilize Autodesk Civil3D\/ArcMap\/Global Mapper software to prepare initial project boundaries and final map deliverables\nProvide internal daily status reports of activities\nAbility to organize daily and weekly plans\nExceptional data management skills\nAble to work in a team environment\nExcellent communication both written and verbal\nHigh level of computer literacy\nObligation to produce high quality work\nCommunicate and coordinate with internal and external departments to achieve resolution of project-related activities\nAdapt to multiple production task \u201a\u00c4\u00ec cross trainable\nAble to work effectively with repetitive, computer-based tasks\nGood organizational skills\nPositive attitude and willing to expand their knowledge in the Geomatics field\nMeets expectations for attendance and punctuality\nMust be able to work independently\nValid driver's license\nWillingness to embrace and learn new technologies\nShow more\nShow less",
      "job_skills":"Photogrammetry, LiDAR, GIS, Geometrics, Land Surveying, Mapping, Aerial Photography, Data Processing, Data Analysis, Data Classification, Data Extraction, 3D Visualization, Data Validation, Data Quality Control, Data Accuracy, Data Specifications, Feature Coding, Project Boundaries, Attribute Features, Microsoft Office Suite, Adobe Suite, MicroStation, Terrascan, Pix4D, AutoCAD Civil3D, ArcGIS, Google Earth, Global Mapper, Spatial Explorer, PosPac, TerraSolid, ArcMap",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Engineer Fortune 100 Co Hiring ASAP Salary up to $140K per year +10% Bonus",
      "company":"Confidential",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-fortune-100-co-hiring-asap-salary-up-to-%24140k-per-year-%2B10%25-bonus-at-confidential-3777004484",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Lead Data Engineer wanted for Fortune 100 Co in Houston.\nMust be authorized to work in USA HIRING ASAP Direct Hire with full benefits 401k Match PTO MANY MORE\nShow more\nShow less",
      "job_skills":"Data Engineer",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Land Data Analyst",
      "company":"Endeavor Energy Resources, LP",
      "job_location":"Midland, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-land-data-analyst-at-endeavor-energy-resources-lp-3688410478",
      "search_city":"Midland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"As one of the largest employers in the Permian, we\u201a\u00c4\u00f4re committed to the success of our employees and providing an environment that fosters people and teamwork, continuous improvement, HSE excellence, technical and financial discipline, and integrity. Poised for sustainable growth, we look forward to executing our horizontal program with a world class land position and valued employees whose knowledge and expertise drive the success of this company. Interested in joining our team?\nLand Data Analyst are responsible for researching, identifying, and analyzing land data within Company land systems and delivering the data to stakeholders within the enterprise in an accurate, streamlined, and consumable format.\nEssential Duties And Responsibilities\nThe following represents many of the duties performed by the position, but is not meant to be all-inclusive nor prevent other duties from being assigned when necessary:\nKnowledgeable of land specific data, including tracts, depths, ownership and terms of oil and gas leases and\/or assignments and input data into land database\nReview, identify, analyze, and update large amount of data associated with oil and gas leases, contracts, surface, right-of-way, mineral deeds, title opinions and division orders in Company land system\nBuild simple to use tools, dashboards, and reports that are capable of handling large amounts of data to drive decisions which enhance Company performance and drive value\nUse of data analytics to provide quick reports, visual aids and statistical analysis facilitating information sharing and process improvement\nExtract, Transform and Load (ETL) data from acquired asset data rooms into core Company systems\nCommunicate technical requirements of the Company Land Department to Company IT Department and\/or 3rd party software vendors (i.e. Enertia)\nAssist with special projects such as audits, acquisitions, and divestitures\nOther tasks as assigned\nSkills And Experience\nBachelor\u201a\u00c4\u00f4s degree required (Data Science, Energy Management or Business Degree preferred) The combination of education and relevant experience may substitute for degree\nMinimum of 3 years of experience in the oil and gas industry; Data Science, Land or Land Administration preferred\nExhibit a high aptitude in analytical thinking\nExperience with data extraction, data automation, artificial intelligence and machine learning preferred\nProven proficiency with data analytics software (Spotfire and\/or PowerBi preferred)\nEstablished proficiency in Microsoft Office required, with emphasis in Excel, Word, and Teams.\nExperience with Land Data Management Software (Enertia preferred)\nExperience with Document Management Systems (M-Files and\/or Thomson Reuters Document Intelligence preferred)\nAbility to effectively communicate and build relationships with various levels of company personnel\nDemonstrate time management and organizational skills approaching projects with a sense of urgency\nDetail oriented with the ability to multi-task with attention to accuracy\nRecognizes value in, and seeks opportunities for, continued development and improvement\nAbility to seek out, implement and adapt to new technologies, workflows, and processes\nTeam player who possesses the ability to adapt to a changing and fast paced work environment\nEndeavor Energy Resources, LP is an Equal Opportunity Employer and does not discriminate in regard to race, color, creed, age, religion, ancestry, national origin, sex, genetics, marital status or disability. Endeavor Energy Resources, L.P. complies with all local, state, and federal laws pertaining to employment, and discrimination will not be tolerated.\nShow more\nShow less",
      "job_skills":"Data Science, Energy Management, Data Analytics, Data Extraction, Data Automation, Artificial Intelligence, Machine Learning, Spotfire, PowerBi, Microsoft Office, Excel, Word, Teams, Enertia, MFiles, Thomson Reuters Document Intelligence",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Building Operating Engineer",
      "company":"JLL",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-building-operating-engineer-at-jll-3748261882",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"General Description:\nThe Data Center Operations Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)\nPrincipal Duties and Responsibilities\nTask will include but not be limited to:\nResponsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire\/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.\nRequires the ability to analyze the operation of various systems, determine the cause of any problems\/malfunctions and take corrective action as required.\nComply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.\nLearn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.\nWork order management, including CMMS, Vendor Management, and Customer Facing Tickets.\nUnderstanding and complying with emergency escalation procedures.\nPerform additional job duties as required.\nMinimum Requirements:\nPreferred to have hands-on experience working in a data center\/critical facility, including UPS.\nSystems, emergency generators, and switchgears.\nHigh School diploma or GED equivalent\n2+ years related work experience.\nWorking knowledge of computer applications including Word and Excel.\nDemonstrated verbal\/written communication skills.\nPreferred Requirements:\nCorrigo Experience.\nMCIM \/ Salesforce Experience.\nZendesk Experience.\nService Now Experience.\nReceived EPA 608.\nTrained in NFPA70E.\nShow more\nShow less",
      "job_skills":"UPS, HVAC, Chillers, Crac, Crah, Plumbing, Emergency backup systems, Lighting, ATS, STS, PDU, Generators, Primary switchgear, Power distribution, Transformers, Hot water systems, Refrigeration, Chilled water, Air conditioning equipment, Boilers, Ventilating, Water heaters, Pumps, Valves, Piping, Filters, CMMS, Vendor Management, Customer Facing Tickets, Corrigo, MCIM, Salesforce, Zendesk, Service Now, EPA 608, NFPA70E",
      "Category":"Data Science"
  },
  {
      "job_title":"Building Operating Engineer - Data Center",
      "company":"JLL",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/building-operating-engineer-data-center-at-jll-3748265361",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"General Description:\nThe Data Center Operations Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)\nPrincipal Duties and Responsibilities\nTask will include but not be limited to:\nResponsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire\/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.\nRequires the ability to analyze the operation of various systems, determine the cause of any problems\/malfunctions and take corrective action as required.\nComply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.\nLearn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.\nWork order management, including CMMS, Vendor Management, and Customer Facing Tickets.\nUnderstanding and complying with emergency escalation procedures.\nPerform additional job duties as required.\nMinimum Requirements:\nPreferred to have hands-on experience working in a data center\/critical facility, including UPS.\nSystems, emergency generators, and switchgears.\nHigh School diploma or GED equivalent\n2+ years related work experience.\nWorking knowledge of computer applications including Word and Excel.\nDemonstrated verbal\/written communication skills.\nPreferred Requirements:\nCorrigo Experience.\nMCIM \/ Salesforce Experience.\nZendesk Experience.\nService Now Experience.\nReceived EPA 608.\nTrained in NFPA70E.\nShow more\nShow less",
      "job_skills":"Data Center Operations, Electrical and mechanical infrastructure, UPS systems, MV electrical systems, Generators, Cooling systems, HVAC systems, Chillers, Crac, Crah, Plumbing, Controls, Emergency backup systems, Lighting, ATS, STS, PDU, Transformers, Power distribution, Hot water systems, Refrigeration, Chilled water, Air conditioning equipment, Boilers, Ventilating, Water heaters, Pumps, Valves, Piping, Filters, CMMS, Vendor Management, Customer Facing Tickets, Emergency escalation procedures, Corrigo, MCIM, Salesforce, Zendesk, Service Now, EPA 608, NFPA70E",
      "Category":"Data Science"
  },
  {
      "job_title":"Building Operating Engineer - Data Center",
      "company":"JLL",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/building-operating-engineer-data-center-at-jll-3748264637",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"General Description:\nThe Data Center Operations Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)\nPrincipal Duties and Responsibilities\nTask will include but not be limited to:\nResponsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire\/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.\nRequires the ability to analyze the operation of various systems, determine the cause of any problems\/malfunctions and take corrective action as required.\nComply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.\nLearn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.\nWork order management, including CMMS, Vendor Management, and Customer Facing Tickets.\nUnderstanding and complying with emergency escalation procedures.\nPerform additional job duties as required.\nMinimum Requirements:\nPreferred to have hands-on experience working in a data center\/critical facility, including UPS.\nSystems, emergency generators, and switchgears.\nHigh School diploma or GED equivalent\n2+ years related work experience.\nWorking knowledge of computer applications including Word and Excel.\nDemonstrated verbal\/written communication skills.\nPreferred Requirements:\nCorrigo Experience.\nMCIM \/ Salesforce Experience.\nZendesk Experience.\nService Now Experience.\nReceived EPA 608.\nTrained in NFPA70E.\nShow more\nShow less",
      "job_skills":"Data center infrastructure management, UPS systems, MV electrical systems, Generators, Cooling systems, Fire\/life safety systems, HVAC systems, Chillers, Plumbing, Electrical systems, Emergency backup systems, Lighting, PDUs, Transformers, Power distribution, Hot water systems, Refrigeration, Air conditioning equipment, Boilers, Pumps, Valves, Piping, Filters, CMMS, Vendor management, Customer facing tickets, Emergency escalation procedures, Corrigo, MCIM, Salesforce, Zendesk, Service Now, EPA 608, NFPA70E, Word, Excel",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Building Operating Engineer",
      "company":"JLL",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-building-operating-engineer-at-jll-3770695700",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Data Center Operating Engineer\nGeneral Description:\nThe Data Center Building Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)\nLocation:\nPrincipal Duties and Responsibilities\nTask will include but not be limited to:\nResponsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire\/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.\nRequires the ability to analyze the operation of various systems, determine the cause of any problems\/malfunctions and take corrective action as required.\nComply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.\nLearn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.\nWork order management, including CMMS, Vendor Management, and Customer Facing Tickets.\nUnderstanding and complying with emergency escalation procedures.\nPerform additional job duties as required.\nMinimum Requirements:\nPreferred to have hands-on experience working in a data center\/critical facility, including UPS.\nSystems, emergency generators, and switchgears.\nHigh School diploma or GED equivalent\n2+ years related work experience.\nWorking knowledge of computer applications including Word and Excel.\nDemonstrated verbal\/written communication skills.\nPreferred Requirements:\nCorrigo Experience.\nMCIM \/ Salesforce Experience.\nZendesk Experience.\nService Now Experience.\nReceived EPA 608.\nTrained in NFPA70E.\nShow more\nShow less",
      "job_skills":"UPS, HVAC, Chillers, CRAC, CRAH, Plumbing, ATS, STS, PDU, Generators, CMMS, Vendor Management, Word, Excel, Corrigo, MCIM, Salesforce, Zendesk, Service Now, EPA 608, NFPA70E",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer - Dallas",
      "company":"DeRisk Technologies",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-dallas-at-derisk-technologies-3766685012",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Job Responsibilities:\nDeployment \/ In-Scope Configuration Items\nServers (Virtual & Physical)\nStorage & Backup Devices\nServer Appliances\nHyper Converged Infrastructure (E.g. Nutanix, Cisco UCS)\nTape Storage Units\nPower Distribution Units rated 3KVA and below\nSAN Fabric Switches\nNetwork Switches\nKVM Units\nWAN Optimization Devices\nFirewalls\nAccess Points\nRouters\nPhysical Cabling\nCable Management\nCables which connect the device to itself, a peripheral, or a power\/network port Break-fix \/ Technical Tasks List\nPower Cycling\nRunning Diagnostics Commands\nConducting whole unit replacement\nInserting\/Removing Media\nReplacing Defective Components\nAssist with fault diagnosis and investigation\nConfiguring Remote Access\nBasic Storage Array Configuration\nReplacing faulty cables\nTape Management and Maintenance\nRebooting routers, servers, storage devices or other equipment\nOperations Tasks List\nUpdating and Recording of activities in relevant IT Ticket Management System\nCoordinating and agreeing attendance time and date with key stakeholders\nProvide support either through phone, remote tools, or in person at onsite\nPerform installation as needed either through physical or network medium\nCoordinate actual activity date and timings including arrival and departure times\nCarry all necessary tools, laptops etc. which might be needed to support issues in the infrastructure environment\nLabelling, Patching and Asset Tagging activities\nFollowing specific task instructions and provision necessary reporting as necessary\nRequirements\nJob Requirements:\nTechnical Skills\nGood general understanding of IT principles such as Networks, Hardware and Domains\nKnowledge of Infrastructure (Data Center and Network) hardware architecture as to understand the procedure shared by L3 teams during troubleshooting,H&E support\nKnowledge of server\/client operations in a domain environment including Active Directory\nUnderstanding of current and legacy hardware Infrastructure platforms\nHands-on experience in installation and troubleshooting Infrastructure (DC & Network) equipment's, Rack and Stack of the equipment\/cable\nGood Hands-on Experience in IMAC and Break-fix activities related to Infrastructure environment\nAbility to identify Excellent the right defective spares and replace them with provided good spares as instructed and by physical observations\nKnowledge of TCP\/I P standards and networking\nExperience with Tape Management activities\nExcellent knowledge of best practices around management, control, and monitoring of server infrastructure\nFamiliarity with backup and recovery software and methodologies\nLanguage skills needed\nEnglish Soft Skills\nExceptional customer facing skills\nAble to communicate clearly and effectively both with Client and the Customer\nLogical and analytical approach to work\nAccurate record keeping\nAble to work unsupervised\nGood timekeeper\nIntense focus on quality work\nProductive and Efficient Academic Background\nBachelor of Engineering \/ Technology \/ Science or Equivalent Work Experience Overall Experience (in yrs.)\n5 - 7 years (min\nBenefits\nSalary and Benefits as per market standard\nShow more\nShow less",
      "job_skills":"Networking, Hardware, Domains, Infrastructure Architecture, Server Operations, Client Operations, Active Directory, Legacy Hardware, Troubleshooting, Rack and Stack, IMAC, Breakfix, TCP\/IP Standards, Tape Management, Backup and Recovery, English Communication, Customer Service, Logical Thinking, Analytical Thinking, Record Keeping, Unsupervised Work, Time Management, Quality Control, Productivity, Bachelor's Degree, Engineering, Technology, Science",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Electrical Engineer - Data Center",
      "company":"Olsson",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-electrical-engineer-data-center-at-olsson-3759390621",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Company Description\nWe are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.\nOur most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u201a\u00c4\u00ee and will continue to allow us \u201a\u00c4\u00ee to grow. The result? Inspired people, amazing designs, and projects with purpose.\nJob Description\nAs an Electrical Engineer, you will work directly with some of the world\u201a\u00c4\u00f4s largest technology companies and other mission-critical clients. You will serve as an electrical engineer on projects, design calculations, write technical reports, and prepare documents. Experience in the Data Center industry is preferred. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients.\nQualifications\nYou are passionate about:\nWorking collaboratively with others\nHaving ownership in the work you do\nUsing your talents to positively affect communities\nYou bring to the team:\nStrong communication skills\nAbility to contribute and work well on a team\nBachelor's degree in electrical engineering\n8+ years of electrical engineering experience\nLicensed PE\nAbility to be a self-starter to take on a variety of tasks to best serve the client and their project work\nInvestigation and troubleshooting of problems to find solutions\nAdditional Information\nOlsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u201a\u00c4\u00f4re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.\nAs an Olsson employee, you\u201a\u00c4\u00f4ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u201a\u00c4\u00f4ll:\nBecome an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)\nEngage in work that has a positive impact in communities\nReceive an excellent 401(k) match\nParticipate in a wellness program promoting balanced lifestyles\nBenefit from a bonus system that rewards performance\nHave the possibility for flexible work arrangements\nOlsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.\nShow more\nShow less",
      "job_skills":"Electrical Engineering, Data Center Industry, Technical Reports, Documentation, Communication, Teamwork, Troubleshooting",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Electrical Engineer - Arc Flash - Data Center (Remote)",
      "company":"Olsson",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-electrical-engineer-arc-flash-data-center-remote-at-olsson-3737829711",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Company Description\nWe are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.\nOur most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u201a\u00c4\u00ee and will continue to allow us \u201a\u00c4\u00ee to grow. The result? Inspired people, amazing designs, and projects with purpose.\nJob Description\nAs an Electrical Engineer, you will work directly with some of the world\u201a\u00c4\u00f4s largest technology companies and other mission-critical clients. You will serve as an electrical engineer on projects, design calculations, write technical reports, and prepare documents. Experience in performing short circuit analysis and producing arc flash studies is required. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients. You may travel to job sites for observation and attend client meetings.\nWe currently have one opening and will consider candidates interested in being located in most locations across the United States.\nQualifications\nYou are passionate about:\nWorking collaboratively with others\nHaving ownership in the work you do\nUsing your talents to positively affect communities\nElectrical Engineering knowledge\nYou bring to the team:\nStrong communication skills\nAbility to contribute and work well on a team\nAbility to be a self-starter to take on a variety of tasks to best serve the client and their project work\nInvestigation and troubleshooting of problems to find solutions\nAbility to contribute and work well on a team\nBachelor's Degree in electrical engineering\n8+ years or related electrical engineering experience\nRegistered professional engineer (PE) required\nSKM and ETAP software experience is preferred\nAdditional Information\nOlsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u201a\u00c4\u00f4re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.\nAs an Olsson employee, you\u201a\u00c4\u00f4ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u201a\u00c4\u00f4ll:\nBecome an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)\nEngage in work that has a positive impact in communities\nReceive an excellent 401(k) match\nParticipate in a wellness program promoting balanced lifestyles\nBenefit from a bonus system that rewards performance\nHave the possibility for flexible work arrangements\nOlsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.\nShow more\nShow less",
      "job_skills":"Electrical Engineering, SKM, ETAP, Short Circuit Analysis, Arc Flash Studies, Troubleshooting, Communication, Problem Solving, Teamwork, SelfStarter, Project Management, AutoCAD, Microsoft Office",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Alpine Solutions Group",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-alpine-solutions-group-3777303108",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"MUST:\n2+ years of very strong with SQL querying\nETL knowledge , we write them in SQL everything runs off of database\nhands on experience with BI tools\nunderstanding with platform maintenance within MYSQL (they are Maria DB in MYSQL)\nability to communicate with the c suite\nexperience building out dashboards and reports, could be within tableau or any other BI tools.\nAbility to help automate manual reporting\/manual data entry\nPLUS:\nMasters in Data Science\nDAY TO DAY:\nOur client in Dallas, a fast growing consulting firm, is looking to hire a BI Analyst to come aboard their team as a full time employee. This position will be hybrid in Dallas and report into the Lead BI Analyst. This person will be helping to set up reporting through a newly selected BI tool (we are looking for this person to help spearhead the selection of that tool and help maintain is at well). We are looking for someone who can help standardize reporting and work to help various departments in the company who still do manual data entry\/manual reporting to automate those processes. This person will play a role in analyzing and transforming the data into insights for our company, and will work cross departmental. Other responsibilities could be: gathering, cleaning, and analyzing data to identify trends, develop dashboards\/reports, monitor KPI\u201a\u00c4\u00f4s, and conduct ad-hoc analysis to support stakeholders as needed.\nShow more\nShow less",
      "job_skills":"SQL, ETL, BI tools, Tableau, Data automation, Reporting, Dashboard creation, Data analysis, Data transformation, Data cleaning, Data visualization, KPI monitoring, Adhoc analysis",
      "Category":"Data Science"
  },
  {
      "job_title":"Research Data Specialist I",
      "company":"The University of Texas at Dallas",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/research-data-specialist-i-at-the-university-of-texas-at-dallas-3776128940",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"The Decision Support Specialist assists the Office of Institutional Success and Decision Support with a variety of tasks related to accreditation, assessment, policy development and evaluation, institutional research, and office management. This entry-level role will support data management, data collection, administrative functions of the office and documentation of processes and procedures.\nThe specialist reports to the Associate Vice President and works closely with the Assistant Director on the day-to-day tasks of the unit, ensuring that project milestones are communicated to unit stakeholders, and assists with the coordination of unit events (webinars, workshops, trainings, and development programming). The specialist also supports the assessment staff in maintaining program assessment documentation, including assessment reports, using the University's online assessment platform.\nThe specialist will also assist with the collection and analysis of assessment data, organizing materials, and editing and proofreading documents and reports. The specialist may also be asked to conduct reviews of other institutions' policies and best practices within higher education and review documentation related to accreditation reports.\nMinimum Education And Experience\nBachelor's degree with six months of experience in a related field. An equivalent combination of relevant education and\/or experience may be considered.\nSix (6) months of process documentation\nSix (6) months of technical communication\nPreferred Education And Experience\nPreferred Education and Experience\nEducation:\nA Bachelor's degree in business administration, social sciences, education, or a related field.\nExperience:\nExperience working in higher education, some experience with qualitative and\/or quantitative data collection and analysis.\nSkills\n: Basic project management; excellent customer service skills; strong verbal, written, and interpersonal communication skills; collaboration, ability to manage multiple tasks and projects, and ability to respond to requests in a timely manner.\nEssential Duties And Responsibilities\nGeneral unit support includes assisting colleagues with:\nreviewing annual assessment plan and report submissions in the University's assessment platform for completion and communicating with assessment staff, as well as academic and administrative programs about assessment reports.\nproofreading reports and documents, including identifying discrepancies within text and visuals.\nmaking business processes transparent and sustainable\ntracking project milestones and communicating progress to unit leaders\nassisting with entry-level data collection, coding, and analysis tasks\ncollection and preparation of business expense and travel expense reimbursements\noffice purchases and maintaining office supply inventory\nprocessing and reviewing eCATs for building access, keys, and computer access\nwork order submissions to facilities management\nscheduling of Alpine Conference Room\ncollecting and distributing mail\nmaintaining and documenting computer inventory\nprocurement activities: utilize procurement software to prepare, review, submit, and receive purchase orders\nother duties as assigned\nAdditional Information\nRemote Work:\nAfter the probationary period, this role may be eligible for a hybrid (partly remote\/partly in office) work schedule, subject to business need and manager approval. A UT Dallas Remote Work Agreement will be required within 14 days after approval. The Research Data Specialist I must be located within the DFW Area and have the ability to be on campus within 24 hours of notice.\nWhat We Can Offer:\nUT Dallas aims to attract and retain talented faculty and staff to support the university's mission. We offer a comprehensive compensation and benefits package.\nMedical\nDental\nVision\nPaid time off\nRetirement\nLife insurance\nAD&D coverage\nUT Dallas also offers employee wellness programs, tuition assistance, and professional development through their BRIGHT Leaders program and a variety of virtual learning platforms. BRIGHT Leaders aims to support, encourage, and serve as a resource to cultivate and nurture effective leadership at all levels by providing trainings and resources to help all UTD employees grow their leadership skills. Visit our benefits webpage,\nhttps:\/\/hr.utdallas.edu\/employees\/benefits\/\nfor more information.\nIf you are looking for a rewarding career opportunity with great benefits? Look no further! Join our team!\nImportant Message\nAll employees serve as a representative of the University and are expected to display respect, civility, professional courtesy, consideration of others and discretion in all interactions with members of the UT Dallas community and the general public.\nThe University of Texas at Dallas is committed to providing an educational, living, and working environment that is welcoming, respectful, and inclusive of all members of the university community. UT Dallas does not discriminate on the basis of race, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, national origin, disability, genetic information, or veteran status in its services, programs, activities, employment, and education, including in admission and enrollment. EOE, including disability\/veterans. The Universityis committed to providing access, equal opportunity, and reasonable accommodationfor individuals with disabilities.To request reasonable accommodation in the employment application and interview process, contact theADA Coordinator.For inquiries regarding nondiscrimination policies, contact theTitle IX Coordinator.\nShow more\nShow less",
      "job_skills":"Project management, Customer service, Verbal communication, Written communication, Interpersonal communication, Collaboration, Multitasking, Time management, Data management, Data collection, Data analysis, Process documentation, Technical communication, Qualitative data analysis, Quantitative data analysis, Business process management, Procurement, Microsoft Office Suite, eCATs, Alpine Conference Room, BRIGHT Leaders program",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr Data Modeler",
      "company":"EMBTEL, INC.",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-modeler-at-embtel-inc-3726872380",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"We EMBTEL, Inc one of the fastest growing IT Staffing & Recruitment Company in US. We are U.S. Federal Govt. approved vendor and Certified Minority Business Enterprise(MBE\n)\ncompany. We have an urgent requirement with our client\/Implementation partner. The job details are given below-(\nhttps:\/\/embtel.com\/careers\/\nhttps:\/\/www.linkedin.com\/jobs\/search\/?f_C=15556444&geoId=92000000\n)\nWe EMBTEL, Inc one of the fastest growing IT Staffing & Recruitment Company in the US. We are U.S. Federal Govt. approved vendor and Certified Minority Business Enterprise (MBE) company. We have an urgent requirement with our client\/Implementation partner. The job details are given below -\nhttps:\/\/embtel.com\/careers\/\nhttps:\/\/www.linkedin.com\/jobs\/search\/?f_C=15556444&geoId=92000000\nJob Title: Sr Data Modeler\nRole: Dallas, USA (hybrid)\nMust Skill: Data Vault exp\nContract\nJd\nDesigns, implements, and documents data architecture and data modeling solutions, which include the use of relational, dimensional\nResponsible for the development of the conceptual, logical, and physical data models\nImplementation of RDBMS, operational data store (ODS), data marts, and data lakes on target platforms\nDefine and govern data modeling and design standards, tools, best practices, and related development for enterprise data models\nHands-on modeling, design, configuration, installation, performance tuning\nExperience in Data Vault modeling approach\nExtensive knowledge of Snowflake.\nGood knowledge of metadata management, data modeling, and related tools (Erwin or ER Studio or others) required\nWork closely with the database engineers to create optimal physical data models of datasets\nLeadership Skills & Stakeholder Management\nWork very closely with customer stakeholders to understand their needs and make recommendations.\nInteract with SMEs (business) and Architect to validate whether the data model is aligned with the technology suggested for the project.\nRelay the information gained from onshore to the team and offshore for seamless collaboration and desired outcome.\nSubmission Format\nNeed Resume, and photo id with below details.\nCandidate Full Name Phone: Email ID Current Location Availability to start on the project Next 3 days availability for Screening (WebEx\/Skype, etc)\nWe EMBTEL, Inc one of the fastest growing IT Staffing & Recruitment Company in the US. We are U.S. Federal Govt. approved vendor and Certified Minority Business Enterprise (MBE) company. We have an urgent requirement with our client\/Implementation partner. (\nhttps:\/\/embtel.com\/careers\/\nhttps:\/\/www.linkedin.com\/jobs\/search\/?f_C=15556444&geoId=92000000\n)\nShow more\nShow less",
      "job_skills":"Data Vault, Relational Database Management Systems, Data Marts, Data Lakes, Snowflake, Metadata Management, Data Modeling, Erwin, ER Studio, SQL",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Data Scientist",
      "company":"Trident Consulting",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-scientist-at-trident-consulting-3784827491",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Trident Consulting is seeking a \"\nSr Data Scientist\n\" for one of our clients in \"\nCharlotte, NC\/ Dallas, TX -Onsite (Need Local Only\n\". A global leader in business and technology services.\nJob Title:\nSr. Data Scientist\nJob Location:\nCharlotte, NC\/ Dallas, TX -Onsite (Need Local Only)\nJob Type:\nContract\nExperience\n: 10 to 12yrs.\nRequired Skills:\nData Architect\nJob Description\nCybersecurity is seeking a Sr Data Scientist to join the Cyber Analytics and Data Science team.\nThis position will use machine learning, data engineering, automation, and Data Science principles to solve enterprise problems and advance our Cyber Security mission.\nThis role is a key contributor to our practice and will be directly responsible for design, development, deployment, and automation.\nThe successful candidate will work closely with key stakeholders to rapidly advance the use of predictive and prescriptive analytics for cybersecurity as well as help the Cyber team with automation efforts.\nWe are seeking candidates with passion to lead the implementation of cutting-edge technology and methodologies while establishing strong partnerships with data owners and stakeholders across Cybersecurity.\nThe Sr Data Scientist will have demonstrated experience as a problem-solver, working alongside IT and business partners, and act as a trusted consultant.\nResponsibilities\nStructure business problems and drive viable, data-driven hypotheses in collaboration with business partners\nAbility to skillfully enumerate a business problem, quantify its impact, size relevant data, and document applicable sources\nDevise, develop and disseminate actionable intelligence from disparate data sources using advanced data analytics tools and techniques\nAbility to identify needs and opportunities for advancements in innovations, processes and automation\nAble to work proactively and take initiative without being specifically directed\nAbility to extract & aggregate data from disparate data sources\nAbility to perform in depth data analysis including but not limited to Machine Learning Classification Optimization Time Series analysis Pattern Recognition Establish and develop end-to-end automated processes (i.e.: data analyses, model development & implementation, manual processes, etc) Ability to communicate complex topics in an easy-to-understand manner when prese\nAbout Trident:\nTrident Consulting is an award-winning IT\/engineering staffing company founded in 2005 and headquartered in San Ramon, CA. We specialize in placing high-quality vetted technology and engineering professionals in contract and full-time roles. Trident's commitment is to deliver the best and brightest individuals in the industry for our clients' toughest requirements.\nSome of our recent awards include:\n\u201a\u00c4\u00a2 2022, 2021, 2020 Inc. 5000 fastest-growing private companies in America\n\u201a\u00c4\u00a2 2022, 2021 SF Business Times 100 fastest-growing private companies in Bay Area\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Automation, Data Engineering, Predictive Analytics, Prescriptive Analytics, Data Analytics, Advanced Data Analytics Tools and Techniques, Data Aggregation, Data Analysis, Machine Learning Classification, Optimization, Time Series Analysis, Pattern Recognition, EndtoEnd Automated Processes, Data Analyses, Model Development, Implementation, Complex Topics Communication",
      "Category":"Data Science"
  },
  {
      "job_title":"AI\/ML Developer - Lead Data Scientist",
      "company":"Digital Janet",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/ai-ml-developer-lead-data-scientist-at-digital-janet-3758737591",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Role: Senior AI\/ML Developer- Lead Data Scientist\nLocation: Charlotte NC\/ Dallas, TX (Hybrid)\nW2 only\nShow more\nShow less",
      "job_skills":"AI, ML, Data Scientist, Hybrid",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"InfoVision Inc.",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-infovision-inc-3783961042",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"\u00ac\u2211 Independently create and\/or Assist lead data scientists in developing various kinds of machine learning models for personalized customer service domain using state of the art ML algorithms such as GBM, XGBoost, Deep Learning etc. on CPU and GPU environments\n\u00ac\u2211 Conduct pre-modeling activities such as data clean up, exploratory data analysis, scaling\/normalization, feature engineering, etc. with data in Google Cloud Platform ecosystem, notebooks\n\u00ac\u2211 Proficient with standard Data Science Libraries such as NumPy, Pandas and Deep learning. In addition, proficiency in libraries for GPUs is a huge plus\n\u00ac\u2211 Knowledge of Pytorch or Tensorflow and experience with modern neural NLP approaches is a plus.\n\u00ac\u2211 Developing test cases and executing test cases for developed ML models\n\u00ac\u2211 Assist in performance\/load testing\/monitoring of the deployed models\n\u00ac\u2211 Documenting the models, features and any decisions made during modeling\n\u00ac\u2211 Assist ML engineers during solution deployment on on-prem and AWS for authoring\/making changes to API wrappers\n\u00ac\u2211 Ability to rapidly learn the current state of the project and independently work with minimal assistance after the initial ramp up time\nShow more\nShow less",
      "job_skills":"Machine Learning, GBM, XGBoost, Deep Learning, NumPy, Pandas, PyTorch, Tensorflow, NLP, Unit Testing, Performance Testing, Load Testing, API Development",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"InfoVision Inc.",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-infovision-inc-3762682686",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Title: Senior Data Scientist\nDuration: 12+ Months contract (Can go up to 24 Months)\nLocation: Irving, TX \u201a\u00c4\u00ec (Hybrid 2 Days in a week) \u201a\u00c4\u00ec Need onsite Day 1\nRequired Qualifications\nGood experience deploying models in Production.\nAnother with PyTorch\/TorchLighting knowledge to help us build\/edit models.\nEx-Telecom Projects Plus\nDeploying experience is must\nWork with a focus on MLOps\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, PyTorch, TorchLighting, MLOps, Model Deployment, Telecom Projects",
      "Category":"Data Science"
  },
  {
      "job_title":"Full Time : GCP Data Analyst : Austin , TX ( Onsite )",
      "company":"Nexwave",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/full-time-gcp-data-analyst-austin-tx-onsite-at-nexwave-3778212340",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Role: GCP Data Analyst\nLocation: Austin, TX\nFull Time\nclean-up and organize unstructured data from different sources\ndiscover correlations and insights from a unstructured set of data\nindependently run researches and analyses on different data sources\nuse (even in a basic way) tools and framework to process and visualize data\nwith a knowledge for community and people orgs domains as a plus.\nThanks & Regards\nC Naveen\nPhone: 9725979189 Ext 403\nEmail : cnaveen@nexwaveinc.com\nLinkedin :https:\/\/www.linkedin.com\/in\/naveen-chowdary-65b610115\/\n5490 McGinnis Village Place Suite 237 Alpharetta GA 30005\nWeb: www.nexwaveinc.com\nUSA II INDIA II Canada II UK II Germany\nDisclaimer:\nThis e-mail and any attachments to it may be confidential and are intended solely for the use of the individual to whom it is addressed. The information contained in this e-mail and any attachment(s) must not be published, copied, disclosed, or transmitted in any form to any person or entity unless expressly authorized by the sender. If you have received this mail in\nERROR\n, please reply to us with\n\"Remove\"\nin the subject. We respect your online privacy and our apologies for any inconvenience caused.\nShow more\nShow less",
      "job_skills":"GCP, Data Cleaning, Data Organization, Data Analysis, Research, Visualization, Data Processing, Community Domain Knowledge, People Orgs Domain Knowledge",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Scientist",
      "company":"LS Technologies",
      "job_location":"Mountain View, WY",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-at-ls-technologies-3748873680",
      "search_city":"Wyoming",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This position is in support of the NASA Ames Research Center (ARC), whose primary focus is on research and development (R&D) including fundamental scientific research, concept development, prototype testing, and new technology creation. ARC performs R&D in support of NASA missions in collaboration with other NASA centers, academia, other federal organizations, not-for-profit organizations, and industry partners. Successful candidates will support success of NASA and ARC mission and goals in aeronautics, science, space technology, and human exploration in partnership with leading edge technical and research expertise from both student and faculty researchers.\nThis work is directly supporting NASA Academic Mission Services-2 (NAMS-2) which will provide the Aeronautics Directorate and the Exploration Technology Directorate of NASA ARC with capabilities to fulfill mission requirements from fundamental R&D through field-test deployments and operational missions. NAMS-2 includes a broad scope of evolving research, including the development of new and emerging capabilities and technologies. Projects include scientific research associated with air traffic management, advanced technology, nanoelectronics, and prototype software. This team will help meet aeronautics and technology mission objectives, particularly the improvement of aircraft and airspace safety as well as the transition of advanced aeronautics technologies into future air vehicles.\nJob Description\nIdentifies trends, patterns, and anomalies found in big data sets by performing extensive data analysis to develop insights.\nPerforms data mining, cleaning, and aggregation processes to prepare data, implement data models, conduct analysis, and develop databases.\nInterprets results from multiple structured and unstructured data sources using programming, statistical, and analytical techniques and tools.\nCollaborates with teams to understand each data analysis projects' underlying purpose, focus, and objectives.\nDesigns, develops, and implements the most valuable data-driven solutions\nRequirements\nA master's degree in computer science, mathematics, engineering or equivalent.\nRequires 5 - 8 years of related experience.\nLS Technologies, LLC provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, ender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\nJob Posted by ApplicantPro\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Mining, Data Cleaning, Data Aggregation, Data Modelling, Data Interpretation, Statistical Analysis, Analytical Techniques, Programming, Databases, Big Data, DataDriven Solutions",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Research\/Data Analyst IA020124",
      "company":"State of Missouri",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-research-data-analyst-ia020124-at-state-of-missouri-3784938593",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Senior Research\/Data Analyst \u201a\u00c4\u00ec\nPublic Service Commission \/ Industry Analysis Division \/ Water, Sewer, and Steam Department\nJob Posting Number:\nIA020124\nSalary:\nStarting salary will be commensurate with education and experience. Annual salary range: $66,053 - $70,980\nJob Location:\nThis position is located at 200 Madison Street, Jefferson City, MO 65102\nWhy You\u201a\u00c4\u00f4ll Love This Position\nThe Missouri Public Service Commission regulates investor-owned electric, natural gas, steam, water and sewer utilities in Missouri. We ensure that Missourians receive safe and reliable utility services at just, reasonable and affordable rates. The Water and Sewer Department performs evaluations and on-going reviews of all tariff filings made by companies to ensure compliance with Commission rules and procedures. The department participates in all formal and informal rate filings made by regulated companies by reviewing existing and proposed rate design proposals and determining the appropriateness and need for plant additions. The department provides responses to customer inquiries and complaints concerning rate matters and quality of service issues and performs periodic inspections of company facilities and operations to ensure that companies are in compliance with Commission rules and are operating adequately. The department also participates in the review of finance cases filed before the Commission to ensure the appropriateness of the projects being financed and participates in the review of certificate applications before the Commission.\nWhat You\u201a\u00c4\u00f4ll Do\nPerform reviews and analysis of policies and programs affecting rates used to charge water, sewer, and steam customers in the state of Missouri.\nEnsure customers receive safe and adequate service.\nCoordinate technical aspects of rate cases before the Commission.\nNegotiate with utility representatives and interveners.\nReview legislative proposals and participate in rule making.\nProvide input and testify on issues as an expert witness.\nResearch new environmental requirements affecting water, sewer, and steam utilities.\nMake recommendations to utilities to ensure rule and regulation compliance.\nPosition may require occasional in- and out-of-state travel.\nMinimum Qualifications\nAll you need for success:\nA Bachelor\u201a\u00c4\u00f4s degree from an accredited four-year college or university and;\n4-6 years of relevant experience and\/or appropriate certification.\nProfessional experience in a utility or regulatory environment preferred.\nKnowledge of drinking water or wastewater environmental regulations a plus.\nMust have strong interpersonal, communication, active listening, and writing skills.\nPersonal computer experience required, Microsoft Office experience required.\nAbility to work within a team setting or independently is required.\nMust have initiative and strong work ethic.\nIf you have questions about this position, please contact:\npscjobs@psc.mo.gov\nTo be considered for this position, please submit an application, resume, and provide a copy of each transcript from all colleges\/universities attended, and a one to two page technical writing sample by 5:00 pm January 12, 2024. For additional information about this position, you may visit http:\/\/psc.mo.gov\/General\/Career_Opportunities .\nThe State of Missouri is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\nShow more\nShow less",
      "job_skills":"Data analysis, Microsoft Office, Research, Negotiation, Communication, Writing, Regulatory compliance, Environmental regulations, Utility regulation, Rate design, Water and wastewater treatment, Public speaking, Teamwork, Initiative, Work ethic",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Research\/Data Analyst - Epidemiology (4206900)",
      "company":"State of Missouri",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-research-data-analyst-epidemiology-4206900-at-state-of-missouri-3789727773",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Location:\nThis position will be located at 930 Wildwood Dr., Jefferson City, 65109 with the possibility of a hybrid or distributed work schedule once training is complete.\nWhy You'll Love This Position\nWe are seeking a highly motivated individual with a background in public health, statistics, research methods, and\/or health information analysis and presentation. This individual will work with a variety of programs and consult with them on their data needs. This part-time position will collaborate with internal and external epidemiologists, analysts, and program staff to conduct research on cutting-edge and emerging health issues.\nWhat You'll Do\nConduct routine data management activities, analyses and interpretations, report writing, and data visualization projects to meet grant reporting and evaluation needs for programs.\nDesign and execute complex analyses\/research that furthers program goals and supports the mission of public health organizations in Missouri.\nDevelop methods and tools for data collection and analysis in addition to creating and\/or updating data dissemination products such as grant-related reports, maps, presentations, factsheets, or dashboards.\nProvide analytical support for public health epidemiology \/ surveillance needs, including data linkages and analysis, program evaluation, needs assessment, and responding to data requests.\nWork on special data analytic projects that contribute towards the advancement of knowledge and practices for improving maternal child health, chronic disease and communicable disease epidemiology in Missouri.\nProvide analytical consultation and support to other internal and external programs as needed.\nMinimum Qualifications\nAll you need for success:\nBachelor\u201a\u00c4\u00f4s degree and 4-6 years of relevant experience and\/or appropriate certification (Substitutions allowed.)\nKnowledge of data management, research design, and current analytical\/statistical methods\nA high degree of analytical expertise, and the ability to use substantial independent judgment when applying technical concepts and methodologies\nAbility to plan and execute complex research studies, conduct comprehensive data analysis, and interpret data\nExperience with SAS, SQL, or other analytical software and general programming techniques required and their applications in public health\nExperience with Microsoft Office Suite and the ability to quickly learn new systems and applications (such as ArcGIS, SQL Server, or Tableau)\nLack of post-secondary education will not be used as the sole basis denying consideration to any applicant.\nIf You Have Questions About This Position Please Contact\nKatie Long, Katie.Long@health.mo.gov\nThe State of Missouri is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\nShow more\nShow less",
      "job_skills":"SAS, SQL, ArcGIS, SQL Server, Tableau, Microsoft Office Suite, Data management, Research design, Analysis, Data visualization, Statistics, Epidemiology, Data linkages, Needs assessment, Data dissemination, Analytical consultation, Programming techniques",
      "Category":"Data Science"
  },
  {
      "job_title":"Master Data Analyst",
      "company":"SSM Health",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/master-data-analyst-at-ssm-health-3742536117",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"It's more than a career, it's a calling.\nMO-REMOTE\nWorker Type:\nRegular\nJob Highlights:\nSSM Health \u201a\u00c4\u00ee a nationally recognized Catholic, not-for-profit integrated health system serving Illinois, Missouri, Oklahoma, and Wisconsin \u201a\u00c4\u00ee is seeking a Master Data Analyst.\nTo confidentially submit your interest or nominate a fellow colleague, please contact:\nDonald R. Schlag\nExecutive and Professional Recruiter\nDonald.Schlag@SSMHealth.com\nJob Summary:\nParticipates on collaborative team to create and maintain master data elements including item file, contract data and price lists, and ensures system data integrity in accordance with guidelines and internal controls.\nJob Responsibilities and Requirements:\nPrimary Responsibilities\nBuilds and maintains contracts, item files, vendor files, transmissions and pricing in database.\nFollows system-wide processes to minimize non-file purchases through reporting and item file management.\nReviews and analyzes materials data for consistency and accuracy. Investigates, reconciles and determines reason for pricing and other irregularities. Identifies results not meeting standard thresholds.\nInvestigates pricing discrepancies by reviewing contracts and initiating credit requests with vendors.\nServes as key member of team to coordinate data elements that integrate with clinical and financial information systems.\nProvides support for process owners, health ministries and their associates; answers questions, resolves issues or errors, and escalates issues that cannot be resolved.\nCollaborates with leadership to improve process efficiency.\nPerforms other duties as assigned.\nEDUCATION\nBachelor's degree or equivalent years of experience or education\nExperience\nFive years' experience\nDepartment:\n8725030033 Purchasing\nWork Shift:\nDay Shift (United States of America)\nScheduled Weekly Hours:\n40\nSSM Health is an equal opportunity employer. SSM Health does not discriminate on the basis of race, color, religion, national origin, age, disability, sex, sexual orientation, gender identity, pregnancy, veteran status\n,\nor any other characteristic protected by applicable law. Click here to learn more.\nShow more\nShow less",
      "job_skills":"Master Data Analyst, Database, Contracts, Item Files, Vendor Files, Transmissions, Pricing, Systemwide Processes, Reporting, Item File Management, Materials Data, Consistency, Accuracy, Investigations, Reconciliation, Pricing Discrepancies, Clinical Information Systems, Financial Information Systems, Process Owners, Health Ministries, Associates, Leadership, Process Efficiency",
      "Category":"Data Science"
  },
  {
      "job_title":"Master Data Analyst",
      "company":"SSM Health",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/master-data-analyst-at-ssm-health-3742532785",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"It's more than a career, it's a calling.\nMO-REMOTE\nWorker Type:\nRegular\nJob Highlights:\nSSM Health \u201a\u00c4\u00ee a nationally recognized Catholic, not-for-profit integrated health system serving Illinois, Missouri, Oklahoma, and Wisconsin \u201a\u00c4\u00ee is seeking a Master Data Analyst.\nTo confidentially submit your interest or nominate a fellow colleague, please contact:\nDonald R. Schlag\nExecutive and Professional Recruiter\nDonald.Schlag@SSMHealth.com\nJob Summary:\nParticipates on collaborative team to create and maintain master data elements including item file, contract data and price lists, and ensures system data integrity in accordance with guidelines and internal controls.\nJob Responsibilities and Requirements:\nPrimary Responsibilities\nBuilds and maintains contracts, item files, vendor files, transmissions and pricing in database.\nFollows system-wide processes to minimize non-file purchases through reporting and item file management.\nReviews and analyzes materials data for consistency and accuracy. Investigates, reconciles and determines reason for pricing and other irregularities. Identifies results not meeting standard thresholds.\nInvestigates pricing discrepancies by reviewing contracts and initiating credit requests with vendors.\nServes as key member of team to coordinate data elements that integrate with clinical and financial information systems.\nProvides support for process owners, health ministries and their associates; answers questions, resolves issues or errors, and escalates issues that cannot be resolved.\nCollaborates with leadership to improve process efficiency.\nPerforms other duties as assigned.\nEDUCATION\nBachelor's degree or equivalent years of experience or education\nExperience\nFive years' experience\nDepartment:\n8725030033 Purchasing\nWork Shift:\nDay Shift (United States of America)\nScheduled Weekly Hours:\n40\nSSM Health is an equal opportunity employer. SSM Health does not discriminate on the basis of race, color, religion, national origin, age, disability, sex, sexual orientation, gender identity, pregnancy, veteran status\n,\nor any other characteristic protected by applicable law. Click here to learn more.\nShow more\nShow less",
      "job_skills":"Master Data Analyst, Contract Data, Price Lists, Item File, Clinical Information Systems, Financial Information Systems, Database Management, Data Integrity, Contract Management, Vendor Management, Pricing Discrepancies, Credit Requests, Process Improvement, Team Collaboration, Problem Resolution, Escalation Management, Bachelor's Degree, 5 Years Experience, Purchasing, Day Shift",
      "Category":"Data Science"
  },
  {
      "job_title":"Associate Research\/Data Analyst - 5034196",
      "company":"State of Missouri",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/associate-research-data-analyst-5034196-at-state-of-missouri-3781637863",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Associate Research\/Data Analyst\nDepartment of Revenue \u201a\u00c4\u00ec Taxation Division \u201a\u00c4\u00ec Income Tax Bureau\nAnnual Salary: $ 45,006.24\nLocation: 301 West High Street, Jefferson City, MO\nDOR\u201a\u00c4\u00f4s Vision: To provide every customer the best experience every time.\nHow This Position Supports The Department\u201a\u00c4\u00f4s Vision\nThis position is the Department of Revenue\u201a\u00c4\u00f4s Federal and State Coordinator and the liaison with the Internal Revenue Service and state tax agencies. The main responsibility of this position is to ensure federal tax information that the Department of Revenue receives from the Internal Revenue Service is safeguarded to the requirements in IRS Publication 1075. Create procedures and conduct educational sessions on IRS Pub 1075 requirements and on other Income Tax Bureau processes and functions. Advise Department of Revenue team members on IRS Pub 1075 requirements as needed. Analyze tax data. Work with other Departments to create agreements between the Department of Revenue and other agencies.\nThis position requires the candidate to work independently, have good organizational, written and verbal communication skills, and be able to prioritize duties and adjust as priorities change.\nDuties Performed To Support The Department\u201a\u00c4\u00f4s Vision\nSelf-Directed\nAttention to Detail\nOrganized\nEffective Writing\nProfessional\nExcellent Time Management\nSafeguarding Federal Tax Information\nCommunication between the Internal Revenue Service and the Missouri Department of Revenue\nCore Compentencies Needed\nComputer Literacy Effective Writing Excellent Customer Service\nSelf-directed Attention to Detail Analytical Thinking\nClear Communication Organizational Abilities\nQualifications\nKnowledge of basic research methods and analysis, computer information systems, and statistical software.\nAbility to perform basic queries and analysis of data.\nBachelor\u201a\u00c4\u00f4s degree and 0-2 years of relevant experience and\/or appropriate certification. (Substitutions may be allowed.)\nMore Reasons To Love This Position\nThe State of Missouri offers an excellent benefits package that includes a defined pension plan, generous amounts of leave and holiday time, and eligibility for health insurance coverage. Your total compensation is more than the dollars you receive in your paycheck. To help demonstrate the value of working for the State of Missouri, we have created an interactive Total Compensation Calculator. This tool provides a comprehensive view of benefits and more that are offered to prospective employees. The Total Compensation Calculator and other applicant resources can be found here .\nPlease Direct Any Questions About This Position To\nThe Missouri Department of Revenue Human Resources and Total Rewards office at (573) 751-1291.\nWe celebrate diversity and are committed to creating an inclusive environment for all employees\nThe State of Missouri is an equal opportunity employer.\nShow more\nShow less",
      "job_skills":"Research methods, Data analysis, Statistical software, Data queries, IRS Publication 1075, IRS Pub 1075 requirements, Clear communication, Effective writing, Excellent time management, Safeguarding federal tax information, Computer literacy, Core competencies, Attention to detail, Selfdirected, Analytical thinking, Organizational abilities, Basic research methods, Computer information systems",
      "Category":"Data Science"
  },
  {
      "job_title":"Associate Scientist, Data Review",
      "company":"Eurofins BioPharma Product Testing (US)",
      "job_location":"Columbia, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/associate-scientist-data-review-at-eurofins-biopharma-product-testing-us-3782889523",
      "search_city":"Missouri",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nEurofins BPT-Columbia is looking for a\nAssociate Scientist, Data Review\nto join our Quality Assurance team located in Columbia, Missouri. The Quality Assurance Associate position is an entry-level position involved in day-to-day activities in a laboratory setting under prescribed processes (protocols, standard operating procedures, methods, etc.).\nResponsibilities include reviewing scientific reports under CGMP guidelines, and assisting with internal audits. The Quality Assurance Associate I review scientific reports to ensure regulatory requirements have been met, data is whole and accurate and the report generated is of high quality. Quality Assurance Associates work closely with laboratory operations staff on a day-to-day basis and have the authority and responsibility for final report sign-off.\nShow more\nShow less",
      "job_skills":"Data Review, Quality Assurance, CGMP, Laboratory Operations, Report Generation, Regulatory Compliance, Data Analysis, Data Integrity, SOPs, Protocols, Methods, Internal Audits",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst I",
      "company":"Lockton",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-i-at-lockton-3774281918",
      "search_city":"Excelsior Springs",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Your Responsibilities\nDescription:\nCollects data and analyzes client information\nWork collaboratively with managers and other teammates to collect data, ensuring reporting is accurate, timely, and of high quality.\nAudits data results and reports findings to supervisors\nPrepares standard and ad hoc reports\nFacilitates process and complete pricing comparisons for request for proposals (RFPs)\nAnalyzes client data in conjunction with other consultants to recommend plan design changes, programs or formulary changes\nIntegrates data from multiple data sets into relevant systems for reports publication.\nFollows policies, procedures, and\/or reports that make the overall practice more efficient and effective\nSupports standard data sets monthly within relevant systems\nCoordinates new client set-up, including file submission and testing, with consultants and system administrators\nGathers new reporting requirements from business users and coordinate development\/deployment with system administrators\nQualifications\nQualifications:\nBachelor's degree required. Major in Actuarial Science, Mathematics, Statistics or Finance.\nMS Excel experience required. In addition, experience using SQL and MS Access a plus.\nUnderstands data sources, processes, formulas and output General knowledge of healthcare issues and their associated impacts on plan sponsors and plan members.\nAbility to understand data integrity and correctness.\nExcellent written and oral communication skills to effectively present information to Associates at all levels of the Lockton organization.\nStrong proactive style.\nProven ability to manage multiple projects simultaneously.\nUnderstands industry trends and governmental regulations\nAbility to complete continuing education requirements as needed\nAbility to attend company, department, and team meetings as required, including industry training sessions\nAbility to comply with all company policies and procedures, proactively protecting confidentiality of Client and company information\nAbility to efficiently organize work and manage time in order to meet deadlines\nAbility to travel by automobile and aircraft\nAbility to use office equipment such as a computer, keyboard, calculator, photocopier, and facsimile machine\nAbility to work on a computer for a prolonged amount of time\nAbility to work outside of normal business hours as needed\nLegally able to work in the United States\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Collection, MS Excel, SQL, MS Access, Data Reporting, Pricing Comparisons, Data Integration, Healthcare Issues, Data Integrity, Communication Skills, Project Management, Industry Trends, Continuing Education, Confidentiality, Time Management, Travel, Office Equipment, Prolonged Computer Work, Outside Work Hours",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Brooksource",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-brooksource-3763821614",
      "search_city":"Collinsville",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Associate Data Analyst\nSt. Louis, MO\n(Required to go onsite 3X\/week - no remote candidates will be considered)\nContract-to-hire\n$60-65k\nAs the Associate Data Analyst, you will analyze data to promote client growth alongside a product analytics team of a Fortune 15 company. You will utilize SQL to support in the reporting of client specific analyses, as well as support in the buildout of client dashboard templates. You will have the ability to present findings to various stakeholders and collaborate cross functionally with business teams. This is a great opportunity to access mentorship and training in various technologies.\nMinimum Qualifications:\n\u00ac\u2211 Bachelor\u201a\u00c4\u00f4s Degree OR relevant equivalent experience (Military, technical bootcamp, etc.)\n\u00ac\u2211 Solid understanding and hands on experience with SQL\n\u00ac\u2211 Familiarity or ability to tell a data story through visualization tools, Tableau is a plus\n\u00ac\u2211 Data Presentation experience through classroom or internship projects\n\u00ac\u2211 Passion for working with clients and collaborating with high-level stakeholders\nResponsibilities:\n\u00ac\u2211 Write SQL to create new queries and dashboards that will become standard for client visits\n\u00ac\u2211 Analyze client data and visualize this analysis within Tableau dashboards\n\u00ac\u2211 Present data and conclusions to stakeholders on a daily basis\n\u00ac\u2211 Aid in general project coordination tasks including coordinating client events to ensure they are properly supported\nWhat\u201a\u00c4\u00f4s In It For You?\n\u00ac\u2211 Opportunity to start your career at a Fortune 15 Healthcare Company\n\u00ac\u2211 You will be trained and mentored by senior technologists\n\u00ac\u2211 You will attend networking events with senior leadership\n\u00ac\u2211 Weekly paychecks\nShow more\nShow less",
      "job_skills":"SQL, Tableau, Data visualization, Data analysis, Client presentation, Project coordination, Client support",
      "Category":"Data Science"
  },
  {
      "job_title":"Big Data Developer",
      "company":"Sigmaways Inc",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-developer-at-sigmaways-inc-3778728506",
      "search_city":"Collinsville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"We are looking for a\nBig data Developer\nwho will contribute to high-quality technology solutions that address business needs by developing data applications for the customer business lines. You will contribute to the development and ongoing maintenance of several strategic data initiatives and data and analytic applications.\nResponsibilities:\nHands-on development role focused on creating big data and analytics solutions.\nCoding of mission-critical components.\nA strong Big data developer\/coder who can write database queries and also tune those queries to perform optimally.\nAnalyze business and functional requirements and contribute to the overall solution.\nParticipate in design reviews, and provide input to the design recommendations.\nParticipate in project planning sessions with project managers, business analysts, and team members.\nRequired skills:\nBS or MS in Computer Science or equivalent experience.\nSoftware development experience with solid working experience in Big Data technologies.\nKnowledge of the architecture and internals of technologies in the Hadoop ecosystem\nExperience designing and implementing large, scalable distributed systems.\nMust have solid expertise and hands-on experience in\nSpark,\nScala and SQL\nS\nolid experience of the Hadoop Ecosystem ( HDFS, Yarn, MapReduce, Spark, Hive, Impala )\nand should be able to mentor and lead junior team members.\nGood understanding of database technologies, including SQL and NoSQL databases\nAbility to debug and promptly resolve production issues.\nProficiency with advanced object-oriented programming.\nExcellent problem-solving and analytical skills.\nExcellent written and oral communication skills.\nShow more\nShow less",
      "job_skills":"Big data, Data applications, Data analytics, Database queries, Hadoop ecosystem, Spark, Scala, SQL, HDFS, Yarn, MapReduce, Hive, Impala, NoSQL databases, Objectoriented programming, Problemsolving, Analytical skills, Communication skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Master Data Analyst",
      "company":"Kforce Inc",
      "job_location":"Ballwin, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/master-data-analyst-at-kforce-inc-3777072399",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nKforce has a client that is looking for a Master Data Analyst in Ballwin, MO. Summary: We are seeking a tech-savvy and motivated Master Data Analyst to join our Master Data Team. Reporting to the Master Data Team Lead, the successful candidate will be responsible for ensuring the accuracy, consistency, and optimization of our master data sets. This role offers an excellent opportunity for growth within the organization and to contribute to our data management strategies. Responsibilities:\nMaster Data Analyst will collaborate with various teams to understand data requirements and ensure the accuracy and completeness of master data sets\nConduct data entry, validation, and maintenance tasks to uphold consistency and integrity of master data\nAssist in identifying and resolving data quality issues and discrepancies\nContribute to the development and implementation of data governance policies and best practices\nAs a Master Data Analyst, you will generate reports and provide data analysis to support decision-making processes\nParticipate in data-related projects and initiatives aimed at enhancing data quality and operational efficiency\nStay updated on industry best practices and emerging trends in data management\nRequirements\nBachelor's degree in Computer Science, Information Systems, or business related field\n1-3 years of experience in data analysis, preferably in master data mgmt. or a related field\nTech-savvy individual with basic understanding of enterprise resource planning (ERP) systems (e.g., IQMS, Oracle), database management systems (e.g., SQL) and data visualization tools (e.g., Power BI)\nStrong analytical skills with proficiency in data analysis tools and techniques\nExcellent communication and collaboration skills to work effectively within a team environment\nDetail-oriented with a commitment to maintaining data accuracy and integrity\nEagerness to learn and grow within the organization\nAbility to adapt to changing priorities and handle multiple tasks concurrently\nThe pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.\nWe offer comprehensive benefits including medical\/dental\/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.\nNote: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.\nThis job is not eligible for bonuses, incentives or commissions.\nKforce is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nSalary: $35 - $50 per hour\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Mining, Data Visualization, SQL, Power BI, ERP, Data Governance, Data Quality, Communication, Collaboration, Problem Solving, Team Work, Attention to Detail, Adaptability, Multitasking",
      "Category":"Data Science"
  },
  {
      "job_title":"IT Data Integration Analyst",
      "company":"Woodgrain",
      "job_location":"Chesterfield, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/it-data-integration-analyst-at-woodgrain-3789876552",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Full-Time, Exempt\nLocation:\nSt. Louis, MO\nSalary:\n$58,000 - $70,000\n(depending on experience)\nHybrid Work Schedule (3\/2)\nWoodgrain, Inc. offers competitive salaries, an annual incentive bonus, and great benefits.\nCurrent benefits include:\n401(k) with employer match, Medical (PPO or HSA), Dental, Vision, Employer paid Life Insurance and AD&D, Employer paid Short- and Long-Term Disability, voluntary supplemental hospital and accident plans, supplement long-term disability and life insurance plans, 9 annual paid holidays, and progressive paid time off accruals.\nJob Summary:\nThe Integration Analyst is responsible for serving as the liaison between business users, BPOs and other IT analysts to document business requirements, process, and procedures surrounding EDI and Data Integration needs. This position works closely with IT development resources to design and test technical solutions for EDI and Data Integration through the various applications. A secondary function of this position is to provide monitoring and support for the implemented systems to ensure stability and identify areas of improvements.\nRequirements:\nBachelor's degree in a technical area such as Computer Science, Information Technology, or MIS. Equivalent relevant experience can be considered in lieu of a degree.\n1 to 3 years working as a Business Analyst or in a similar role.\nPrior experience working with EDI process, integration applications, ETL technologies, Value Added Networks (VAN), and EDI standards is required.\nKnowledge of SAP PO is preferred.\nAdditional Skills:\nAbility to effectively communicate in English, both verbally and in writing. Additional languages preferred.\nExcellent customer service skills.\nExcellent computer knowledge and skills.\nEffective oral and written communication skills.\nCome join the Woodgrain Family! #\nWoodgrain, Inc. is an EEO employer offering our employees a drug, alcohol, and tobacco-free work environment. All offers of employment are contingent on background and pre-employment drug screening.\nApplications are being accepted until 12\/29\/2023\nPowered by JazzHR\n5sVNK4Lk32\nShow more\nShow less",
      "job_skills":"EDI, Data Integration, IT Development, Monitoring, SAP PO, ETL, VAN, English, Customer Service, Computer Knowledge, SAP PO",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"Cloudflare",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-cloudflare-3732383583",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"About Us\nAt Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world\u201a\u00c4\u00f4s largest networks that powers approximately 25 million Internet properties, for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine\u201a\u00c4\u00f4s Top Company Cultures list and ranked among the World\u201a\u00c4\u00f4s Most Innovative Companies by Fast Company.\nWe realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!\nData Center Operations Engineer\nAbout the department\nIn this role, you will be focused on maintaining the Clou dflare global network. You 'll work closely with Cloudflare\u201a\u00c4\u00f4s SRE (Site Reliability Engineering) team, Network Engineering team, Network Deployment Engineering team and with various vendors and partners (including hardware vendors, datacenter and network providers, and ISPs) to maintain and improve our global infrastructure. You will further be responsible for the development and implementation of consistent processes and visibility measurements for consistent and effective management of our infrastructure. This is a highly visible position that requires deep technical understanding of datacenter infrastructure, networking (physical), and basic experience with data analysis and project management.\nTo be successful in this position, you should have excellent technical skills, communication skills, and be able to navigate a range of challenges and constraints (e.g. schedule adherence, time zones, and cultures). You will have the opportunity to (literally) build a faster, safer Internet for our millions of users and the billions of web surfers that visit their sites each month.\nWho You Are\nYou will thrive in a hypergrowth engineering environment and be self driven with a keen attention to detail. You will come with a deep technical understanding of Data Center colocation environments, network architecture and server technologies. You will be used to working through partners to support infrastructure delivery to a number of remote locations. You will have had experience managing operational environments, and used to developing new approaches to improve delivery efficiency or operational stability.\nWhat You'll Do\nCollaborating with internal teams (Infrastructure, Network Engineering and SRE). Create documentation and manage remote contractors to complete datacenter tasks, working with hardware manufacturers, datacenter and network providers, logistics partners and other service providers in support of our 300+ datacenter locations\nMaintain Data Center environment operational availability\nCreating and maintaining documentation, plans, SOP\u201a\u00c4\u00f4s, MOP\u201a\u00c4\u00f4s etc.\nSupport and configure network infrastructure where required\nProviding feedback to internal teams to support internal tools and external vendor partnerships\nRequired Experience\nMinimum of 5 yrs of Linux systems administration\nExperience with Juniper, Cisco and DWDM network equipment\nExperience managing and instructing remote contractors\nFamiliarity with work required to stand up infrastructure in remote colocation facilities\nExperience running and improving operational processes, including automation tooling, in a rapidly changing environment\nFamiliarity with day-to-day tasks and projects common to Data Center Operations (deployment, migration, decommissioning etc.)\nComfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA\nIncident management\nOther Responsibilities May Include\nAggressively seek opportunities to introduce cutting-edge technology and automation solutions that are effective, efficient and scalable in order to improve our ability to deploy and maintain our global infrastructure\nAssist with the definition, documentation and implementation of consistent processes across all region\nLimited travel\nExamples Of Desirable Skills, Knowledge And Experience\nBachelor\u201a\u00c4\u00f4s degree; technical background in engineering, computer science, or MIS\nDirect experience executing on complex data center\/infrastructure projects\nPrevious experience installing \/ maintaining data center (and other IT) infrastructure and DCIM tools\nExperience running and improving operational processes in a rapidly changing environment\nStrong verbal and written communication skills, problem-solving skills, attention to detail, and interpersonal skills\nMust be proactive with proven ability to learn fast and execute on multiple tasks simultaneously\nAbility to manage MS excel and Google spreadsheets\nComfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA\nMust be a team player\nBonus Points\nMulti-lingual; experience working with infrastructure in multiple countries\nComfortable with remote \u201a\u00c4\u00falights-out\u201a\u00c4\u00f9 and out-of-band access to data center resources\nLinux certifications (RHCSA etc.)\nNetwork certifications (CCNA, JNCIA or higher)\nCompensation\nCompensation may be adjusted depending on work location.\nFor Colorado-based hires: Estimated annual salary of $ 111,000 - $ 135,000 .\nFor New York City, Washington, and California (excluding Bay Area) based hires: Estimated annual salary of $ 135,000 - $ 165,000\nFor Bay Area-based hires: Estimated annual salary of $ 142,000 - $ 174,000 .\nEquity\nThis role is eligible to participate in Cloudflare\u201a\u00c4\u00f4s equity plan.\nBenefits\nCloudflare offers a complete package of benefits and programs to support you and your family. Our benefits programs can help you pay health care expenses, support caregiving, build capital for the future and make life a little easier and fun! The below is a description of our benefits for employees in the United States, and benefits may vary for employees based outside the U.S.\nHealth & Welfare Benefits\nMedical\/Rx Insurance\nDental Insurance\nVision Insurance\nFlexible Spending Accounts\nCommuter Spending Accounts\nFertility & Family Forming Benefits\nOn-demand mental health support and Employee Assistance Program\nGlobal Travel Medical Insurance\nFinancial Benefits\nShort and Long Term Disability Insurance\nLife & Accident Insurance\n401(k) Retirement Savings Plan\nEmployee Stock Participation Plan\nTime Off\nFlexible paid time off covering vacation and sick leave\nLeave programs, including parental, pregnancy health, medical, and bereavement leave\nWhat Makes Cloudflare Special?\nWe\u201a\u00c4\u00f4re not just a highly ambitious, large-scale technology company. We\u201a\u00c4\u00f4re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.\nProject Galileo\n: We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare\u201a\u00c4\u00f4s enterprise customers--at no cost.\nAthenian Project\n: We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.\nPath Forward Partnership\n: Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.\n1.1.1.1\n: We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here\u201a\u00c4\u00f4s the deal - we don\u201a\u00c4\u00f4t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.\nSound like something you\u201a\u00c4\u00f4d like to be a part of? We\u201a\u00c4\u00f4d love to hear from you!\nThis position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.\nCloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA\/Veterans\/Disabled Employer.\nCloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.\nShow more\nShow less",
      "job_skills":"Linux, Juniper, Cisco, DWDM, MS Excel, Google Spreadsheets, JIRA, RHCSA, CCNA, JNCIA, Virtual Data Center Management, Network Architecture, Server Technologies",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer - Kansas City",
      "company":"DeRisk Technologies",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-kansas-city-at-derisk-technologies-3766680683",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Job Responsibilities:\nDeployment \/ In-Scope Configuration Items\nServers (Virtual & Physical)\nStorage & Backup Devices\nServer Appliances\nHyper Converged Infrastructure (E.g. Nutanix, Cisco UCS)\nTape Storage Units\nPower Distribution Units rated 3KVA and below\nSAN Fabric Switches\nNetwork Switches\nKVM Units\nWAN Optimization Devices\nFirewalls\nAccess Points\nRouters\nPhysical Cabling\nCable Management\nCables which connect the device to itself, a peripheral, or a power\/network port Break-fix \/ Technical Tasks List\nPower Cycling\nRunning Diagnostics Commands\nConducting whole unit replacement\nInserting\/Removing Media\nReplacing Defective Components\nAssist with fault diagnosis and investigation\nConfiguring Remote Access\nBasic Storage Array Configuration\nReplacing faulty cables\nTape Management and Maintenance\nRebooting routers, servers, storage devices or other equipment\nOperations Tasks List\nUpdating and Recording of activities in relevant IT Ticket Management System\nCoordinating and agreeing attendance time and date with key stakeholders\nProvide support either through phone, remote tools, or in person at onsite\nPerform installation as needed either through physical or network medium\nCoordinate actual activity date and timings including arrival and departure times\nCarry all necessary tools, laptops etc. which might be needed to support issues in the infrastructure environment\nLabelling, Patching and Asset Tagging activities\nFollowing specific task instructions and provision necessary reporting as necessary\nRequirements\nJob Requirements:\nTechnical Skills\nGood general understanding of IT principles such as Networks, Hardware and Domains\nKnowledge of Infrastructure (Data Center and Network) hardware architecture as to understand the procedure shared by L3 teams during troubleshooting,H&E support\nKnowledge of server\/client operations in a domain environment including Active Directory\nUnderstanding of current and legacy hardware Infrastructure platforms\nHands-on experience in installation and troubleshooting Infrastructure (DC & Network) equipment's, Rack and Stack of the equipment\/cable\nGood Hands-on Experience in IMAC and Break-fix activities related to Infrastructure environment\nAbility to identify Excellent the right defective spares and replace them with provided good spares as instructed and by physical observations\nKnowledge of TCP\/I P standards and networking\nExperience with Tape Management activities\nExcellent knowledge of best practices around management, control, and monitoring of server infrastructure\nFamiliarity with backup and recovery software and methodologies\nLanguage skills needed\nEnglish Soft Skills\nExceptional customer facing skills\nAble to communicate clearly and effectively both with Client and the Customer\nLogical and analytical approach to work\nAccurate record keeping\nAble to work unsupervised\nGood timekeeper\nIntense focus on quality work\nProductive and Efficient Academic Background\nBachelor of Engineering \/ Technology \/ Science or Equivalent Work Experience Overall Experience (in yrs.)\n5 - 7 years (min\nBenefits\nSalary and Benefits as per market standard\nShow more\nShow less",
      "job_skills":"Networking, Hardware, Active Directory, Data Center, Rack and Stack, IMAC, Breakfix, Troubleshooting, TCP\/IP, Backup, Recovery, English",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Electrical Engineer - Data Center",
      "company":"Olsson",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-electrical-engineer-data-center-at-olsson-3759391574",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Company Description\nWe are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.\nOur most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u201a\u00c4\u00ee and will continue to allow us \u201a\u00c4\u00ee to grow. The result? Inspired people, amazing designs, and projects with purpose.\nJob Description\nAs an Electrical Engineer, you will work directly with some of the world\u201a\u00c4\u00f4s largest technology companies and other mission-critical clients. You will serve as an electrical engineer on projects, design calculations, write technical reports, and prepare documents. Experience in the Data Center industry is preferred. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients.\nQualifications\nYou are passionate about:\nWorking collaboratively with others\nHaving ownership in the work you do\nUsing your talents to positively affect communities\nYou bring to the team:\nStrong communication skills\nAbility to contribute and work well on a team\nBachelor's degree in electrical engineering\n8+ years of electrical engineering experience\nLicensed PE\nAbility to be a self-starter to take on a variety of tasks to best serve the client and their project work\nInvestigation and troubleshooting of problems to find solutions\nAdditional Information\nOlsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u201a\u00c4\u00f4re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.\nAs an Olsson employee, you\u201a\u00c4\u00f4ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u201a\u00c4\u00f4ll:\nBecome an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)\nEngage in work that has a positive impact in communities\nReceive an excellent 401(k) match\nParticipate in a wellness program promoting balanced lifestyles\nBenefit from a bonus system that rewards performance\nHave the possibility for flexible work arrangements\nOlsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.\nShow more\nShow less",
      "job_skills":"Electrical Engineering, Project Design, Technical Reports, Data Center, Communication, Teamwork, Investigation, Troubleshooting, Problem Solving, Licenses, CAD, PE",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Electrical Engineer - Arc Flash - Data Center (Remote)",
      "company":"Olsson",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-electrical-engineer-arc-flash-data-center-remote-at-olsson-3737828943",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Company Description\nWe are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.\nOur most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u201a\u00c4\u00ee and will continue to allow us \u201a\u00c4\u00ee to grow. The result? Inspired people, amazing designs, and projects with purpose.\nJob Description\nAs an Electrical Engineer, you will work directly with some of the world\u201a\u00c4\u00f4s largest technology companies and other mission-critical clients. You will serve as an electrical engineer on projects, design calculations, write technical reports, and prepare documents. Experience in performing short circuit analysis and producing arc flash studies is required. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients. You may travel to job sites for observation and attend client meetings.\nWe currently have one opening and will consider candidates interested in being located in most locations across the United States.\nQualifications\nYou are passionate about:\nWorking collaboratively with others\nHaving ownership in the work you do\nUsing your talents to positively affect communities\nElectrical Engineering knowledge\nYou bring to the team:\nStrong communication skills\nAbility to contribute and work well on a team\nAbility to be a self-starter to take on a variety of tasks to best serve the client and their project work\nInvestigation and troubleshooting of problems to find solutions\nAbility to contribute and work well on a team\nBachelor's Degree in electrical engineering\n8+ years or related electrical engineering experience\nRegistered professional engineer (PE) required\nSKM and ETAP software experience is preferred\nAdditional Information\nOlsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u201a\u00c4\u00f4re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.\nAs an Olsson employee, you\u201a\u00c4\u00f4ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u201a\u00c4\u00f4ll:\nBecome an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)\nEngage in work that has a positive impact in communities\nReceive an excellent 401(k) match\nParticipate in a wellness program promoting balanced lifestyles\nBenefit from a bonus system that rewards performance\nHave the possibility for flexible work arrangements\nOlsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.\nShow more\nShow less",
      "job_skills":"Electrical Engineering, Communication, Collaboration, Problem Solving, Troubleshooting, SKM, ETAP, Arc Flash Studies, Short Circuit Analysis",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Mechanical Engineer - Data Center",
      "company":"Olsson",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-mechanical-engineer-data-center-at-olsson-3775327283",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Company Description\nWe are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.\nOur most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u201a\u00c4\u00ee and will continue to allow us \u201a\u00c4\u00ee to grow. The result? Inspired people, amazing designs, and projects with purpose.\nJob Description\nAs a Mechanical Engineer, you will work directly with some of the world\u201a\u00c4\u00f4s largest technology companies and other mission-critical clients. You will serve as a mechanical engineer on projects, design calculations, write technical reports, and prepare documents. Experience in the Data Center industry is preferred. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients.\nQualifications\nYou are passionate about:\nWorking collaboratively with others\nHaving ownership in the work you do\nUsing your talents to positively affect communities\nYou bring to the team:\nStrong communication skills\nAbility to contribute and work well on a team\nBachelor's degree in mechanical engineering\n8+ years of mechanical engineering experience\nLicensed PE\nAbility to be a self-starter to take on a variety of tasks to best serve the client and their project work\nInvestigation and troubleshooting of problems to find solutions\nAdditional Information\nOlsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u201a\u00c4\u00f4re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.\nAs an Olsson employee, you\u201a\u00c4\u00f4ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u201a\u00c4\u00f4ll:\nBecome an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)\nEngage in work that has a positive impact in communities\nReceive an excellent 401(k) match\nParticipate in a wellness program promoting balanced lifestyles\nBenefit from a bonus system that rewards performance\nHave the possibility for flexible work arrangements\nOlsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.\nShow more\nShow less",
      "job_skills":"Mechanical Engineering, Data Center, Design Calculations, Technical Reports, Document Preparation, Communication, Teamwork, AutoCAD, Pro Engineer, SolidWorks, Finite Element Analysis (FEA), Project Management, Problem Solving, Troubleshooting",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Electrical Engineer (Mission Critical\/Data Center)",
      "company":"WSP in the U.S.",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-electrical-engineer-mission-critical-data-center-at-wsp-in-the-u-s-3775563149",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who We Are\nAt WSP, we are driven by inspiring future-ready pioneers to innovate. We\u201a\u00c4\u00f4re looking to grow our teams with people who are ready to collaborate in building communities and expanding our skylines. To do this, we hire candidates of all experiences, skillsets, backgrounds and walks of life. We actively foster a work environment and culture where inclusion and diversity is part of our fundamental structure. This is delivered behaviorally, through our policies, trainings, local partnerships with professional diverse organizations, internal networks and most importantly with the support and sponsorship of our leaders who help drive our commitment to an inclusive, diverse, welcoming and equitable work environment. Anything is within our reach and yours as a WSP employee. Come join us and help shape the future!\nGreat people. Great places. Great projects. kW Mission Critical Engineering, a WSP company, is a high-performance, fast-paced consulting engineering firm designing data centers and mission critical environments across the globe. We hire smart, responsive, team players to work in collaborative and mentoring office settings. Our mechanical, electrical, plumbing, fire protection, controls, telecommunications, and security building system designs keep many of the world\u201a\u00c4\u00f4s top Fortune 100 financial, technology, enterprise, hyperscale, and colocation companies up and running 24 hours a day, 365 days a year.\nWe work on innovative, award-winning, large-scale projects. We travel to construction sites to see our designs being built. As part of WSP, we are able to offer our employees increased professional development and career opportunities in addition to kW MCE\u201a\u00c4\u00f4s office culture which is consistently recognized as one of the \u201a\u00c4\u00faBest Places to Work.\u201a\u00c4\u00f9 Join our great people at our great places designing great projects.\nThis Opportunity\nkW Mission Critical Engineering, a WSP company, is looking for a\nSenior Electrical Engineer\nfor our\nkW Tempe, Arizona office.\nAs an Electrical Engineer with us, you will design complex power and other building systems including generator plants, medium voltage distribution, uninterruptible power systems, lighting, fire alarm, and grounding.\nYour Impact\nDesign electrical systems for buildings including lighting, receptable, general, essential, and critical electrical infrastructure\nWork in a team or independently, planning and executing engineering tasks within projects\nDemonstrate significant understanding of the range of services provided by the kW MCE engineering teams & related practices\nIndependently, support the team during design and construction stages of projects\nLead the electrical design of complex projects\nWork within multi-discipline project teams to develop drawing and specification documents for issuance to architects, contractors and building owners\nAttend client meetings and contribute to discussions\nLead and mentor entry-level and junior engineers\nCollaborate and coordinate with internal project discipline team members, equipment vendors, and manufacturers\nCommunicate complex electrical engineering concepts and decisions to clients and stakeholders\nIntegrate complex electrical engineering requirements into facility designs\nInteract regularly with clients to maintain current relationships and develop new relationships\nLead meetings with internal and external stakeholders\nResearch & recommend fundamental components identified in electrical designs\nDevelop equipment rooms layouts, floor plan, and one-line diagrams\nSchedule equipment\nPrepare short circuit, coordination and arc flash calculations\nPerform construction administration tasks\nSurvey and evaluate existing conditions\nWho You Are\nThe ideal candidate has familiarity with Building Information Modeling using Revit, has strong communication skills, and an interest in liaising with internal and external design, client and construction team members.\nRequired Qualifications\nBachelor\u201a\u00c4\u00f4s degree in Electrical Engineering or Architectural Engineering with electrical building systems emphasis\n5+ years of experience in designing electrical systems for the high performing, commercial, industrial or mission critical\/data center buildings.\nExcellent interpersonal skills, teamwork, and communication skills, both written and verbal\nProficiency with applicable software packages including AutoCAD, Revit, SKM, eTap or Cyme.\nKnowledge of building, electrical and energy codes.\nAbility to organize and present design information to project staff\nAttention to detail, highly organized, self-starter\nAbility to travel to project sites\nPreferred Qualifications:\nEIT or Registered Professional Engineer (PE), if applicable\nExperience with the analysis and modeling of short circuit, coordination, and arc flash analysis\nExperience with the design of highly reliable, robust and concurrently maintainable Medium and Low Voltage infrastructure\nMission Critical\/Data Center experience\nExperience with international projects\nAdditional Requirements\nTo perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.\nAdditional Details\nTravel Required: 20%\nJob Status: Regular\nEmployee Type: Full\nPrimary Location: TEMPE - E RIO SALADO PKWY\nAll locations: US-AZ-Phoenix, US-AZ-Tempe, US-AZ-Tucson, US-MO-Kansas City\nAbout WSP\nWSP USA is the U.S. operating company of WSP, one of the world's leading engineering and professional services firms. Dedicated to serving local communities, we are engineers, planners, technical experts, strategic advisors and construction management professionals. WSP USA designs lasting solutions in the buildings, transportation, energy, water and environment markets. With more than 15,000 employees in over 300 offices across the U.S., we partner with our clients to help communities prosper. www.wsp.com\nWSP provides a flexible and agile workplace model while meeting client needs. Employees are also afforded a comprehensive suite of benefits including medical, dental, vision, disability, life, and retirement savings focused on providing health and financial stability throughout the employee\u201a\u00c4\u00f4s career.\nAt WSP, we want to give our employees the challenges they seek to grow their careers and knowledge base. Your daily contributions to your team will be essential in meeting client objectives, goals and challenges. Are you ready to get started?\nWSP USA (and all of its U.S. companies) is an Equal Opportunity Employer Race\/Age\/Color\/Religion\/Sex\/Sexual Orientation\/Gender Identity\/National Origin\/Disability or Protected Veteran Status.\nThe selected candidate must be authorized to work in the United States.\nNOTICE TO THIRD PARTY AGENCIES:\nWSP does not accept unsolicited resumes from recruiters, employment agencies, or other staffing services. Unsolicited resumes include any resume or hiring document sent to WSP in the absence of a signed Service Agreement where WSP has expressly requested recruitment\/staffing services specific to the position at hand. Any unsolicited resumes, including those submitted to hiring managers or other business leaders, will become the property of WSP and WSP will have the right to hire that candidate without reservation \u201a\u00c4\u00ec no fee or other compensation will be owed or paid to the recruiter, employment agency, or other staffing service.\nShow more\nShow less",
      "job_skills":"Revit, AutoCAD, SKM, eTap, Cyme, Electrical Building Systems, Lighting, Receptacles, Essential Electrical Infrastructure, Critical Electrical Infrastructure, Generator Plants, Medium Voltage Distribution, Uninterruptible Power Systems, Fire Alarm, Grounding, Electrical Engineering, Building Codes, Energy Codes, Short Circuit Calculations, Coordination Calculations, Arc Flash Calculations, Construction Administration, Building Information Modeling",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Scientist, Product Growth",
      "company":"Jerry",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-product-growth-at-jerry-3789682450",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"We'd love to hear from you if you like:\nMaking a big impact with a Forbes Top Startup Employer\nWorking on products that have traction (40X revenue growth in 4 years | #1 rated app in the insurance comparison category)\nSolving problems in a huge market ($2T market size)\nWorking closely with serial entrepreneurs and seasoned leaders who have scaled companies like Robinhood, Amazon, LinkedIn, Wayfair, SoFi, Microsoft, etc.\nAbout the opportunity:\nWe are looking for a Senior Data Scientist to join our central data team and partner with one of our emerging product groups. Helping everyday, hard working Americans save time and money on their cars and creating a world class experience is what drives every decision we make as a company. Since launching our mobile app in 2019, we have amassed over 4M customers, expanded our product offerings to multiple categories and scaled our team 10X. Our data team fuels all of our business and product decisions through delivering analytical insights and building advanced models.\nWorking with a brilliant team of product managers, product designers, software engineers, and key business leaders, you will leverage data and insights to drive growth and retention for one of our emerging product groups (car repair marketplace or chatbot). You will perform analytical deep dives, develop and analyze experiments, build predictive models, and make recommendations that inform our product roadmap and new investment opportunities.\nHow you will make an impact:\nPartner closely with our product managers, software engineers, product designers, and key business leaders to drive user growth and retention for our core insurance product\nDesign, run, and analyze A\/B experiments on new and existing features; extract key insights, share learnings and make recommendations on next steps\nBuild key reports, dashboards, and predictive models to monitor the performance of our insurance business, and communicate analytical outcomes to our teams\nTransform and refine raw production data for analytical needs\nContinually improve our data governance and data consistency standards within our database\nWork with data engineering team on data tracking, integrity, and security as needed\nWork with other data scientists to evolve, optimize and integrate machine learning models\nWho you are:\nIntellectually curious: You're not satisfied with surface level insights. You dive deep to understand how systems work, why people behave in certain ways and are intrinsically motivated to uncover root causes for issues or underlying reasons behind decisions.\nCreative problem-solver: No challenge is too complex, no issue is too hard.\nData-driven: You're extremely analytical and live in data. At the same time, you're confident enough to make decisions when the data is limited.\nStrong communicator: Able to drive alignment and communicate effectively to different audiences.\nIdeal profile:\nBachelor\u201a\u00c4\u00f4s degree in Mathematics, Statistics, Economics, Computer Science or a related discipline\n2+ years of experience as a data scientist or product analyst in a consumer-facing web or mobile app environment\nExperience designing and implementing A\/B tests, and analyzing user experience\nHands-on experience with SQL (advanced proficiency)\nJerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.\nJerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at\nrecruiting@getjerry.com\nAbout Jerry:\nJerry is America\u201a\u00c4\u00f4s first and only AllCar\u201a\u00d1\u00a2 app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets.\nBacked by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all.\nWe are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 4 million customers \u201a\u00c4\u00ee and we\u201a\u00c4\u00f4re just getting started.\nJerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing.\nJoin our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that\u201a\u00c4\u00f4s disrupting a massive market.\nShow more\nShow less",
      "job_skills":"A\/B Testing, Data Analysis, Data Governance, Data Integration, Data Science, Machine learning, Product Management, Software Engineering, Predictive Modeling, SQL, Statistics, Experimentation, Business Intelligence",
      "Category":"Data Science"
  },
  {
      "job_title":"Principal Data and Integration Engineer * 100% Remote \/ W2 Only *",
      "company":"Amerit Consulting",
      "job_location":"Maryland Heights, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-data-and-integration-engineer-100%25-remote-w2-only-at-amerit-consulting-3780541715",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Overview:\nOur client, a US Fortune 500 company and a provider of managed Health care, Pharmacy benefits & specialty areas for managed care organizations \/ employers \/ government agencies, seeks an accomplished\nPrincipal Data and Integration Engineer.\n*** Candidate must be authorized to work in USA without requiring sponsorship ***\n********************************************************\n*** Location: 100% Remote (Maryland Heights, MO)\n*** Duration: 3+ months with possible conversion\nWorking Schedule: Hours: 8am to 5pm Central\nSummary:\nDevelops, tests and maintains code using software development methodology and appropriate technologies for the system being used. Works closely with Business Analysts to develop detail systems design and written test plans for online and report application programs. Participates in design walkthroughs with appropriate focus groups and related users to verify the accuracy of design in meeting business needs. Prepares installation instructions and coordinates installation procedures. Supports and troubleshoots application code problems. Provides status reports that give a detailed description of the current projects progress and indicate time devoted to each task of the project. Coordinates, guides, and mentors programming efforts performed by in-house programmers or outside consultants to ensure that all programming is completed according to the project plan.\nResponsibilities:\nDevelops, tests and maintains code using software development methodology and appropriate technologies for the system being used.\nWorks closely with Business Analysts or System Analyst to develop detailed systems design and written test plans for online and report application programs.\nPerforms analysis on projects and provides a project plan that shows the tasks needing to be completed and a time estimate for each task.\nProvides status reports that give a detailed description of the current project's progress and indicate time devoted to each task.\n3 Must-Haves (Hard Skills):\nHands-on experience in designing, coding, enhancing, testing and production support of custom SQL Server Datawarehouse to meet business process requirements.\nProficient with Excel and creating Apps in Excel using VBCode.\nConfident in Microsoft SQL Server (using SSMS \u201a\u00c4\u00ec Advanced TSQL, Stored Procedures, best practices in RDBMS) best practices for writing clean effective code and balancing Declarative customizations with Programmatic customizations.\nNice-To-Haves (Hard Skills)\nKnowledge\/experience in Oracle (PLSQL using TOAD)\nSalesforce knowledge and experience\nSnapLogic knowledge and experience\nTableau knowledge and experience\n***********************************************************\nI'd love to talk to you if you think this position is right up your alley, and assure a prompt communication, whichever direction.\nIf you're looking for rewarding employment and a company that puts its employees first, we'd like to work with you.\nSam Banga\nLead Recruiter\nCompany Overview:\nAmerit Consulting\nis an extremely fast-growing staffing and consulting firm. Amerit Consulting was founded in 2002 to provide consulting, temporary staffing, direct hire, and payrolling services to Fortune 500 companies nationally; as well as small to mid-sized organizations on a local & regional level. Currently, Amerit has over 2,000 employees in 47 states. We develop and implement solutions that help our clients operate more efficiently, deliver greater customer satisfaction, and see a positive impact on their bottom line. We create value by bringing together the right people to achieve results. Our clients and employees say they choose to work with Amerit because of how we work with them - with service that exceeds their expectations and a personal commitment to their success. Our deep expertise in human capital management has fueled our expansion into direct hire placements, temporary staffing, contract placements, and additional staffing and consulting services that propel our clients\u201a\u00c4\u00f4 businesses forward.\nAmerit Consulting provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\nThis policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\nApplicants, with criminal histories, are considered in a manner that is consistent with local, state and federal laws.\nShow more\nShow less",
      "job_skills":"Software Development Methodology, SQL Server Datawarehouse, Excel, VBCode, Microsoft SQL Server (SSMS), TSQL, Stored Procedures, Best Practices in RDBMS, Oracle (PLSQL), Salesforce, SnapLogic, Tableau",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Architect | TS\/SCI",
      "company":"YO HR Consultancy",
      "job_location":"Springfield, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-architect-ts-sci-at-yo-hr-consultancy-3767417101",
      "search_city":"Spokane",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Overview\nYO HR CONSULTANCY is a leading HR consulting firm operating in the None industry. We specialize in providing comprehensive human resources solutions to companies of all sizes, helping them achieve their talent acquisition and management goals.\nRole And Responsibilities\nWe are currently seeking a highly skilled Senior Data Architect who will be responsible for the design and implementation of data architectures that support our clients' business goals. In this role, you will be working on various projects, researching and evaluating sources of information, applying sampling techniques, analyzing statistical information, and utilizing statistical methods to solve industry-specific problems. You will also be responsible for preparing detailed reports, training team members, and designing computer code to improve software and applications.\nCandidate Qualifications\nBachelor's degree in mathematics, statistics, computer science or a related field\nMinimum 8 years of related data engineering architecture and design\nComfort with Linux\/Windows command line\nMinimum 8 years of system administration and\/or DevOps environment experience\nTS\/SCI Clearance\nRequired Skills\nResearch and analytical skills\nStatistical analysis and problem-solving\nData interpretation and reporting\nTraining and mentoring\nSoftware development and coding\nSkills: automation solutions,data engineer,statistics,architecture,computer science,data engineering architecture,research,voip phone setup,mathematics,device apis,economics,devops,engineering,linux\/windows command line,design,data architecture,statistical methods,computer code,operational metrics,data engineering,data pipelines,sampling techniques,system administration,devops environment\nShow more\nShow less",
      "job_skills":"Linux, Windows, Command line, Statistical analysis, Problemsolving, Data interpretation, Reporting, Software development, Coding, Automation, Data engineering, Research, Architecture, Computer science, Mathematics, Economics, DevOps, System administration, Data engineering architecture, Data pipelines, Sampling techniques, Operational metrics",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Brooksource",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-brooksource-3763821614",
      "search_city":"Collinsville",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Associate Data Analyst\nSt. Louis, MO\n(Required to go onsite 3X\/week - no remote candidates will be considered)\nContract-to-hire\n$60-65k\nAs the Associate Data Analyst, you will analyze data to promote client growth alongside a product analytics team of a Fortune 15 company. You will utilize SQL to support in the reporting of client specific analyses, as well as support in the buildout of client dashboard templates. You will have the ability to present findings to various stakeholders and collaborate cross functionally with business teams. This is a great opportunity to access mentorship and training in various technologies.\nMinimum Qualifications:\n\u00ac\u2211 Bachelor\u201a\u00c4\u00f4s Degree OR relevant equivalent experience (Military, technical bootcamp, etc.)\n\u00ac\u2211 Solid understanding and hands on experience with SQL\n\u00ac\u2211 Familiarity or ability to tell a data story through visualization tools, Tableau is a plus\n\u00ac\u2211 Data Presentation experience through classroom or internship projects\n\u00ac\u2211 Passion for working with clients and collaborating with high-level stakeholders\nResponsibilities:\n\u00ac\u2211 Write SQL to create new queries and dashboards that will become standard for client visits\n\u00ac\u2211 Analyze client data and visualize this analysis within Tableau dashboards\n\u00ac\u2211 Present data and conclusions to stakeholders on a daily basis\n\u00ac\u2211 Aid in general project coordination tasks including coordinating client events to ensure they are properly supported\nWhat\u201a\u00c4\u00f4s In It For You?\n\u00ac\u2211 Opportunity to start your career at a Fortune 15 Healthcare Company\n\u00ac\u2211 You will be trained and mentored by senior technologists\n\u00ac\u2211 You will attend networking events with senior leadership\n\u00ac\u2211 Weekly paychecks\nShow more\nShow less",
      "job_skills":"SQL, Tableau, Data Visualization, Data Analysis, Data Presentation, Client Collaboration, Dashboard Creation, Project Coordination",
      "Category":"Data Science"
  },
  {
      "job_title":"Commissioning Agent - Data Center",
      "company":"Olsson",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/commissioning-agent-data-center-at-olsson-3737832313",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Description\nWe are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.\nOur most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u201a\u00c4\u00ee and will continue to allow us \u201a\u00c4\u00ee to grow. The result? Inspired people, amazing designs, and projects with purpose.\nJob Description\nOlsson has a job opportunity available to work directly with the world\u201a\u00c4\u00f4s largest technology companies. As a Commissioning Agent on the Data Center On-Site Services Team, you will serve as project manager on projects, performing various commissioning functions within the data center. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients. You may travel to job sites for observation and attend client meetings.\nQualifications\nYou are passionate about:\nWorking collaboratively with others\nHaving ownership in the work you do\nUsing your talents to positively affect communities\nYou bring to the team:\nStrong communication skills\nAbility to contribute and work well on a team\nBachelor\u201a\u00c4\u00f4s Degree in engineering preferred\n5 or more years of engineering experience in Data Centers\nRegistered as a professional engineer is preferred\nAdditional Information\nOlsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u201a\u00c4\u00f4re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.\nAs an Olsson employee, you\u201a\u00c4\u00f4ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u201a\u00c4\u00f4ll:\nBecome an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)\nEngage in work that has a positive impact in communities\nReceive an excellent 401(k) match\nParticipate in a wellness program promoting balanced lifestyles\nBenefit from a bonus system that rewards performance\nHave the possibility for flexible work arrangements\nOlsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.\nShow more\nShow less",
      "job_skills":"engineering, data center, project management, communication skills, teamwork, bachelor's degree, engineering experience, professional engineer, planning and design, field services, environmental, technology",
      "Category":"Data Science"
  },
  {
      "job_title":"Master Data Analyst",
      "company":"SSM Health",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/master-data-analyst-at-ssm-health-3742532785",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"It's more than a career, it's a calling.\nMO-REMOTE\nWorker Type:\nRegular\nJob Highlights:\nSSM Health \u201a\u00c4\u00ee a nationally recognized Catholic, not-for-profit integrated health system serving Illinois, Missouri, Oklahoma, and Wisconsin \u201a\u00c4\u00ee is seeking a Master Data Analyst.\nTo confidentially submit your interest or nominate a fellow colleague, please contact:\nDonald R. Schlag\nExecutive and Professional Recruiter\nDonald.Schlag@SSMHealth.com\nJob Summary:\nParticipates on collaborative team to create and maintain master data elements including item file, contract data and price lists, and ensures system data integrity in accordance with guidelines and internal controls.\nJob Responsibilities and Requirements:\nPrimary Responsibilities\nBuilds and maintains contracts, item files, vendor files, transmissions and pricing in database.\nFollows system-wide processes to minimize non-file purchases through reporting and item file management.\nReviews and analyzes materials data for consistency and accuracy. Investigates, reconciles and determines reason for pricing and other irregularities. Identifies results not meeting standard thresholds.\nInvestigates pricing discrepancies by reviewing contracts and initiating credit requests with vendors.\nServes as key member of team to coordinate data elements that integrate with clinical and financial information systems.\nProvides support for process owners, health ministries and their associates; answers questions, resolves issues or errors, and escalates issues that cannot be resolved.\nCollaborates with leadership to improve process efficiency.\nPerforms other duties as assigned.\nEDUCATION\nBachelor's degree or equivalent years of experience or education\nExperience\nFive years' experience\nDepartment:\n8725030033 Purchasing\nWork Shift:\nDay Shift (United States of America)\nScheduled Weekly Hours:\n40\nSSM Health is an equal opportunity employer. SSM Health does not discriminate on the basis of race, color, religion, national origin, age, disability, sex, sexual orientation, gender identity, pregnancy, veteran status\n,\nor any other characteristic protected by applicable law. Click here to learn more.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Management, Database Management, Contract Management, Pricing Analysis, Data Integrity, Data Quality, System Integration, Clinical Information Systems, Financial Information Systems, Process Improvement, Collaboration, Leadership",
      "Category":"Data Science"
  },
  {
      "job_title":"Master Data Analyst",
      "company":"SSM Health",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/master-data-analyst-at-ssm-health-3742536117",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"It's more than a career, it's a calling.\nMO-REMOTE\nWorker Type:\nRegular\nJob Highlights:\nSSM Health \u201a\u00c4\u00ee a nationally recognized Catholic, not-for-profit integrated health system serving Illinois, Missouri, Oklahoma, and Wisconsin \u201a\u00c4\u00ee is seeking a Master Data Analyst.\nTo confidentially submit your interest or nominate a fellow colleague, please contact:\nDonald R. Schlag\nExecutive and Professional Recruiter\nDonald.Schlag@SSMHealth.com\nJob Summary:\nParticipates on collaborative team to create and maintain master data elements including item file, contract data and price lists, and ensures system data integrity in accordance with guidelines and internal controls.\nJob Responsibilities and Requirements:\nPrimary Responsibilities\nBuilds and maintains contracts, item files, vendor files, transmissions and pricing in database.\nFollows system-wide processes to minimize non-file purchases through reporting and item file management.\nReviews and analyzes materials data for consistency and accuracy. Investigates, reconciles and determines reason for pricing and other irregularities. Identifies results not meeting standard thresholds.\nInvestigates pricing discrepancies by reviewing contracts and initiating credit requests with vendors.\nServes as key member of team to coordinate data elements that integrate with clinical and financial information systems.\nProvides support for process owners, health ministries and their associates; answers questions, resolves issues or errors, and escalates issues that cannot be resolved.\nCollaborates with leadership to improve process efficiency.\nPerforms other duties as assigned.\nEDUCATION\nBachelor's degree or equivalent years of experience or education\nExperience\nFive years' experience\nDepartment:\n8725030033 Purchasing\nWork Shift:\nDay Shift (United States of America)\nScheduled Weekly Hours:\n40\nSSM Health is an equal opportunity employer. SSM Health does not discriminate on the basis of race, color, religion, national origin, age, disability, sex, sexual orientation, gender identity, pregnancy, veteran status\n,\nor any other characteristic protected by applicable law. Click here to learn more.\nShow more\nShow less",
      "job_skills":"Data Management, Data Analysis, Data Integrity, Contract Management, Item Management, Vendor Management, Pricing Analysis, Database Management, Reporting, Data Entry, Data Validation, Data Reconciliation, Troubleshooting, Issue Resolution, Process Improvement, Collaboration, Communication",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"Kforce Inc",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-kforce-inc-3782232154",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nKforce has a client that is seeking a Lead Data Engineer in Saint Louis, MO. Your role here: From Day 1, you will collaborate closely with the data analytics, Power BI reporting, and functional teams to deliver top notch analytics. Key Tasks:\nLead Data Engineer provides technical leadership in Microsoft Synapse, spanning numerous services (Pipelines, Notebooks, Azure Storage, Logic Apps)\nInteracts with various business functions to define requirements and build a strategy to implement within our modern data framework\nInteracts with engineering team to implement a high quality, efficient, dependable, and secure data platform while maintaining consistent data standards, patterns, and practices across the organization (Data warehouse, Data Lakehouse)\nAs a Lead Data Engineer, you will perform code review and verifies compliance with code standards\nOwns Data Analytics team delivery outcomes\nWhat You Can Expect From Us\nOur salaries are competitive\nComprehensive benefits in medical, dental, and vision insurance\n401(k) plan with employer match\nPaid time off plus holidays\nTuition reimbursement, and much more\nRequirements\nTo be considered for this position, candidates must have experience in a similar role, or they must possess significant knowledge, experience, and abilities to successfully perform the responsibilities listed\nRelevant education and\/or training will be considered a plus\nThe pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.\nWe offer comprehensive benefits including medical\/dental\/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.\nNote: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.\nThis job is not eligible for bonuses, incentives or commissions.\nKforce is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nSalary: $128,000 - $140,000 per year\nShow more\nShow less",
      "job_skills":"Data Engineering, Microsoft Synapse, Pipelines, Notebooks, Azure Storage, Logic Apps, Power BI, Data Analytics, Data Framework, Data Warehouse, Data Lakehouse, Code Review, Data Compliance, Medical Insurance, Dental Insurance, Vision Insurance, 401(k) Plan, Paid Time Off, Holidays, Tuition Reimbursement",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"TricorBraun",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-tricorbraun-3733281824",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Make our IT Team your best move ever\nWe\u201a\u00c4\u00f4re looking for a highly detailed Lead Data Engineer to join our IT team to deliver reliable and scalable analytics.\nWhy here\n?\nTricorBraun is a global packaging leader, with team members working in locations throughout the Americas, Europe, Asia, Australia and New Zealand. As North America\u201a\u00c4\u00f4s largest distributor of primary packaging, we provide innovative solutions to customers from a wide variety of industries. Our customers range from cutting-edge start-ups to the world\u201a\u00c4\u00f4s most iconic brands. We put people first and live by that every day. Join us and you will be welcomed by our friendly, motivated and supportive team. Many of the products we distribute are already sitting in your home.\nYour role here\nFrom Day 1, you will collaborate closely with the data analytics, Power BI reporting, and functional teams to deliver top notch analytics.\nYour Experience And Background\nProvides technical leadership in Microsoft Synapse, spanning numerous services (Pipelines, Notebooks, Azure Storage, Logic Apps)\nInteracts with various business functions to define requirements and build a strategy to implement within our modern data framework.\nInteracts with engineering team to implement a high quality, efficient, dependable, and secure data platform while maintaining consistent data standards, patterns, and practices across the organization (Data warehouse, Data Lakehouse)\nPerforms code review and verifies compliance with code standards.\nOwns Data Analytics team delivery outcomes.\nWhat You Can Expect From Us\nBecause we\u201a\u00c4\u00f4re a well-known and respected leader in packaging, we have many opportunities here. We\u201a\u00c4\u00f4ll get you started with an exceptional training program providing classroom, online and hands on work with colleagues. There\u201a\u00c4\u00f4s always someone to answer any questions and ensure you\u201a\u00c4\u00f4re getting the right information you need to excel. And the compensation and benefits are what you can expect from a people-first company.\nOur salaries are competitive\nComprehensive benefits in medical, dental, and vision insurance\n401(k) plan with employer match\nPaid time off plus holidays\nTuition reimbursement, and much more\nWe are proudly an equal-opportunity employer and will consider all applications.\nShow more\nShow less",
      "job_skills":"Data Engineering, Microsoft Synapse, Azure Storage, Logic Apps, Power BI, Data Analytics, Data Warehouse, Data Lakehouse, Code Review, Data Standards, Data Patterns, Data Practices",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Analyst",
      "company":"Kforce Inc",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-at-kforce-inc-3782228566",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nKforce has a client in Saint Louis, MO that is seeking a Senior Data Analyst. Responsibilities:\nProvides guidance on the most complex and unique matters related to data reporting and analytic techniques that have a significant impact to the region and ministry; May lead work of others within business operations\nEnsures collaboration with key decision makers to identify and solve a variety of business or operational problems and objectives\nInterprets complex data, identifies trends, establishes\/utilizes benchmark data, creates data visualization, and applies information to the business to determine impact, significance, and opportunities\nResponsible for developing specifications of analytic and reporting needs through participation in project teams or meetings with internal\/external customers for projects and\/or ad hoc requests\nUtilizes a variety of databases and advanced query tools to gather data and information\nEnsures all requirements are well defined from the customer to meet reporting and analysis specifications\nEnsures data integrity and data quality; Supplies business and leadership with deep insights into the daily operations and overall business operations; Viewed as a subject matter expert for the team\nPartners closely with technical and build team members to establish reports and dashboards within applications that will support operations\nPartners with customers, peers and cross functional teams to discover new business needs; Proactively offer options and solutions\nOversees the evaluation, analysis, and development of reporting and analytical tools to analyze department and division performance indicators\nLeverages advanced analytic techniques necessary to meet needs of business users supported by the analytic team\nSupports both new and ongoing operational reporting needs, business process redesign, process improvement initiatives by providing data insights\nRequirements\nBachelor's degree or equivalent combination of education and experience\nThe pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.\nWe offer comprehensive benefits including medical\/dental\/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.\nNote: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.\nThis job is not eligible for bonuses, incentives or commissions.\nKforce is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nSalary: $65 - $75 per hour\nShow more\nShow less",
      "job_skills":"Data analysis, Data reporting, Data visualization, Business operations, Decision making, Data interpretation, Trend analysis, Benchmarking, Data integrity, Data quality, Deep insights, Reporting needs, Analytical tools, Business insights, Data mining, Process redesign, Process improvement, Datadriven decision making, Advanced analytic techniques, Compensation, Benefits, Equal Opportunity\/Affirmative Action",
      "Category":"Data Science"
  },
  {
      "job_title":"CRM Data Analyst",
      "company":"Netskope",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/crm-data-analyst-at-netskope-3756678621",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"About Netskope\nToday, there's more data and users outside the enterprise than inside, causing the network perimeter as we know it to dissolve. We realized a new perimeter was needed, one that is built in the cloud and follows and protects data wherever it goes, so we started Netskope to redefine Cloud, Network and Data Security.\nSince 2012, we have built the market-leading cloud security company and an award-winning culture powered by hundreds of employees spread across offices in Santa Clara, St. Louis, Bangalore, London, Melbourne, and Tokyo. Our core values are openness, honesty, and transparency, and we purposely developed our open desk layouts and large meeting spaces to support and promote partnerships, collaboration, and teamwork. From catered lunches and office celebrations to employee recognition events (pre and hopefully post-Covid) and social professional groups such as the Awesome Women of Netskope (AWON), we strive to keep work fun, supportive and interactive. Visit us at Netskope Careers. Please follow us on LinkedIn and Twitter@Netskope.\nAbout the position:\nThe Netskope Data Operations team is looking for a CRM (Customer Relationship Management) Data Analyst, who will help drive data operational excellence. As a member of the Data Operations team, this candidate will be responsible for the integrity, completeness and quality of data within the CRM. This individual will develop and implement standard procedures for capturing, cleansing, and updating data in the CRM and document data governance policies.\nNetskope\u201a\u00c4\u00f4s Go-to-Market (GTM) Data Operations team exists to maintain accurate, actionable, and non-duplicative Account, Lead and Contact data that accurately reflects corporate hierarchies and key data points enabling Sales to better manage Customers and target Prospects. This role requires subject matter expertise on enrichment, normalization and cleansing of data in Salesforce and an understanding of how changes can impact other systems and processes.\nResponsibilities:\nRegularly perform data cleansing and validation processes to ensure data accuracy, completeness, and consistency\nProactively identify data quality issues and work with relevant teams to implement improvements\nPerform tasks related to data acquisition, validation and enrichment as they relate to Accounts, Leads and Contacts\nWork cross-functionally within the organization to ensure data from other systems (such as marketing automation tools, sales and customer service platforms) are properly integrated with Salesforce to ensure data integrity is maintained\nPropose and implement data governance solutions for the proper management of CRM data\nIdentify opportunities to streamline data-related processes and workflows to drive greater efficiency and accuracy.\nProvide support to cross functional teams such as: training on data entry best practices and troubleshooting issues related to data quality\nRequirements:\n5+ years of work experience as a technical data steward with a strong background in Data Governance Policies, Processes and Tools\nExperience in Salesforce, Excel, 3rd Party Data Tools (e.g. Zoominfo, D&B) and Data Cleansing Tools (e.g. Ringlead, Demandtools, Openprise)\nStrong attention to detail with a focus on building standardized and consistent best practices\nUnderstanding of marketing and privacy regulations (e.g. Opt In\/Out, GDPR)\nProven ability to collaborate well with others and meet deadlines\nPersistent in finding accurate information leveraging all available resources\nExperience documenting business processes and developing training materials for data integrity and governance\nPreferred Qualifications:\nHigh level of integrity and transparency in working with peers and stakeholders\nComfort with ambiguity and proven ability to work independently\nStrong written and verbal communication skills\nAbility to multitask and meet Service Level Agreements (SLAs), specific to work efforts\nProven ability to meet timelines and deliver business results\nA self-starter who is detail-oriented and can engage across stakeholders with confidence\nEducation:\nBachelor\u201a\u00c4\u00f4s degree\nNetskope is committed to implementing equal employment opportunities for all employees and applicants for employment. Netskope does not discriminate in employment opportunities or practices based on religion, race, color, sex, marital or veteran statues, age, national origin, ancestry, physical or mental disability, medical condition, sexual orientation, gender identity\/expression, genetic information, pregnancy (including childbirth, lactation and related medical conditions), or any other characteristic protected by the laws or regulations of any jurisdiction in which we operate.\nNetskope respects your privacy and is committed to protecting the personal information you share with us, please refer to Netskope's Privacy Policy for more details.\nShow more\nShow less",
      "job_skills":"Salesforce, Data Governance, Data Cleansing, Data Integrity, Data Quality, Data Enrichment, Data Validation, Data Acquisition, Data Stewardship, Data Governance Policies, Data Governance Processes, Data Governance Tools, Excel, Zoominfo, D&B, Ringlead, Demandtools, Openprise, GDPR, Service Level Agreements",
      "Category":"Data Science"
  },
  {
      "job_title":"Big Data Developer",
      "company":"Sigmaways Inc",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-developer-at-sigmaways-inc-3778728506",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"We are looking for a\nBig data Developer\nwho will contribute to high-quality technology solutions that address business needs by developing data applications for the customer business lines. You will contribute to the development and ongoing maintenance of several strategic data initiatives and data and analytic applications.\nResponsibilities:\nHands-on development role focused on creating big data and analytics solutions.\nCoding of mission-critical components.\nA strong Big data developer\/coder who can write database queries and also tune those queries to perform optimally.\nAnalyze business and functional requirements and contribute to the overall solution.\nParticipate in design reviews, and provide input to the design recommendations.\nParticipate in project planning sessions with project managers, business analysts, and team members.\nRequired skills:\nBS or MS in Computer Science or equivalent experience.\nSoftware development experience with solid working experience in Big Data technologies.\nKnowledge of the architecture and internals of technologies in the Hadoop ecosystem\nExperience designing and implementing large, scalable distributed systems.\nMust have solid expertise and hands-on experience in\nSpark,\nScala and SQL\nS\nolid experience of the Hadoop Ecosystem ( HDFS, Yarn, MapReduce, Spark, Hive, Impala )\nand should be able to mentor and lead junior team members.\nGood understanding of database technologies, including SQL and NoSQL databases\nAbility to debug and promptly resolve production issues.\nProficiency with advanced object-oriented programming.\nExcellent problem-solving and analytical skills.\nExcellent written and oral communication skills.\nShow more\nShow less",
      "job_skills":"Big Data, Data Analytics, Hadoop Ecosystem, NoSQL Databases, Spark, Scala, SQL, HDFS, Yarn, MapReduce, Hive, Impala, Database Management Systems, ObjectOriented Programming, ProblemSolving, Analytical Skills, Communication Skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Looking for Azure Database Engineer -St. Louis MO (Hybrid) - Contract",
      "company":"Extend Information Systems Inc.",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/looking-for-azure-database-engineer-st-louis-mo-hybrid-contract-at-extend-information-systems-inc-3704057850",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Hi,\nI hope you are doing well!\nWe have an opportunity for\nAzure Database Engineer\nwith one of our clients for\nSt. Louis MO (Hybrid).\nPlease see the job details below and let me know if you would be interested in this role.\nIf interested, please send me a copy of your resume, contact details, availability, and a good time to connect with you.\nTitle:\nAzure Database Engineer\nLocation: St. Louis MO (Hybrid)\nTerms:\nContract\nJob Details\nJob Responsibility:\nCollaborate with data architects and other stakeholders to design scalable and optimized data warehouse solutions on the Azure platform.\nDevelop and maintain data warehouse architectural documentation, including schema designs, data flow diagrams, and integration patterns.\nMove SSIS \/ ETL Processes and execute SSIS within Azure Data Factory.\nDesign the NextGen Data Warehouse using Azure.\nExpertise in using Master Data Management strategies, design Data Warehouse structure and schema with Azure Data services..\nExecute SSIS packages in Azure from SSDT to assess the cloud compatibility of SSIS packages and run them on Azure-SSIS IR within ADF.\nFix any issues found in IR testing and can migrate all SSIS packages to run in Azure.\nRe-write all SSIS packages into ADF and expand analytics using Azure Synapse and Power BI\nInvestigate use of Azure Fabric for end to end data processes from Data Science to Analytics\nWrite efficient T-SQL queries for data transformation, extraction, loading, and reporting purposes.\nImplement data partitioning, indexing, and distribution strategies to enhance query performance.\nIntegrate data from various sources, both on-premises and in the cloud, into the Azure Data Warehouse using appropriate ETL\/ELT techniques.\nWork with data integration tools such as Azure Data Factory or SSIS to automate data pipelines.\nMonitor and analyze query performance and data warehouse health, identifying and resolving bottlenecks and performance issues.\nOptimize query execution plans, indexing strategies, and data distribution to achieve optimal performance.\nImplement security measures to protect sensitive data within the Azure Data Warehouse, following best practices for data encryption, access controls, and data masking.\nEnsure compliance with relevant data privacy and security regulations, such as GDPR or HIPAA.\nProvide training and guidance to junior team members on data warehouse best practices and technologies.\nQualifications\nBachelor's or higher degree in Computer Science, Information Technology, or a related field.\nProven experience in designing, implementing, and optimizing data warehousing solutions using Azure services (Azure Synapse Analytics, Azure Data Factory, Azure SQL Data Warehouse).\nPlan the ETL process for the data warehouse design.\nChoose appropriate Azure data services (Synapse, ADF, ?)\nCreate data warehouse operations runbook\nManage Data Quality ongoing\n.\n--\nThanks & Regards\nMonika Singh\nExtend Information System Inc\nPhone: (571)-622-3980\nEmail: monika@extendinfosys.com\n44258 Mercure Circle, UNIT 102 A, Sterling VA, USA 20166\nShow more\nShow less",
      "job_skills":"Azure Data Factory, Azure Data Warehouse, Azure SQL Data Warehouse, Azure Synapse Analytics, AzureSSIS IR, ADF, Data Science, Data Warehouse, ETL, GDPR, HIPAA, Master Data Management, Power BI, SSIS, SSDT, TSQL",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Data Governance Analyst",
      "company":"Accounting Career Consultants & HR Career Consultants",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-governance-analyst-at-accounting-career-consultants-hr-career-consultants-3768713926",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Why is This a Great Opportunity?\n-great boss\n-autonomy in role\n-tremendous flexibility\n-high-level exposure role\n-tons of growth\n-top company\n-strong comp package\nJob Description:\n-Expertise in Data Management: Demonstrate a profound understanding of master data management, data standards, data quality, and data lineage, ensuring a comprehensive approach to Data Governance.\n-Partnership and Documentation: Collaborate closely with functional stakeholders to develop and document Data Governance best practices, standards, principles, and policies that align with organizational objectives.\n-Data Quality Reporting: Contribute to the development of data quality reports and dashboards, providing valuable insights to stakeholders and ensuring the health of data aligns with business goals.\n-Continuous Improvement: Embrace a continuous improvement mindset, identifying opportunities to enhance processes and systems that align with Data Governance policies and standards.\n-Promotion of Data Governance Tools: Actively facilitate and promote the adoption of data governance tools, processes, and procedures among functional business users, ensuring widespread understanding and compliance.\nQualifications:\n-2+ years of data governance experience\n-self-starter\n-strong\nShow more\nShow less",
      "job_skills":"Data Management, Data Governance, Master Data Management, Data Standards, Data Quality, Data Lineage, Partnership, Documentation, Data Quality Reporting, Dashboards, Continuous Improvement, Data Governance Tools, Data Governance Policies, Data Governance Standards",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Migration Analyst - Hybrid",
      "company":"Swank Motion Pictures, Inc.",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-migration-analyst-hybrid-at-swank-motion-pictures-inc-3766477789",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Swank Motion Pictures is looking for a technical business analyst to join an existing and growing team working on innovative and leading-edge technologies. We are looking for someone with strong data analysis skills necessary to work on multiple projects simultaneously with minimal oversight in an agile\/iterative IT environment. These projects are primarily custom software development and business process improvements. This position is a liaison between non-technical business stakeholders and technology teams. This position is in the IT department and will interact with multiple levels of management within the company. This position is intended to be a year-long position with the opportunity of becoming a permanent role within the group. At Swank Motion Pictures, we are not just looking for employees; we are investing in future leaders. For the Data Migration Analyst role, we offer a pathway for professional growth and development. As our company evolves, there will be abundant opportunities for you to expand your skill set, take on new challenges, and advance your career. We are committed to fostering a culture of learning and innovation where your contributions will be recognized and your professional aspirations supported.\nResponsibilities\nThis position has the primary responsibility to analyze corporate data and assist in its migration from one system to another. Corporate data includes but is not limited to accounts, contacts, agreements, orders, and invoices. The data migration analyst will elicit, verify, and document business-defined data migration rules; analyze data based on those rules for consistency, cleanliness, and outliers; perform quality control checks against data transfer files; and share findings from those checks with the data migration team. The Data Migration Analyst will be expected to develop and maintain comprehensive documentation, including data mappings, transformation rules, and workflow diagrams, to ensure clarity and consistency throughout the data migration process. This individual will be an integral part of a team consisting of data architects, system specialists, and project managers. The Data Migration Analyst will collaborate closely with data governance teams to uphold meaningful data quality and compliance standards across all stages of the migration process. This position is a hybrid position \u201a\u00c4\u00ec the individual must be willing to be in the office at least 2 days per week.\nRequirements\nSkills Needed\nInterpersonal skills to negotiate priorities and collaborate with both business and IT peers\nInterview skills to ask the proper questions for gathering essential requirements and listen attentively to their feedback\nAnalytical skills to critically evaluate data of different types, discern data patterns, and identify data outliers using a high level of attention to detail\nCommunication skills to effectively share ideas and requirements with both technical and non-technical audiences through meetings, working group sessions, whiteboard sessions using data visualization skills and too\nCreativity skills to be flexible and think outside the box when solving problems\nOrganizational skills to meet deadlines, ensure quality deliverables, and cope with rapidly changing information in a hybrid work environment\nExperience Needed\n3 to 5 years of experience executing business analysis with a focus on data analysis and migration\nExperience working with and analyzing large amounts of data via Excel \u201a\u00c4\u00ec SQL experience is nice to have but not required\nAn understanding of best practices for eliciting, analyzing, documenting, validating, and managing requirements, along with knowing when to apply them\nExperience facilitating meetings with both business and IT stakeholders from any level within the organization\nExperience eliciting requirements via one-on-one interviews, group meetings, brainstorming sessions, and other methods as needed\nExperience collaborating with Project Management, Development, and Quality Assurance personnel on software development projects\nDetailed expertise using Microsoft Word, PowerPoint, and Excel a must; familiarity with Atlassian Jira and Confluence preferred but not required\nEducational Requirements\nBachelor\u201a\u00c4\u00f4s degree in technology related field required\nBenefits\nWe are pleased to offer:\nComprehensive compensation and healthcare packages, including medical, dental, vision, and life insurance products\n401(K) plan with employer match\nCompetitive paid time off: vacation, personal time, holidays and winter break\nCompany sponsored volunteer & community outreach opportunities\nOrganizational growth potential through our company sponsored online learning platform\nEOE, including disability\/vets\nShow more\nShow less",
      "job_skills":"Data Analysis, Agile\/Iterative IT, Custom Software Development, Business Process Improvement, Data Migration, Data Mapping, Transformation Rules, Workflow Diagrams, Data Governance, Interpersonal Skills, Negotiation, Interview Skills, Analytical Skills, Communication Skills, Creativity, Organizational Skills, Business Analysis, Excel, SQL, Requirements Gathering, Microsoft Word, PowerPoint, Jira, Confluence, Bachelor's in Technology",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst I",
      "company":"Lockton",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-i-at-lockton-3774281918",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Your Responsibilities\nDescription:\nCollects data and analyzes client information\nWork collaboratively with managers and other teammates to collect data, ensuring reporting is accurate, timely, and of high quality.\nAudits data results and reports findings to supervisors\nPrepares standard and ad hoc reports\nFacilitates process and complete pricing comparisons for request for proposals (RFPs)\nAnalyzes client data in conjunction with other consultants to recommend plan design changes, programs or formulary changes\nIntegrates data from multiple data sets into relevant systems for reports publication.\nFollows policies, procedures, and\/or reports that make the overall practice more efficient and effective\nSupports standard data sets monthly within relevant systems\nCoordinates new client set-up, including file submission and testing, with consultants and system administrators\nGathers new reporting requirements from business users and coordinate development\/deployment with system administrators\nQualifications\nQualifications:\nBachelor's degree required. Major in Actuarial Science, Mathematics, Statistics or Finance.\nMS Excel experience required. In addition, experience using SQL and MS Access a plus.\nUnderstands data sources, processes, formulas and output General knowledge of healthcare issues and their associated impacts on plan sponsors and plan members.\nAbility to understand data integrity and correctness.\nExcellent written and oral communication skills to effectively present information to Associates at all levels of the Lockton organization.\nStrong proactive style.\nProven ability to manage multiple projects simultaneously.\nUnderstands industry trends and governmental regulations\nAbility to complete continuing education requirements as needed\nAbility to attend company, department, and team meetings as required, including industry training sessions\nAbility to comply with all company policies and procedures, proactively protecting confidentiality of Client and company information\nAbility to efficiently organize work and manage time in order to meet deadlines\nAbility to travel by automobile and aircraft\nAbility to use office equipment such as a computer, keyboard, calculator, photocopier, and facsimile machine\nAbility to work on a computer for a prolonged amount of time\nAbility to work outside of normal business hours as needed\nLegally able to work in the United States\nShow more\nShow less",
      "job_skills":"Actuarial Science, Mathematics, Statistics, Finance, MS Excel, SQL, MS Access, Data sources, Data processes, Data formulas, Data output, Healthcare issues, Plan sponsors, Plan members, Data integrity, Data correctness, Communication skills, Proactive style, Project management, Industry trends, Governmental regulations, Continuing education, Company policies, Confidentiality, Time management, Deadlines, Travel, Office equipment, Computer skills, Extended computer use, Nonstandard working hours, United States work authorization",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst III",
      "company":"Lockton",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-iii-at-lockton-3720808018",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Your Responsibilities\nDescription:\nWe are looking for a data analyst to be responsible for creating complex analysis of medical, pharmacy, and biometric data using SQL and Tableau . The ideal candidate will be motivated, results-driven, flexible, detail-oriented, and collaborative. Our fast-paced environment has a supportive culture that values autonomy, initiative, and personal accountability.\nJob Duties:\nDevelop and support new analytical tools and reports, primarily using SQL and Tableau.\nGathers new reporting requirements from stakeholders.\nWork collaboratively to ensure reporting that is accurate, timely, and of high quality.\nSet strategies and take ownership in on-going analytics development.\nGenerate benchmark data on a requested basis.\nResponsible for data consolidation, analysis, and business reporting.\nDevelops and maintains reports for stakeholders at all levels of the organization.\nProvides support to research teams or management by collecting and analyzing data and reporting results based on the needs of end users.\nMaintains data integrity and data processing efficiency by working to eliminate redundancy and applying best practice data stewardship techniques.\nStays informed of the ways the organization uses its data.\nRecognize data issues and work with data quality team to resolve problems.\nMust continuously be learning and staying abreast of technology advances.\nProvide exceptional customer service and adhere to the Lockton philosophies.\nQualifications\nRequirements:\nBachelor's degree required. Major in Mathematics, Statistics, Finance, Insurance, or Economics preferred.\nAdvanced knowledge and experience using SQL.\nKnowledge of Tableau strongly preferred.\nUnderstand data sources, processes, formulas, and output.\nAbility to understand data integrity and correctness.\nPrevious experience working with claims data, CPT codes, and ICD-10 codes preferred.\nProven ability to manage multiple projects simultaneously.\nAptitude to develop unique, creative, and efficient work products.\nExcellent written and oral communication skills to effectively present information to associates at all levels of the Lockton organization.\nAssumes ownership for individual projects. Strong proactive style and self-motivated to actively seek solutions to problems without supervision.\nAbility to comply with all company policies and procedures, proactively protecting confidentiality of client and company information.\nShow more\nShow less",
      "job_skills":"SQL, Tableau, Data analysis, Data consolidation, Data reporting, Data stewardship, Data integrity, Data quality, Customer service, Mathematics, Statistics, Finance, Insurance, Economics, Claims data, CPT codes, ICD10 codes, Project management, Communication, Problem solving",
      "Category":"Data Science"
  },
  {
      "job_title":"Azure Data Engineer",
      "company":"CoxHealth",
      "job_location":"Springfield, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/azure-data-engineer-at-coxhealth-3729763601",
      "search_city":"Missouri",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Summary\nThe Azure Data Engineer works directly with the Microsoft EDW Development team, supporting the CoxHealth System. To be successful in this position, the Engineer must have strong communication skills and the ability to collaborate with different analysts\/developers across the team. This position is focused on the development of data management solutions within the Microsoft Azure Synapse environment.\nJob Requirements\nEducation\nRequired: Bachelor\u201a\u00c4\u00f4s Degree in Information Technology, Computer Science, or other related discipline OR 8 years' experience in IT or Computer Science\nExperience\nRequired: 1 year experience in one of the following areas:\nExperience with cloud-based technologies, preferably Azure, Data Factory, Databricks, Synapse Analytics, Azure Key Vault\nExperience with Spark, preferably in a Databricks notebook-based development environment\nExperience designing Data Lakes and Data Warehouses\nExperience leveraging, designing, and building database schemas for analytics\nExperience designing, building, and maintaining ETL\/ELT data pipelines, preferably SSIS & Data Factory using multiple data source types like custom API sources, file based, RDBMs systems (SQL Server, Oracle, Snowflake, etc.)\nSkills\nDevelop, test and configure automated deployments of data management solutions (data ingestion, transformation, modeling, interfaces, etc.)\nUnderstand SQL query optimization, profiling, and performance monitoring tools & techniques\nExcellent communication skills required with ability to effectively collaborate with members of the technical team and with business leaders in a fully-remote or hybrid capacity.\nMust be very detailed oriented, with excellent organizational skills with the ability to manage\/prioritize multiple tasks concurrently.\nLicensure\/Certification\/Registration\nNone Required\nShow more\nShow less",
      "job_skills":"Azure, Data Factory, Databricks, Synapse Analytics, Azure Key Vault, Spark, Data Lakes, Data Warehouses, ETL\/ELT, SSIS, SQL Server, Oracle, Snowflake, SQL query optimization, Data profiling, Performance monitoring, Communication skills, Collaboration, Organizational skills, Prioritization",
      "Category":"Data Science"
  },
  {
      "job_title":"Master Data Analyst",
      "company":"Kforce Inc",
      "job_location":"Ballwin, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/master-data-analyst-at-kforce-inc-3777072399",
      "search_city":"Cahokia",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nKforce has a client that is looking for a Master Data Analyst in Ballwin, MO. Summary: We are seeking a tech-savvy and motivated Master Data Analyst to join our Master Data Team. Reporting to the Master Data Team Lead, the successful candidate will be responsible for ensuring the accuracy, consistency, and optimization of our master data sets. This role offers an excellent opportunity for growth within the organization and to contribute to our data management strategies. Responsibilities:\nMaster Data Analyst will collaborate with various teams to understand data requirements and ensure the accuracy and completeness of master data sets\nConduct data entry, validation, and maintenance tasks to uphold consistency and integrity of master data\nAssist in identifying and resolving data quality issues and discrepancies\nContribute to the development and implementation of data governance policies and best practices\nAs a Master Data Analyst, you will generate reports and provide data analysis to support decision-making processes\nParticipate in data-related projects and initiatives aimed at enhancing data quality and operational efficiency\nStay updated on industry best practices and emerging trends in data management\nRequirements\nBachelor's degree in Computer Science, Information Systems, or business related field\n1-3 years of experience in data analysis, preferably in master data mgmt. or a related field\nTech-savvy individual with basic understanding of enterprise resource planning (ERP) systems (e.g., IQMS, Oracle), database management systems (e.g., SQL) and data visualization tools (e.g., Power BI)\nStrong analytical skills with proficiency in data analysis tools and techniques\nExcellent communication and collaboration skills to work effectively within a team environment\nDetail-oriented with a commitment to maintaining data accuracy and integrity\nEagerness to learn and grow within the organization\nAbility to adapt to changing priorities and handle multiple tasks concurrently\nThe pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.\nWe offer comprehensive benefits including medical\/dental\/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.\nNote: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.\nThis job is not eligible for bonuses, incentives or commissions.\nKforce is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nSalary: $35 - $50 per hour\nShow more\nShow less",
      "job_skills":"Data Analysis, Master Data Management, Data Governance, Data Visualization, Enterprise Resource Planning (ERP), Database Management Systems (DBMS), SQL, Power BI, Data Quality, Data Integrity, Communication, Collaboration, DetailOriented, ProblemSolving, Adaptability, Multitasking",
      "Category":"Data Science"
  },
  {
      "job_title":"Principal Data and Integration Engineer * 100% Remote \/ W2 Only *",
      "company":"Amerit Consulting",
      "job_location":"Maryland Heights, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-data-and-integration-engineer-100%25-remote-w2-only-at-amerit-consulting-3780541715",
      "search_city":"East Saint Louis",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Overview:\nOur client, a US Fortune 500 company and a provider of managed Health care, Pharmacy benefits & specialty areas for managed care organizations \/ employers \/ government agencies, seeks an accomplished\nPrincipal Data and Integration Engineer.\n*** Candidate must be authorized to work in USA without requiring sponsorship ***\n********************************************************\n*** Location: 100% Remote (Maryland Heights, MO)\n*** Duration: 3+ months with possible conversion\nWorking Schedule: Hours: 8am to 5pm Central\nSummary:\nDevelops, tests and maintains code using software development methodology and appropriate technologies for the system being used. Works closely with Business Analysts to develop detail systems design and written test plans for online and report application programs. Participates in design walkthroughs with appropriate focus groups and related users to verify the accuracy of design in meeting business needs. Prepares installation instructions and coordinates installation procedures. Supports and troubleshoots application code problems. Provides status reports that give a detailed description of the current projects progress and indicate time devoted to each task of the project. Coordinates, guides, and mentors programming efforts performed by in-house programmers or outside consultants to ensure that all programming is completed according to the project plan.\nResponsibilities:\nDevelops, tests and maintains code using software development methodology and appropriate technologies for the system being used.\nWorks closely with Business Analysts or System Analyst to develop detailed systems design and written test plans for online and report application programs.\nPerforms analysis on projects and provides a project plan that shows the tasks needing to be completed and a time estimate for each task.\nProvides status reports that give a detailed description of the current project's progress and indicate time devoted to each task.\n3 Must-Haves (Hard Skills):\nHands-on experience in designing, coding, enhancing, testing and production support of custom SQL Server Datawarehouse to meet business process requirements.\nProficient with Excel and creating Apps in Excel using VBCode.\nConfident in Microsoft SQL Server (using SSMS \u201a\u00c4\u00ec Advanced TSQL, Stored Procedures, best practices in RDBMS) best practices for writing clean effective code and balancing Declarative customizations with Programmatic customizations.\nNice-To-Haves (Hard Skills)\nKnowledge\/experience in Oracle (PLSQL using TOAD)\nSalesforce knowledge and experience\nSnapLogic knowledge and experience\nTableau knowledge and experience\n***********************************************************\nI'd love to talk to you if you think this position is right up your alley, and assure a prompt communication, whichever direction.\nIf you're looking for rewarding employment and a company that puts its employees first, we'd like to work with you.\nSam Banga\nLead Recruiter\nCompany Overview:\nAmerit Consulting\nis an extremely fast-growing staffing and consulting firm. Amerit Consulting was founded in 2002 to provide consulting, temporary staffing, direct hire, and payrolling services to Fortune 500 companies nationally; as well as small to mid-sized organizations on a local & regional level. Currently, Amerit has over 2,000 employees in 47 states. We develop and implement solutions that help our clients operate more efficiently, deliver greater customer satisfaction, and see a positive impact on their bottom line. We create value by bringing together the right people to achieve results. Our clients and employees say they choose to work with Amerit because of how we work with them - with service that exceeds their expectations and a personal commitment to their success. Our deep expertise in human capital management has fueled our expansion into direct hire placements, temporary staffing, contract placements, and additional staffing and consulting services that propel our clients\u201a\u00c4\u00f4 businesses forward.\nAmerit Consulting provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\nThis policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\nApplicants, with criminal histories, are considered in a manner that is consistent with local, state and federal laws.\nShow more\nShow less",
      "job_skills":"SQL Server, Datawarehouse, TSQL, Visual Basic, Oracle, PLSQL, Salesforce, SnapLogic, Tableau",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Architect - Government Healthcare (Remote)",
      "company":"S2Tech",
      "job_location":"Chesterfield, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-architect-government-healthcare-remote-at-s2tech-3786832965",
      "search_city":"East Saint Louis",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Job Details\nDescription\nData Architect \u201a\u00c4\u00ec Government Healthcare\nLocation: Remote\nAbout Us\nKnown for \u201a\u00c4\u00faDelighting the Client\u201a\u00c4\u00f9 through performance, innovation and an employee-centric culture, S2Tech is a fast-growing IT consulting company serving clients in over a quarter of the United States. We are widely recognized as a leading provider of both technical and business services in support of Health and Human Services related projects. Feel free to learn more at www.s2tech.com .\nWhy S2Tech?\n:\nStable privately-owned company with a strong reputation for building long-term client relationships through the delivery of consistent value-based service\n25 year history of providing IT and Business services to private customers and government programs throughout the United States\nExpansive client portfolio and active projects \u201a\u00c4\u00ec employees benefit from innovative project exposure and in-house skill development training\/courses\nCorporate culture that emphasizes the importance of family and promotes healthy work-life balance\nOffer competitive pay and a range of benefits including:\nMedical \/ Dental \/ Vision Insurance \u201a\u00c4\u00ec insurance premium assistance provided\nAdditional Insurance (Life, Disability, etc.)\nPaid Time Off (Vacation & Sick Leave)\n401(k) Retirement Savings Plan & Health Savings Account\nVarious training courses to promote continuous learning\nCorporate Wellness Program\nBe part of a company that gives back through its non-profit organization, Fortune Fund, which was launched in 2001. The goal of the Fortune Fund is to close the rural\/urban divide by ensuring children in rural communities in India and the United States understand the importance of education & are aware of professional career opportunities allowing them to link their professional & educational goals\nJob Overview\nWe are seeking a highly skilled and experienced Data Architect that will be responsible for designing and engineering scalable, integrated solutions, focusing on data structures such as data warehouses, data lakes, and data marts. The primary objective is to enhance data quality, streamline data flow, and maintain security standards, particularly aligning with the Health Insurance Portability and Accountability Act (HIPAA) requirements.\nResponsibilities\nDesign and engineer scalable, integrated solutions encompassing data warehouses, data lakes, data marts, applications, and infrastructure\nImprove data quality, optimize data flow, and ensure compliance with HIPAA standards\nArchitect and model an enterprise data presentation layer, semantic layer, distribution layer, dependent data marts, and business intelligence reporting solutions against an enterprise-wide data warehouse\nAct as the primary interface between business stakeholders, enterprise architecture, and technical resources in the development of information management solutions\nCollaborate with cross-functional teams to understand business requirements and translate them into effective data management solutions\nEnsure adherence to industry standards in the design and implementation of data architectures\nStay abreast of emerging trends and technologies in data management and make recommendations for continuous improvement\nQualifications\nBachelor's Degree in Information Systems Engineering, Computer Science, or a related field is preferred\nMinimum of five (5) years of experience in designing and engineering data management solutions for government healthcare systems\nExtensive experience in architecting and modeling enterprise data presentation layers, semantic layers, distribution layers, dependent data marts, and business intelligence reporting solutions against enterprise-wide data warehouses\nSuperior communication skills with the ability to serve as the primary interface between business, enterprise architecture, and technical teams\nProficiency in data modeling, database design, and data architecture principles\nIn-depth knowledge of data warehousing, data lakes, and data mart concepts\nStrong understanding of HIPAA standards and experience implementing security measures in data management solutions\nExpertise in business intelligence reporting solutions and tools\nExcellent problem-solving skills and the ability to think strategically about data architecture\nS2Tech is committed to hiring and retaining a diverse workforce. We are an equal opportunity employer making decisions without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or any other protected class.\nShow more\nShow less",
      "job_skills":"Data Architect, Data Structures, Data Warehouses, Data Lakes, Data Marts, Data Quality, Data Flow, HIPAA, Enterprise Data Presentation Layer, Semantic Layer, Distribution Layer, Dependent Data Marts, Business Intelligence Reporting Solutions, Data Modeling, Database Design, Data Architecture Principles, Business Requirements, Data Management Solutions, Industry Standards, Emerging Trends, Data Management, Information Systems Engineering, Computer Science, Government Healthcare Systems, Communication Skills, Business Intelligence Reporting Tools, ProblemSolving Skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Building Operating Engineer (2nd Shift)",
      "company":"JLL",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-building-operating-engineer-2nd-shift-at-jll-3748261882",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"General Description:\nThe Data Center Operations Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)\nPrincipal Duties and Responsibilities\nTask will include but not be limited to:\nResponsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire\/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.\nRequires the ability to analyze the operation of various systems, determine the cause of any problems\/malfunctions and take corrective action as required.\nComply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.\nLearn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.\nWork order management, including CMMS, Vendor Management, and Customer Facing Tickets.\nUnderstanding and complying with emergency escalation procedures.\nPerform additional job duties as required.\nMinimum Requirements:\nPreferred to have hands-on experience working in a data center\/critical facility, including UPS.\nSystems, emergency generators, and switchgears.\nHigh School diploma or GED equivalent\n2+ years related work experience.\nWorking knowledge of computer applications including Word and Excel.\nDemonstrated verbal\/written communication skills.\nPreferred Requirements:\nCorrigo Experience.\nMCIM \/ Salesforce Experience.\nZendesk Experience.\nService Now Experience.\nReceived EPA 608.\nTrained in NFPA70E.\nShow more\nShow less",
      "job_skills":"UPS, HVAC, Chillers, Crac, Crah, Plumbing, Electrical, ATS, STS, PDU, Refrigeration, Air conditioning, Boilers, Water heaters, Pumps, Valves, Piping, Filters, CMMS, EPA 608, NFPA70E",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Building Operating Engineer (2nd Shift)",
      "company":"JLL",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-building-operating-engineer-2nd-shift-at-jll-3748265361",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"General Description:\nThe Data Center Operations Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)\nPrincipal Duties and Responsibilities\nTask will include but not be limited to:\nResponsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire\/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.\nRequires the ability to analyze the operation of various systems, determine the cause of any problems\/malfunctions and take corrective action as required.\nComply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.\nLearn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.\nWork order management, including CMMS, Vendor Management, and Customer Facing Tickets.\nUnderstanding and complying with emergency escalation procedures.\nPerform additional job duties as required.\nMinimum Requirements:\nPreferred to have hands-on experience working in a data center\/critical facility, including UPS.\nSystems, emergency generators, and switchgears.\nHigh School diploma or GED equivalent\n2+ years related work experience.\nWorking knowledge of computer applications including Word and Excel.\nDemonstrated verbal\/written communication skills.\nPreferred Requirements:\nCorrigo Experience.\nMCIM \/ Salesforce Experience.\nZendesk Experience.\nService Now Experience.\nReceived EPA 608.\nTrained in NFPA70E.\nShow more\nShow less",
      "job_skills":"Data center operations, Electrical systems, Mechanical systems, HVAC, Chillers, CRAC, CRAH, Plumbing, Controls, UPS, ATS, STS, PDU, Generators, Switchgear, Power distribution, Transformers, Hot water systems, Refrigeration, Chilled water, Air conditioning, Boilers, Ventilating, Water heaters, Pumps, Valves, Piping, Filters, CMMS, Vendor management, Customer facing tickets, Emergency escalation procedures, EPA 608, NFPA70E, Corrigo, MCIM, Salesforce, Zendesk, ServiceNow, Word, Excel",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Data Analyst",
      "company":"Aston Carter",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-aston-carter-3788861259",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Description:*\nEssential Job Functions:*\nSupport clients: Work and communicate closely with their clients throughout the report\/dashboard development process. Provide status updates. Help clients understand their report\/dashboard. Provide on-going maintenance and support.\nSupport projects: Participate in outcome evaluation, program evaluation, and quality improvement studies. Attend meetings, answer data-related questions, and offer suggestions.\nCreate reports and dashboards: Create ad-hoc and routine reports. Design and develop dashboards to display key metrics and trends.\nManage data: Collect, organize, store, and share a wide variety of data.\nTransform data: Clean and optimize data for analyses.\nEnsure data quality: Audit data, data transformation processes, workflow, deliverables and outputs.\nPerform analyses: Perform statistical analyses (descriptive and inferential analyses).\nPresent findings: Present data and findings in a clear and concise manner, using appropriate reporting and data visualization tools.\nCreate and maintain documentation: Create FDD, document report requirement, business logic and workflow. Create data dictionaries. Ensure documentation is up-to-date.\nMaintain up-to-date knowledge on information management systems, processes and data.\nManage compliance reporting: Maintain up-to-date knowledge of CMS, DHCS and internal compliance reporting requirement. Translate reporting requirement into reports. Work with clients to ensure accuracy of data. Submit report to external and internal agencies in a timely manner. Attend compliance trainings, meetings, and data validation webinars.\nSupport system enhancement\/implementation: Perform data-related research and testing. Stay informed of system and process changes. Identify impact on existing reports and dashboards. Modify existing reports and dashboards accordingly.\nPrioritize work and keep supervisor informed: Work on multiple projects at the same time. Organize and prioritize work effectively. Inform management when requirement or due date cannot be met.\nAdheres to all quality, compliance and regulatory standards to achieve organization outcomes.\nRequired Education: *\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Analytics, Healthcare Informatics, Statistics, Computer Science, or related field.\nRequired Experience:*\nAt least 5 years of experience analyzing and compiling data, preferably in a health plan setting.\nRequired Skills\/Abilities:*\nAbility to manipulate and analyze data to produce accurate results. Present results in data visualizations, dashboards, and reports.\nKnowledge in CMS Medicare Advantage (Part C), CMS Prescription Drug Coverage (Part D), and CMS Special Needs Plan (SNP), and DHCS Medi-Cal Managed Care reporting requirements.\nKnowledge in authorization, claims, and encounter data. Clinical code knowledge (ICD, CPT, etc) related to utilization data.\nAdvanced skills in Microsoft Office, SQL Transactional SQL (T-SQL), SQL Server Reporting Services (SSRS), and Tableau.\nExperience in SQL Server Integration Services (SSIS), Visual Basic for Applications (VBA).\nMust have analytical, communication, documentation, interpersonal, planning, presentation, problem-solving and research skills.\nAbout Aston Carter:\nPlease Note: Scammers are posing as Aston Carter. We'll never contact you via Gmail, Telegram, or WhatsApp and we'll never solicit money from you.\nAt Aston Carter, we\u201a\u00c4\u00f4re dedicated to expanding career opportunities for the skilled professionals who power our business. Our success is driven by the talented, motivated people who join our team across a range of positions \u201a\u00c4\u00ec from recruiting, sales and delivery to corporate roles. As part of our team, employees have the opportunity for long-term career success, where hard work is rewarded and the potential for growth is limitless. Established in 1997, Aston Carter is a leading staffing and consulting firm, providing high-caliber talent and premium services to more than 7,000 companies across North America. Spanning four continents and more than 200 offices, we extend our clients\u201a\u00c4\u00f4 capabilities by seeking solvers and delivering solutions to address today\u201a\u00c4\u00f4s workforce challenges. For organizations looking for innovative solutions shaped by critical-thinking professionals, visit [AstonCarter.com.](AstonCarter.com) Aston Carter is a company within Allegis Group, a global leader in talent solutions. The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law. If you would like to request a reasonable accommodation, such as the modification or adjustment of the job application process or interviewing process due to a disability, please call 888-237-6835 or email [astoncarteraccommodation@astoncarter.com](mailto:%20astoncarteraccommodation@astoncarter.com) for other accommodation options. However, if you have questions about this position, please contact the Recruiter located at the bottom of the job posting. The Recruiter is the sole point of contact for questions about this position.\nShow more\nShow less",
      "job_skills":"Healthcare Informatics, Statistics, Computer Science, Data Analytics, Data Visualization, Data Management, Data Transformation, Data Auditing, Statistical Analysis, Reporting, Data Documentation, CMS Medicare Advantage (Part C), CMS Prescription Drug Coverage (Part D), CMS Special Needs Plan (SNP), DHCS MediCal Managed Care reporting, Authorization Data, Claims Data, Encounter Data, Clinical Code Knowledge, ICD, CPT, Microsoft Office, SQL Transactional SQL (TSQL), SQL Server Reporting Services (SSRS), Tableau, SQL Server Integration Services (SSIS), Visual Basic for Applications (VBA), Analytical Skills, Communication Skills, Documentation Skills, Interpersonal Skills, Planning Skills, Presentation Skills, ProblemSolving Skills, Research Skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Analyst",
      "company":"Proven Recruiting",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-at-proven-recruiting-3771218654",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Senior Data Analyst \u201a\u00c4\u00ec Contract to Hire\nMust be local to Houston and able to work a hybrid work schedule downtown.\nWhat you will do:\nWork closely with Stakeholders to understand and gather requirements, create visualization in Tableau, write complex SQL queries.\nRequirements:\n5 years' experience in Tableau \u201a\u00c4\u00ec\n5 years experience in SQL and writing complex queries\nGCP BigQuery Experience\nBachelor's Degree\nEligible to work in the US without sponsorship\n8-5 M-F\nWhat does this position pay?\nCompensation is determined by several factors which may include skillset, experience level, and geographic location.\nThe expected range for this role is $45.00 to $53.00 per hour. Please note this range is an estimate and actual pay may vary based on qualifications and experience.\nShow more\nShow less",
      "job_skills":"Tableau, SQL, GCP BigQuery",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analytics Engineer",
      "company":"NR Consulting",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analytics-engineer-at-nr-consulting-3768017759",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Summary\nMembers of the Analytics Engineering team become experts in the use of our software products and work with customers in helping them solve their industrial process analytics challenges and foster user engagement. The mission of the Analytics Engineering team is to design and implement technical solutions to extract maximum customer value from Client's solution adoption. This means partnering with customers to deliver sustainable, scalable, and profitable business outcomes.\nKey Responsibilities\nAs a Key Customer-facing Team Member, You Will\nShowcase Client solutions.\nIntroduce the art of the possible to both active and prospective customers with Client through promotional content and targeted demos to land and expand Client use.\nImplement Client solutions to foster user engagement.\nLeverage customer relationships to Client and implement high-value use cases that expand Client usage.\nWhen applicable, collaborate with Client partners to deliver value for the customer.\nTrain and coach customer team on analytics methodology to implement and operationalize Client solution.\nServe as customers Trusted Technical Advisor\nIdentify and build relationships with customer champions and end-users to understand business objectives and process pain points.\nCollaborate with customer champions and end-users to complete use cases that deliver a high return on investment for the customer.\nIdentify gaps in Client capabilities required to meet customer needs and give relevant technical product feedback to the product\nShow more\nShow less",
      "job_skills":"Technical Consulting, Software Products, Analytics, Technical Solutions, Client Solutions, Customer Engagement, HighValue Use Cases, Analytics Methodology, Product Feedback, Training and Coaching, Problem Solving, Demos, Customer Relationships, User Engagement, Communication, Collaboration, Product Knowledge, Implementation, Use Cases, Gap Analysis",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst II-Mid-level",
      "company":"ReviveRX",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-ii-mid-level-at-reviverx-3787930410",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Summary\/Objective\nThis position supports the product and strategy team by collecting, processing, and analyzing datasets to extract meaningful insights. Statistical methods and data visualization tools are utilized to present findings.\nEssential Functions\nInvolved in projects related to implementing data-driven solutions, particularly focused on AI and LLM based projects, machine learning, and chatbot technologies.\nEnhances efficiency, user experience, and overall success through advanced analytics and innovative technologies.\nPlays a crucial role in creating operational dashboards and KPIs for different departments.\nIndicates a comprehensive approach to data analytics and visualization, aligning with organizational objectives and contributing to enhanced operational insights.\nWorks on assigned daily and weekly tasks to maintain automations and business intelligence (BI) processes.\nUses a ticketing system to ensure a systematic approach in addressing new requests and monitors the progress of tasks, providing a clear and organized way to manage workflows and product orders.\nCollaborates with team leads and team members in setting priorities for the tickets, ensuring efficient task management and timely completion.\nConducts trend analysis to identify patterns, anomalies, and potential areas for improvement. Stays informed about industry trends and best practices in data analysis.\nDevelops and implements predictive models to forecast trends and outcomes.\nEvaluates model performance and iterates as needed for continuous improvement.\nCreates visually appealing and understandable dashboards and reports.\nCommunicates findings effectively to both technical and non-technical audiences.\nPerforms ETL by extracting data from various sources, transforming it into a consistent format, and loading it into a destination for analysis.\nWrites scripts or codes to perform statistical analysis on datasets.\nPerforms other related duties as required and assigned.\nSkills And Attributes\nCapability to generate innovative ideas and think outside conventional boundaries to foster creativity.\nAdaptability to adjust and thrive in changing environments.\nStrong analytical and problem-solving skills.\nAbility to quickly grasp and comprehend new information or skills.\nAttention to detail and ability to work independently or in a team.\nSupervisory Responsibility\nThis position has no supervisory responsibly.\nWork Environment\nThis is a remote position which would ideally be conducted in a home office setting. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines.\nPhysical Demands\nThis position requires frequent sitting, walking, standing, reading, seeing, speaking, hearing, listening, organizing, interpreting data and information, operating office equipment, typing using a computer keyboard and mouse, viewing a computer screen monitor, and use of a telephone. Some positions may require lifting, occasional bending or kneeling. The working environment consists of an indoor and climate-controlled setting the majority of the time. The employee may regularly lift and\/or move objects up to 25 pounds.\nTravel\nTravel is primarily local during the business day, although some out-of-area and overnight travel may be expected.\nRequired Education And Experience\nBA\n2-4 years\u201a\u00c4\u00f4 experience in healthcare or Tech environment.\nStrong knowledge of Receiving, Warehouse, and Material Handling operations, methods, and practices.\nAdditional Eligibility Qualifications\nPower BI or Data Visualization Certification preferred.\nOther Duties\nPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice\nPowered by JazzHR\nfp3q8HxeJT\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Visualization, AI, Machine Learning, Chatbot Technologies, Advanced Analytics, Business Intelligence, Data Warehousing, ETL, Statistical Analysis, Predictive Modeling, Dashboard Creation, Report Creation, Data Communication, Power BI, Data Visualization Certification",
      "Category":"Data Science"
  },
  {
      "job_title":"Principal Data Engineer",
      "company":"Inceed",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-data-engineer-at-inceed-3770814508",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Compensation:\n$140,000-$160,000\nLocation:\nHouston, TX Hybrid\nPrincipal Data Engineer\nInceed has partnered with a growing supply chain and logistics company to help find an eager and experienced Principal Data Engineer to add to their team!\nThe successful candidate will be responsible for leading a team of data engineers who are responsible for designing, building, and maintaining robust data pipelines and processing systems.\nResponsibilities:\nLead and inspire a team of data engineers, providing day-to-day guidance and support to ensure the successful design, development, and maintenance of data pipelines and processing systems.\nUtilize your deep expertise in technologies such as Azure, Spark SQL, SQL Server, Azure Data Factory, Azure Synapse, Azure Databricks, Dimensional Modeling, Agile, Azure DevOps, and DataOps to drive innovative and efficient solutions.\nProvide technical guidance and promote best practices in data engineering, ensuring the team follows industry standards and delivers high-quality solutions.\nTake ownership of the successful delivery of data engineering projects, collaborating with cross-functional teams and resolving technical challenges.\nAssist in shaping and evolving our data infrastructure to support current and future data needs.\nDemonstrate strong verbal and written communication skills, effectively communicating technical concepts to both technical and non-technical stakeholders.\nRequired Qualifications & Experience:\n10+ years of overall working experience.\n5+ years of experience in a data engineer, data integration, or data warehousing role.\n5+ years of hands-on experience with Azure Data Factory, Azure Synapse, and Azure Databricks.\nProficiency in SQL programming and experience working with SQL Server.\nStrong communication skills, both verbally and in writing.\nPerks & Benefits:\nCompetitive salary\nHealth, dental, and vision insurance\nRetirement plans\nFlexible working hours\nBonus opportunity\nOpportunities for professional development and growth\nOther Information:\nThis position requires a hybrid schedule of 4 days onsite, 1 day remote.\nIf you are interested in learning more about the Principal Data Engineer opportunity, please submit your resume for consideration. Our client is unable to provide sponsorship at this time.\nWe are Inceed, a staffing and direct placement firm who believes in the possibility of something better. Our mission is simple: We\u201a\u00c4\u00f4re here to help every person, whether client, candidate, or employee, find and secure what\u201a\u00c4\u00f4s better for them.\nInceed is an equal opportunity employer. Inceed prohibits discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.\nShow more\nShow less",
      "job_skills":"Data Engineering, Azure, Spark SQL, SQL Server, Azure Data Factory, Azure Synapse, Azure Databricks, Dimensional Modeling, Agile, Azure DevOps, DataOps, SQL Programming",
      "Category":"Data Science"
  },
  {
      "job_title":"Power BI Data Analyst",
      "company":"Korn Ferry",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/power-bi-data-analyst-at-korn-ferry-3785871646",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"We have partnered with our global technology company client in search for a Power Business Intelligence Analyst for their corporate office for a long-term contract. Our client is open to hybrid or remote consultant and seeking an someone available to start by next week.\nResponsibilities\nPower BI expert that can help us build reports with data sets that already exist\nAutomation and clean up of what exists\nAbility to manually load budgets and excel based datasets\nAbility to create ad hoc reporting in BI by linking excel files\/data sets\nAbility to build in calculations in a BI reports\nAbility to put together data sets out of ERP systems and put them in a data warehouse. This person will build formulas and reporting.\nSkills Required\nBI Power User\nFinance background\nEducation & Work\nExperience\nBachelors degree in related discipline\n5+ years experience\nTitle Power BI Data Analyst\nLocation Open\nClient Industry Technology\nAbout Korn Ferry\nKorn Ferry unleashes potential in people, teams, and organizations. We work with our clients to design optimal organization structures, roles, and responsibilities. We help them hire the right people and advise them on how to reward and motivate their workforce while developing professionals as they navigate and advance their careers. To learn more, please visit Korn Ferry at\nwww.Kornferry.com\nShow more\nShow less",
      "job_skills":"Power BI, Data Analysis, Data Visualization, Reporting, Automation, Data Cleaning, Data Warehousing, ERP Systems, Finance, Excel",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Analyst",
      "company":"V-Soft Consulting Group, Inc.",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-at-v-soft-consulting-group-inc-3782727862",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Hiring-Data Analyst- Houston, TX (Hybrid) - Must go onsite in Downtown Houston 3x a week.\nJob Title: Data Analyst\nHouston, TX (Hybrid) - Must go onsite in Downtown Houston 3x a week.\n6-12 Month Contract\nOpening with Chevron for a Data Analyst. I would like to show profiles to the manager today for a quick turn around. Ive attached the resume of someone that has just got the offer on the same team for a data analyst position as well.\nThe priorities for this role are: (Need local candidates)\n\u201a\u00c4\u00a2 PowerBI\n\u201a\u00c4\u00a2 SQL\n\u201a\u00c4\u00a2 Oil & Gas \/ Utility domain experience\nThis is Data analyst IV so we can target 5+ years of experience .\nThe official Job description is below but again, we only need 5 years of experience despite what the job description is\nSeeking data analysts. Responsibilities are to collect, clean, and interpret datasets from various sources to support building of the Surface Data Hub, an ecosystem of defined interrelated data products to service the Surface domain.\nKey job responsibilities\n\u201a\u00c4\u00a2 Receive direction from Product owner and Data Architect for data analysis objectives and tasks (story level)\n\u201a\u00c4\u00a2 Act as a mentor to junior Data Analysts on the team\n\u201a\u00c4\u00a2 Collaborating with data architects, data analysts and data engineers to develop the desired solutions\no Collaborate and receive rules and requirements from business, functional, or application SMEs to inform analysis tasks.\no Analyze datasets, entities, application and system of record data sources, define relationships and attributes, and determine source to target mapping requirements\no Clean and validate data to ensure accuracy and quality prior to maturing the feature to build\no Define data engineering requirements for pipeline and data products build\no Spike with other IT professionals to define interface requirements between applications or systems within the Chevron portfolio or externally with vendors apps\no Occasional collaboration with the Enterprise Data Architects and the Surface Platform Architects to develop and refine the Data Models as part of the Chevron Enterprise Data Model\no Initial QC and validation of produced data products before delivering to stakeholders\nRequired skills\n\u201a\u00c4\u00a2 Strong knowledge of the Facilities business domain and processes\n\u201a\u00c4\u00a2 Strong data-level analytical skills\n\u201a\u00c4\u00a2 Strong interpersonal skills working within a team\n\u201a\u00c4\u00a2 Proficient interpersonal skills working external to the immediate team (i.e. system of record SMEs or admins, functional SMEs, vendor SMEs)\n\u201a\u00c4\u00a2 Proficient SQL skills to build queries\nPreferred Requirements\n\u201a\u00c4\u00a2 Basic or awareness of data modeling and approaches\n\u201a\u00c4\u00a2 Experience with cloud services such as ADLS gen 2, Databricks, Synapse, Azure SQL\n\u201a\u00c4\u00a2 Basic or awareness of knowledge of the Chevron Enterprise Data Model\n\u201a\u00c4\u00a2 ERP system experience (e.g. SAP S\/4HANA, JDE)\n\u201a\u00c4\u00a2 Product allocation experience (e.g. Energy Components)\n\u201a\u00c4\u00a2 Awareness of industry standards such as ISO-14224, CFIHOS\nLocation preference:\n1. Houston\n2. Aberdeen, UK\n3. Any US onshore or nearshore option like Buenos Aires that has timezone overlap with Houston and Aberdeen,\nWarm Regards\nPriyanka\npneelam@vsoftconsulting.com\n502-242-1668\n#LI-PN1\nShow more\nShow less",
      "job_skills":"PowerBI, SQL, Oil & Gas \/ Utility, Data Analysis, Data Modeling, Data Engineering, Azure Data Lake Storage gen 2, Databricks, Synapse, Azure SQL, SAP S\/4HANA, JDE, ISO14224, CFIHOS",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Analyst",
      "company":"David Weekley Homes",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-analyst-at-david-weekley-homes-3780062363",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nDavid Weekley Homes is seeking a Lead Data Analyst for a full-time, in office role. This position will play a key role in implementing our data strategy, serving as our company\u201a\u00c4\u00f4s technical expert in Reporting & Analytics, while understanding our data's business and IT implications, usage, and significance. You will be instrumental in bridging the gap between data, business, and IT, turning data into actionable business insights.\nResponsibilities\nData Expertise and Standards Implementation:\nDevelop a comprehensive understanding of how data is utilized across the organization, understanding its impact in various business and IT contexts.\nEstablish and enforce standards for data usage, presentation, and Power BI report formatting, ensuring consistency and quality across all data-driven initiatives.\nServe as a leading authority on the data's meaning, origins, and applications, providing guidance on best practices in data management and reporting.\nCollaborate with the Director of Data Analytics to align the reporting and analytics strategy with the overall business objectives.\nAd-hoc Analysis And Insights\nConduct targeted ad-hoc data analyses to address specific business challenges.\nTranslate complex datasets into clear, actionable insights for various departments, adhering to established standards for data presentation.\nEffectively communicate analytical findings to a wide range of stakeholders, maintaining high standards in data clarity and accuracy.\nPower BI Report Development\nLead the development and maintenance of Power BI reports and dashboards, following organizational guidelines for report design and data visualization.\nEnsure reporting tools are accurate, timely, and aligned with established data standards and best practices.\nParticipation In Data Solutions Testing\nCollaborate in testing data solutions, including data integrations and data warehouses, ensuring alignment with business, IT requirements, and data standards.\nAssist in identifying and resolving data-related issues, maintaining a focus on data quality and adherence to standards.\nStakeholder Engagement\nWork closely with both business and IT units, leveraging your extensive data knowledge to meet their analytical needs.\nProvide guidance and support on Power BI tools, data interpretation, and best practices in data reporting.\nContinuous Improvement\nContinually enhance data analysis methodologies, reporting processes, and standards.\nStay updated on the latest trends in data analysis, Power BI, and business intelligence.\nQualifications\nMinimum of 7 years of experience performing data analysis.\nMinimum of 2 years of experience in Power BI report development, including data modeling, DAX, and Power Query.\nStrong proficiency in SQL, Microsoft Excel, and other data analysis tools.\nExperience in participating in the testing of data solutions and integrations.\nExceptional analytical and problem-solving skills.\nExcellent communication skills, able to effectively articulate complex data insights to both technical and non-technical audiences.\nSelf-motivated, able to work independently in a dynamic business and IT environment.\nWork Location:\nThis is a full-time position that is required to be on-site. Our office is located in West Houston, near the intersection I-10 Katy Freeway and 610 W Loop N Frwy.\nAbout Us\nDavid Weekley Homes is an award-winning home builder that has earned spots on FORTUNE\u00ac\u00c6 magazine's list of \u201a\u00c4\u00fa100 Best Companies to Work For\u201a\u00c4\u00f9 17 times! We build homes in 19 markets coast to coast and are the largest privately held builder in America.\nWe have an excellent benefits package, with some unique features including:\nGreat opportunities to participate in outreach and community involvement programs\nMedical, Dental and Vision insurance\nPaid Vacation, Holidays and PTO\n401(k) with discretionary 8% match\nProfit Sharing\nTeam Member & Family New Home Discount\nTeam Member Product Discounts\nCollege Scholarship Program\nAnd More!!\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Management, Data Reporting, Data Standards, Data Strategy, Power BI, Power Query, Microsoft Excel, SQL, DAX, Business Intelligence, Data Visualization, Data Integration, Data Warehousing, Analytical Thinking, Problem Solving, Stakeholder Engagement, Communication Skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"World Wide Technology",
      "job_location":"Roanoke, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-world-wide-technology-3782269155",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Data Center Engineer\nCompany Overview\nWorld Wide Technology (WWT), a global technology solutions provider with $17 billion in annual revenue, combines the power of strategy, execution and partnership to accelerate transformational outcomes for large public and private organizations around the world. Through its Advanced Technology Center, a collaborative ecosystem of the world's most advanced hardware and software solutions, WWT helps customers and partners conceptualize, test and validate innovative technology solutions for the best business outcomes and then deploys them at scale through its 4 million square feet of global warehousing, distribution and integration space. With over 10,000 employees and more than 55 locations around the world, WWT's culture, built on a set of core values and established leadership philosophies, has been recognized 11 years in a row by Fortune and Great Place to Work\u00ac\u00c6 for its unique blend of determination, innovation and leadership for diversity and inclusion. With this culture at its foundation, WWT bridges the gap between business and technology to make a new world happen for its customers, partners and communities.\nWorld Wide Technology Holding Co, LLC. (WWT) has an opportunity available for a\nData Center Engineer\nto support our client in an ongoing Data Center refresh project.\nLocation:\nRoanoke, TX\nAvailable Shifts:\n(2 Openings) 7 PM \u201a\u00c4\u00ec 7 AM CST Thursday, Friday, Saturday, and Alternating Wednesdays.\nMUST BE OKAY WITH 12 HOUR NIGHT SHIFTS - Expectation is to have 80 hours of work in a 2 week period.\nDuration:\n12 Months (Expected to renew for up to 3 years, on an ongoing 12-month renewal)\nContract Designation:\nFull Time Contingent \u201a\u00c4\u00ec Contractors will be eligible for WWT\u201a\u00c4\u00f4s Full Time Employee Benefits Package including Medical, Vision, Dental, PTO, Paid Holidays, and more.\nResponsibilities:\nInstalling\/de-installing\/relocating all distributed systems and network hardware (CSUs, DSUs, routers, switches, encryptors, firewalls, etc.) in the Americas Data Centers within the internal service level mandates\nInstalling\/de-installing \/extending\/relocating\/testing all carrier circuits to the network hardware\nInstalling\/de-installing\/relocating all patch cabling for systems and network hardware\nInstalling\/de-installing\/relocating all Data Center hardware\nAssist with the coordination of cabinet power, circuit, and patch infrastructure installations w\/various facilities, electrical and communications vendors\nAssist with the coordination of network component configurations\nCoordinate and Install SAN cabling infrastructure\nManaging network ports and assist with the management of all consumable items (cables, labels, tie wraps, rail kits, etc.)\nMaintaining the integrity of the data center facilities, systems and communications environments through general housekeeping and best operations practices\nQualifications:\nRequired skills include 3+ years of experience in the implementation, maintenance and analysis of data center facilities, hardware, communications infrastructure, strategies, tools and effective troubleshooting techniques.\nBasic background on enterprise data center facilities and infrastructure environments such as PDUs, RPPs, network and SAN infrastructures. In depth knowledge on complex, Enterprise class inter-networked environments involving a combination of switched\/routed\/shared Ethernet, TwinAx (100GigE, 25GigE,10GigE, GigE, 100M, and 10M), token ring, SAN, and wide area connectivity.\nStrong knowledge of WAN technologies (OC-x, DS-x), subnetting and TCP\/IP protocol a must.\nExcellent communication and writing skills a must.\nKnowledge of trouble ticketing systems, change control, Project processes and associated tools.\nLogical problem- solving techniques and associated experience in system, data center facilities, and telecommunications.\nMust be Able to Lift up to 50lbs.\nEqual Opportunity Employer Minorities\/Women\/Veterans\/Disabled\nShow more\nShow less",
      "job_skills":"Data Center Facilities, Hardware, Communications Infrastructure, Troubleshooting, PDUs, RPPs, Network Infrastructures, SAN Infrastructures, Switched\/Routed\/Shared Ethernet, TwinAx, Token Ring, Wide Area Connectivity, WAN Technologies, OCx, DSx, Subnetting, TCP\/IP Protocol, Trouble Ticketing Systems, Change Control, Project Processes, Logical ProblemSolving Techniques",
      "Category":"Data Science"
  },
  {
      "job_title":"Analyst, Data Accuracy Response Team",
      "company":"Palo Alto Networks",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/analyst-data-accuracy-response-team-at-palo-alto-networks-3783916444",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Company Description\nOur Mission\nAt Palo Alto Networks\u00ac\u00c6 everything starts and ends with our mission:\nBeing the cybersecurity partner of choice, protecting our digital way of life.\nOur vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we\u201a\u00c4\u00f4re looking for innovators who are as committed to shaping the future of cybersecurity as we are.\nOur Approach to Work\nWe lead with flexibility and choice in all of our people programs. We have disrupted the traditional view that all employees have the same needs and wants. We offer personalization and offer our employees the opportunity to choose what works best for them as often as possible - from your wellbeing support to your growth and development, and beyond!\nAt Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together!\nJob Description\nYour Career\nPalo Alto Networks\u00ac\u00c6 is the fastest-growing security company in history. If you are a motivated, intelligent, creative, and hardworking individual, then this is the place for you! One of the keys to our success is our relentless focus on leveraging data to drive insights and decision making. Our Data Accuracy Response Team is tasked with ensuring our data is regulated, accurate, and reliable on a day to day basis. This includes managing urgent escalations, executing and monitoring changes in data, and observing trends to guide system improvements. The Data Governance Analyst is the front line in ensuring that these goals come to fruition. This position reports to the Director, Sales Operations for Data Integrity and Policy and will have a high degree of interaction with the Analytics, Business Operations, and IT functions across Palo Alto Networks.\nYour Impact\nCollaborate with internal stakeholders to solve service requests\/issue resolution related to Data Governance\nEfficiently manage and execute against overall ticket queue to adhere to SLA requirements\nResearch and analyze public data to validate changes to account hierarchies, deduplication, and firmographic, etc.\nEnforce data standards, policies, and processes\nPerform mass data analysis and updates of account information to increase account accuracy\nExecute regular and periodic data maintenance and validation activities\nHandle issues and escalations to closure\nMonitor service request trends\nAssist in SLA design, development, and execution\nCollaborate with the Data Integrity and Policy Team on documentation of data standard and policies\nQualifications\nYour Experience\nInterest in the concerns and topics related to data maintenance\nCan execute tasks with high attention to detail and a commitment to accuracy\nOrganized, proactive individual that can operate independently in solving complex problems with little guidance\nStrong interpersonal skills for internal collaboration\nSkillfully manage requestor escalations through appropriate channels\nProficient in public data research and analysis\nExperience with SFDC is required\nExperience using data management tools such as SOQL\/ETL a big plus\nExperience working with Google Suite or similar platforms\nComfortable working in a fast-paced, dynamic work environment\nAbility to speak fluently in business language\nSpanish fluency considered a significant advantage\nAdditional Information\nThe Team\nOur Strategy & Operations team at Palo Alto Networks works on a set of strategic initiatives to drive process improvement projects to deliver improved efficiency and scale through simplification, automation and innovation across Sales Operations tools and processes.\nYou will be part of a growing, passionate, and dynamic team with an opportunity to work on challenging and exciting projects \u201a\u00c4\u00ec centered on what we believe is one of the most significant mission statements in the world.\nOur Commitment\nWe\u201a\u00c4\u00f4re trailblazers that dream big, take risks, and challenge cybersecurity\u201a\u00c4\u00f4s status quo. It\u201a\u00c4\u00f4s simple: we can\u201a\u00c4\u00f4t accomplish our mission without diverse teams innovating, together.\nWe are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.\nPalo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.\nAll your information will be kept confidential according to EEO guidelines.\nThe compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales\/commissioned roles) is expected to be between $81,900\/yr to $132,450\/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.\nShow more\nShow less",
      "job_skills":"Data Governance, Data Accuracy, Data Integrity, Data Analysis, Data Management, Data Maintenance, Research, SFDC, SOQL, ETL, Google Suite",
      "Category":"Data Science"
  },
  {
      "job_title":"Business Intelligence Analyst \u201a\u00c4\u00ec Data Engineering Support",
      "company":"The University of Texas at Dallas",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/business-intelligence-analyst-%E2%80%93-data-engineering-support-at-the-university-of-texas-at-dallas-3785764107",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"The Business Intelligence Analyst position in OISDS will work collaboratively as a member of the team and will interact with internal and external stakeholders to support a variety of data management, training, analysis and benchmarking initiatives at The University of Texas at Dallas. The person in this role will assist with the ongoing development and implementation of tools to promote the development and use of analytic dashboards designed for wide distribution to UT Dallas campus stakeholders.\nThe primary functions of this role will be to\n1)\nassist OISDS with building relationships with campus constituents to develop analytic data resources and institutional research studies,\n2)\nassist with training and knowledge transfer activities related to OISDS tools, and\n3)\nconduct internal institutional research studies, assist with external data requests, perform data analysis, generate analytics, and communicate results involving internal data across numerous domains.\nIn this role, the Business Intelligence Analyst will provide direct support to internal and external stakeholders, manage relationships with data providers and end users. This role will also be tasked with enhancing existing and developing new analytics and data resources. The person in this role will report to the Senior Director of Institutional Reporting and Analytics.\nMinimum Education And Experience\nBachelors degree in related field.\nFour (4) years related professional experience.\nEquivalent combination of education and experience may be considered.\nPreferred Education And Experience\nMaster's Degree in a related field and two years of data analysis work experience.\nPossess a strong working knowledge of SQL and SAS programming.\nExperience in predictive analytics and machine learning.\nExperience working in an institutional research setting, a basic working knowledge of financial aid, admissions, and student data sources in a higher education setting (e.g., institutional, Federal (Integrated Post-Secondary Educational Data System), and the State via the Texas Higher Education Coordinating Board.\nBasic working knowledge of economic and accounting principles and practices, legal statutes, and analysis and reporting of financial data.\nExperience in designing business intelligence and\/or qualitative\/quantitative research studies to assist organizations in developing data-informed strategies.\nEssential Duties And Responsibilities\nReporting to the Senior Director, this Business Intelligence Analyst will focus on the data preparation processes for business intelligence solutions. The person in this role will work closely with the Data Warehouse Team to support the vision and delivery of optimized and accessible institutional data to deliver metrics capable of making data informed decisions across the University through reporting and analytics.\nWrites complex SQL and\/or DAX statements and scripts to support the development of business intelligence deliverables.\nDevelops and validates data models and schemas.\nDevelops and documents processes and procedures in collaboration with OISDS team members and other stakeholders for accessing data and for ensuring reliability of information retrieved.\nAutomates processes for ingesting, merging, and working with data from disparate sources using tools and applications.\nMaintains knowledge of best practices and emerging trends for infrastructure and processes (e.g., ETL, API) needed to collect, store, and analyze institutional data.\nAdditional Information\nRemote Work:\nThis role is eligible for a hybrid (partly remote\/partly in office) work schedule, subject to business need and manager approval. A UT Dallas Remote Work Agreement will be required within 14 days after approval. The Business Intelligence Analyst \u201a\u00c4\u00ec Data Visualizations must be located within the DFW Area and have the ability to be on campus within 24 hours of notice.\nWhat We Can Offer\nUT Dallas is an Equal Opportunity Employer. We offer an employee-friendly work environment with a comprehensive benefit package including:\nCompetitive Salary\nTuition Benefits\nInternal Training\nMedical insurance \u201a\u00c4\u00ec including\n100% paid\nemployee medical coverage for full-time employees\nDental Insurance\nVision Insurance\nLong and short-term disability\nRetirement Plan Options\nPaid time off\nPaid Holidays All UT Dallas employees have access to various\nprofessional development\nopportunities\n, including a membership to Academic Impressions, LinkedIn Learning, and UT Dallas Bright Leaders Program.\nVisit\nhttps:\/\/hr.utdallas.edu\/employees\/benefits\/\nfor more information.\nAbout Us:\nUT Dallas is a top public research university located in one of the nation's fastest-growing metropolitan regions. Our seven schools offer more than 140 undergraduate and graduate programs, plus professional certificates and fast-track programs. Our student body is 31,000 strong, reflecting students from over 100 countries and a multiplicity of identities and experiences. UT Dallas is committed to graduating well-rounded members of the global community whose education has prepared them for rewarding lives and productive careers in a constantly changing world. The University has a variety of programs and initiatives to support engagement and success for all members of the campus community. Employee benefits include a range of physical and mental wellness resources. \u201a\u00c4\u00faLilyPad\u201a\u00c4\u00f9 lactation facilities are located throughout the campus. There are several Employee Resource Groups (ERGs) comprised of individuals who share common interests to help build community among UT Dallas faculty and staff (e.g., Universal Access ERG, Military and Veteran ERG, UT Dallas Young Professionals). Rich with visual and performing arts venues, museum districts, professional and semi-professional athletics teams, botanical gardens, accessible trails and so much more, the Dallas-Fort Worth (DFW) metroplex has something for everyone to explore. UT Dallas partners with regional higher education institutions and school districts and with the\nRichardson Innovation Quarter\n(Richardson IQ), a major hub for innovation, entrepreneurship, and educational activities.\nImportant Message\nAll employees serve as a representative of the University and are expected to display respect, civility, professional courtesy, consideration of others and discretion in all interactions with members of the UT Dallas community and the general public.\nThe University of Texas at Dallas is committed to providing an educational, living, and working environment that is welcoming, respectful, and inclusive of all members of the university community. UT Dallas does not discriminate on the basis of race, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, national origin, disability, genetic information, or veteran status in its services, programs, activities, employment, and education, including in admission and enrollment. EOE, including disability\/veterans. The Universityis committed to providing access, equal opportunity, and reasonable accommodationfor individuals with disabilities.To request reasonable accommodation in the employment application and interview process, contact theADA Coordinator.For inquiries regarding nondiscrimination policies, contact theTitle IX Coordinator.\nShow more\nShow less",
      "job_skills":"SQL, DAX, ETL, API, Data mining, Data preparation, Predictive analytics, Machine learning, Data modeling, Data analysis, Data visualization, Data management, Data warehousing, Institutional research, Business intelligence, Data governance, Data architecture, Data infrastructure, SAS",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Building Operating Engineer (3rd Shift)",
      "company":"JLL",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-building-operating-engineer-3rd-shift-at-jll-3748264637",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"General Description:\nThe Data Center Operations Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)\nPrincipal Duties and Responsibilities\nTask will include but not be limited to:\nResponsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire\/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.\nRequires the ability to analyze the operation of various systems, determine the cause of any problems\/malfunctions and take corrective action as required.\nComply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.\nLearn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.\nWork order management, including CMMS, Vendor Management, and Customer Facing Tickets.\nUnderstanding and complying with emergency escalation procedures.\nPerform additional job duties as required.\nMinimum Requirements:\nPreferred to have hands-on experience working in a data center\/critical facility, including UPS.\nSystems, emergency generators, and switchgears.\nHigh School diploma or GED equivalent\n2+ years related work experience.\nWorking knowledge of computer applications including Word and Excel.\nDemonstrated verbal\/written communication skills.\nPreferred Requirements:\nCorrigo Experience.\nMCIM \/ Salesforce Experience.\nZendesk Experience.\nService Now Experience.\nReceived EPA 608.\nTrained in NFPA70E.\nShow more\nShow less",
      "job_skills":"Data Center Operations, UPS, Electrical Systems, Generators, Cooling Systems, HVAC, Chillers, CRAC, CRAH, Plumbing, Controls, ATS, STS, PDU, Primary Switchgear, Power Distribution, Transformers, CMMS, Vendor Management, Customer Facing Tickets, Corrigo, MCIM, Salesforce, Zendesk, Service Now, EPA 608, NFPA 70E, Word, Excel",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Building Operating Engineer (3rd Shift)",
      "company":"JLL",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-building-operating-engineer-3rd-shift-at-jll-3748261897",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"General Description:\nThe Data Center Operations Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)\nPrincipal Duties and Responsibilities\nTask will include but not be limited to:\nResponsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire\/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.\nRequires the ability to analyze the operation of various systems, determine the cause of any problems\/malfunctions and take corrective action as required.\nComply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.\nLearn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.\nWork order management, including CMMS, Vendor Management, and Customer Facing Tickets.\nUnderstanding and complying with emergency escalation procedures.\nPerform additional job duties as required.\nMinimum Requirements:\nPreferred to have hands-on experience working in a data center\/critical facility, including UPS.\nSystems, emergency generators, and switchgears.\nHigh School diploma or GED equivalent\n2+ years related work experience.\nWorking knowledge of computer applications including Word and Excel.\nDemonstrated verbal\/written communication skills.\nPreferred Requirements:\nCorrigo Experience.\nMCIM \/ Salesforce Experience.\nZendesk Experience.\nService Now Experience.\nReceived EPA 608.\nTrained in NFPA70E.\nShow more\nShow less",
      "job_skills":"Data Center Operations, Electrical Systems, Mechanical Systems, HVAC, Chillers, CRAC, CRAH, Plumbing, Controls, Emergency Backup Systems, Lighting, UPS, ATS, STS, PDU, Generators, Primary Switchgear, Power Distribution, Transformers, Hot Water Systems, Refrigeration, Chilled Water, Air Conditioning Equipment, Boilers, Ventilating, Water Heaters, Pumps, Valves, Piping, Filters, CMMS, Vendor Management, Customer Facing Tickets, Emergency Escalation Procedures, Corrigo, MCIM, Salesforce, Zendesk, ServiceNow, EPA 608, NFPA70E",
      "Category":"Data Science"
  },
  {
      "job_title":"Research Data Specialist I",
      "company":"The University of Texas at Dallas",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/research-data-specialist-i-at-the-university-of-texas-at-dallas-3776128940",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"The Decision Support Specialist assists the Office of Institutional Success and Decision Support with a variety of tasks related to accreditation, assessment, policy development and evaluation, institutional research, and office management. This entry-level role will support data management, data collection, administrative functions of the office and documentation of processes and procedures.\nThe specialist reports to the Associate Vice President and works closely with the Assistant Director on the day-to-day tasks of the unit, ensuring that project milestones are communicated to unit stakeholders, and assists with the coordination of unit events (webinars, workshops, trainings, and development programming). The specialist also supports the assessment staff in maintaining program assessment documentation, including assessment reports, using the University's online assessment platform.\nThe specialist will also assist with the collection and analysis of assessment data, organizing materials, and editing and proofreading documents and reports. The specialist may also be asked to conduct reviews of other institutions' policies and best practices within higher education and review documentation related to accreditation reports.\nMinimum Education And Experience\nBachelor's degree with six months of experience in a related field. An equivalent combination of relevant education and\/or experience may be considered.\nSix (6) months of process documentation\nSix (6) months of technical communication\nPreferred Education And Experience\nPreferred Education and Experience\nEducation:\nA Bachelor's degree in business administration, social sciences, education, or a related field.\nExperience:\nExperience working in higher education, some experience with qualitative and\/or quantitative data collection and analysis.\nSkills\n: Basic project management; excellent customer service skills; strong verbal, written, and interpersonal communication skills; collaboration, ability to manage multiple tasks and projects, and ability to respond to requests in a timely manner.\nEssential Duties And Responsibilities\nGeneral unit support includes assisting colleagues with:\nreviewing annual assessment plan and report submissions in the University's assessment platform for completion and communicating with assessment staff, as well as academic and administrative programs about assessment reports.\nproofreading reports and documents, including identifying discrepancies within text and visuals.\nmaking business processes transparent and sustainable\ntracking project milestones and communicating progress to unit leaders\nassisting with entry-level data collection, coding, and analysis tasks\ncollection and preparation of business expense and travel expense reimbursements\noffice purchases and maintaining office supply inventory\nprocessing and reviewing eCATs for building access, keys, and computer access\nwork order submissions to facilities management\nscheduling of Alpine Conference Room\ncollecting and distributing mail\nmaintaining and documenting computer inventory\nprocurement activities: utilize procurement software to prepare, review, submit, and receive purchase orders\nother duties as assigned\nAdditional Information\nRemote Work:\nAfter the probationary period, this role may be eligible for a hybrid (partly remote\/partly in office) work schedule, subject to business need and manager approval. A UT Dallas Remote Work Agreement will be required within 14 days after approval. The Research Data Specialist I must be located within the DFW Area and have the ability to be on campus within 24 hours of notice.\nWhat We Can Offer:\nUT Dallas aims to attract and retain talented faculty and staff to support the university's mission. We offer a comprehensive compensation and benefits package.\nMedical\nDental\nVision\nPaid time off\nRetirement\nLife insurance\nAD&D coverage\nUT Dallas also offers employee wellness programs, tuition assistance, and professional development through their BRIGHT Leaders program and a variety of virtual learning platforms. BRIGHT Leaders aims to support, encourage, and serve as a resource to cultivate and nurture effective leadership at all levels by providing trainings and resources to help all UTD employees grow their leadership skills. Visit our benefits webpage,\nhttps:\/\/hr.utdallas.edu\/employees\/benefits\/\nfor more information.\nIf you are looking for a rewarding career opportunity with great benefits? Look no further! Join our team!\nImportant Message\nAll employees serve as a representative of the University and are expected to display respect, civility, professional courtesy, consideration of others and discretion in all interactions with members of the UT Dallas community and the general public.\nThe University of Texas at Dallas is committed to providing an educational, living, and working environment that is welcoming, respectful, and inclusive of all members of the university community. UT Dallas does not discriminate on the basis of race, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, national origin, disability, genetic information, or veteran status in its services, programs, activities, employment, and education, including in admission and enrollment. EOE, including disability\/veterans. The Universityis committed to providing access, equal opportunity, and reasonable accommodationfor individuals with disabilities.To request reasonable accommodation in the employment application and interview process, contact theADA Coordinator.For inquiries regarding nondiscrimination policies, contact theTitle IX Coordinator.\nShow more\nShow less",
      "job_skills":"Data Management, Data Collection, Administrative Functions, Documentation, Processes, Project Management, Customer Service, Communication, Collaboration, Multiple Tasks Management, Timely Response, Annual Assessment, Proofreading, Business Processes, Project Milestones, Data Collection, Coding, Analysis, Business Expenses, Travel Expenses, Office Purchases, Office Supplies, Computer Access, Work Order Submissions, Conference Room Scheduling, Mail Collection, Computer Inventory, Procurement Activities, Purchase Orders",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Warrior Tech Solutions",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-warrior-tech-solutions-3766018260",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title:\nData Engineer\nLocation:\nSan Antonio, TX\/Plano, TX - onsite\nVisa:\nNo GC\nJob Description\nWe are in search of a highly experienced Senior Data Engineer who possesses strong expertise in DBT and Snowflake.\nRequriments For Candidates With Below Experiences\nDBT (data build tool)\nSQL Performance tunings in DBT\nSynchronization process in DBT\nComplex SQL queries\nReal-time CDC process\nSCD type process\nKindly share the resumes to *pavithran@warriortechsolutions.com* or contact@ +1 (813) 398-2457\nDeadline for Submission : 11\/21\/2023\nShow more\nShow less",
      "job_skills":"Data Engineering, DBT (Data Build Tool), Snowflake, SQL Performance Tuning, Synchronization Processes, Complex SQL Queries, Realtime CDC Process, SCD Type Process",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Engineer - Remote",
      "company":"Crash Champions",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-remote-at-crash-champions-3761294463",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Overview\nCrash Champions is home to a collection of team members driven by a deeply rooted purpose and guided by a powerful principle: Here, We Do More.\nIt is the Crash Champions DNA and it is the mark of who we are. Above everything, we believe in what we do; and we hold fast to the conviction of why we do it. As the largest founder-led collision repair service provider in the U.S., we serve our customers and business partners with an unexpected level of personal and professional service to build trust at every touch point.\nResponsibilities\nCrash Champions is seeking a Senior Database Engineer to join our IT Data Analytics team which supports Data andReportinginitiatives across the organization. The primary responsibility of this role is to design, implement, and support reporting and our data warehousesolutions.The candidatemusthave strong experience using the Microsoft SQL Server Platform with an emphasis in T-SQL and SSIS development. As a member of our Data Analytics team, the role will work closely with ourData Architect and IT Directorand business stakeholders across the organization.\nResponsible for working with business leaderships and IT Data Analytics team to gather business requirements, use cases, technical design, and implement solutions for data analysis, reporting, and data interfaces\nWorks in cross-functional team environment and has a strong track record to communicating insights and technical solutions to business functional leaders\nSQL performance tuning and optimization\nBuild technical\/data architecture for ODS\/DW using Kimball methodology\nDevelop and test SSIS ETL packages using SSDT\nManaging Timelines and task priorities utilizing Agile Scrum methodology\nCreate complex queries, data transformation, aggregation, stored procedures, and triggers.\nImplement and administer SQL Server Master Data Management Services.\nPerform unit, system, and integration testing of all developed code and DB objects.\nFully support the documentation of the data integration solutions, provide data dictionaries, Data Flow\/Process Flow diagrams and update runbooks.\nAutomate DB deployments using DevOps Pipelines.\nQualifications\nExperience with SQL Server 2012 and higher (SQL Server 2016 and higher is a plus), including SQL Server Master Data Management Services\nExperience with Snowflake, Azure SQL Server, Data Warehouse, Power App and Data Factory a plus\nKnowledge and experience implementing ETL design patterns for data warehousing including Kimball methodology\nExperience working with different source data such as SQL Server, Excel, Access, Flat Files, On-Prem, Cloud, APIs, RESTful API calls within SSIS\/ETL , and many more\nDemonstrate understanding of error handling techniques in MS SQL code and Microsoft SSIS solutions.\nStrong analytical ability, problem-solving, and critical thinking skills\nStrong attention to detail and data validationand in documentation of methods, procedures, standards\nExcellent communication and presentation skills to effectively collaborate with multiple business functions across our organization; and works effectively in a team environment\nFull lifecycle development (SDLC) skillsusing Azure DevOps, GIT, and SmartSheetto work and roadmap in a fast paced, dynamic environment with changing deadlines and requirements\nBachelor\u201a\u00c4\u00f4s Degree in Management Systems, Engineering, Mathematics, Economics, Computer Science or related field with 7+ years of daily experience with Microsoft SQL Server administration and development\nMust be U.S. Citizen or Permanent Resident\nTechnologies\nMicrosoft SQL Server 2012+ JSON\/XML\nT-SQL\nMaster Data Services\nMS BI Stack (SSRS, SSIS, SSAS)\nPower BI preferred but not required\nSnowflake, Microsoft Azure SQL Server, Data Warehouse and Data Factory\nTFS\/VSTS\/GIT Source Control\nSubmit a Referral (https:\/\/careers-cchampions.icims.com\/jobs\/3852\/senior-data-engineer----remote\/job?mode=apply&apply=yes&in\\_iframe=1&hashed=-1834384512)\nLocation\nUS-TX-Richardson\nID\n2023-3852\nCategory\nInformation Technology\nPosition Type\nRegular Full-Time\nRemote\nYes\nLocation : Address\n808 S. Central Expressway\nShow more\nShow less",
      "job_skills":"Microsoft SQL Server, TSQL, SSIS, SSRS, SSAS, Kimball methodology, DevOps, Agile Scrum, JSON\/XML, Master Data Services, Power BI, Snowflake, Azure SQL Server, Data Warehouse, Data Factory, TFS\/VSTS\/GIT, ETL, ODS\/DW, SQL Server Master Data Management Services, Data dictionaries, Data Flow\/Process Flow diagrams, Runbooks, Git, SmartSheet, SDLC",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst (Hybrid)",
      "company":"BGSF",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-hybrid-at-bgsf-3781102803",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"BGSF is representing a $1.5B private equity backed Manufacturing client in Irving, Texas seeking to hire Data Analyst with experience in Finance, Procurement, Strategic Sourcing, or Data Analysis.\nMajor deliverable is to create reports and conduct analytics for procurement to drive decision making. This will be a task heavy role for a while as the company is working within 13 ERP systems currently as they work towards converting all prior acquisitions to MS Dynamics. The ideal individual will need to be able to roll data up, have eye for detail, and be creative in how to bring data together to make sense. Additionally, candidate should be comfortable getting data from market (company subscribes to several market reports).\nHybrid work model: 4 days in-office \/ 1 day remote option (Friday)\nGreat Culture ~ laid back environment and no micro-management (everyone is accountable)\nIdeal experience is to be data savvy and have strong analytics in Excel, strong math or procurement background, spend management analytics, and cost savings analytics\nQUALIFICATIONS:\nBachelors degree in Business, Finance, Engineering, or Supply Chain\n3+ years in Finance, Procurement, Strategic Sourcing, or Data Analysis\nExperience with financial data analytics, multiple ERP systems, data mining, validations, data manipulation, interpretation & visualization of data\nSolid Excel skills (pivot tables, VBA, H\/VLOOKUP, COUNTIFs, index match\nPower BI required\nBase + Bonus + Benefits\nShow more\nShow less",
      "job_skills":"Data Analysis, Finance, Procurement, Strategic Sourcing, Data Mining, Data Manipulation, Data Visualization, Power BI, Excel, Pivot Tables, VBA, H\/VLOOKUP, COUNTIFs, Index Match, MySQL Dynamics",
      "Category":"Data Science"
  },
  {
      "job_title":"Discipline Director Design Management - Data Centers (DTC)",
      "company":"Exyte Management GmbH-Recruiter",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/discipline-director-design-management-data-centers-dtc-at-exyte-management-gmbh-recruiter-3762679585",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Discover your exciting role\nThe Discipline Director - Design Management - Data Centers (DTC) is responsible for managing staff within the Design Management and Coordination department. Manages career development for discipline staff while aligning capabilities to meet current and future market needs. Ensures the team meets task schedules, produces quality deliverables, and respects project budgets and earned value projections. Cooperates with and supports Project Management in achieving contracted deliverables and target profitability margins on projects. Manages the discipline budget.\nExplore your tasks and responsibilities\nAdopts and promotes the Exyte commitment to always provide a safe workplace that strives for an Incident and Injury Free environment where everyone goes home safe every day\nEnsures company safety policies and the Site Specific Plan are proactively communicated and consistently enforced on all projects\nAttracts and retains premier talent through recruiting, mentoring, training and other employee development activities\nEncourages and promotes an atmosphere of collaboration, creativity, ingenuity, progress, efficiency, and enthusiasm within the respective Discipline, including contributing to professional association workgroups, industry forums, and technical seminars and conferences\nFunctions as a senior level client liaison, soliciting feedback from clients regarding team performance, potential projects, and other support needed. Through this process, establish strong client relationships in order to position Exyte as the preferred partner for key clients\nCollaborates with Discipline Directors, Project Managers and Construction Managers to develop and integrate processes and procedures (Project Execution Systems) including Quality Management and Continuous Improvement Programs\nSupports development and effective use of Project Controls including budget and cost analysis, project scheduling, use of the Fee Development Guide (FDG), and Earned Value Analysis\nAccountable to the Director Design Operations for the Discipline\nResponsible for managing a multi office organization\nResponsible for providing a balance of support, guidance, empowerment and accountability of the department\u201a\u00c4\u00f4s staff\nManages annual Forecast projections, financial performance assessment, and ongoing staffing and utilization forecasts\nEstablishes and maintains a succession strategy for key positions including the Director in the discipline\nIf a registered Professional Engineer, the Discipline Director is expected to serve as the Company\u201a\u00c4\u00f4s Engineer in Responsible Charge or qualifier (for purposes of acquiring and maintaining corporate licenses) in all jurisdictions in which he\/she maintains a professional registration. The Discipline Director may also be required, as business needs dictate, to seek licensure in additional jurisdiction\nOther duties as assigned\nShow your expertise\nBachelor\u201a\u00c4\u00f4s Degree in Engineering or related field preferred\nProfessional Engineering (PE) License required\nProject Management Professional (PMP) certification preferred\n7+ years of experience in Data Centers (DTC)\n4+ years of Management experience\nPrior experience in Engineering Project Delivery Leadership role, including management\nExperience in the role of Project Discipline Lead\nPrior experience in roles with primary function as a Project Engineer\/Architect as well as a project lead for design or design-build project(s) for high-tech manufacturing or \u201a\u00c4\u00faclean\u201a\u00c4\u00f9 facilities, scope including all typical facility design disciplines (CSA, MEP, etc.)\nExperience of minimum of two projects with at least $100M in COW for Engineering Design services\nExperience working directly with clients and internal team leads for active change management through all phases of project development\nExperience in leading proposal development\nProven examples of at least two direct reports growing into new roles\nExperience should include examples of promoting a strong Safety Culture, including incorporation of Safety in Design\nAbility to inspire, direct and manage others\nAbility to manage a multi office organization\nAble to manage discipline specific consultants as required by projects; developing master service agreements and scopes of work for project contracts\nDemonstrated ability managing at least five direct reports\nStrong Communication skills and inclusion of all Stakeholders in decision process\nStrong problem-solving and organizational skills\nExcellent general understanding of related engineering disciplines such as mechanical, electrical, process systems, automation, structural and architectural\nShow more\nShow less",
      "job_skills":"Safety policies, Project execution systems, Quality management, Continuous improvement programs, Project controls, Budget analysis, Cost analysis, Project scheduling, Earned value analysis, Succession planning, Engineering design, Change management, Proposal development, Safety culture, Project management, Stakeholder management, Problemsolving, Organizational skills, Communication skills, Engineering disciplines",
      "Category":"Data Science"
  },
  {
      "job_title":"Looking for Database Engineer - Plano TX\/ Mclean VA - C2C",
      "company":"Extend Information Systems Inc.",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/looking-for-database-engineer-plano-tx-mclean-va-c2c-at-extend-information-systems-inc-3673991291",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Hi,\nI hope you are doing well!\nWe have an opportunity for\nDatabase Engineer\nwith one of our clients for\nPlano TX\/ Mclean VA\nPlease see the job details below and let me know if you would be interested in this role.\nIf interested, please send me a copy of your resume, contact details, availability, and a good time to connect with you.\nTitle:\nDatabase Engineer\nLocation:\nPlano TX\/ Mclean VA\nTerms:\nC2C\nJob Details\nManage SQL Server databases\nConfigure and maintain database servers and processes\nMonitor system's health and performance\nEnsure high levels of performance, availability, sustainability and security\nAnalyze, solve, and correct issues in real time\nProvide suggestions for solutions\nRefine and automate regular processes, track issues, and document changes\nAssist developers with query tuning and schema refinement\nPerform scheduled maintenance and support release deployment activities after hours\nQualifications\n5 years of experience as a SQL Server DBA\/Sybase\/DB2 or similar role\n4 years of experience with SQL Server DBA\/Sybase\/DB2 Administration experience required\nCritical thinker and problem-solving skills\nThanks & Regards\nMonika Singh\nExtend Information System Inc\nPhone:571-622-3980\nEmail: monika@extendinfosys.com\n44258 Mercure Circle, UNIT 102 A, Sterling VA, USA 20166\nShow more\nShow less",
      "job_skills":"SQL Server, Database Administration, System Health Monitoring, Performance Analysis, Problem Solving, Query Tuning, Schema Refinement, Release Deployment, Critical Thinking",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"Mitchell Martin Inc.",
      "job_location":"Grapevine, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-mitchell-martin-inc-3762681379",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Our direct hiring manager is looking for a DataCenter Engineer who has Hvac and racking \/Stacking experience. Please review the details below and let me know if you are qualified and interested.\nPrimary point of contact for Data Center technologies and related mechanical devices. Participates in projects to design and implement mechanical and electrical improvements to data centers. Develops procedures to outline data center processes, and related tasks. Participates and leads in the design and engineering data center technologies and future datacenter related initiatives. Mentors Data Center Operations team members and helps increase their effectiveness and skillset.\nHVAC and Racking\/Stacking. Have to have both (Electrical and Network Knowledge)\nHands on data center\nMust be flexible with work schedule and hours\nBachelors degree and 4 years related experience\nKnowledge of:\nDatacenter HVAC, CRAC, CRAH cooling technologies\nDatacenter power, UPS, generator operations, etc\nDatacenter fire suppression systems (FM200, HFC125, etc)\nGeneral knowledge of datacenter design and construction\nLAN\/WAN\nEmerging Technology Trends\nDatacenter Best Practice and Industry Standard Methodology\nSkills\/Abilities:\nEvaluate critical systems, prioritize workflow and determine solutions\nExcellent written and verbal communication skills\nInterpret and apply laws, regulations and policies\nRead and understand technical manuals\nWork for extended time at keyboard\/terminal\nMaintain effective working relationships with supervisor and coworkers\nWork flexible hours, including weekends and evenings\nValue open, honest communication\nEager to be transparent and truthful as a primary matter of course\nShow more\nShow less",
      "job_skills":"HVAC, Racking, Stacking, Electrical, Network, Datacenter, CRAC, CRAH, UPS, Generator, Fire suppression systems, LAN, WAN, Industry Standard Methodology, Communication, Interpretation",
      "Category":"Data Science"
  },
  {
      "job_title":"Licensed Civil Engineer - Data Center (Remote)",
      "company":"Olsson",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/licensed-civil-engineer-data-center-remote-at-olsson-3784206324",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Company Description\nWe are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.\nOur most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u201a\u00c4\u00ee and will continue to allow us \u201a\u00c4\u00ee to grow. The result? Inspired people, amazing designs, and projects with purpose.\nJob Description\nOlsson provides multidisciplinary design services for some of the largest and most forward-thinking and desirable companies in the world to work for. The large hyperscale data center campuses we design throughout the U.S. will give you the opportunity to work on some of the largest and most complex engineering-driven projects being built today. Our clients are relationship based and truly value the work we do for them, affording us the opportunity to contribute to society\u201a\u00c4\u00f4s technological and connected community through the design of the critical infrastructure that is the foundation of these projects.\nAs a Licensed Civil Engineer on our Data Center Civil Team, you will be a part of the firm\u201a\u00c4\u00f4s largest and most complex projects. You will serve as a project manager on some projects and lead design engineer on others. Prepare planning and design documents, process design calculations, and develop and maintain team and client standards. You may lead quality assurance\/quality control and act as an advisor on complex projects. You will also coordinate with other Olsson teams, professional staff, technical staff, clients, and other consultants.\nYou may travel to job sites for observation and attend client meetings.\nOlsson currently has one opportunity for an Experienced Engineer. This role offers flexible work options, including remote and hybrid opportunities, to accommodate diverse working preferences and promote work-life balance. Candidates can live in Lincoln, Omaha, Phoenix, Chandler, or Dallas-Fort Worth area and work remotely, or work out of any Olsson office location in these regions\/areas.\nQualifications\nYou are passionate about:\nWorking collaboratively with others\nHaving ownership in the work you do\nUsing your talents to positively affect communities\nSolving problems\nProviding excellence in client service\nYou bring to the team:\nStrong communication skills\nAbility to contribute and work well on a team\nBachelor's Degree in civil engineering\nAt least 6 years of related civil engineering experience\nProficient in Civil 3D software\nMust be a registered professional engineer\nAdditional Information\nOlsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u201a\u00c4\u00f4re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.\nAs an Olsson employee, you\u201a\u00c4\u00f4ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u201a\u00c4\u00f4ll:\nBecome an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)\nEngage in work that has a positive impact in communities\nReceive an excellent 401(k) match\nParticipate in a wellness program promoting balanced lifestyles\nBenefit from a bonus system that rewards performance\nHave the possibility for flexible work arrangements\nOlsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.\nShow more\nShow less",
      "job_skills":"Civil Engineering, Project Management, Design Engineering, Planning Documents, Design Calculations, Quality Assurance, Quality Control, Client Coordination, Civil 3D, Registered Professional Engineer",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Systems Developer \u201a\u00c4\u00ec (Epic Certification required Tapestry, Clarity)",
      "company":"Kelsey-Seybold Clinic",
      "job_location":"Pearland, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-systems-developer-%E2%80%93-epic-certification-required-tapestry-clarity-at-kelsey-seybold-clinic-3756387677",
      "search_city":"Dickinson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nJob Description\nWorks collaboratively as a senior member of the Business Intelligence & Reporting team under direction of KSC Application Technology Leadership. Supports, develops, and maintains business intelligence (BI), data warehousing, and reporting systems. Acts as a project lead or team member on multi-team projects and uses advanced skill set to develop, test, troubleshoot, and support BI and reporting-related projects and associated solutions\/applications. Acts as mentor to others learning essential and advanced BI and\/or reporting-related skills.\nJob Title: Senior Data Systems Developer \u201a\u00c4\u00ec IT Admin\nClinic Location: Pearland Administrative Office\nDepartment: IT Admin\nJob Type: Full Time\nSalary Range: $110,090 - $135,995 (Pay is based on several factors including but not limited to education, work experience, certifications, etc.)\nQualifications\nEducation\nRequired: Bachelor\u201a\u00c4\u00f4s degree in a technical area or equivalent work experience\nPreferred: Advanced degree preferred.\nExperience\nRequired: Minimum of four years\u201a\u00c4\u00f4 experience in data warehouse\/business intelligence development.\nExperience as BI\/DW architect or lead in at least one BI\/DW initiative \/ project. Senior level member of BI\/DW initiatives and projects.\nPreferred: Previous experience in a healthcare industry, large-scale data warehousing, and\/or exposure to Epic Systems Clarity.\nLicense(s)\nRequired: Valid Texas driver\u201a\u00c4\u00f4s license\nPreferred: N\/A\nSpecial Skills\nRequired: Significant experience and thorough technical knowledge in several of the following tools:\nMS SQL Database Services \/ Transact-SQL (T-SQL)\nMS SQL Analysis Services (SSAS)\nMS SQL Reporting Services (SSRS)\nMS SQL Server Integration Services (SSIS)\nBusiness Objects \/ Crystal Reports\nOther BI\/DW Toolsets including Cognos, Microsoft, Oracle, Microstrategy\nThorough understanding and knowledge of the following topics:\nDatawarehouse design\nReporting\nOLAP \/ Cubes\nKPIs, Scorecards, Dashboards\nAd-Hoc\nAnalytics\nData Mining\nMetadata Management\nData Quality\nMaster Data Management\nPreferred: Advanced certification including:\nMS SQL-related Certifications\nCrystal Report-Related Certifications\nVendor-Specific Certifications\nOther\nRequired: Flexibility and the ability to adapt to change. Proven communication, presentation, analytical, problem solving, technical and writing skills. Candidates must have a positive \u201a\u00c4\u00facan do\u201a\u00c4\u00f9 attitude and a professional demeanor.\nPreferred: N\/A\nWorking Environment:\nOffice\nAbout Us\nStart your career journey and become a part of a community of renowned Healthcare professionals. Kelsey-Seybold Clinic is Houston\u201a\u00c4\u00f4s fastest growing, multispecialty organization with more than 40 premier locations and over 65 specialties. Our clinics are comprised of more than 600 physicians and as we continue to grow, our focus is providing quality patient care by adding to our team of clinical and non-clinical professionals that work together in a convenient, coordinated, and collaborative manner. Enjoy the rewards of a successful career while maintaining a work\/life balance by joining our team today and changing the way health cares.\nWhy Kelsey-Seybold Clinic?\nMedical, Vision, and Dental\nTuition Reimbursement\nCompany Matching 401K\nEmployee Reward and Recognition Program\nPaid time off for vacation, sick, and holidays\nEmployee Assistance Program\nContinuing Medical Education allowance\nShow more\nShow less",
      "job_skills":"Data Warehouse, Business Intelligence, MS SQL Database Services, TransactSQL (TSQL), MS SQL Analysis Services (SSAS), MS SQL Reporting Services (SSRS), MS SQL Server Integration Services (SSIS), Business Objects, Crystal Reports, Cognos, Microsoft, Oracle, Microstrategy, Datawarehouse design, Reporting, OLAP \/ Cubes, KPIs, Scorecards, Dashboards, AdHoc, Analytics, Data Mining, Metadata Management, Data Quality, Master Data Management, MS SQLrelated Certifications, Crystal ReportRelated Certifications, VendorSpecific Certifications",
      "Category":"Data Science"
  },
  {
      "job_title":"Data & Integration Analyst",
      "company":"Maxor National Pharmacy Services, LLC",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-integration-analyst-at-maxor-national-pharmacy-services-llc-3787392018",
      "search_city":"Dallas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Overview\nThe\nData & Integration Analyst\nis responsible for implementing, supporting, and maintaining inbound\/outbound data file exchanges. Enable and integrate clients and 3 rd party vendors onto Maxor\u201a\u00c4\u00f4s PBM platform. Assist in documenting and creating efficient\/automated solutions to promote operational capability while also improving client data integrity. Reporting to the Sr. Director of Eligibility and Accumulators the Data & Integration Analyst will meet all service standards to ensure client satisfaction.\nPosition Location\nThis is a remote-based position.\nOur Company\nWe're Maxor and we're building a different kind of pharmacy company. We're transforming the pharmacy industry to create healthier lives through purposeful engagement across Pharmacy Benefit Management, Pharmacy Management, Specialty Pharmacy, 340B, Rebate and Formulary Management, and Pharmacies. We put people first and are committed to providing outstanding service across all aspects of our business. We believe there's a better way to deliver pharmacy and healthcare services to people across the country, and we'd love for you to help us do it.\nOur Locations\nThe Maxor workforce brings robust experience, diverse perspectives and passion from over 1,000 employees working all over the US in pharmacies, hospitals, home offices, or corporate offices.\nResponsibilities\nSupport new and existing clients through implementation\/conversion\/integration processes working directly with clients, account managers and implementation teams though full data-life-cycle development.\nServe as a Subject Matter Expert (SME) on integration points with Maxor\u201a\u00c4\u00f4s PBM platform, application, file integration functions\/standards and back end data models.\nExecute advanced\/dynamic SQL scripts to generate flat files or reports to support backend file processing, reconciliation analysis, and internal\/external reporting.\nReview, analyze, and implement complex file mappings and data conversions to support standard and custom file integrations between Maxor and our clients.\nPlan, document, implement new or improved automated\/ETL solutions\nConduct system testing of new features, integrations and backend features\nWith a focus on quality and timeliness, maintain ownership for assigned goals\nEnsure quality, service level, productivity and customer standards are consistently met.\nHandle routine work stream assignments along with, but not limited to, member and file research, assisting with file processing\/data analysis, advise\/consult with our internal teams and clients\nComply with Maxor\u201a\u00c4\u00f4s Ethical Business Conduct policy and Maxor\u201a\u00c4\u00f4s Compliance Program.\nComplete required training, as assigned, within the established timeframes.\nMust be able to cope with the mental and emotional stress of the position.\nPromote teamwork and best practices\nMaintain regular attendance in accordance with established policies.\nPerform other job-related duties as assigned.\nQualifications\nEducation:\nBachelor\u201a\u00c4\u00f4s Degree in business, computer science, operations, engineering or related field required.\nExperience:\nExperience in data cleansing\/mapping\/formatting, ETL frameworks, and\/or database relational models. Previous experience with health care enrollment\/eligibility\/accumulator fundamentals and Pharmacy Benefits Managers (PBMs) data\/file\nExchange\/integration Experience Preferred.\nKnowledge, Skills, and Abilities:\n5+ years of experience in data exchange, integration, ETL frameworks, data visualization and\/or relational database models\/design.\n5+ years of experience as Data\/Integration\/EDI Analyst with relevant PBM\/Heath Benefit\/Health IT experience.\nStrong business acumen with healthcare and pharmacy benefit management industry knowledge preferred.\nA desire to problem solve, think critically, analyze and interpret data.\nWillingness to solution across business and technical domains.\nAbility to identify assumptions, be inquisitive and reach conclusions.\nAbility to communicate, document, share and acquire knowledge.\nAbility to adapt, continuously improve, enjoy building new tools and process.\nProven ability to develop effective working relationships with internal and external stakeholders.\nMotivated by goal oriented delivery, ability to understand overall business objectives and drive towards results.\nWHY CHOOSE A CAREER AT MAXOR?\nDid you know that patients see their pharmacist an average of 12 times a year? Pharmacy is at the heart of healthcare. Come join Maxor and make a direct impact on patients\u201a\u00c4\u00f4 lives. Improve your own wellbeing with our robust benefits and flexible work environment. At Maxor, you have a career with limitless possibilities and the charge to make a difference. A company of 1,000 diverse people and almost 100 years of pharmacy experience, we offer the stability of a Fortune 500 company with the energy and innovation of a startup. We provide services and technology that fuel the entire pharmacy ecosystem, but we are more than pharmacy services. We enable pharmacy care .\nWE OFFER\n: A diverse, progressive culture that supports a \u201a\u00c4\u00fadress for your day\u201a\u00c4\u00f9 attire and a collaborative, team oriented environment. Our industry leading compensation and health benefits include:\nComprehensive mental health and wellbeing resources\nNationwide Blue Cross Blue Shield PPO with employee friendly plan design, including $850 individual annual medical deductible, $25 office visit copays, Low biweekly premiums\nCompany paid basic life\/AD&D, Short-term and Long-term disability insurance\nRx, dental, vision, short-term disability, and FSA\nEmployer-matched 401k Plan\nIndustry leading PTO plan\nAnd MORE!\nApply today at :\nhttps:\/\/careers-maxor.icims.com\/\nMaxor is an EOE, including disability\/vets\nShow more\nShow less",
      "job_skills":"SQL, ETL frameworks, Database relational models, Data visualization, Data exchange, Data integration, Data cleansing, Data mapping, Data formatting, Business acumen, Healthcare industry knowledge, Pharmacy benefit management industry knowledge, Problemsolving skills, Critical thinking skills, Data analysis skills, Communication skills, Documentation skills, Knowledge sharing skills, Adaptability, Continuous improvement skills, Relationshipbuilding skills, Goaloriented delivery skills, Blue Cross Blue Shield PPO, 401k Plan, PTO plan",
      "Category":"Data Science"
  },
  {
      "job_title":"Looking Forward To Hearing From You Onsite Role San Antonio, TX Fraud- Data Analyst",
      "company":"Accuro",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/looking-forward-to-hearing-from-you-onsite-role-san-antonio-tx-fraud-data-analyst-at-accuro-3742070482",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Greetings from Accuro Group,\nMy name is Bharat Gautam, and I am working with Accuro Group.\nIf I am unable to answer your call, kindly Send me a message. On LinkedIn: linkedin.com\/in\/bharat-gautam-645546252\nJob Title: Fraud- Data Analyst\nWork Location: San Antonio, TX (Onsite)\nimplementation partner: TCS\nCheck processing is a must with debit card fraud. Fraud analysts investigate theft and fraud within transactions on behalf of a company or a financial institution.\nFraud analysts examine data and fraudulent activity to brainstorm new techniques to help prevent future fraudulent activity from happening.\nA fraud analyst is someone who investigates fraudulent activity related to financial transactions and accounts on behalf of a bank or a financial institution.\nThey monitor and analyze the data to detect and resolve fraud cases such as identity theft, forgery, or unauthorized usage of cards.\nThey also strive to minimize potential risks to the institution and its clients. Their responsibilities may differ depending on the type of field.\nBehind every resume is a human being with hopes, dreams and a family\nEarly response is appreciated....\nRegards\nBharat Gautam | Sr.Technical Recruiter\nDesk:+1 919-364-1229 *164\nEMAIL Bharat.g@accurogroup.com\nlinkedin.com\/in\/bharat-gautam-645546252\nShow more\nShow less",
      "job_skills":"Data Analysis, Fraud Detection, Financial Transactions, Risk Management, Identity Theft, Forgery, Unauthorized Card Usage, Debit Card Fraud",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Facilities Operator",
      "company":"JLL",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-facilities-operator-at-jll-3775808568",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"The Data Center Operations Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)\nLocation: San Antonio TX\nPrincipal Duties and Responsibilities\nTask will include but not be limited to:\nResponsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire\/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.\nRequires the ability to analyze the operation of various systems, determine the cause of any problems\/malfunctions and take corrective action as required.\nComply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.\nLearn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.\nWork order management, including CMMS, Vendor Management, and Customer Facing Tickets.\nUnderstanding and complying with emergency escalation procedures.\nPerform additional job duties as required.\nMinimum Requirements:\nPreferred to have hands-on experience working in a data center\/critical facility, including UPS.\nSystems, emergency generators, and switchgears.\nHigh School diploma or GED equivalent\n2+ years related work experience.\nWorking knowledge of computer applications including Word and Excel.\nDemonstrated verbal\/written communication skills.\nPreferred Requirements:\nCorrigo Experience.\nMCIM \/ Salesforce Experience.\nZendesk Experience.\nService Now Experience.\nReceived EPA 608.\nTrained in NFPA70E.\nPHYSICAL WORK ABILITIES AND REQUIREMENTS\n:\nThis position requires frequent walking, climbing, bending, kneeling, lifting, stooping, and working\/extending overhead, including:\nWalking large, campus-like settings.\nLifting a minimum of 50 lbs.\nClimbing stairs and navigating rooftops to access equipment.\nUsing ladders up to 30 ft and working from heights.\nAbility to Climb a ladder with a 300-lb weight limit.\nMust be able to work different schedules.\nMust be able to work Holidays.\nMust be able to respond to site emergencies.\nPersonalized benefits that support personal well-being and growth:\nJLL recognizes the impact that the workplace can have on your wellness, so we offer a supportive culture and comprehensive benefits package that prioritizes mental, physical and emotional health. Some of these benefits, include:\n401(k) plan with matching company contributions\nComprehensive Medical, Dental & Vision Care\nFMLA at 100% of salary after 1 year of employment.\nPaid Time Off and Company Holidays.\nCompensated for Holidays Worked.\n15% Pay differential for Night Shift Employment.\nLooking for a job that values YOU beyond the checkboxes? Don't let requirements hold you back. At our company, we're all about embracing new perspectives and unique talents. So, if you're someone who's ready to bring your A-game and show us what you're made of, we want to meet you! Apply now and let your skills and passion shine through. Be bold, be yourself, and let's create something extraordinary together!\nPotential pay is $32-$36 based on experience\nShow more\nShow less",
      "job_skills":"Data Center Operations, Electrical Systems, Mechanical Systems, UPS, Generators, HVAC, Chillers, Crac, Crah, Plumbing, Controls, ATS, STS, PDU, Primary Switchgear, Power Distribution, Transformers, Hot Water Systems, Refrigeration, Air Conditioning Equipment, Boilers, Ventilating, Water Heaters, Pumps, Valves, Piping, Filters, CMMS, Vendor Management, Customer Facing Tickets, Corrigo, MCIM, Salesforce, Zendesk, Service Now, EPA 608, NFPA70E, Microsoft Word, Microsoft Excel",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Engineer - Snowflake",
      "company":"Tata Consultancy Services",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-snowflake-at-tata-consultancy-services-3752006423",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title - Sr. Data Engineer - Snowflake\nJob Type - Full Time\nLocation - San Antonio, TX or Plano, Tx (Onsite Role)\nExperience required - 5+ Years\nRoles & Responsibility\nAnalyze, develop, refactor, fix, test, review and deploy functionality, and bug fixes in ETL that moves data between Snowflake data layers.\nDatabase and Query tuning, diagnosis, and resolution of performance issues leveraging ELT and push-down if required.\nUse and improve ETL frameworks, continuous data quality frameworks and other automation in data pipeline.\nService data availability SLOs and attend triage meetings to engage with Security, Infrastructure and Workload management teams to issue resolutions.\nCompliance to Agile Jira SDLC controls, Service Now Change & Incident management, and Data Ops Gitlab CI\/CD pipeline.\nParticipate in daily standups, lead design reviews and offshore coordination.\nShow more\nShow less",
      "job_skills":"Snowflake, ETL, ELT, Agile Jira SDLC, Service Now, Gitlab CI\/CD, Data Ops",
      "Category":"Data Science"
  },
  {
      "job_title":"LEAD ANALYST - LEAD ENGINEER - PRINCIPAL ENGINEER - Systems Engineer\/Data Science Engineer",
      "company":"Southwest Research Institute",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-analyst-lead-engineer-principal-engineer-systems-engineer-data-science-engineer-at-southwest-research-institute-3739152874",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Who We Are:\nJoin Our Team! The Tactical Aerospace Department is a premier supplier for aerospace quality technology insertion on new and legacy DoD systems. This includes avionics, ground systems, and cutting edge third generation AI\/ML for DoD platforms.\nObjectives of this Role:\nDevelop System and LRU Architectures; this includes Data Science\/Analytics techniques to design data pipelines that utilizes second\/third generation AI\/ML.\nWork collaboratively across a multi-disciplinary engineering teams to establish hardware, firmware, and AI\/ML requirements for complex flight worthy avionics hardware.\nInteract directly with clients to establish system requirements and architectures to meet client expectations.\nProvide technical project leadership throughout each program.\nUtilize Model Based Systems Engineering (MBSE) processes to support system designs\/architectures.\nSupport department management in specific marketing activities, proposal development of embedded avionics programs, and in the development of product\/technical roadmaps.\nDaily and Monthly Responsibilities:\nPerform as a System Engineer over embedded avionics programs.\nLead a multi-disciplinary team to develop, integrate, and test complex avionics; this includes electrical, mechanical, firmware, data pipelines, data science, and AI\/ML.\nMeet with internal and external customers to establish system technical requirements and facilitate development of specification documents and system architectures.\nLead trade analyses within and across the relevant domains.\nWork with stakeholders to allocate functions to components\/systems and develop those allocations into requirements for the engineers, designers, and managers to design, develop, integrate and test.\nRequirements:\nRequires a Bachelor of Science in Electrical Engineering, Data Engineering, Data Science, Data Analytics or related with directly related experience\nShown experience in complex electronic avionics systems.\nShown experience with System Safety Analysis, FMEA, Hardware architectures, avionic I\/O , latency analysis, and MBSE.\n8 years: Experience developing, deriving, and allocating tiered Systems Engineering requirements in Avionics applications including data pipelines and tiered Data Science applications\nExperience developing Architectures and basic\/Intermediate experience with MBSE\nBroad, basic understanding of engineering activities\/disciplines in avionics development (e.g. Systems, Hardware Development, Firmware, Integration, Testing, Bid and Proposal efforts, CONOPS, Certification, System Safety, FMEA, Lab activities, etc)\nA valid\/clear driver's license is required\nSpecial Requirements:\nApplicant selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information. Applicant must be a U.S. citizen.\nJob Locations: San Antonio, Texas\nShow more\nShow less",
      "job_skills":"Avionics, Ground Systems, AI\/ML, Data Science\/Analytics, Hardware, Firmware, MBSE, System Engineering, Electrical Engineering, Data Engineering, System Safety Analysis, FMEA, Hardware Architectures, Avionic I\/O, Latency Analysis, Systems Engineering Requirements, Data Pipeline Architecture, Data Science Applications, Bid and Proposal Efforts, CONOPS, Certification, Lab Activities",
      "Category":"Data Science"
  },
  {
      "job_title":"Bus Analyst I Data,Rept&Vis",
      "company":"H-E-B",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/bus-analyst-i-data-rept-vis-at-h-e-b-3779272578",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"The H-E-B Planning & Analysis Team develops and maintains budgets and financial systems while providing current, reliable financial data, analysis, and technical info. To help make essential Corporate planning decisions, our Analysts apply data-wrangling skills and business acumen to identify and tackle business problems. As a Business Analyst - Data, Reporting & Visualization, you'll support Product Manager work with data analysis, requirements documentation, and reporting and visualization.\nOnce you're eligible, you'll become an Owner in the company, so we're looking for commitment, hard work, and focus on quality and Customer service. 'Partner-owned' means our most important resources--People--drive the innovation, growth, and success that make H-E-B The Greatest Omnichannel Retailing Company.\nDo you have a:\nHEART FOR PEOPLE... skills to communicate technical data to non-technical people?\nHEAD FOR BUSINESS... visualization skills?\nPASSION FOR RESULTS... drive to explore \/ map data and processes?\nWe are looking for:\na related degree or comparable formal training, certification, or work experience\n2+ years of experience in business intelligence report development\nWhat is the work?\nAnalytics \/ Reporting & Documentation:\nCollaborates with Product Owners and stakeholders to document business processes and detailed requirements for Data Engineers and Report Developers\nApplies understanding of project vision from Product Owner; assists in coordinating efforts with a cross-functional team\nAssists Product Owners in building out project roadmaps\nLearns to serve as data SME in specific subject area(s); applies understanding of data flow across all systems that support the business process; supports mapping of business process to systems and data to support Visualization\nSupports Data Engineers in translating product into solutions\nExplores \/ profiles new data sets to understand scenarios and anomalies\nAccesses \/ organizes data; builds out analyses to support \/ propose solutions for business problems\nCreates simple reports and visualization as part of data exploration and analysis\nPerforms quality assurance \/ user acceptance testing for Data Solution or Report Development solutions\nProvides ongoing support for products built by the vertical scrum team and across verticals\nProvides ongoing reporting and subject area training for H-E-B BI users\nWhat is your background?\nA related degree or comparable formal training, certification, or work experience\n2+ years of experience in business intelligence report development\nExperience on H-E-B data engineering, financial analysis, or merchandising teams (a plus)\nDo you have what it takes to be a fit as an H-E-B Business Analyst - Data, Reporting & Visualization?\nStrong working knowledge of SQL\nStrong data visualization skills\nAbility to extract, explore, and profile data\nAbility to communicate with all levels of stakeholders\nCan you...\nFunction in a fast-paced, retail, office environment\nWork extended hours, as needed\n11-2020\nShow more\nShow less",
      "job_skills":"Data Wrangling, SQL, Data Visualization, Business Intelligence, Report Development, Data Analysis, Requirements Documentation, Project Roadmaps, Data Mapping, Data Profiling, Data Exploration, Data Exploration, Data Solution Testing, User Acceptance Testing, Data Training, Financial Analysis, Merchandising",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Energy Marshal 2",
      "company":"Ascendion",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-energy-marshal-2-at-ascendion-3782503747",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"About Ascendion\nAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.\nAscendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\nBuild the coolest tech for world\u201a\u00c4\u00f4s leading brands\nSolve complex problems \u201a\u00c4\u00ec and learn new skills\nExperience the power of transforming digital engineering for Fortune 500 clients\nMaster your craft with leading training programs and hands-on experience\nExperience a community of change makers!\nJoin a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:\nThe Energy Marshal is an assurance role that helps ensure the vendors\u201a\u00c4\u00f4 and contractors\u201a\u00c4\u00f4 Energy Isolation Program meets or exceeds company safety policy requirements as stood up by the Authorizing Energy Marshal.\nEnergy Isolation Management is a significant part of construction and commissioning efforts. To ensure focus and compliance for all aspects and types of energy isolation a Energy Marshal is required for each campus or project.\nThis critical role implements learnings, provides consistency, and drives rigor into company's energy isolation program. The Energy Marshal is a companies representative who oversees and assures the Authorizing Energy Marshal (GC) and supplemental vendor support comply with the overall Energy Isolation Program Management on a datacenter construction campus.\nJob Title: Data Center Energy Marshal 2\nKey Responsibilities:\nThe Energy Marshal is an assurance role that helps ensure the vendors\u201a\u00c4\u00f4 and contractors\u201a\u00c4\u00f4 Energy Isolation Program meets or exceeds any Company's safety policy requirements and is stood up by the Authorizing Energy Marshal.\nUtilize SPS-101 Energy Isolation SPS and SPS-101 Energy Isolation Guidebook as the baseline and foundation of the Energy Isolation Program that is implemented throughout the campus and project.\nEstablishes and manages an Energy Isolation assurance process and works with site teams to close any gaps identified in assurance audits. Alignment Checklist SPS 101 Energy Isolation is provided as a reference \/ guideline\nParticipate in High Risk Activity (HRA) planning meetings associated with Energy Isolation.\nEnsures approval process for proposed Energy Isolation procedures is in place.\nWork with the Authorizing Energy Marshal to establish an Energy Isolation Permit process.\nEnsures SoWs, MOPs, and Scripts are reviewed, and all sources of energy are identified.\nHelps determine if a group or individual LOTO will be required. Establishes with the Authorizing Energy Marshal a centralized LOTO with all site entities.\nEnsures process is established that verifies qualifications, training, and PPE of personnel performing the work.\nDelegates alternates that are qualified to assume role during multi-shift and peak energization time frames.\nActs in coordination with the Authorizing Energy Marshal as a subject matter expert in all Energy Isolation incident investigations in area of responsibility.\nServes as an independent authority for stopping all unsafe work practices regarding Energy Isolation.\nSkills:\nAbility to audit site practices against written standards as part of assurance role\nDC construction\nGood ability to effectively communicate complex technical solutions and concepts to engineers and non-engineers\nLocation: San Antonio, TX\nSalary Range: The salary for this position is between $176800\u201a\u00c4\u00ec $197600 annually. Factors that may affect pay within this range may include geography\/market, skills, education, experience, and other qualifications of the successful candidate.\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: Medical insurance, Dental insurance, Vision insurance, 401(k) retirement plan, long-term disability insurance, short-term disability insurance, and 5 personal days accrued each calendar year. The Paid time off benefits meets the paid sick and safe time laws that pertain to the City\/ State, 10-15 days of paid vacation time, 6 paid holidays, and 1 floating holiday per calendar year, Ascendion Learning Management System.\nWant to change the world? Let us know.\nTell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let\u201a\u00c4\u00f4s talk!\nShow more\nShow less",
      "job_skills":"Energy Isolation Management, SPS101 Energy Isolation SPS, SPS101 Energy Isolation Guidebook, Energy Isolation Assurance Process, Alignment Checklist SPS 101 Energy Isolation, High Risk Activity (HRA) Planning Meetings, Energy Isolation Permit Process, SoWs, MOPs, Scripts, LOTO, PPE, Energy Isolation Incident Investigations, DC Construction, Technical Communication",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Systems Engineer",
      "company":"CyberCoders",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-systems-engineer-at-cybercoders-3779627997",
      "search_city":"Union",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Title\n: Data Systems Engineer\nJob Location\n: Baton Rouge, LA OR Houston, TX (mainly remote; however, candidates MUST be local to Baton Rouge or Houston)\nSalary\n: $70-100K DOE (benefits, time off, etc.)\nRequirements\nBachelor's degree in Computer Science, Engineering, or related field (or equivalent work experience).\n3+ years of recent professional experience developing SQL queries and ETL processes.\nExperience with Microsoft T-SQL, .NET, Visual Studio, and\/or Oracle is preferred, but not required.\nFor over 60 years, we have provided solutions for industrial valve\/instrumentation applications in the oil\/gas industry. Due to recent growth, we are seeking a talented Data Systems Engineer to join our team. This position requires a Bachelor's degree in Computer Science, Engineering, or related field (or equivalent work experience) and 3+ years of recent professional experience developing SQL queries and ETL processes. Experience with Microsoft T-SQL, .NET, Visual Studio, and\/or Oracle is preferred, but not required.\nWhat You Will Be Doing\nDeveloping solutions to support business analytics\/data processing needs.\nDesigning, developing, and maintaining data lake\/warehouse.\nImplementing reports\/data extracts and data sources for visualization tools (ex. Tableau).\nWhat You Need for this Position\nBachelor's degree in Computer Science, Engineering, or related field (or equivalent work experience).\n3+ years of recent professional experience developing SQL queries and ETL processes.\nPreferred Qualifications\nAzure\nT-SQL\n.NET, SSRS, SSIS, Excel\nVisual Studio, SQL Managment Studio\nOracle PL\/SQL\nWhat's In It for You\nCompetitive Base Salary ($70-100K DOE)\nMedical, Dental, Vision Insurance\nTime Off\nSo, if you are a Data Systems Engineer with SQL and ETL experience, please apply today!\nEmail Your Resume In Word To\nLooking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:\nBrittany.Owen@CyberCoders.com\nPlease do NOT change the email subject line in any way. You must keep the JobID: linkedin : BO4-1777444L440 -- in the email subject line for your application to be considered.***\nBrittany Owen - Executive Recruiter - CyberCoders\nApplicants must be authorized to work in the U.S.\nCyberCoders is proud to be an Equal Opportunity Employer\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\nYour Right to Work\n\u201a\u00c4\u00ec In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\nCyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.\nShow more\nShow less",
      "job_skills":"SQL, ETL, Data Lake, Data Warehouse, Tableau, Data Visualization, Azure, .NET, Visual Studio, SQL Management Studio, Oracle PL\/SQL, SSRS, SSIS, Excel",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Engineer with Netsuite at Houston, Texas, Hybrid",
      "company":"Steneral Consulting",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-with-netsuite-at-houston-texas-hybrid-at-steneral-consulting-3682449785",
      "search_city":"Union",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Must be local DL\nShare only 2 profiles only\nUrgently seeking Houston based Data Migration Engineers for a 4 - 5 month consulting project. Selected individual will be migrating financial data and reports from a legacy system over to Netsuite.\nRequired: Netsuite, SQL, Excel and ability to sit onsite 2-3 days a week at a minimum.\nLocation is Houston, Texas they must be local\nThey must have Netsuite -if they don't, we can't submit. They must be local to Houston or we can't submit.\nData Migration Engineer with Netsuite (required)\nUrgently seeking Houston based Data Migration Engineers for a 4 - 5 month consulting project. Selected individual will be migrating financial data and reports from a legacy system over to Netsuite.\nRequired: Netsuite, SQL, Excel and ability to sit onsite 3+ days a week at a minimum.\nShow more\nShow less",
      "job_skills":"Data Migration, NetSuite, SQL, Excel, Consulting, Financial Data, Reports, Legacy System",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Analyst",
      "company":"Texas Tech University",
      "job_location":"Lubbock, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-analyst-at-texas-tech-university-3733827590",
      "search_city":"Lubbock",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Lubbock\nLead Data Analyst\n35349BR\nData Management Division\nPosition Description\nResponsibilities\nPerforms specialized analytical duties in the operation and maintenance of assigned area. Responsibilities include collecting, analyzing and developing data relative to area, making recommendations and assisting in implementation of projects. Work is performed under general supervision with latitude for independent judgment in accordance with established policies and procedures. While some management oversight may be expected for specific projects, this position is expected to exercise discretion and independent judgment in the performance of the following duties:\nPerforms data analysis and develops database actions defined in project plans to meet customer requirement and\/or marketing objectives.\nAbout The Department And\/or College\nThrough collaboration and coordination with campus partners, the Data Management Division will support all areas of Texas Tech University with the development, execution, and supervision of plans, policies, programs, and practices that deliver, control, protect, and enhance the value of data and information assets throughout their lifecycles.\nMajor\/Essential Functions\nOversight for Data Governance Projects (Data Quality and Audits).\nEvaluate\/understand high level data flow and data exchange between systems.\nEvaluate technical standards for critical systems.\nCoordinate with technical staff on metadata, data dictionaries, data protection, and data quality management.\nUnderstands data across systems and alignment with business processes.\nSupports change controls related to critical data.\nManages initial triage work for data related issues and projects before it is escalated to the Data Stewardship Council.\nIdentify and track critical dependencies between business requirements and data.\nRequired Qualifications\nBachelor's degree plus four years progressively responsible related experience; OR a combination of education and\/or experience to equal eight years\nPreferred Qualifications\nExperience developing data quality measures that align with business processes. Understanding of Master Data, Metadata, Reference Data, Data Warehousing, and BI principles and processes including technical architecture. Familiarly with enterprise information tools like SQL Server, Power BI, Oracle, etc. Excellent soft skills, including the ability to communicate well with various levels. Experience with Data Management Principles or Data Governance and Technical Writing.\nSafety Information\nAdherence to robust safety practices and compliance with all applicable health and safety regulations are responsibilities of all TTU employees.\nOccasional Duties\nOccasional work outside of normal hours required to meet project deadlines and travel to attend conferences or training.\nDoes this position work in a research laboratory?\nNo\nRequired Attachments\nCover Letter, Professional\/Personal References, Resume \/ CV\nOptional Attachments\nTranscript\nJob Type\nFull Time\nPay Basis\nHourly\nMinimum Hire Rate\n20.76\nPay Statement\nCompensation is commensurate upon the qualifications of the individual selected and budgetary guidelines of the hiring department, as well as the institutional pay plan. For additional information, please reference the institutional pay plan by visiting www.depts.ttu.edu\/hr\/payplan.\nTravel Required\nUp to 25%\nShift\nDay\nSchedule Details\nM-F, 8AM-5PM\nGrant Funded?\nNo\nJob Group\nInformation and Records Clerks\nEEO Statement\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, age, disability, genetic information or status as a protected veteran.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Governance, Data Quality, Data Warehousing, Business Intelligence, SQL Server, Power BI, Oracle, Master Data, Metadata, Reference Data, Technical Writing, Data Management Principles, Data Stewardship",
      "Category":"Data Science"
  },
  {
      "job_title":"Data QA Engineer -locals",
      "company":"Steneral Consulting",
      "job_location":"Spring, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-qa-engineer-locals-at-steneral-consulting-3762496226",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Spring TX\nUSC or GC Holder\n12 month contract\nHybrid (onsite Tuesday \u201a\u00c4\u00ec Thursday)\nTop 3 Skills\nExperience extracting from user stories\nSQL (needs to be a 3-5 out of 10)\nExperience working in a continuous integration team \u201a\u00c4\u00ec must know the principles\nMust have tested data warehouses\nData QA Engineer\nThe Data and Analytics team at is seeking a skilled and detail-oriented Quality Engineer with expertise in ETL\/ELT data pipelines to join our dynamic team. As a Data QA Engineer, you will play a critical role in ensuring that data processed into our data lakehouse is of high quality and reliability, and that we avoid functional and regression defects. You will collaborate closely with cross-functional teams, including product managers, data engineers, BI developers and data scientists, to identify, report, and help resolve issues in our data-driven applications.\nResponsibilities\nUtilize Azure DevOps for test case management and issue\/defect tracking.\nWrite clear and concise defect details describing actual versus expected behaviors.\nIdentify and implement automated test cases required for Azure DevOps user stories and\/or defects based on ticket descriptions, ensuring accuracy of D&A\u201a\u00c4\u00f4s ETL\/ELT pipelines.\nConduct thorough manual and automated testing of data pipelines and transformations to identify defects and inconsistencies.\nCollaborate with the development and product management teams to understand complex data requirements, transformations, and analytical processes, providing early feedback on potential issues.\nContinuously improve testing processes, methodologies, and tools related to data quality, analytics testing, and Azure DevOps integration.\nPerform regression testing of data-related components to validate bug fixes and new features across different releases.\nQualifications\nStrong understanding of software testing methodologies, tools, and processes, with a specific focus on data validation, analytics testing, and Azure DevOps integration.\n5 years of experience as a QA Engineer in writing clear and concise test cases and test documentation for software applications\nShow more\nShow less",
      "job_skills":"SQL, Azure DevOps, ETL\/ELT, Data Warehouses, Data Pipelines, Data Quality, Data Validation, Analytics Testing, Regression Testing, Continuous Integration, Test Case Management, Defect Tracking, Software Testing Methodologies, Data Analytics, Data Warehousing",
      "Category":"Data Science"
  },
  {
      "job_title":"Data QA Engineer -locals",
      "company":"Steneral Consulting",
      "job_location":"Spring, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-qa-engineer-locals-at-steneral-consulting-3759316531",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Spring TX\nUSC or GC Holder\n12 month contract\nHybrid (onsite Tuesday \u201a\u00c4\u00ec Thursday)\nData QA Engineer\nThe Data and Analytics team at is seeking a skilled and detail-oriented Quality Engineer with expertise in ETL\/ELT data pipelines to join our dynamic team. As a Data QA Engineer, you will play a critical role in ensuring that data processed into our data lakehouse is of high quality and reliability, and that we avoid functional and regression defects. You will collaborate closely with cross-functional teams, including product managers, data engineers, BI developers and data scientists, to identify, report, and help resolve issues in our data-driven applications.\nResponsibilities\nUtilize Azure DevOps for test case management and issue\/defect tracking.\nWrite clear and concise defect details describing actual versus expected behaviors.\nIdentify and implement automated test cases required for Azure DevOps user stories and\/or defects based on ticket descriptions, ensuring accuracy of D&A\u201a\u00c4\u00f4s ETL\/ELT pipelines.\nConduct thorough manual and automated testing of data pipelines and transformations to identify defects and inconsistencies.\nCollaborate with the development and product management teams to understand complex data requirements, transformations, and analytical processes, providing early feedback on potential issues.\nContinuously improve testing processes, methodologies, and tools related to data quality, analytics testing, and Azure DevOps integration.\nPerform regression testing of data-related components to validate bug fixes and new features across different releases.\nQualifications\nStrong understanding of software testing methodologies, tools, and processes, with a specific focus on data validation, analytics testing, and Azure DevOps integration.\n5 years of experience as a QA Engineer in writing clear and concise test cases and test documentation for software applications\nShow more\nShow less",
      "job_skills":"Data QA, ETL\/ELT, Azure DevOps, Manual testing, Automated testing, Data validation, Analytics testing, Data lakehouse, Regression testing, Software testing methodologies, Test case management, Defect tracking, Test case automation, Data quality",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Data Analyst",
      "company":"Texas A&M University",
      "job_location":"College Station, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-analyst-at-texas-a-m-university-3784937672",
      "search_city":"College Park",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title\nLead Data Analyst\nAgency\nTexas A&M University\nDepartment\nVP for Planning, Assessment & Strategy\nProposed Minimum Salary\nCommensurate\nJob Location\nCollege Station, Texas\nJob Type\nStaff\nJob Description\nOur Commitment\nTexas A&M University is committed to enriching the learning and working environment by promoting a culture that respects all perspectives, talents & identities. Embracing varying opinions and perspectives strengthens our core values which are: Respect, Excellence, Leadership, Loyalty, Integrity, and Selfless Service.\nWho We Are\nPlanning, Assessment, and Strategy provides leadership related to the strategic and operational plans and priorities of the University, as well as assessing, recommending, and advising on university structures and communication strategies. Additionally, the group advises on access, affordability, continuous improvement, and growth initiatives.\nWhat We Want\nThe Lead Data Analyst, under general direction, serves as technical lead and lead programmer for a variety of data processes. Provides technical oversight for the application of and compliance with technical standards. May coordinate the technical activities of a systems analysis and development team. Completes reports and summaries for management and users including data requests, data sets for State and Federal agencies, data sets and analyses for university administration and committees, project status reports, problem reports, and progress summaries. Documents all developed processes and reporting methodologies.\nWhat you need to know\nCompensation Will Be Commensurate To Selected Hire\u201a\u00c4\u00f4s Experience\nA cover letter and resume are strongly recommended\nRequired Education & Experience:\nBachelor\u201a\u00c4\u00f4s degree or equivalent combination of education and experience\nFive years with SQL scripting or similar programming background\nRequired Knowledge, Skills, and Abilities:\nAbility to write complex scripts in SQL to load recurring data extracts into databases, and to manipulate and merge data from various sources\nRequires heavy use of SQL tools for handling data\nAbility to interpret data requests, determine most appropriate tool for writing the report, and prepare end product for customer\nAbility to create reports based on user specifications\nAbility to multi-task and work cooperatively with others\nPreferred Qualifications:\nMaster\u201a\u00c4\u00f4s degree in information technology, Business Analytics, Data Science, Programming, or similar field\nEight years experience in information technology or institutional research\nExperience with Informatica, Tableau, and Cognos a plus\nResponsibilities:\nTechnical Lead on Data Project (Student Reports\/Faculty Reports\/Texas Higher Education Coordinating Board Reports) - Act independently as a technical lead on various data projects. Analyze, review, document and develop complex IT processes and data structures to meet Reporting needs for the University administration as well as for State and Federal agencies. Acquire, load, and merge data from various campus sources to produce required State and Federal reports. Run processes during key data acquisition dates, make modifications to scripts, and document scripts as data profile and requirements change. Work with University administration and committees to provide data needed for strategic initiatives.\nCoordination with Others to Implement Systems - Work with end users or agencies to make sure that the systems developed meet the requirements of the processes. Meet with data owners to make sure reports generated by processes accurately reflect source data. Also, work with data owners to find solutions to data quality issues and to monitor progress of changes. Maintains current knowledge of State and Federal requirements for reporting to ensure reports generated by the department are correct.\nAd Hoc Reporting - Assist in the response to requests for special data from both within the University and outside the university. Determine appropriate tool and data source for the request.\nWhy Texas A&M University?\nWe are a prestigious university with strong traditions, Core Values, and a community of caring and collaboration.\u201a\u00c4\u00d8 Amenities associated with a major university, such as sporting and cultural events, state-of-the-art recreation facilities, the Bush Library and Museum, and much more await you.\u201a\u00c4\u00d8 Experience all that a big city has to offer but with a reasonable cost-of-living and no long commutes.\nHealth, dental, vision, life and long-term disability insurance with Texas A&M contributing to employee health and basic life premiums\n12-15 days of annual paid holidays\nUp to eight hours of paid sick leave\u201a\u00c4\u00d8and at least\u201a\u00c4\u00d8eight hours of paid vacation\u201a\u00c4\u00d8each month\nAutomatically enrollment in the\u201a\u00c4\u00d8Teacher Retirement System of Texas\nHealth and Wellness: Free exercise programs and release time\nProfessional Development: All employees have access to free\u201a\u00c4\u00d8LinkedIn Learning\u201a\u00c4\u00d8training, webinars, and limited financial support to attend conferences, workshops, and more\nEmployee Tuition Assistance and Educational Release time for completing a degree while a Texas A&M employee\nInstructions to Applicants: Applications received by the School of Nursing must have all job application data entered and must include the following attachments: resume, cover letter and list of references. Failure to provide all job application data and attachments could result in an invalid submission and a rejected application. We encourage all applicants to upload a resume or use a LinkedIn profile to pre-populate the online application.\nAll positions are security-sensitive. Applicants are subject to a criminal history investigation, and employment is contingent upon the institution\u201a\u00c4\u00f4s verification of credentials and\/or other information required by the institution\u201a\u00c4\u00f4s procedures, including the completion of the criminal history check.\nEqual Opportunity\/Affirmative Action\/Veterans\/Disability Employer.\nShow more\nShow less",
      "job_skills":"SQL, SQL scripting, Data extraction, Data manipulation, Data merging, Data analysis, Reporting, Data visualization, Informatica, Tableau, Cognos, Data quality management, Data governance, Data project management, Systems analysis and design, Project management, Communication, Teamwork, Problemsolving, Critical thinking, Attention to detail, Accuracy, Time management, Multitasking, Flexibility, Adaptability, Initiative, Selfmotivation, Leadership, Mentoring, Training",
      "Category":"Data Science"
  },
  {
      "job_title":"Business Intelligence Data Analyst - ELP",
      "company":"Education at Work",
      "job_location":"El Paso, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/business-intelligence-data-analyst-elp-at-education-at-work-3779625206",
      "search_city":"El Centro",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Education at Work is an innovative, mission driven business process outsourcing (BPO) company putting college students at the forefront of our unique business model. As a rapidly growing company with a start-up mindset, we are committed to fostering a collaborative environment and entrepreneurial culture which values and progresses out of the box thinkers and savvy problem solvers.\nPosition Summary\nThe Data Analyst who is able to turn project requirements into custom-formatted data reports. The ideal candidate for this position is able to do complete life cycle data generation and outline critical information for the company. Ideally, the Data Analyst is able to analyze business procedures and recommend specific types of data that can be used to improve upon them. A data analyst's job is to take that data and use it to help the company make better business decisions.\nEssential Functions\nDevelopment and maintain various reports required to analyze call trends and historical patterns.\nSynthesize current business intelligence or trend data to support recommendations for action.\nManage timely flow of business intelligence information to users.\nGathering user requirements.\nProvide error free decision-making reports to management on a daily, weekly, monthly and annual basis.\nDesigning and automating reporting using Power BI.\nVarious performance related analysis as needed.\nOther duties as deemed by Management.\nMinimum Job Requirements\nProficient knowledge of Power BI \u201a\u00c4\u00ec including multiple data connections, visualizations, DAX, M.\nExpert knowledge of Excel- including graphs, pivot tables, formulas.\nExcellent communication skills.\nStrong organizational skills.\nDetail orientated.\nAbility to work effectively as an individual and in a team environment.\nAbility to meet company attendance and dependability guidelines.\nMust be able to sit for long periods of time and repeatedly use a computer or other operational hardware.\nEducation\nBachelor\u201a\u00c4\u00f4s degree, preferred. Equivalent level of work experience considered.\nWorking Conditions\nAbility to travel on occasion.\nAbility to function at a computer workstation for long periods of time.\nAbility to work independently.\nAbility to work with team members offsite.\n$50,000 - $60,000 a year\nExempt Position\nTHE AMERICANS WITH DISABILITIES ACT OF 1990 (ADA) PROHIBITS DISCRIMINATION IN COMPENSATION AND EMPLOYMENT OPPORTUNITIES AGAINST QUALIFIED INDIVIDUALS WITH DISABILITIES. TO DETERMINE WHETHER AN INDIVIDUAL IS QUALIFIED, THE ESSENTIAL FUNCTIONS OF EACH JOB MUST BE IDENTIFIED. ESSENTIAL FUNCTIONS ARE THOSE THAT ARE INTRINSIC TO THE POSITION, AND THAT THE INDIVIDUAL(S) WHO HOLDS THE JOBS MUST BE ABLE TO PERFORM WITH OR WITHOUT REASONABLE ACCOMMODATION.\nShow more\nShow less",
      "job_skills":"Power BI, DAX, M, Excel, Pivot tables, Data connections, Communication, Organization, Detail orientation, Team work, Attendance, Reliability, Bachelor's degree, Travel, Independent work, Offsite team work",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Process Analyst with Security Clearance",
      "company":"ClearanceJobs",
      "job_location":"El Paso, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-process-analyst-with-security-clearance-at-clearancejobs-3753486308",
      "search_city":"El Centro",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Responsibilities PeopleTec is currently seeking a Data Process Analyst to support our El Paso, TX (Fort Bliss) location. Our team is looking for an exceptionally motivated self-starting professional with a background supporting front-end\/UI software development, intelligence analysis, and\/or big data projects . The candidate will support our growing team of cyber, space, and engineering professionals who design, implement, test, and deploy end-to-end 2D\/3D geospatial solutions. The Data Entry Analyst is responsible for ensuring the accurate entry of operational and intelligence data from operational reporting into collaboration environments like Command and Control of the Information Environment (C2IE). Th Data Entry Analyst supports an operational joint task force with a critical National defense mission in a fast-paced environment. This Data Entry Analyst is uniquely gifted to enjoy detailed data entry processes and solve different problems each day. This position involves collaborating with intelligence, operational, & data professionals across multiple echelons of Command. Qualifications Required Skills\/Experience :\nDevelop statistical material and reports\nBuild briefing products that provide situational awareness for the counter-narcotics mission\nTransfer data from various formats & locations (e.g., paper, storyboards, other databases) into a common collaboration environment like C2IE\nCreate spreadsheets and other products that are used to make data-driven decisions based on data trends & synthesis\nClean, process, and retrieve data from a variety of databases & sources to ingest into the collaboration environment\nPerform regular backups to ensure data preservation\nSort and organize paperwork after entering data to ensure it is not lost\nCollaborate with operational staff (e.g., intelligence, operations, IT, Command) to gain user requirements for data insights\nTravel: 0 %\nMust be a U.S. Citizen\nAn active DoD Secret clearance is required to perform this work. Candidates are required to have an active Secret clearance upon hire, and the ability to maintain this level of clearance during their employment. Education Requirements :\nHigh school degree or equivalent & proven experience as data entry professional Desired Skills :\nHave general knowledge and access to decision support systems (i.e., C2IE, Advana) and the experience working with data in the environment\nExposure to\/experience in USG organizations that have a counter-narcotics mission\nAS or BS in data, statistics, or another relevant subject Projected Timeframe to Employee :\nFeb 1, 2024 Overview People First. Technology Always. PeopleTec, Inc. is an employee-owned small business founded in Huntsville, AL that provides exceptional customer support by employing and retaining a highly skilled workforce. Culture: The name \"PeopleTec\" was deliberately chosen to remind us of our core value system - our people. Our company's foundation was built on placing our employees and customers first. With an award-winning atmosphere, we have matured into a company that boasts the best and brightest across multiple technical fields. Career: At PeopleTec, we value your long-term goals. Whether it's through our continuing-education opportunities, our robust training programs, or our \"People First\" benefits package, PeopleTec truly believes that our best investments are our people. Come Experience It. #cjpost #dpost EEO Statement PeopleTec, Inc. is an Equal Employment Opportunity employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in its job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may use the following email address, and\/or phone number (256.319.3800) to contact us about your interest in employment with PeopleTec, Inc. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, genetic information, citizenship, ancestry, marital status, protected veteran status, disability status or any other status protected by federal, state, or local law. PeopleTec, Inc. participates in E-Verify.\nShow more\nShow less",
      "job_skills":"Data Entry, Geospatial, Databases, C2IE, Advana, Spreadsheets, Statistical Material, Briefing Products, Big Data, Data Processing",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Marketing Data Analyst - Remote",
      "company":"Signet Jewelers",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-marketing-data-analyst-remote-at-signet-jewelers-3771698451",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"We have many opportunities available on our other career site pages. Click here to link to our careers page!\nSignet Jewelers is the world's largest retailer of diamond jewelry, operating more than 2,800 stores worldwide under the iconic brands: Kay Jewelers, Zales, Jared, H.Samuel, Ernest Jones, Peoples, Banter by Piercing Pagoda, Rocksbox, JamesAllen.com and Diamonds Direct. We are a people-first company and this core value is at the heart of everything we do, from empowering our valued team members, to collaborating with our customers, to fostering the communities in which we live and serve. People \u201a\u00c4\u00ec and the love their actions inspire \u201a\u00c4\u00ec are what drive us. We\u201a\u00c4\u00f4re not only proud of the love we inspire outside our walls, we\u201a\u00c4\u00f4re especially proud of the diversity, inclusion and equity we\u201a\u00c4\u00f4re inspiring inside. There are dynamic career paths awaiting you \u201a\u00c4\u00ec rewarding opportunities to impact the lives of others and inspire love. Join us!\nPOSITION SUMMARY\n:\nTo provide Signet Marketing with visibility and insights into customer, marketing, and business health and across all banners. The Sr. Analyst accomplishes this by utilizing the power of analytics tools (SQL, Excel, Alteryx & Tableau) across the Signet Enterprise Data Lake, Marketing platforms (Meta, Google, Adobe, etc.), and 3rd party datasets to pull actionable insight out of disparate datasets. While an Analyst surfaces what happened, the Sr. Analyst sheds light into why it may have happened, the potential implications of what happened, and what we can do about it to have a material impact on the business. The Sr. Analyst can work both independently and in a collaborative environment with data scientists, data engineers, strategy, and marketing teams. He or she has a passion for analyzing complex datasets and converting them into insights that drive decisions that create value.\nMAJOR RESPONSIBILITIES\/ESSENTIAL FUNCTIONS\n:\nBuild data extracts using SQL, Excel, Alteryx, Tableau, and data analysis skills to efficiently curate data sets from multiple data sources necessary to support Marketing Mix Modeling (MMM) data collection, QA, planning, and performance analysis.\nSupport the development and maintenance of recurring reporting and insight development related to MMM, marketing campaign performance, competitive intelligence, and other marketing team activities.\nDesign and build visualizations that present complex data in an easily digestible way, surfacing learnings that drive action. (e.g. Marketing campaign trends and anomalies, share-of-voice measurement, and audience performance dashboards)\nPresent findings\/recommendations to all levels of management based on data and analysis of results. Communicate data findings to technical and non-technical partners.\nPartner with business and marketing teams to understand the full context of ad hoc data\/analysis requests. Align on scope, approach, and timeline in conjunction with management team.\nIdentify opportunities for process improvements and automation to standardize workflows and improve efficiency.\nPOSITION QUALIFICATIONS\n:\nEducation Required\n: Bachelor\u201a\u00c4\u00f4s degree in related field\nRequired or Acceptable Job-Related Experience\n: Previous agency analytics experience and Familiarity with marketing mix modeling in a Saas capacity\nYears of Job-Related Experience Required\n: 4+ years\nTechnical\/Other Skills Required\n:\nData manipulation and visualization experience via Tableau \/ Power BI, SQL, Advanced Excel\nStrong knowledge of marketing platforms (Meta, Google, TradeDesk, etc.) and datasets supplied to MMM models, including understanding of important marketing tactics\/objectives for business owners\nExperience with marketing platform campaign data, web analytics tools (Adobe), and sales\/financial data (Business Objects)\nFamiliarity with cross-channel marketing measurement, MMM, attribution and test design\nProven ability to derive actionable insights from data and present recommendations\nAbility to estimate and communicate timelines\nAbility to project manage multiple workstreams\nAbility to work cross-functionally with many departments\/disciplines throughout the company and with its partners\nIntellectual and analytical curiosity\nWillingness\/ability to learn new concepts, tools, and processes quickly\nBENEFITS & PERKS\n:\nCompetitive healthcare, dental & vision insurance\n401(k) matching after one year of employment\nGenerous time off + company holidays\nMerchandise discount\nLearning & Development programs\nMuch more!\nThe salary range for this opportunity is $70,000.00 \u201a\u00c4\u00ec $85,000.00 Base pay offered may vary depending on geographic region, internal equity, job related knowledge, skills and experience, among other factors.\nShow more\nShow less",
      "job_skills":"SQL, Excel, Alteryx, Tableau, Marketing mix modeling, Power BI, Meta, Google, TradeDesk, Adobe, Business Objects, Crosschannel marketing measurement, Attribution, Test design, Data visualization, Data analysis, Data manipulation, Project management, Communication, Problem solving, Critical thinking, Analytical skills, Intellectual curiosity, Ability to learn new concepts quickly",
      "Category":"Data Science"
  },
  {
      "job_title":"Licensed Civil Engineer - Data Center (Remote)",
      "company":"Olsson",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/licensed-civil-engineer-data-center-remote-at-olsson-3784202748",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Company Description\nWe are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.\nOur most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u201a\u00c4\u00ee and will continue to allow us \u201a\u00c4\u00ee to grow. The result? Inspired people, amazing designs, and projects with purpose.\nJob Description\nOlsson provides multidisciplinary design services for some of the largest and most forward-thinking and desirable companies in the world to work for. The large hyperscale data center campuses we design throughout the U.S. will give you the opportunity to work on some of the largest and most complex engineering-driven projects being built today. Our clients are relationship based and truly value the work we do for them, affording us the opportunity to contribute to society\u201a\u00c4\u00f4s technological and connected community through the design of the critical infrastructure that is the foundation of these projects.\nAs a Licensed Civil Engineer on our Data Center Civil Team, you will be a part of the firm\u201a\u00c4\u00f4s largest and most complex projects. You will serve as a project manager on some projects and lead design engineer on others. Prepare planning and design documents, process design calculations, and develop and maintain team and client standards. You may lead quality assurance\/quality control and act as an advisor on complex projects. You will also coordinate with other Olsson teams, professional staff, technical staff, clients, and other consultants.\nYou may travel to job sites for observation and attend client meetings.\nOlsson currently has one opportunity for an Experienced Engineer. This role offers flexible work options, including remote and hybrid opportunities, to accommodate diverse working preferences and promote work-life balance. Candidates can live in Lincoln, Omaha, Phoenix, Chandler, or Dallas-Fort Worth area and work remotely, or work out of any Olsson office location in these regions\/areas.\nQualifications\nYou are passionate about:\nWorking collaboratively with others\nHaving ownership in the work you do\nUsing your talents to positively affect communities\nSolving problems\nProviding excellence in client service\nYou bring to the team:\nStrong communication skills\nAbility to contribute and work well on a team\nBachelor's Degree in civil engineering\nAt least 6 years of related civil engineering experience\nProficient in Civil 3D software\nMust be a registered professional engineer\nAdditional Information\nOlsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u201a\u00c4\u00f4re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.\nAs an Olsson employee, you\u201a\u00c4\u00f4ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u201a\u00c4\u00f4ll:\nBecome an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)\nEngage in work that has a positive impact in communities\nReceive an excellent 401(k) match\nParticipate in a wellness program promoting balanced lifestyles\nBenefit from a bonus system that rewards performance\nHave the possibility for flexible work arrangements\nOlsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.\nShow more\nShow less",
      "job_skills":"Civil Engineering, Civil 3D, Project Management, Design Engineering, Planning, Design Documents, Design Calculations, Team and Client Standards, Quality Assurance\/Quality Control, Client Service, Communication, Teamwork, AutoCAD, Microsoft Office Suite",
      "Category":"Data Science"
  },
  {
      "job_title":"Cloud Big Data Engineer Lead",
      "company":"Elevance Health",
      "job_location":"Grand Prairie, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/cloud-big-data-engineer-lead-at-elevance-health-3780068084",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Description\nCloud Big Data Engineer Lead\nLocation:\nThis position will work a hybrid model (remote and office). Ideal candidates will live in the state of Georgia or within 50 miles of one of our Pulse Point locations.\nPreferred Location: Atlanta, GA.\nThe\nCloud Big Data Engineer Lead\nis responsible for full delivery of end to end system development and maintenance on medium Enterprise wide technology platforms. A proud member of the Elevance Health family of companies, CarelonRx (formerly IngenioRx) leverages the power of new technologies and a strong, clinical first lens, to deliver member centered, lasting pharmacy care.\nHow You Will Make An Impact\nMaintains active relationships with customers to determine business requirements and leads requirements gathering meetings.\nLeads requirements gathering meetings and reviews designs with the business.\nLeads efforts with Web and marketing team to increase the presence of web products.\nMay implement improvements in stability, performance, and scalability across major business-critical systems.\nMay implement process to reduce barriers and roadblocks in projects, services, and processes in order to operate more efficiently.\nOwns the change request process and coordinates with other teams as necessary.\nDevelops and owns list of final enhancements.\nDevelops and defines application scope and objectives and supervises the preparation of technical and\/or functional specifications from with programs will be written.\nPerforms technical design reviews and code reviews.\nEnsures unit test is completed and meets the test plan requirements, system testing is completed and system is implemented according to plan.\nResponsible for delivery of application technology solutions and data information planning effort.\nCoordinates and manages on-call support and owns the system monitoring process.\nOwns the technical development environment and works on the Enterprise team.\nLeads multiple or large projects and facilitates large group JAD sessions for requirements, modeling in several disciplines.\nLeads vendor evaluation and analysis.\nMinimum Qualifications\nRequires an BA\/BS degree in Information Technology, Computer Science or related field of study and a minimum of 7 years related experience; multi platform, multi-dimensional experience, and expert level experience with business and technical applications; or any combination of education and experience, which would provide an equivalent background.\nPreferred Skills, Capabilities And Experiences\nExperience mentoring others and provide troubleshooting support strongly preferred.\nMulti database and\/or multi language strongly preferred.\nPlease be advised that Elevance Health only accepts resumes for compensation from agencies that have a signed agreement with Elevance Health. Any unsolicited resumes, including those submitted to hiring managers, are deemed to be the property of Elevance Health.\nWho We Are\nElevance Health is a health company dedicated to improving lives and communities \u201a\u00c4\u00ec and making healthcare simpler. We are a Fortune 25 company with a longstanding history in the healthcare industry, looking for leaders at all levels of the organization who are passionate about making an impact on our members and the communities we serve.\nHow We Work\nAt Elevance Health, we are creating a culture that is designed to advance our strategy but will also lead to personal and professional growth for our associates. Our values and behaviors are the root of our culture. They are how we achieve our strategy, power our business outcomes and drive our shared success - for our consumers, our associates, our communities and our business.\nWe offer a range of market-competitive total rewards that include merit increases, paid holidays, Paid Time Off, and incentive bonus programs (unless covered by a collective bargaining agreement), medical, dental, vision, short and long term disability benefits, 401(k) +match, stock purchase plan, life insurance, wellness programs and financial education resources, to name a few.\nElevance Health operates in a Hybrid Workforce Strategy. Unless specified as primarily virtual by the hiring manager, associates are required to work at an Elevance Health location at least once per week, and potentially several times per week. Specific requirements and expectations for time onsite will be discussed as part of the hiring process. Candidates must reside within 50 miles or 1-hour commute each way of a relevant Elevance Health location.\nThe health of our associates and communities is a top priority for Elevance Health. We require all new candidates in certain patient\/member-facing roles to become vaccinated against COVID-19. If you are not vaccinated, your offer will be rescinded unless you provide an acceptable explanation. Elevance Health will also follow all relevant federal, state and local laws.\nElevance Health is an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to age, citizenship status, color, creed, disability, ethnicity, genetic information, gender (including gender identity and gender expression), marital status, national origin, race, religion, sex, sexual orientation, veteran status or any other status or condition protected by applicable federal, state, or local laws. Applicants who require accommodation to participate in the job application process may contact elevancehealthjobssupport@elevancehealth.com for assistance.\nShow more\nShow less",
      "job_skills":"Information Technology, Computer Science, Multi platform experience, Multidimensional experience, Business applications, Technical applications, Web products, Stability, Performance, Scalability, Process improvement, Change request process, Application scope definition, Technical design review, Code review, Unit testing, System testing, Application technology solutions, Data information planning, Vendor evaluation, Multidatabase, Multilanguage",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"World Wide Technology",
      "job_location":"Georgetown, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-world-wide-technology-3782264840",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Data Center Engineer\nCompany Overview\nWorld Wide Technology (WWT), a global technology solutions provider with $17 billion in annual revenue, combines the power of strategy, execution and partnership to accelerate transformational outcomes for large public and private organizations around the world. Through its Advanced Technology Center, a collaborative ecosystem of the world's most advanced hardware and software solutions, WWT helps customers and partners conceptualize, test and validate innovative technology solutions for the best business outcomes and then deploys them at scale through its 4 million square feet of global warehousing, distribution and integration space. With over 10,000 employees and more than 55 locations around the world, WWT's culture, built on a set of core values and established leadership philosophies, has been recognized 11 years in a row by Fortune and Great Place to Work\u00ac\u00c6 for its unique blend of determination, innovation and leadership for diversity and inclusion. With this culture at its foundation, WWT bridges the gap between business and technology to make a new world happen for its customers, partners and communities.\nWorld Wide Technology Holding Co, LLC. (WWT) has an opportunity available for a\nData Center Engineer\nto support our client in an ongoing Data Center refresh project.\nLocation:\nGeorgetown, TX\nAvailable Shifts:\n(2 Openings) 7 PM \u201a\u00c4\u00ec 7 AM CST Thursday, Friday, Saturday, and Alternating Wednesdays.\nMUST BE OKAY WITH 12 HOUR NIGHT SHIFTS - Expectation is to have 80 hours of work in a 2 week period.\nDuration:\n12 Months (Expected to renew for up to 3 years, on an ongoing 12-month renewal)\nContract Designation:\nFull Time Contingent \u201a\u00c4\u00ec Contractors will be eligible for WWT\u201a\u00c4\u00f4s Full Time Employee Benefits Package including Medical, Vision, Dental, PTO, Paid Holidays, and more.\nResponsibilities:\nInstalling\/de-installing\/relocating all distributed systems and network hardware (CSUs, DSUs, routers, switches, encryptors, firewalls, etc.) in the Americas Data Centers within the internal service level mandates\nInstalling\/de-installing \/extending\/relocating\/testing all carrier circuits to the network hardware\nInstalling\/de-installing\/relocating all patch cabling for systems and network hardware\nInstalling\/de-installing\/relocating all Data Center hardware\nAssist with the coordination of cabinet power, circuit, and patch infrastructure installations w\/various facilities, electrical and communications vendors\nAssist with the coordination of network component configurations\nCoordinate and Install SAN cabling infrastructure\nManaging network ports and assist with the management of all consumable items (cables, labels, tie wraps, rail kits, etc.)\nMaintaining the integrity of the data center facilities, systems and communications environments through general housekeeping and best operations practices\nQualifications:\nRequired skills include 3+ years of experience in the implementation, maintenance and analysis of data center facilities, hardware, communications infrastructure, strategies, tools and effective troubleshooting techniques.\nBasic background on enterprise data center facilities and infrastructure environments such as PDUs, RPPs, network and SAN infrastructures. In depth knowledge on complex, Enterprise class inter-networked environments involving a combination of switched\/routed\/shared Ethernet, TwinAx (100GigE, 25GigE,10GigE, GigE, 100M, and 10M), token ring, SAN, and wide area connectivity.\nStrong knowledge of WAN technologies (OC-x, DS-x), subnetting and TCP\/IP protocol a must.\nExcellent communication and writing skills a must.\nKnowledge of trouble ticketing systems, change control, Project processes and associated tools.\nLogical problem- solving techniques and associated experience in system, data center facilities, and telecommunications.\nMust be Able to Lift up to 50lbs.\nEqual Opportunity Employer Minorities\/Women\/Veterans\/Disabled\nShow more\nShow less",
      "job_skills":"Data center engineering, Installing\/deinstalling\/relocating hardware, Cabling infrastructure, Cisco hardware (CSUs DSUs routers switches etc.), Carrier circuits, Patch cabling, SAN cabling infrastructure, Network component configurations, Managing network ports, Consumable items management, Troubleshooting techniques, Enterprise data center facilities, PDUs, RPPs, Network infrastructures, SAN infrastructures, Complex Enterprise class internetworked environments, Switched\/routed\/shared Ethernet, TwinAx (100GigE 25GigE10GigE GigE 100M and 10M), Token ring, WAN technologies (OCx DSx), Subnetting, TCP\/IP protocol, Communication skills, Writing skills, Trouble ticketing systems, Change control, Project processes, Logical problem solving techniques",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"K&L Gates",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-k-l-gates-3728651279",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Job Summary\nJob Description\nAt K&L Gates, we are looking for smart, imaginative and hard-working people with diverse backgrounds, experiences and ideas to join us. Perhaps our search for talented visionaries and your search for important and impactful work lead to the same place.\nWe are seeking a Data Center Engineer to join any U.S. office. The candidate will be responsible for daily operations of data center services for K&L Gates. Responsible for hardware and systems support and engineering relating to data centers and local office server rooms. Candidates must be self-starters who possess the ability to work independently and as part of a team. Excellent communication skills and a commitment to providing the highest quality client service are strongly preferred.\nEssential duties\nDevelops UPS strategies and solutions for new infrastructure configurations within the local office environments, for either existing or new office build-outs, taking into consideration load and run-time requirements. Knowledge of smart PDUs a plus.\nProvides operational data center reports for various departmental subscribers which contributes to the firm\u201a\u00c4\u00f4s capacity planning efforts. Reports are crafted using tools such as Visio, Excel and Powerpoint.\nConfigures and monitors alerts from data center systems in order to ensure system reliability and uptime. Monitoring systems such as Schneider\u201a\u00c4\u00f4s Struxureware or standalone power systems are used for this monitoring.\nCoordinates maintenance scheduling with vendors and data center staff, tracks open maintenance tickets and works with Change Management on system change details.\nProvides system analysis and debugging strategies for resolving communication links between power systems and monitoring systems.\nConfigures security layers for local and data center monitoring systems. Manages the UPS device passwords in secret server (or equivalent password store).\nOperates UPS test lab for systems testing and automation upgrades.\nAnalyzes power consumption of systems to provide estimates for local office power installations and makes recommendations for implementing efficiencies or reducing consumption when applicable.\nWorks directly (or as a team member) with technical staff in other departments to resolve incidents or complete project tasks related to data center systems.\nProvides technical expertise related to UPS and data center systems to management or other engineers for incident or planning purposes.\nComplies with physical and logical security policies covering data center systems and sites.\nComplies with departmental documentation standards such as creating and updating standard operating procedures, following through on installation qualification\/operational qualification steps, or adhering to departmental web sites document requirements.\nUtilizes vendor-based portals and interfaces to stay abreast of open incidents. Stays on top of internal data center requests originating from peer engineers in order to ensure jobs are not slipping from desired implementation dates.\nIntegrates data from monitoring systems into reports or databases which are used for operations reports and capacity planning decisions by management.\nTracks equipment shipments, alerts team lead and management of equipment provisioning delays.\nGathers and\/or transcribes data related to data center systems and local office hardware into various repositories. Data is used to produce rack elevation diagrams, hardware identifiers, or data extracts for other databases\/reports.\nSets up alerts for power consumption monitoring, gathers data regarding power quality and consumption at the data center and local offices\nWorks with asset management personnel regarding equipment attrition and destroy orders and receipts.\nProvides guidance on media destruction policy and procedures to ensure that the firm\u201a\u00c4\u00f4s sensitive information on media is secure.\nExperience And Skills Required\nDemonstrates a solid discipline for consistent operational housekeeping and ability to stay on tasks and meet deadlines.\nSufficient knowledge of information technology systems including data center specific systems, power and UPS systems. Networking and DHCP concepts must be understood along with layer 1 troubleshooting (physical layer).\nUnderstanding of power operation for both single phase and 3 phase power. Understanding of power draw and ability to size UPS devices based on power and load requirements.\nKnowledge of server room hardware, cabinets, PDUs, server room layout types and power design is recommended.\nStrong communication and interpersonal skills required for illustrating technical\/complex engineering concepts.\nAbility to adapt to fast pace work environment and rapidly changing priorities. Projects can be delayed or changed at any time to adapt to system failures\/incidents.\nBachelors Degree, or equivalent plus 2+ years experience in information technology field. Experience with data centers or server rooms is highly recommended.\nAdditional Abilities Required\nCollaborative demeanor with other team members and\/or departments on but not limited to hardware installs and decommissions.\nMaintain a congenial yet assertive position with vendors and data center staff.\nResponsibilities occasionally may require an adjusted work schedule during rollouts or DR events.\nSome physical work is involved when installing\/removing\/adjusting equipment such as servers, switches, cabling and heavy UPS devices.\nOn-call duties are shared among team members. On call duties require ability to resolve issues 24 hours per day while on call.\nAble to effectively work remotely.\nAbility to travel domestically and internationally.\nCompensation Salary $80,400 - $120,700\/ year\nThe compensation salary for this position will be determined during the interview process and will vary based on multiple factors, including but not limited to prior experience, relevant expertise, current business needs, and market factors.\nAs required by the Los Angeles Fair Chance Initiative Ordinance and San Francisco Fair Chance Ordinance, qualified applicants for our Los Angeles and San Francisco offices with arrest and conviction records will be considered.\nAbout The Firm\nK&L Gates is a fully integrated global law firm with lawyers located across five continents in more than 40 offices. We have experienced dramatic growth in the past decade and now rank among the largest U.S. based law firms in the world. We take pride in constantly striving for innovation, imagination and an entrepreneurial spirit. We come up with big ideas and then roll up our sleeves to get the job done, guiding our clients through their most complex issues in a variety of industry sectors and across multiple regions of the world.\nThe industry recognition the firm has garnered emanates from the foundation of a global community aligned on behalf of our clients. The people at K&L Gates are committed to working together to create a legacy for each other, the firm, our clients, and the communities in which we serve. We thrive in an inclusive and socially conscious environment that embraces diversity and takes a holistic approach to the career evolution of all our professionals.\nFor more information or to view other job opportunities, please click here to go back to our careers page.\nNotice: We participate in E-Verify in certain Firm locations for purposes of verifying employment eligibility.\nBenefits\nK&L Gates offers our personnel a comprehensive suite of benefits to help meet your needs now and in the future. Depending on your eligibility, options for full-time personnel include:\nMedical\/Prescription Drug Coverage (including a Health Savings Account feature)\nBack-up Child\/Elder Care and access to a caregiving concierge\nDental Insurance\nWellness Program\nVision Insurance\nPre-tax Commuting Benefits\n401(k) Retirement Plan and Profit Sharing\nBusiness Travel Accident Insurance\nShort- and Long-term Disability Protection\nPet Insurance\nLife Insurance (including Basic, Supplemental, Spouse, Child, and Accidental Death and Dismemberment)\nHealth Advocacy Services\nPaid Time Off (25-30 days per year)\nIdentity Protection\/Restoration and Fraud Insurance\nParental Leave (18 weeks of which 6 are paid; short-term disability may provide additional paid time off)\nStudent loan refinancing options and access to a student loan concierge service\nPaid Holidays (12)\nAddiction Resources\nFamily Building Benefits\nBreast Milk Delivery and Lactation Support Services\nFlexible Spending Accounts\nEmployees also may be eligible to receive bonuses and certain expense reimbursements\nEmployee Assistance Program\nProfessional Development and CLE Credit Opportunities\n529 Deductions\nRelocation\nAccident Insurance\nEmployee Referral Program\nCritical Illness Insurance\nHybrid\/Remote Work Opportunities\nHospital Indemnity Insurance\nPerks including: Technology, Entertainment, and Travel Discount Programs\nBereavement Leave\nAll other benefits (such as leaves of absence) required by law\nEQUAL EMPLOYMENT OPPORTUNITY\nThe Firm is an equal opportunity employer. All employment decisions will be based on merit, qualifications, competence, and business need. Employment practices will not be influenced or affected by a person\u201a\u00c4\u00f4s race, color, religion, sex (including pregnancy, childbirth, or related conditions), national origin, age, sexual orientation, gender identity or expression, marital status, disability, genetic information, military or veteran status, or any other characteristic protected by applicable law. This policy governs all aspects of employment including, without limitation, recruiting, hiring, compensation, benefits, promotion, assignment, and dismissal. In addition, it is the Firm\u201a\u00c4\u00f4s policy to provide an environment that is free of all unlawful harassment including, without limitation, that based on sex, race, age, disability, or national origin. The Firm complies with federal and state disability laws and makes reasonable accommodations for applicants and employees with disabilities. If you require reasonable accommodation in completing this application, interviewing, or otherwise participating in the employee selection process, please contact askHR@klgates.com .\nShow more\nShow less",
      "job_skills":"Data Center Operations, Power and UPS Systems, Networking, DHCP Concepts, Layer 1 Troubleshooting, Power Operation, Power Draw Analysis, UPS Sizing, Server Room Hardware, Cabinets, PDUs, Server Room Layout Types, Power Design, Communication Skills, Interpersonal Skills, Adaptability, FastPaced Work Environment, Bachelors Degree, Information Technology Field Experience, Collaborative Demeanor, Vendor and Data Center Staff Management, OnCall Duties, Remote Work, Domestic and International Travel, Microsoft Office Suite, Visio, Excel, PowerPoint, Schneider's Struxureware, UPS Test Lab Operations, Power Consumption Analysis, Rack Elevation Diagrams, Hardware Identifiers, Data Extraction, Asset Management, Media Destruction Policy and Procedures, Project Management, Problem Solving, Time Management, Physical Work, Heavy Lifting",
      "Category":"Data Science"
  },
  {
      "job_title":"MAOP Data Analyst",
      "company":"Acadian Ambulance",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/maop-data-analyst-at-acadian-ambulance-3778734216",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nThe contract MAOP Data Analyst will work with a team of four to five other analysts under the supervision of a team lead. Duties and tasks would include:\nCompilation\nSorting and indexing of MAOP records for historic pipeline projects\nReviewing and conducting comparative analysis of MAOP records\nCorrelating technical documents against baseline GIS data to identify any gap between the two Following documented workflow and procedures.\nRequired Skills And Experience\nMust be familiar with pipe construction and MAOP validation work\nMAOP\/MOP records verification for pipelines, components, and facilities\nExperience with PHMSA Audits for pipelines\nAnalysis of MAOP\/MOP for high pressure pipeline segments\nProcurement process for pipeline materials and components\nAbility to read and interpret pipeline as built drawings\nWorking knowledge of pipeline data tools such PODS, GIS, etc.\nWorking knowledge of pipeline materials and yield strength calculation\nWorking knowledge of PHMSA 49 CFR Part 192\/195 regulations and fundamental knowledge of construction and operation of high-pressure pipelines\nStrong verbal and written communication and customer service skills to interact with other groups\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\nLiberty Energy Services, a division of Safety Management Systems, has extensive professional experience and expertise within the oil and gas industry. Our clients have come to realize that they receive phenomenal services from an elite group of highly skilled consultants that deliver every time.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Compilation, Data Sorting, Data Indexing, Data Review, Comparative Analysis, GIS Data, PHMSA Audits, Pipeline Materials, Pipeline Components, Pipeline Construction, Pipeline Drawings, Pipeline Regulations, Construction Operations, Verbal Communication, Written Communication, Customer Service",
      "Category":"Data Science"
  },
  {
      "job_title":"Palantir Data Engineer",
      "company":"Trident Consulting",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/palantir-data-engineer-at-trident-consulting-3784650592",
      "search_city":"Mansfield",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Trident Consulting is seeking a\n\"Palantir Data Engineer\"\nfor one of our industry leading clients\n.\nTitle: Palantir Data Engineer\nLocation: Dallas, TX\nJob Type: Contract\nJob Description:\n8-10+years of experience in implementing analytical solutions by leveraging Networking data using Palantir foundry.\nIntegrate advanced analytics capabilities within the Palantir platform to enhance data-driven decision-making.\nExpertise in Palantir technologies, including hands-on experience in analytics components.\nAbout Trident:\nTrident Consulting is an award-winning IT\/engineering staffing company founded in 2005 and headquartered in San Ramon, CA. We specialize in placing high-quality vetted technology and engineering professionals in contract and full-time roles. Trident's commitment is to deliver the best and brightest individuals in the industry for our clients' toughest requirements.\nSome of our recent awards include:\n\u201a\u00c4\u00a2 2022, 2021, 2020 Inc. 5000 fastest-growing private companies in America\n\u201a\u00c4\u00a2 2022, 2021 SF Business Times 100 fastest-growing private companies in Bay Area\nShow more\nShow less",
      "job_skills":"Palantir Foundry, Data Analytics, Data Engineering, Networking, Advanced Analytics, Handson experience",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Land Data Analyst",
      "company":"Endeavor Energy Resources, LP",
      "job_location":"Midland, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-land-data-analyst-at-endeavor-energy-resources-lp-3688410478",
      "search_city":"Midland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"As one of the largest employers in the Permian, we\u201a\u00c4\u00f4re committed to the success of our employees and providing an environment that fosters people and teamwork, continuous improvement, HSE excellence, technical and financial discipline, and integrity. Poised for sustainable growth, we look forward to executing our horizontal program with a world class land position and valued employees whose knowledge and expertise drive the success of this company. Interested in joining our team?\nLand Data Analyst are responsible for researching, identifying, and analyzing land data within Company land systems and delivering the data to stakeholders within the enterprise in an accurate, streamlined, and consumable format.\nEssential Duties And Responsibilities\nThe following represents many of the duties performed by the position, but is not meant to be all-inclusive nor prevent other duties from being assigned when necessary:\nKnowledgeable of land specific data, including tracts, depths, ownership and terms of oil and gas leases and\/or assignments and input data into land database\nReview, identify, analyze, and update large amount of data associated with oil and gas leases, contracts, surface, right-of-way, mineral deeds, title opinions and division orders in Company land system\nBuild simple to use tools, dashboards, and reports that are capable of handling large amounts of data to drive decisions which enhance Company performance and drive value\nUse of data analytics to provide quick reports, visual aids and statistical analysis facilitating information sharing and process improvement\nExtract, Transform and Load (ETL) data from acquired asset data rooms into core Company systems\nCommunicate technical requirements of the Company Land Department to Company IT Department and\/or 3rd party software vendors (i.e. Enertia)\nAssist with special projects such as audits, acquisitions, and divestitures\nOther tasks as assigned\nSkills And Experience\nBachelor\u201a\u00c4\u00f4s degree required (Data Science, Energy Management or Business Degree preferred) The combination of education and relevant experience may substitute for degree\nMinimum of 3 years of experience in the oil and gas industry; Data Science, Land or Land Administration preferred\nExhibit a high aptitude in analytical thinking\nExperience with data extraction, data automation, artificial intelligence and machine learning preferred\nProven proficiency with data analytics software (Spotfire and\/or PowerBi preferred)\nEstablished proficiency in Microsoft Office required, with emphasis in Excel, Word, and Teams.\nExperience with Land Data Management Software (Enertia preferred)\nExperience with Document Management Systems (M-Files and\/or Thomson Reuters Document Intelligence preferred)\nAbility to effectively communicate and build relationships with various levels of company personnel\nDemonstrate time management and organizational skills approaching projects with a sense of urgency\nDetail oriented with the ability to multi-task with attention to accuracy\nRecognizes value in, and seeks opportunities for, continued development and improvement\nAbility to seek out, implement and adapt to new technologies, workflows, and processes\nTeam player who possesses the ability to adapt to a changing and fast paced work environment\nEndeavor Energy Resources, LP is an Equal Opportunity Employer and does not discriminate in regard to race, color, creed, age, religion, ancestry, national origin, sex, genetics, marital status or disability. Endeavor Energy Resources, L.P. complies with all local, state, and federal laws pertaining to employment, and discrimination will not be tolerated.\nShow more\nShow less",
      "job_skills":"Data Science, Energy Management, Business Degree, Oil and Gas Industry, Analytical Thinking, Data Extraction, Data Automation, Artificial Intelligence, Machine Learning, Data Analytics Software, Spotfire, PowerBI, Microsoft Office, Excel, Word, Teams, Land Data Management Software, Enertia, Document Management Systems, MFiles, Thomson Reuters Document Intelligence, Effective Communication, Relationship Building, Time Management, Organizational Skills, Detail Orientation, MultiTasking, Accuracy, Continuous Development, Adaptability, New Technologies, Workflows, Processes, Team Player, FastPaced Work Environment",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Building Operating Engineer (2nd shift)",
      "company":"JLL",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-building-operating-engineer-2nd-shift-at-jll-3770695700",
      "search_city":"McKinney",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Data Center Operating Engineer\nGeneral Description:\nThe Data Center Building Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)\nLocation:\nPrincipal Duties and Responsibilities\nTask will include but not be limited to:\nResponsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire\/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.\nRequires the ability to analyze the operation of various systems, determine the cause of any problems\/malfunctions and take corrective action as required.\nComply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.\nLearn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.\nWork order management, including CMMS, Vendor Management, and Customer Facing Tickets.\nUnderstanding and complying with emergency escalation procedures.\nPerform additional job duties as required.\nMinimum Requirements:\nPreferred to have hands-on experience working in a data center\/critical facility, including UPS.\nSystems, emergency generators, and switchgears.\nHigh School diploma or GED equivalent\n2+ years related work experience.\nWorking knowledge of computer applications including Word and Excel.\nDemonstrated verbal\/written communication skills.\nPreferred Requirements:\nCorrigo Experience.\nMCIM \/ Salesforce Experience.\nZendesk Experience.\nService Now Experience.\nReceived EPA 608.\nTrained in NFPA70E.\nShow more\nShow less",
      "job_skills":"UPS, Electrical Systems, Generators, Cooling Systems, HVAC, Chillers, CRAC, CRAH, Plumbing, Controls, Lighting, ATS, STS, PDU, Power Distribution, Transformers, Hot Water Systems, CMMS, Vendor Management, Customer Facing Tickets, Corrigo, MCIM, Salesforce, Zendesk, Service Now, EPA 608, NFPA70E",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Analyst",
      "company":"Brooksource",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-at-brooksource-3705699979",
      "search_city":"McKinney",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Data Analyst\nPlano, TX\n6+ Month CTH\nAs a Senior Data Analyst in Data and Analytics team, you will be a crucial member of our data engineering team, serving as the key domain expert overseeing our PepsiCo\u201a\u00c4\u00f4s business processes. You will play a pivotal role in driving discussions around understanding Supply Chain, Financial, Consumer, Channel, and Category. This will involve close collaboration with business SME\u201a\u00c4\u00f4s, the data science team, and the data engineering team. You will be responsible for developing an in-depth understanding of our business processes and translating business requirements into technical specifications for the data engineering team.\nMINIMUM QUALIFICATIONS\nBachelor\u201a\u00c4\u00f4s degree in Supply Chain and\/or Operations Management\n5+ years of experience with data analysis & data profiling in project, business requirements definition or data engineering in CPG or Manufacturing Industry\n5+ years\u201a\u00c4\u00f4 work experience in the areas of Distribution Network Analysis, Manufacturing, Production Network Optimization, Transportation, Demand Planning, or other areas related to Supply Chain or other domains such as Financial, Consumer, Channel, Category etc.\n4+ years of strong Data Profiling experience & ability to identify trends and anomalies in the data to in-form data model build out\nExperience in working with Datasets from POS Aggregators such as IRI, Nielsen, Kantar, Fetch, 8451, Luminate etc.\nExperience working with structured\/unstructured datasets, ability to clearly document and communicate requirement to technical team members\nExperience with Business Intelligence tools, SQLTools\nExperience leading projects working with large data sets, finding insights, and telling stories using data\nRESPONSIBILITES:\nDemonstrated high curiosity and ownership to learn and deep dive in problems\nDemonstrated proficient in data mining principles: predictive analytics, mapping, collecting data from multiple data systems on premises and cloud-based data sources\nHave knowledge on business process and SAP ERP Modules, such as, order to Cash, Account Payables, Finance (GL), Purchase Order, etc\nDevelop metrics, storyboards, and dashboards by gathering data from various sources to tell a story about the data\nAnalyze complex data to identify patterns, detect anomalies in data using statistical concepts and tools\nGather and analyze data pertaining to various business processes such as sales, forecasts, capital requirements, inventory, logistic, manufacturing and production capacity to develop supply chain models. geographics, POS, pricing and promotion, store profile, e-commerce data to develop channel models\nPerform in-depth data analysis, including data cleansing, transformation, and validation, to ensure the accuracy and reliability of data used for reporting and analysis\nDevelop and apply statistical models, including logistic regression, linear regression, and other methods, to analyze data trends, identify patterns, and make predictions that inform business strategies and decisions\nHands on experience in data visualizations and dashboards using tools like OpenRefine, Tableau, Power BI, SAP Business Objects, Databricks, or other data visualization platforms to communicate insights effectively to stakeholders\nInterpret and explain complex data sets to non-technical stakeholders, translating data findings into actionable recommendations\nCollaborate with data engineering teams to ensure data quality and consistency, including identifying and resolving data anomalies or discrepancies\nWork closely with cross-functional teams to uncover actionable insights and trends that drive business growth and customer satisfaction in the CPG industry\nAdhere to data governance policies and best practices, ensuring compliance with data privacy and security regulations\nExpertise with Database systems, SAP, SAP BW, SAP BO, RDBMS (Oracle, SQL Server, MySQL) with an excellent understanding of transaction management\nAbility to learn and adapt to new technologies, passion for continuous improvement\nCreate high-level process models (system interface diagrams, workflow & swim lane diagrams, data flow diagrams) to represent processes for the area under analysis\nBrooksource provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Profiling, Data Mining, Predictive Analytics, Mapping, Data Visualization, Data Cleansing, Data Transformation, Data Validation, Statistical Models, Logistic Regression, Linear Regression, Tableau, Power BI, SAP Business Objects, Databricks, OpenRefine, SAP, SAP BW, SAP BO, RDBMS, Oracle, SQL Server, MySQL, Transaction Management, Database Systems",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"Cloudflare",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-cloudflare-3732383582",
      "search_city":"Oxnard",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"About Us\nAt Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world\u201a\u00c4\u00f4s largest networks that powers approximately 25 million Internet properties, for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine\u201a\u00c4\u00f4s Top Company Cultures list and ranked among the World\u201a\u00c4\u00f4s Most Innovative Companies by Fast Company.\nWe realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!\nData Center Operations Engineer\nAbout the department\nIn this role, you will be focused on maintaining the Clou dflare global network. You 'll work closely with Cloudflare\u201a\u00c4\u00f4s SRE (Site Reliability Engineering) team, Network Engineering team, Network Deployment Engineering team and with various vendors and partners (including hardware vendors, datacenter and network providers, and ISPs) to maintain and improve our global infrastructure. You will further be responsible for the development and implementation of consistent processes and visibility measurements for consistent and effective management of our infrastructure. This is a highly visible position that requires deep technical understanding of datacenter infrastructure, networking (physical), and basic experience with data analysis and project management.\nTo be successful in this position, you should have excellent technical skills, communication skills, and be able to navigate a range of challenges and constraints (e.g. schedule adherence, time zones, and cultures). You will have the opportunity to (literally) build a faster, safer Internet for our millions of users and the billions of web surfers that visit their sites each month.\nWho You Are\nYou will thrive in a hypergrowth engineering environment and be self driven with a keen attention to detail. You will come with a deep technical understanding of Data Center colocation environments, network architecture and server technologies. You will be used to working through partners to support infrastructure delivery to a number of remote locations. You will have had experience managing operational environments, and used to developing new approaches to improve delivery efficiency or operational stability.\nWhat You'll Do\nCollaborating with internal teams (Infrastructure, Network Engineering and SRE). Create documentation and manage remote contractors to complete datacenter tasks, working with hardware manufacturers, datacenter and network providers, logistics partners and other service providers in support of our 300+ datacenter locations\nMaintain Data Center environment operational availability\nCreating and maintaining documentation, plans, SOP\u201a\u00c4\u00f4s, MOP\u201a\u00c4\u00f4s etc.\nSupport and configure network infrastructure where required\nProviding feedback to internal teams to support internal tools and external vendor partnerships\nRequired Experience\nMinimum of 5 yrs of Linux systems administration\nExperience with Juniper, Cisco and DWDM network equipment\nExperience managing and instructing remote contractors\nFamiliarity with work required to stand up infrastructure in remote colocation facilities\nExperience running and improving operational processes, including automation tooling, in a rapidly changing environment\nFamiliarity with day-to-day tasks and projects common to Data Center Operations (deployment, migration, decommissioning etc.)\nComfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA\nIncident management\nOther Responsibilities May Include\nAggressively seek opportunities to introduce cutting-edge technology and automation solutions that are effective, efficient and scalable in order to improve our ability to deploy and maintain our global infrastructure\nAssist with the definition, documentation and implementation of consistent processes across all region\nLimited travel\nExamples Of Desirable Skills, Knowledge And Experience\nBachelor\u201a\u00c4\u00f4s degree; technical background in engineering, computer science, or MIS\nDirect experience executing on complex data center\/infrastructure projects\nPrevious experience installing \/ maintaining data center (and other IT) infrastructure and DCIM tools\nExperience running and improving operational processes in a rapidly changing environment\nStrong verbal and written communication skills, problem-solving skills, attention to detail, and interpersonal skills\nMust be proactive with proven ability to learn fast and execute on multiple tasks simultaneously\nAbility to manage MS excel and Google spreadsheets\nComfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA\nMust be a team player\nBonus Points\nMulti-lingual; experience working with infrastructure in multiple countries\nComfortable with remote \u201a\u00c4\u00falights-out\u201a\u00c4\u00f9 and out-of-band access to data center resources\nLinux certifications (RHCSA etc.)\nNetwork certifications (CCNA, JNCIA or higher)\nCompensation\nCompensation may be adjusted depending on work location.\nFor Colorado-based hires: Estimated annual salary of $ 111,000 - $ 135,000 .\nFor New York City, Washington, and California (excluding Bay Area) based hires: Estimated annual salary of $ 135,000 - $ 165,000\nFor Bay Area-based hires: Estimated annual salary of $ 142,000 - $ 174,000 .\nEquity\nThis role is eligible to participate in Cloudflare\u201a\u00c4\u00f4s equity plan.\nBenefits\nCloudflare offers a complete package of benefits and programs to support you and your family. Our benefits programs can help you pay health care expenses, support caregiving, build capital for the future and make life a little easier and fun! The below is a description of our benefits for employees in the United States, and benefits may vary for employees based outside the U.S.\nHealth & Welfare Benefits\nMedical\/Rx Insurance\nDental Insurance\nVision Insurance\nFlexible Spending Accounts\nCommuter Spending Accounts\nFertility & Family Forming Benefits\nOn-demand mental health support and Employee Assistance Program\nGlobal Travel Medical Insurance\nFinancial Benefits\nShort and Long Term Disability Insurance\nLife & Accident Insurance\n401(k) Retirement Savings Plan\nEmployee Stock Participation Plan\nTime Off\nFlexible paid time off covering vacation and sick leave\nLeave programs, including parental, pregnancy health, medical, and bereavement leave\nWhat Makes Cloudflare Special?\nWe\u201a\u00c4\u00f4re not just a highly ambitious, large-scale technology company. We\u201a\u00c4\u00f4re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.\nProject Galileo\n: We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare\u201a\u00c4\u00f4s enterprise customers--at no cost.\nAthenian Project\n: We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.\nPath Forward Partnership\n: Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.\n1.1.1.1\n: We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here\u201a\u00c4\u00f4s the deal - we don\u201a\u00c4\u00f4t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.\nSound like something you\u201a\u00c4\u00f4d like to be a part of? We\u201a\u00c4\u00f4d love to hear from you!\nThis position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.\nCloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA\/Veterans\/Disabled Employer.\nCloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.\nShow more\nShow less",
      "job_skills":"Linux, Juniper, Cisco, DWDM, Network equipment, Data Center Operations, Deployment, Migration, Decommissioning, JIRA, Program management, MS Excel, Google Spreadsheets, RHCSA, CCNA, JNCIA",
      "Category":"Data Science"
  },
  {
      "job_title":"Associate Research\/Data Analyst - 5034196",
      "company":"State of Missouri",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/associate-research-data-analyst-5034196-at-state-of-missouri-3781637863",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Associate Research\/Data Analyst\nDepartment of Revenue \u201a\u00c4\u00ec Taxation Division \u201a\u00c4\u00ec Income Tax Bureau\nAnnual Salary: $ 45,006.24\nLocation: 301 West High Street, Jefferson City, MO\nDOR\u201a\u00c4\u00f4s Vision: To provide every customer the best experience every time.\nHow This Position Supports The Department\u201a\u00c4\u00f4s Vision\nThis position is the Department of Revenue\u201a\u00c4\u00f4s Federal and State Coordinator and the liaison with the Internal Revenue Service and state tax agencies. The main responsibility of this position is to ensure federal tax information that the Department of Revenue receives from the Internal Revenue Service is safeguarded to the requirements in IRS Publication 1075. Create procedures and conduct educational sessions on IRS Pub 1075 requirements and on other Income Tax Bureau processes and functions. Advise Department of Revenue team members on IRS Pub 1075 requirements as needed. Analyze tax data. Work with other Departments to create agreements between the Department of Revenue and other agencies.\nThis position requires the candidate to work independently, have good organizational, written and verbal communication skills, and be able to prioritize duties and adjust as priorities change.\nDuties Performed To Support The Department\u201a\u00c4\u00f4s Vision\nSelf-Directed\nAttention to Detail\nOrganized\nEffective Writing\nProfessional\nExcellent Time Management\nSafeguarding Federal Tax Information\nCommunication between the Internal Revenue Service and the Missouri Department of Revenue\nCore Compentencies Needed\nComputer Literacy Effective Writing Excellent Customer Service\nSelf-directed Attention to Detail Analytical Thinking\nClear Communication Organizational Abilities\nQualifications\nKnowledge of basic research methods and analysis, computer information systems, and statistical software.\nAbility to perform basic queries and analysis of data.\nBachelor\u201a\u00c4\u00f4s degree and 0-2 years of relevant experience and\/or appropriate certification. (Substitutions may be allowed.)\nMore Reasons To Love This Position\nThe State of Missouri offers an excellent benefits package that includes a defined pension plan, generous amounts of leave and holiday time, and eligibility for health insurance coverage. Your total compensation is more than the dollars you receive in your paycheck. To help demonstrate the value of working for the State of Missouri, we have created an interactive Total Compensation Calculator. This tool provides a comprehensive view of benefits and more that are offered to prospective employees. The Total Compensation Calculator and other applicant resources can be found here .\nPlease Direct Any Questions About This Position To\nThe Missouri Department of Revenue Human Resources and Total Rewards office at (573) 751-1291.\nWe celebrate diversity and are committed to creating an inclusive environment for all employees\nThe State of Missouri is an equal opportunity employer.\nShow more\nShow less",
      "job_skills":"Computer Literacy, Organizing, Statistical Software, Queries, Data Analysis, Analytical Thinking, Information Systems, Computer Programming",
      "Category":"Data Science"
  },
  {
      "job_title":"Mid Level Data Steward (1014383)",
      "company":"The Judge Group",
      "job_location":"Creve Coeur, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/mid-level-data-steward-1014383-at-the-judge-group-3751628194",
      "search_city":"Saint Louis",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Location:\nCreve Coeur, MO\nSalary:\nDepends on Experience\nDescription:\nOur client is currently seeking a\nMid-Level Data Steward- Saint Louis, MO\nJob Description-\nThe job involves analyzing and documenting the current SQL scripts flow and assisting in daily support.\nWe are looking for a Expert SQL candidate\nEducation And Work Experience Requirements\n7+ years with RDBMS, TD (Teradata) and GCP big Query is preferred.\nResponsibilities\nAnalyze\/reverse engineer existing SQL code from stored procedures, scripts, and document flow to create mapping documents\nUnderstand and map source data fields from custodial and market data source.\nGather and document requirements for future system enhancement working with both the business and core systems teams.\nSend status reports on the activities planned vs completed\nPrepare business scenarios and UAT test cases\nSupport of Development, SIT and UAT teams on requirement clarification.\nWork closely with the engineering team to identify, troubleshoot, and resolve issues.\nContact:\nsshriyam@judge.com\nThis job and many more are available through The Judge Group. Find us on the web at www.judge.com\nShow more\nShow less",
      "job_skills":"SQL, Teradata, Google Big Query, RDBMS",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Mechanical Engineer (Mission Critical\/Data Center)",
      "company":"WSP in the U.S.",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-mechanical-engineer-mission-critical-data-center-at-wsp-in-the-u-s-3778949027",
      "search_city":"Cahokia",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who We Are\nAt WSP, we are driven by inspiring future-ready pioneers to innovate. We\u201a\u00c4\u00f4re looking to grow our teams with people who are ready to collaborate in building communities and expanding our skylines. To do this, we hire candidates of all experiences, skillsets, backgrounds and walks of life. We actively foster a work environment and culture where inclusion and diversity is part of our fundamental structure. This is delivered behaviorally, through our policies, trainings, local partnerships with professional diverse organizations, internal networks and most importantly with the support and sponsorship of our leaders who help drive our commitment to an inclusive, diverse, welcoming and equitable work environment. Anything is within our reach and yours as a WSP employee. Come join us and help shape the future!\nGreat people. Great places. Great projects. kW Mission Critical Engineering, a WSP company, is a high-performance, fast-paced consulting engineering firm designing data centers and mission critical environments across the globe. We hire smart, responsive, team players to work in collaborative and mentoring office settings. Our mechanical, electrical, plumbing, fire protection, controls, telecommunications, and security building system designs keep many of the world\u201a\u00c4\u00f4s top Fortune 100 financial, technology, enterprise, hyperscale, and colocation companies up and running 24 hours a day, 365 days a year.\nWe work on innovative, award-winning, large-scale projects. We travel to construction sites to see our designs being built. As part of WSP, we are able to offer our employees increased professional development and career opportunities in addition to kW MCE\u201a\u00c4\u00f4s office culture which is consistently recognized as one of the \u201a\u00c4\u00faBest Places to Work.\u201a\u00c4\u00f9 Join our great people at our great places designing great projects.\nThis Opportunity\nkW Mission Critical Engineering, a member of WSP USA\n, is currently initiating a search for a\nLead Mechanical Engineer\nlocated out of our\nSt. Louis, MO office.\nAs a Mechanical Engineer with us, you will design complex cooling and HVAC systems including air distribution systems, chiller plants, and alternative energy solutions for mission critical facilities.\nYour Impact\nIndependently support the project team during design and construction stages of projects\nDesign air distribution, hydronic and automated temperature controls systems\nIntegrate complex mechanical engineering requirements into facility designs\nWork within multi-discipline project teams to develop drawing and specification documents for issuance to architects, contractors and building owners\nAttend client meetings and contribute to discussions\nCollaborate and coordinate with internal project discipline team members and external vendors and manufacturers\nCommunicate mechanical engineering concepts and decisions to clients and stakeholders\nInteract regularly with clients, which includes maintaining current relationships and developing new relationships\nMentor and train junior engineers\nTrack and coordinate all mechanical disciplines: HVAC, Energy, Controls, Fire Protection, Fire Alarm, Plumbing, Fuel Oil Storage \/ Management \/ Distribution\nProvide oversight of all aspects of mechanical design, review systems, drawings prior to issuance\nPerform Computational Fluid Dynamic (CFD) evaluations for existing and new facilities, both internal and external\nSelect and schedule major equipment\nDevelop project specifications\nSurvey and evaluate existing conditions\nPerform construction administration tasks\nWho You Are\nThe ideal candidate has familiarity with Building Information Modeling using Revit, has strong communication skills, and an interest in liaising with internal and external design, client, and construction team members. Candidate should be willing to travel to client sites.\nRequired Qualifications\nBachelor\u201a\u00c4\u00f4s degree in Mechanical Engineering or Architectural Engineering with mechanical building systems emphasis\n7+ years of experience in designing mechanical systems for the high performing, commercial, industrial or mission critical\/data center buildings\nEIT or Registered Professional Engineer (PE), if eligible\nExcellent interpersonal skills, teamwork, and written and verbal communication skills\nProficiency with applicable software including AutoCAD, Revit, Trane Trace and Pipeflow\nKnowledge of building, mechanical and energy codes\nPreferred Qualifications:\nExperience with the analysis and modeling of interior and exterior Computational Fluid Dynamics of airflow\nMission Critical\/Data Center experience\nExperience with international projects\nAdditional Requirements\nTo perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.\nAdditional Details\nTravel Required: 20%\nJob Status: Regular\nEmployee Type: Full\nPrimary Location: ST LOUIS - N BROADWAY\nAll locations: US-AZ-Phoenix, US-AZ-Tempe, US-MO-St Louis\nAbout WSP\nWSP USA is the U.S. operating company of WSP, one of the world's leading engineering and professional services firms. Dedicated to serving local communities, we are engineers, planners, technical experts, strategic advisors and construction management professionals. WSP USA designs lasting solutions in the buildings, transportation, energy, water and environment markets. With more than 15,000 employees in over 300 offices across the U.S., we partner with our clients to help communities prosper. www.wsp.com\nWSP provides a flexible and agile workplace model while meeting client needs. Employees are also afforded a comprehensive suite of benefits including medical, dental, vision, disability, life, and retirement savings focused on providing health and financial stability throughout the employee\u201a\u00c4\u00f4s career.\nAt WSP, we want to give our employees the challenges they seek to grow their careers and knowledge base. Your daily contributions to your team will be essential in meeting client objectives, goals and challenges. Are you ready to get started?\nWSP USA (and all of its U.S. companies) is an Equal Opportunity Employer Race\/Age\/Color\/Religion\/Sex\/Sexual Orientation\/Gender Identity\/National Origin\/Disability or Protected Veteran Status.\nThe selected candidate must be authorized to work in the United States.\nNOTICE TO THIRD PARTY AGENCIES:\nWSP does not accept unsolicited resumes from recruiters, employment agencies, or other staffing services. Unsolicited resumes include any resume or hiring document sent to WSP in the absence of a signed Service Agreement where WSP has expressly requested recruitment\/staffing services specific to the position at hand. Any unsolicited resumes, including those submitted to hiring managers or other business leaders, will become the property of WSP and WSP will have the right to hire that candidate without reservation \u201a\u00c4\u00ec no fee or other compensation will be owed or paid to the recruiter, employment agency, or other staffing service.\nShow more\nShow less",
      "job_skills":"Mechanical Engineering, Architectural Engineering, HVAC, Energy, MEP, AutoCAD, Revit, CFD, Building Information Modeling, Trace, Pipeflow",
      "Category":"Data Science"
  },
  {
      "job_title":"Lead Electrical Engineer (Mission Critical\/Data Center)",
      "company":"WSP in the U.S.",
      "job_location":"Creve Coeur, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-electrical-engineer-mission-critical-data-center-at-wsp-in-the-u-s-3757436536",
      "search_city":"East Saint Louis",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who We Are\nAt WSP, we are driven by inspiring future-ready pioneers to innovate. We\u201a\u00c4\u00f4re looking to grow our teams with people who are ready to collaborate in building communities and expanding our skylines. To do this, we hire candidates of all experiences, skillsets, backgrounds and walks of life. We actively foster a work environment and culture where inclusion and diversity is part of our fundamental structure. This is delivered behaviorally, through our policies, trainings, local partnerships with professional diverse organizations, internal networks and most importantly with the support and sponsorship of our leaders who help drive our commitment to an inclusive, diverse, welcoming and equitable work environment. Anything is within our reach and yours as a WSP employee. Come join us and help shape the future!\nGreat people. Great places. Great projects. kW Mission Critical Engineering, a WSP company, is a high-performance, fast-paced consulting engineering firm designing data centers and mission critical environments across the globe. We hire smart, responsive, team players to work in collaborative and mentoring office settings. Our mechanical, electrical, plumbing, fire protection, controls, telecommunications, and security building system designs keep many of the world\u201a\u00c4\u00f4s top Fortune 100 financial, technology, enterprise, hyperscale, and colocation companies up and running 24 hours a day, 365 days a year.\nWe work on innovative, award-winning, large-scale projects. We travel to construction sites to see our designs being built. As part of WSP, we are able to offer our employees increased professional development and career opportunities in addition to kW MCE\u201a\u00c4\u00f4s office culture which is consistently recognized as one of the \u201a\u00c4\u00faBest Places to Work.\u201a\u00c4\u00f9 Join our great people at our great places designing great projects.\nThis Opportunity\nWhat You\u201a\u00c4\u00f4ll Do:\nkW Mission Critical Engineering\nis currently initiating a search for a\nLead Electrical Engineer\nthat can be located for our\nkW Tempe, Arizona office or our St. Louis, MO office.\nAs a Lead Electrical Engineer with us, you will design complex power and other building systems including generator plants, medium voltage distribution, uninterruptible power systems, lighting, fire alarm, and grounding while leading projects and a team of electrical engineers.\nYour Impact\nProduce high quality technical and professional deliverables for projects and proposals\nApply deep knowledge of engineering techniques across multiple technical functions\nUtilize advanced analytical and design techniques to solve technical problems\nExemplify well-developed advanced experience in electrical discipline\nLead the development of initial electrical system concepts\nPresent complex technical solutions to clients\nManage and coordinate project teams and projects\nDevelop work plans to address technical issues within project time and budget\nWork within multi-discipline project teams to develop drawing and specification documents for issuance to architects, contractors and building owners\nAttend and lead client meetings\nManage and mentor junior staff\nCollaborate and coordinate with internal project discipline team members, equipment vendors and manufacturers\nPerform project management activities including writing proposals, establishing budgets, and managing client interactions\nCoordinate activities concerned with technical development, scheduling, and resolving engineering design issues\nCoordinate the activities of technical staff from project award through project completion\nDesign complex and large electrical medium voltage and low voltage distribution systems and electrical building systems (i.e. general power, lighting, grounding, etc.)\nSurvey and evaluation of existing conditions\nDevelop project specifications\nPerform construction administration\nDevelop and maintain client relationships\nContribute and interact with team, develop and manage high quality technical and professional deliverables on projects and proposals\nParticipate in local professional organization (attend meetings\/lectures), i.e., poster sessions, participate in conference panel\nExercise responsible and ethical decision-making regarding company funds, resources and conduct and adhere to WSP\"s Code of Conduct and related policies and procedures\nProven track record of upholding workplace safety and ability to abide by WSP\"s health, safety and drug\/alcohol and harassment policies\nWho You Are\nThe ideal candidate has familiarity with Building Information Modeling using Revit, has strong communication skills, and an interest in liaising with internal and external design, client and construction team members. Candidate will have previous experience as a lead project electrical engineer capable of directing the project team.\nRequired Qualifications\nBachelor\u201a\u00c4\u00f4s degree in Electrical Engineering or Architectural Engineering with electrical building systems emphasis\n7+ years of experience in designing electrical systems for the high performing, commercial, industrial or mission critical\/data center buildings\nRegistered Professional Engineer (PE)\nExperience mentoring and training others in field\nStrong verbal and written communication skills\nAbility to interact well with others as well as develop and contribute to high quality technical and professional deliverables on projects and proposals\nStrong working knowledge of electrical systems and codes\nAttention to detail, highly organized, self-starter\nParticipate in conference programs including panels, lectures, poster sessions, papers and presentations\nPreferred Qualifications:\nEnhancing credentials (LEED, Uptime ATD, etc.) preferred\nExperience with the analysis and modeling of short circuit coordination and arc flash studies\nMission Critical\/Data Center experience\nExperience with international projects and knowledge of international codes and standards\nAdditional Requirements\nTo perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.\nAdditional Details\nTravel Required: 10%\nJob Status: Regular\nEmployee Type: Full\nPrimary Location: TEMPE - E RIO SALADO PKWY\nAll locations: US-AZ-Phoenix, US-AZ-Tempe, US-AZ-Tucson, US-MO-Creve Coeur, US-MO-St Louis\nAbout WSP\nWSP USA is the U.S. operating company of WSP, one of the world's leading engineering and professional services firms. Dedicated to serving local communities, we are engineers, planners, technical experts, strategic advisors and construction management professionals. WSP USA designs lasting solutions in the buildings, transportation, energy, water and environment markets. With more than 15,000 employees in over 300 offices across the U.S., we partner with our clients to help communities prosper. www.wsp.com\nWSP provides a flexible and agile workplace model while meeting client needs. Employees are also afforded a comprehensive suite of benefits including medical, dental, vision, disability, life, and retirement savings focused on providing health and financial stability throughout the employee\u201a\u00c4\u00f4s career.\nAt WSP, we want to give our employees the challenges they seek to grow their careers and knowledge base. Your daily contributions to your team will be essential in meeting client objectives, goals and challenges. Are you ready to get started?\nWSP USA (and all of its U.S. companies) is an Equal Opportunity Employer Race\/Age\/Color\/Religion\/Sex\/Sexual Orientation\/Gender Identity\/National Origin\/Disability or Protected Veteran Status.\nThe selected candidate must be authorized to work in the United States.\nNOTICE TO THIRD PARTY AGENCIES:\nWSP does not accept unsolicited resumes from recruiters, employment agencies, or other staffing services. Unsolicited resumes include any resume or hiring document sent to WSP in the absence of a signed Service Agreement where WSP has expressly requested recruitment\/staffing services specific to the position at hand. Any unsolicited resumes, including those submitted to hiring managers or other business leaders, will become the property of WSP and WSP will have the right to hire that candidate without reservation \u201a\u00c4\u00ec no fee or other compensation will be owed or paid to the recruiter, employment agency, or other staffing service.\nShow more\nShow less",
      "job_skills":"Revit, Electrical engineering, Building information modeling, LEED, Uptime ATD, Short circuit coordination, Arc flash studies, Mission critical\/data center, Medium voltage distribution, Low voltage distribution, General power, Lighting, Grounding, Fire alarm, Electrical building systems, Power systems, Uninterruptible power systems, Generator plants, Construction management, Microsoft Office Suite, AutoCAD, Project management, Engineering",
      "Category":"Data Science"
  },
  {
      "job_title":"Engineering Analyst",
      "company":"Ellipsis",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/engineering-analyst-at-ellipsis-3772694956",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Company Overview\nEllipsis U.S. Onshore (\"Ellipsis\") is a new division of Westlawn. Westlawn is a private investment firm focused on upstream oil and gas investments, with an initial concentration on North America, Latin America, and the Middle East. In addition to Ellipsis, Westlawn has two further divisions \u201a\u00c4\u00ec Americas Offshore, and Oman.\nEllipsis is currently seeking non-operated working and mineral interests throughout the major onshore US basins.\nWestlawn was formally launched at the end of 2021. Westlawn invests on behalf of multiple families with an investor base that overlaps with Dorilton Capital (https:\/\/doriltongroup.com\/). Dorilton was formed in 2010 and has invested hundreds of millions of dollars into several sectors including healthcare, industrial services, and motorsports. They are currently the owners of the Williams F1 racing team.\nJob Description\nThe Engineering Analyst will be responsible for assisting the technical team in several areas including but not limited to database management, production monitoring, asset management, reserves reporting, LOS analysis, and asset evaluations. They will also act as a liaison between the technical team and the finance team to convert reserve report statements into outputs suitable for corporate level returns models.\nA comprehensive understanding of petroleum economics and associated inputs are required. The successful candidate will be comfortable in a fast-paced environment with changing priorities from a multi-disciplined team and will be expected to adapt to the business needs in various capacities (learning new software, assisting other departments, etc.).\nResponsibilities\nBuild, manage, and manipulate reserves databases in ARIES and Combo Curve to generate cash flow statements, create type wells, and build out full field development models to determine rates of return and economic values of producing assets and new drilling programs\nPerform basin studies to identify activity trends, cost structures, and production characteristics\nBuild and support tools that improve evaluation efficiency\nProduce reserve data, comparisons, and reconciliations to understand asset valuations and changes to valuations over time\nGather, consolidate, and archive drilling, completion, and production data from multiple proprietary and public sources into various formats suitable for analysis and presentation\nUtilize mapping software to track public and private company acreage and acreage transactions, and to generate contour & heat maps based on several data points such as TOC, Phi-h, and production\nResearch public oil and gas records to analyze production and performance drivers within areas of interest\nSearch for and test out latest public data platforms and make recommendations to team concerning data subscriptions\nMaintain daily and monthly production to ensure data is up-to-date and accurate\nRequirements\nBachelor\u201a\u00c4\u00f4s Degree in Math, Science, or Engineering\nMinimum of 5 years of experience in an Engineering Analyst role\nHighly proficient with ARIES, MS Office, and Enverus\nStrong analytical and organizational skills\nSome travel may be required (data rooms, conferences, etc.)\nFlexible to work a variety of hours which could include nights and weekends as business needs dictate\nProven track record of handling multiple projects concurrently under tight deadlines\nAdditional Desired Skills\nAbility to write macros and functions in Excel, Access, and Word\nWorking knowledge of SQL\nWorking knowledge of Spotfire\nCombo Curve experience\nShow more\nShow less",
      "job_skills":"Database management, Production monitoring, Asset management, Reserves reporting, LOS analysis, Asset evaluations, Liaison between technical and finance teams, Data conversion, Petroleum economics, Adaptability, Fastpaced environment, Multidisciplinary team, New software learning, ARIES, Combo Curve, Cash flow statements, Type wells, Full field development models, Investment returns, Economic values, Basin studies, Activity trends, Cost structures, Production characteristics, Evaluation tools, Data reconciliations, Asset valuations, Drilling, Completion, Production data, Data analysis, Data presentation, Mapping software, Acreage tracking, Contour maps, Heat maps, Data points, TOC, Phih, Public oil and gas records, Performance drivers, Data platforms, Excel, Access, Word, Macros, Functions, SQL, Spotfire",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Alpine Solutions Group",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-alpine-solutions-group-3777303108",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"MUST:\n2+ years of very strong with SQL querying\nETL knowledge , we write them in SQL everything runs off of database\nhands on experience with BI tools\nunderstanding with platform maintenance within MYSQL (they are Maria DB in MYSQL)\nability to communicate with the c suite\nexperience building out dashboards and reports, could be within tableau or any other BI tools.\nAbility to help automate manual reporting\/manual data entry\nPLUS:\nMasters in Data Science\nDAY TO DAY:\nOur client in Dallas, a fast growing consulting firm, is looking to hire a BI Analyst to come aboard their team as a full time employee. This position will be hybrid in Dallas and report into the Lead BI Analyst. This person will be helping to set up reporting through a newly selected BI tool (we are looking for this person to help spearhead the selection of that tool and help maintain is at well). We are looking for someone who can help standardize reporting and work to help various departments in the company who still do manual data entry\/manual reporting to automate those processes. This person will play a role in analyzing and transforming the data into insights for our company, and will work cross departmental. Other responsibilities could be: gathering, cleaning, and analyzing data to identify trends, develop dashboards\/reports, monitor KPI\u201a\u00c4\u00f4s, and conduct ad-hoc analysis to support stakeholders as needed.\nShow more\nShow less",
      "job_skills":"SQL, ETL, MySQL, MariaDB, Business Intelligence (BI) tools, Tableau, Data Science, Data analysis, Data transformation, Data visualization, Dashboard creation, Report creation, KPI monitoring, Data entry automation, Data cleaning, Trend identification, Adhoc analysis",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Business Analyst - Salesforce (Hybrid)",
      "company":"Stryker",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-business-analyst-salesforce-hybrid-at-stryker-3755975924",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Why join Stryker?\nWe are proud to be named one of the World\u201a\u00c4\u00f4s Best Workplaces and a Best Workplace for Diversity by Fortune Magazine! Learn more about our award-winning organization by visiting stryker.com\nAs a Senior Business Analyst, you will be responsible for the overall results in planning, requirements gathering, functional design, testing\/validation, and deployment of business sponsored system enhancements, projects, and issue resolutions.\u201a\u00c4\u00d8You will work with CRM Analysts, Subject Matter Experts, and Business Process Owners. You will gather and analyze data to ensure complete documentation of user stories (business requirements) and functional designs to align with defined business ROIs and success criteria.\u201a\u00c4\u00d8 You will also work with IT resources to translate business requirements to functional requirements to design system capabilities, while leveraging best practices.\nWho We Want:\nCollaborative partners.\nPeople who build and leverage cross-functional relationships to bring\ntogether ideas, data and insights to drive continuous improvement in functions.\nDedicated achievers.\nPeople who thrive in a fast-paced environment and will stop at nothing to\nensure a task or project is complete and meets regulations and expectations.\nStrategic thinkers.\nPeople who enjoy analyzing data, can review current state review application designs for the purposes of planning,\nforecasting, advising, budgeting, reporting and requirements gathering.\nWhat You Will Do:\nDeliver system enhancements and projects.\nEnsure the quality and data integrity of operational CRM systems.\nTranslate business requirements into working applications.\nDelivery of data governance and systems administration.\nPartner with CRM Analysts, SMEs, and Business Process Owners to analyze requests and strategize ROI-based prioritizations.\nFocus on Service business processes enabled through our commercial systems.\nCoordinate with IT counterparts on system enhancements and reported incidents \u201a\u00c4\u00ec accountable for timely and accurate delivery.\nAssist with Regression testing and stay connected to divisional and global CRM launches on our shared platform.\nResearch industry analysis around CRM and apply to job functions.\nStay up-to-date on CRM platform upgrades.\nWhat You Need:\nBachelor\u201a\u00c4\u00f4s degree\u201a\u00c4\u00d8in MIS, IT or Business Operations preferred.\nMinimum\u201a\u00c4\u00d82-5\u201a\u00c4\u00d8years of professional experience required.\nTechnical knowledge of Salesforce.com and Service Max; Service Max certification preferred.\nExperience of working in CRM, ERP and Business Applications preferred.\nAbility to work effectively in a matrix organization structure with significant emphasis on collaboration and persuasion, rather than relying entirely on command and control.\nExperience with process mapping preferred.\nDemonstrated ability to understand, evaluate and recommend changes to business processes preferred.\nKnowledge of Agile Development methodologies preferred.\n$65,400.00 - $132,300.00 salary plus bonus eligible + benefits. Actual minimum and maximum may vary based on location. Individual pay is based on skills, experience, and other relevant factors.\nAbout Stryker\nOur benefits:\n12 paid holidays annually\nHealth benefits include: Medical and prescription drug insurance, dental insurance, vision insurance, critical illness insurance, accident insurance, hospital indemnity insurance, personalized healthcare support, wellbeing program and tobacco cessation program.\nFinancial benefits include Health Savings Account (HSA), Flexible Spending Accounts (FSAs), 401(k) plan, Employee Stock Purchase Plan (ESPP), basic life and AD&D insurance, and short-term disability insurance.\nFor a more detailed overview of our benefits or time off, please follow this link to learn more: US Stryker employee benefits\nAbout Stryker\nStryker is one of the world\u201a\u00c4\u00f4s leading medical technology companies and, together with its customers, is driven to make healthcare better. The company offers innovative products and services in Medical and Surgical, Neurotechnology, Orthopaedics and Spine that help improve patient and healthcare outcomes. Alongside its customers around the world, Stryker impacts more than 130 million patients annually. More information is available at stryker.com.\nKnow someone at Stryker?\nBe sure to have them submit you as a referral prior to applying for this position. Learn more about our employee referral program on our referral page\nStryker is driven to work together with our customers to make healthcare better. Employees and new hires in sales and field roles that require access to customer accounts as a function of the job may be required, depending on customer requirements, to obtain various vaccinations as an essential function of their role.\nR508028\nShow more\nShow less",
      "job_skills":"Salesforce.com, Service Max, Agile Development, CRM, ERP, Business Applications, Process Mapping, Data Governance, Systems Administration",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Anblicks",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-anblicks-3728012251",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position: Sr. Data Analyst with Advanced Commercial Banking System experience\nLocation: Dallas, TX ( 2 Days onsite Mandatory - No travel expenses will be paid )\nDuration: 6+ months Contract with possible extensions.\nSummary:\nWe are in process of migrating few loans from\nAdvanced Commercial Banking System (ACBS) to Wall Street Office (WSO)\nPrimary Skills:\nData Analyst \/ Integration , ACBS & WSO.\nCandidate needs to be able to look at existing code \/ mappings and create new mappings .\nCandidate should have experience with data integration project with SQL knowledge and ability to do basic SQL and read and understand SSIS ( to document , no need to code ).\nDetailed \/ Working knowledge of ACBS.\nDetailed \/ Working knowledge of WSO.\nKnowledge of Azure is a plus.\nShow more\nShow less",
      "job_skills":"Data Analyst, ACBS, WSO, SQL, SSIS, Azure",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Analyst- Tableau, Cognos, BI",
      "company":"LTI - Larsen & Toubro Infotech",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-tableau-cognos-bi-at-lti-larsen-toubro-infotech-3772651827",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"About US:\nLTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 750 clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree \u201a\u00c4\u00ee a Larsen & Toubro Group company \u201a\u00c4\u00ee combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com.\nSenior Data Analyst\/ Information Security Application Vulnerability Governance Data Analyst\nLocation: Irving TX\nDuration: Full time\nInformation Security Application Vulnerability Governance Data Analyst will be responsible for analyzing program data from multiple systems and providing insights to the governance team on effectiveness of security controls. To be successful in this role you need to be a strong analytical thinker, understand business requirements and enjoy solving complex problems, build effective visualizations using excel, be a team player and an effective communicator. The overall objective of this role is to capture clear requirements for metrics and ensure data quality for application security metrics\nJob Responsibilities:\n\u00ac\u2211 Design and implement a solution for performance measurements on effectiveness of controls and overall vulnerability assessment program\n\u00ac\u2211 Analyze trends on assets security health posture and report using visualization tools for program review with management and stakeholders\n\u00ac\u2211 Analyze and report aggregated data from multiple data sources\n\u00ac\u2211 Develop data visualization mock-ups for monitoring program data trends\n\u00ac\u2211 Develop reports for tracking program effectiveness and update power point deck for weekly , monthly and quarterly updates\n\u00ac\u2211 Provide timely, accurate, and actionable reporting on application vulnerability activity, trends, service levels, and areas of concern to senior management\n\u00ac\u2211 Streamline and automate report creation and distribution for weekly & monthly reporting\n\u00ac\u2211 Work with the Metrics reporting team to enhance and refine the metrics and key performance indicators reported to senior management and external regulatory agencies\n\u00ac\u2211 Develop User acceptance test plans for testing changes to system enhancements that impact governance and compliance\n\u00ac\u2211 Document business requirements related to system enhancements and submit for reviews and approvals\n\u00ac\u2211 Perform data analysis from multiple systems and assess completeness of data for reporting\n\u00ac\u2211 Ensure data integrity and compliance by performing data audits and data validation checks\n\u00ac\u2211 Performs root cause analysis on metric trends and provide insight to governance team for appropriate refinements to rules\nRequired Skill:\n\u00ac\u2211 At least 3-5 years of strong data analysis and data testing experience\n\u00ac\u2211 Excellent Excel data analysis and Access database skills\n\u00ac\u2211 experience with data analysis leveraging databases like Oracle, SQL Server, Microsoft Access\n\u00ac\u2211 Excellent SQL Skills\n\u00ac\u2211 Experience with issue resolution - ability to research, identify and communicate solutions\n\u00ac\u2211 Excellent documentation skills - Collect, summarize and synthesize information in an auditable format\n\u00ac\u2211 Excellent organization and multi-tasking skills\n\u00ac\u2211 Proven influencing and relationship management skills\nQualifications:\n\u00ac\u2211 Bachelor\u201a\u00c4\u00f4s degree\/University degree or equivalent experience\n\u00ac\u2211 At least 3 years\u201a\u00c4\u00f4 experience with Business Intelligence Reporting tools like Cognos, Tableau\nBenefits\/perks listed below may vary depending on the nature of your employment with LTIMindtree (\u201a\u00c4\u00faLTIM\u201a\u00c4\u00f9):\nBenefits and Perks:\nComprehensive Medical Plan Covering Medical, Dental, Vision\nShort Term and Long-Term Disability Coverage\n401(k) Plan with Company match\nLife Insurance\nVacation Time, Sick Leave, Paid Holidays\nPaid Paternity and Maternity Leave\nThe range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation.\nDisclaimer:\nThe compensation and benefits information provided herein is accurate as of the date of this posting.\nLTIMindtree\nis an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law.\nSafe return to office\n:\nIn order to comply with LTIMindtree\u201a\u00c4\u00f4 s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree\u201a\u00c4\u00f4s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree\u201a\u00c4\u00f4s applicable processes.\nShow more\nShow less",
      "job_skills":"Data analysis, Data testing, Excel, Access database, Oracle, SQL Server, Microsoft Access, SQL, Cognos, Tableau",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst (Hybrid)",
      "company":"BGSF",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-hybrid-at-bgsf-3781102803",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"BGSF is representing a $1.5B private equity backed Manufacturing client in Irving, Texas seeking to hire Data Analyst with experience in Finance, Procurement, Strategic Sourcing, or Data Analysis.\nMajor deliverable is to create reports and conduct analytics for procurement to drive decision making. This will be a task heavy role for a while as the company is working within 13 ERP systems currently as they work towards converting all prior acquisitions to MS Dynamics. The ideal individual will need to be able to roll data up, have eye for detail, and be creative in how to bring data together to make sense. Additionally, candidate should be comfortable getting data from market (company subscribes to several market reports).\nHybrid work model: 4 days in-office \/ 1 day remote option (Friday)\nGreat Culture ~ laid back environment and no micro-management (everyone is accountable)\nIdeal experience is to be data savvy and have strong analytics in Excel, strong math or procurement background, spend management analytics, and cost savings analytics\nQUALIFICATIONS:\nBachelors degree in Business, Finance, Engineering, or Supply Chain\n3+ years in Finance, Procurement, Strategic Sourcing, or Data Analysis\nExperience with financial data analytics, multiple ERP systems, data mining, validations, data manipulation, interpretation & visualization of data\nSolid Excel skills (pivot tables, VBA, H\/VLOOKUP, COUNTIFs, index match\nPower BI required\nBase + Bonus + Benefits\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Analytics, Business Intelligence, Procurement, Strategic Sourcing, Finance, Economics, Statistics, Data Visualization, Data Mining, Data Interpretation, Microsoft Dynamics, Excel, Power BI, Visual Basic for Applications, MySQL, SQL Server, Oracle, SAP, Tableau",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"IDR, Inc.",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-idr-inc-3761131197",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"IDR is seeking a\nData Analyst\nto join one of our top clients for a\nRemote\nposition in\nDallas, TX\n! If you are looking for an opportunity to join a large organization and work within an ever-growing team-oriented culture, please apply today!\nPosition Overview\/Responsibilities For The Data Analyst\nOur client is looking for a Data Analyst to join their team on a long-term opportunity. This person will report to the Director of Analytics & Reporting. Main job duties will include but are not limited to compliance and regulatory reporting. This person will own the ITL\u201a\u00c4\u00f4s and pull reports\/analytics to provide to their clients requests.\nRequired Skills For The Data Analyst\n3-5 years of Data Analyst experience\nBachelor\u201a\u00c4\u00f4s degree in Business Administration, Information Systems, Health Informatics, or related field\nMust be very proficient within SQL\nExcel for reporting\nHands on Experience using Power BI\nComing from a healthcare environment (dealing with health plans, understanding financial side of health plans)\nWhat\u201a\u00c4\u00f4s in it for you?\nCompetitive compensation package\nFully Remote Opportunity\nFull Benefits; Medical, Vision, Dental, and more!\nOpportunity to get in with an industry leading organization\nClose-knit and team-oriented culture\nWhy IDR?\n20+ Years of Proven Industry Experience in 4 major market\nEmployee Stock Ownership Program\nDedicated Engagement Manager who is committed to you and your success\nMedical, Dental, Vision, and Life Insurance\nClearlyRated\u201a\u00c4\u00f4s Best of Staffing\u00ac\u00c6 Client and Talent Award winner 10 years in a row\nShow more\nShow less",
      "job_skills":"Data Analysis, SQL, Excel, Power BI, Healthcare, Health Plans, Business Administration, Information Systems, Health Informatics",
      "Category":"Data Science"
  },
  {
      "job_title":"Entry Level Data Analyst\/Management Consultant - Nationwide (US Based Candidates Only)",
      "company":"Arcadis",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/entry-level-data-analyst-management-consultant-nationwide-us-based-candidates-only-at-arcadis-3701467670",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Arcadis is the world's leading company delivering sustainable design, engineering, and consultancy solutions for natural and built assets.\nWe are more than 36,000 people, in over 70 countries, dedicated to improving quality of life. Everyone has an important role to play. With the power of many curious minds, together we can solve the world\u201a\u00c4\u00f4s most complex challenges and deliver more impact together.\nRole description:\nNote: See below regarding the nature of this position being a prospecting position.\nArcadis is currently seeking Analysts and Junior Management Consultants to join our world-class Business Advisory practice nationwide.\nWe are looking for candidates who want to apply technical know-how, combined with business principles, to the water, wastewater, and stormwater industry. We want dedicated, creative, and energetic candidates interested in tackling challenges and developing sustainable solutions to address water issues like renewal and replacement of aging infrastructure, funding of capital improvements, water supply, workforce retention and development, and emergency preparedness. Collaborating with our experienced consulting professionals, you will support and contribute to project outcomes; interact, and work with clients, and develop your technical capabilities.\nWe are a People First company, industry thought leaders, and drivers and allies of utility innovation.\nOur passion: to Improve Quality of Life.\nOur approach: to delight our clients by developing successful long-term partnerships and supporting them to address existing and emerging challenges.\nArcadis provides multiple onboarding and development programs created for young professionals that support professional growth and help drive creativeness, innovation, and greater integration within our local, National and global teams.\nRole accountabilities:\nWhat will you do?\nAssess, develop, and support a variety of management consultant projects including performing data analytics, financial analysis, operational and organizational assessments, condition assessments, vulnerability, and mitigation assessments, as well as planning and development for utilities, municipalities, and cities\u201a\u00c4\u00f4 (primarily water\/wastewater\/stormwater utilities).\nUtilize strong analytical skills and ability to apply logic to solve problems.\nSupport teams in tasks ranging from general fieldwork to technical office-based analysis.\nAssist in technical writing which may include preparation of technical reports, business development support, presentations, and other audiovisual materials.\nWork independently and as part of a team, with the flexibility to accommodate collaboration with team members across the U.S. and internationally.\nManage multiple concurrent projects with multiple deadlines, ensuring completion per project budgets and timelines.\nWhat skills will you need?\nReliable, client-focused, and capable of working independently under the supervision of project managers.\nExceptional analytical and problem-solving skills, strong attention to detail, organization skills, and work ethic.\nSelf-motivated and team-oriented, with the ability to work successfully both independently and within a team.\nAbility to balance and address new challenges as they arise and an eagerness to take ownership of tasks.\nKnowledge of engineering concepts, theories, and practices related to water\/wastewater\/stormwater.\nDrive to succeed and grow a career in the utility industry\nQualifications & Experience:\nRequired Qualifications:\nMasters of Science degree in Civil or Environmental Engineering, or closely related STEM discipline; or business analytics\/MBA, MS in data science or related business discipline.\nFor those with engineering degrees, ability to obtain the EIT within six months of start date\nPreferred Qualifications:\nPrevious relevant consulting or utility experience, either internship or full-time.\nExperience applying programming languages and analytics to problem-solving is a plus\nSharePoint, Building Information Modeling (BIM), Power BI, Excel, PowerPoint, Visio, Change Management skills, and\/or Augmented Reality experience\nThis is a general job posting and not tied to a specific current open position. Please make sure you create a search agent to be alerted of specific opportunities of interest. Candidates who submit their resume to this posting may be considered for all future openings as they arise.\nWhy Arcadis?\nWe can only achieve our goals when everyone is empowered to be their best. We believe everyone's contribution matters. It\u201a\u00c4\u00f4s why we are pioneering a skills-based approach, where you can harness your unique experience and expertise to carve your career path and maximize the impact we can make together.\nYou\u201a\u00c4\u00f4ll do meaningful work, and no matter what role, you\u201a\u00c4\u00f4ll be helping to deliver sustainable solutions for a more prosperous planet. Make your mark, on your career, your colleagues, your clients, your life and the world around you.\nTogether, we can create a lasting legacy.\nJoin Arcadis. Create a Legacy.\nOur Commitment to Equality, Diversity, Inclusion & Belonging\nWe want you to be able to bring your best self to work every day which is why we take equality and inclusion seriously and hold ourselves to account for our actions. Our ambition is to be an employer of choice and provide a great place to work for all our people. We are an equal opportunity and affirmative action employer. Women, minorities, people with disabilities and veterans are strongly encouraged to apply. We are dedicated to a policy of non-discrimination in employment on any basis including race, creed, color, religion, national origin, sex, age, disability, marital status, sexual orientation, gender identity, citizenship status, disability, veteran status, or any other basis prohibited by law.\nArcadis offers benefits for full time and part time positions. These benefits include medical, dental, and vision, EAP, 401K, STD, LTD, AD&D, life insurance, paid parental leave, reward & recognition program and optional benefits including wellbeing benefits, adoption assistance and tuition reimbursement. We offer seven paid holidays and potentially up to two floating holidays per calendar year depending on start date, and 15 days PTO that accrue per year. The salary range for this position is $52000 - 89700 \/ year.\n#ANACollege\nShow more\nShow less",
      "job_skills":"Data analytics, Financial analysis, Operational and organizational assessments, Condition assessments, Vulnerability and mitigation assessments, Planning and development, Analytical skills, Problemsolving skills, Attention to detail, Organization skills, Work ethic, Selfmotivated, Teamoriented, Time management, Communication skills, Engineering concepts, Civil engineering, Environmental engineering, STEM, Business analytics, MBA, Data science, Programming languages, SharePoint, Building Information Modeling (BIM), Power BI, Excel, PowerPoint, Visio, Change Management, Augmented Reality",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst, Data and Analysis",
      "company":"Digitas North America",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-data-and-analysis-at-digitas-north-america-3784406973",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Digitas is the Networked Experience Agency, built on the vision that we create magnetic experiences that earn the right for brands to exist in human networks. Today, and tomorrow. We deliver Networked Experiences by leveraging comprehensive data, technology, creative, media and strategy capabilities. Digitas delivers ambitious outcomes via unique solutions that include Creative Experiences, Integrated Media, Addressable Relationships, Social Marketing and Total Commerce. Celebrated by Ad Age as Data and Insights Agency of the Year, U.S Campaign\u201a\u00c4\u00f4s Brand Experience Agency of the Year, Media Network of the Year and celebrated by Forrester and Gartner, Digitas serves the world\u201a\u00c4\u00f4s leading brands through a global network comprised of more than 5,500 employees across over 65 offices in 43 countries.\nJob Description\nThe Data & Analysis team uses data-driven insights to fuel strategic growth for clients. We believe that data should never exist in a vacuum; instead, it should be put to work to bring the best ideas and stories to our clients.\nTo help with this, we\u201a\u00c4\u00f4re looking for an outstanding Senior Analyst\n\u201a\u00c4\u00ec someone who can analyze massive data sets, make insightful cross-channel recommendations, and communicate strategic ideas to clients. Sound like you? Read on.\nJob Responsibilities:\nAs a Senior Analyst,\nyou\u201a\u00c4\u00f4ll build the strategic and tactical foundation for data-driven marketing efforts. You\u201a\u00c4\u00f4ll work to achieve client goals through brand and acquisition campaigns, site optimization, and\/or online testing strategy.\nDay-to-day, your role includes:\nInstituting frameworks across project and campaign lifecycles, including measurement plans, primary and secondary research, and performance reporting\nDiving into large data sets, uncovering insights, and providing impactful recommendations to clients\nConnecting the dots across channels through data (including display media, site, search, email, and social) to provide a holistic view of marketing efforts\nCommunicating with clients regularly on scheduled deliverables and ad-hoc requests\nCollaborating with internal teams and external partners to drive success for client\u201a\u00c4\u00f4s business goals\nQualifications\nWe\u201a\u00c4\u00f4re looking for strong, impactful work experience, which typically includes:\n3-5 years of experience in analytics or strategy\nPassion for digital marketing and emerging trends in the digital landscape\nExperience communicating with internal and external stakeholders at a variety of levels\nFluency with Excel (including pivot tables and vlookups) and\/or other data analysis tools such as SQL or Tableau\nComfortable in a fast-paced and deadline-driven environment\nAdditional Information\nThe Power of One starts with our people! To do powerful things, we offer powerful resources. Our best-in-class wellness and benefits offerings include:\nPaid Family Care for parents and caregivers for 12 weeks or more\nMonetary assistance and support for Adoption, Surrogacy and Fertility\nMonetary assistance and support for pet adoption\nEmployee Assistance Programs and Health\/Wellness\/Comfort reimbursements to help you invest in your future and work\/life balance\nTuition Assistance\nPaid time off that includes Flexible Time off Vacation, Annual Sick Days, Volunteer Days, Holiday and Identity days, and more\nMatching Gifts programs\nFlexible working arrangements\n\u201a\u00c4\u00f2Work Your World\u201a\u00c4\u00f4 Program encouraging employees to work from anywhere Publicis Groupe has an office for up to 6 weeks a year (based upon eligibility)\nBusiness Resource Groups that support multiple affinities and alliances\nThe benefits offerings listed are available to eligible U.S. Based employees, are reviewed on an annual basis, and are governed by the terms of the applicable plan documents.\nDigitas is an Equal Opportunity Employer. Our employment decisions are made without regard to actual or perceived race, color,ethnicity, religion, creed, sex, sexual orientation, gender, gender identity, gender expression, pregnancy, childbirth and related medical conditions, national origin, ancestry, citizenship status, age, disability, medical condition as defined by applicable state law, genetic information, marital status, military service and veteran status, or any other characteristic protected by applicable federal, state or local laws and ordinances.\nAll your information will be kept confidential according to EEO guidelines.\nShow more\nShow less",
      "job_skills":"Data analysis, SQL, Tableau, Excel, Marketing, Datadriven insights, Measurement plans, Primary and secondary research, Performance reporting, Display media, Site, Search, Email, Social, Data visualization, Communication, Collaboration, Teamwork, Problem solving, Analytical thinking, Strategic planning, Project management, Deadlinedriven environment",
      "Category":"Data Science"
  },
  {
      "job_title":"BI Analyst",
      "company":"European Wax Center",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/bi-analyst-at-european-wax-center-3763132915",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Perks & Benefits\nRemote-First Workplace\nFlexible Fridays\nDiversity, Equity & Inclusion Council\nMonthly Remote Stipend\nProfessional Development Stipend (up to $500 annually)\n1 Wellness\/Mental Health Paid Day Off\n1 Volunteer Paid Day Off\nHealth Benefits (Medical, Dental, Vision)\nHDHP with HSA plan (annual employer contribution to HSA)\nEmployer-Paid Basic Life Insurance and AD&D\nEmployer-Paid Short- and Long-term Disability\nEmployer-Paid Wellness Reward Program\nEmployer-Paid Mental Health Benefit\nEmployer-Paid Employee Assistance Program\nEmployer-Paid Out of State Medical Travel Benefit\n401(k) Safe-Harbor Matching\nAncillary Benefits (pet insurance, legal coverage, identity theft protection, accident, hospital, and critical illness coverages)\nPaid Time Off (increases with tenure)\nPaid Parental, Adoption, and Foster Leave\nOut of State Medical Travel Benefit\nAbout The Role\nThe BI Analyst plays a crucial role in analyzing business data, creating reports, and developing dashboards that help make data-driven decisions.\nA Day in the Life\nMake a significant impact on our business decisions by providing valuable insights through data analysis of large datasets.\nCollaborate with various departments within the company to identify and analyze areas of potential revenue growth.\nProvide analytical insights (quantitative and qualitative) from internal and external datasets to support business function decisions.\nDevelop and maintain KPIs, scheduled reports, dashboards and reporting for data integrity.\nClearly and precisely present complex information and viable recommendations to stakeholders, including the C-Suite; translate data into actionable insights.\nCollect and analyze large datasets to identify trends, patterns, and insights to drive business objectives.\nDevelop and implement statistical models to solve business problems.\nCollaborate with relevant EWC departments to understand their data needs, provide recommendations to improve processes, and drive growth with data-based decision-making.\nIdentify opportunities to implement predictive analytics and machine learning algorithms to drive decision-making.\nDevelop and implement research methodologies to inform\/enhance data-driven business decisions.\nStay up-to-date on industry best practices and emerging trends in analytics and data science.\nWhat Sets You Apart\nStrong written and verbal communication skills.\nSelf-starter with a proven ability to facilitate corporate data-driven decision capabilities using effective data visualization techniques.\nStrong analytical and problem-solving skills.\nStrong attention to detail and ability to work with large data sets and experience visualizing them.\nAbility to investigate data to explain anomalies, troubleshoot issues and partner with the business teams as needed.\nDemonstrated ability to manage analytical projects from requirement gathering to presentation and reporting.\nAbility to manage multiple projects and meet deadlines in a fast-paced environment.\nKnowledge of statistical analysis techniques and how to apply them to large datasets.\nKnowledge of earned value management, cost-benefit, what-if, project performance, and business project analysis.\nExcellent communication and collaboration skills with the ability to translate complex data insights into actionable recommendations, plus has the ability to translate technical concepts to both technical and non-technical audiences.\nEducation And Experience\nBachelor's degree in a quantitative field (e.g., statistics, economics, mathematics, computer science, information mgmt.., etc.)\n3+ years of proven proficiency in data visualization tools (e.g. Domo, Tableau, Power BI, Looker); creating impactful dashboards\n3+ years of retail or service-base Franchise data analysis\nEuropean Wax Center is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, protected veteran status, or any other characteristic protected by law.\nThis job description is a general description of essential job functions. It is not intended to describe all duties someone in this position may perform. All employees of EWC and operating subsidiaries are expected to perform tasks as assigned by supervisory\/management personnel, regardless of job title or routine job duties.\nShow more\nShow less",
      "job_skills":"Data Analysis, Business Intelligence, Data Visualization, Dashboard Creation, Reporting, DataDriven Decision Making, Statistical Analysis, Earned Value Management, CostBenefit Analysis, Project Performance Analysis, Domo, Tableau, Power BI, Looker",
      "Category":"Data Science"
  },
  {
      "job_title":"Statistical Analyst I",
      "company":"Medpace",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/statistical-analyst-i-at-medpace-3747761107",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nWrite statistical programs for use in creating analysis datasets, tables, listings, and figures;\nReview analysis plans for appropriate methods;\nProgram study analyses and review study results; and\nCommunicate the project requirements for cleanup and data capture to ensure the key study variables are suitable for analysis.\nQualifications\nMaster\u201a\u00c4\u00f4s Degree in Statistics\/Biostatistics required\nSAS and \/ or statistical programming experience;\nKnowledge of databases and data management process; and\nKnowledge of statistical methods commonly used in pharmaceutical clinical trials.\nTravel:\nMinimal\nMedpace Overview\nMedpace is a full-service clinical contract research organization (CRO). We provide Phase I-IV clinical development services to the biotechnology, pharmaceutical and medical device industries. Our mission is to accelerate the global development of safe and effective medical therapeutics through its scientific and disciplined approach. We leverage local regulatory and therapeutic expertise across all major areas including oncology, cardiology, metabolic disease, endocrinology, central nervous system, anti-viral and anti-infective. Headquartered in Cincinnati, Ohio, employing more than 5,000 people across 40+ countries.\nWhy Medpace?\nPeople. Purpose. Passion. Make a Difference Tomorrow. Join Us Today.\nThe work we\u201a\u00c4\u00f4ve done over the past 30+ years has positively impacted the lives of countless patients and families who face hundreds of diseases across all key therapeutic areas. The work we do today will improve the lives of people living with illness and disease in the future.\nDallas Perks\nDallas Campus Overview\nHybrid work-from-home options (dependent upon position and level)\nCompetitive PTO packages, starting at 20+ days\nFlexible work hours\nCompany-sponsored employee appreciation events\nEmployee health and wellness initiatives\nCompetitive compensation and benefits package\nStructured career paths with opportunities for professional growth\nAnnual bonus and merit programs\nDiscounts on local sports games, local fitness gyms and attractions\nFree on-site parking\n10 Balconies with Outdoor seating\n45,000+ sq ft newly remodeled office\nAwards\nRecognized by Forbes as one of America's Best Mid-size Companies in 2021, 2022 and 2023\nContinually recognized with CRO Leadership Awards from Life Science Leader magazine based on expertise, quality, capabilities, reliability, and compatibility\nWhat To Expect Next\nA Medpace team member will review your qualifications and, if interested, you will be contacted with details for next steps.\nEO\/AA Employer M\/F\/Disability\/Vets\nShow more\nShow less",
      "job_skills":"SAS, Statistics, Data management, Clinical trials, Statistical methods, Databases, Data capture, Data analysis",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst Assoc Manager - Enterprise Data Foundation",
      "company":"PepsiCo",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-assoc-manager-enterprise-data-foundation-at-pepsico-3779719084",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Overview\nWe Are PepsiCo\nJoin PepsiCo and dare to transform! We are the perfect place for curious people, thinkers and change agents. From leadership to front lines, we're excited about the future and working together to make the world a better place.\nBeing part of PepsiCo means being part of one of the largest food and beverage companies in the world, with our iconic brands consumed more than a billion times a day in more than 200 countries.\nIn PepsiCo Mexico is one of the most important consumer products companies in the country. Our product portfolio, which includes 22 of the world's most iconic brands, such as Sabritas, Gamesa, Quaker, Pepsi, Gatorade and Sonrics, has been a part of Mexican homes for more than 116 years.\nA career at PepsiCo means working in a culture where all people are welcome. Here, you can dare to be you. No matter who you are, where you're from, or who you love, you can always influence the people around you and make a positive impact in the world.\nResponsibilities\nAs a member of the data engineering team, you will be the key domain & data expert overseeing PepsiCo's business process in the Supplier Data Domain. You will help identify, define, analyze & prioritize consumer data very closely together with business leads, digital program leads, IT and our data engineering team. You'll develop an in-depth understanding of relevant Consumer business processes and translate business requirements to the data engineering team in a technical way.\nAs Sr Data Analyst - Enterprise Data Foundation your scope would consist of:\nDiscover, analyze, and scope data requirements & representing them in conceptual and logical data models.\nGather and analyze data pertaining to supplier data topics, spanning procurement, supplier , spend , commodity etc.\nCreate high-level process models (system interface diagrams, workflow & swim lane diagrams, data flow diagrams) to represent processes for the area under analysis.\nEmpower the business by creating value through the increased adoption of data, data science and business intelligence landscape.\nResponsible to improve the quality of data in relation to defined expectations.\nPerform analysis of system data to identify patterns, exceptions, and erroneous data\nQualifications\nEducation\nBachelor\u201a\u00c4\u00f4s Degree in Computer Science\/Operations Management\/Sustainability Studies, Masters Preferred.\nExperience\n6+ years of experience with data analysis & data profiling in project, business requirements definition or data engineering in CPG or Manufacturing Industry.\n4+ years of strong Data Profiling experience & ability to identify trends and anomalies in the data to in-form data model build out.\n3+ years\u201a\u00c4\u00f4 work experience in the areas of supplier data topics, spanning procurement, supplier , spend , commodity etc.\nExperience working with structured\/unstructured datasets, ability to clearly document and communicate requirement to technical team members.\nA strong candidate will have proficient knowledge on 3-5 of the tools listed below. The list is indicative and not exhaustive.\nBusiness Process Modelling: Visio, Celonis, UML\nData Profiling: OpenRefine, Informatica, Ataccama, Apache Griffin, Talend, IBM InfoSphere, SAP BODS\nBusiness Intelligence: Power BI, Tableau, Cognos, SAP BI, ORACLE BI, Qlik\nSQL: PostgreSQL, Azure SQL, PgAdmin, Oracle SQL Developer, Microsoft SQL, Datapine SQL Editor, Adminer\nStrong Excel and\/or Access skills\nCompetencies\nStrong knowledge and understanding of supplier data elements and processes per the necessary in-scope data domain\nAbility to translate business requirements into critical data dependencies and requirements\nAble to challenge and align various stakeholders to a common set of standards\nSelf-starter with excellent written & verbal communication skills.\nSelf-learner and eager to understand data, business processes, concepts, and technologies.\nEEO Statement\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.\nPepsiCo is an Equal Opportunity Employer: Female \/ Minority \/ Disability \/ Protected Veteran \/ Sexual Orientation \/ Gender Identity\nIf you'd like more information about your EEO rights as an applicant under the law, please download the availableEEO is the Law&EEO is the Law Supplementdocuments. ViewPepsiCo EEO Policy.\nPlease view ourPay Transparency Statement\nShow more\nShow less",
      "job_skills":"Visio, Celonis, UML, OpenRefine, Informatica, Ataccama, Apache Griffin, Talend, IBM InfoSphere, SAP BODS, Power BI, Tableau, Cognos, SAP BI, ORACLE BI, Qlik, PostgreSQL, Azure SQL, PgAdmin, Oracle SQL Developer, Microsoft SQL, Datapine SQL Editor, Adminer, Excel, Access, SQL, Supplier data, Data analysis, Data profiling, Data modelling, Data engineering",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"ALTEN",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-alten-3648000405",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Location: Dallas, TX (Onsite so need only location Candidate)\nJob Description:\nBasic Qualifications:\nAbility to complete tasks in a high-pressure environment.\nExcellent inter-personal and communication skills, both verbal and in writing\nExperience with enterprise information management, such as data modeling, data governance, reference data management, master data management, meta data management, data integration, etc\n.\nCritical thinking, problem solving, comfortable in making judgement call and able to clearly articulate the tradeoffs in proposed architecture design and solution.\nProficient\nwith Databases and writing SQL queries\nagainst SQL server 2012, Oracle 11i, Postgres, MySQL.\nKnowledge of application lifecycle, design\/design patterns, tools, and methodologies.\nProven ability to work with software engineering teams and understand complex development systems, environments, and patterns.\nExperience with Word, Excel, SharePoint, JIRA, Confluence, SOAP UI, JMeter, Postman is desired.\nProficient in integration development using REST\/SOAP APIs, and asynchronous integrations leveraging Messaging patterns with Apache Kafka\/Active MQ\/IBM MQ.\nMust have good understanding of XML\/JSON\/CSV data structures.\nExperience with Agile software development processes and the development life cycle\nExperience with SOA and Micro services Architecture is preferrable.\nKnowledge of ELK stack is desired.\nUnderstanding of Cloud patterns is a bonus.\nKey Responsibilities\n:\nAnalyze business and user needs, documenting requirements, and revising existing system logic difficulties.\nIdentify and document business rules, dependencies, assumptions, risks, supportability, performance, and training needs.\nCreate Integration technical design documents which includes process flow\/sequence diagrams, entity transformation mapping definitions (JSON, XML, CSV) and documentation for the engineering teams to be able to build.\nFacilitate application onboarding process, understand the technical challenges, and propose an optimal solution.\nCollaborate with Solution architects and engineering team to implement the solution following design principles.\nIntegrate multiple applications with middleware and derive mappings from source and target applications, using multiple technologies.\nProvide end user support for integration projects and translate needs into developing test plans.\nThis includes a coordinated effort with stakeholders by participating\/facilitating User Acceptance Testing for application signoff.\nCreate test plans, including definition of testing requirements; testing criteria, test data, scripts, user acceptance conditions and end-to end test requirements.\nFacilitate load and performance tests for applications.\nAct as a subject matter expert for integration customers, and answer queries for integrating applications, end users, developers, and architects.\nPerforms the investigation and resolution of complex and critical data integration issues in the production environment.\nWork with Product Managers and Scrum Master to estimate, design, and build efficient, long term business applications utilizing standards.\nBreak down tasks, estimate effort, identify, and raise blockers, issues, and risks.\nGenerate tables and\/or charts in excel to present meaningful data.\nAdhere to security, compliance and best-practices guidelines\nEducation & Experience:\nTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and\/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\nUniversity degree in Computer Science, Computer Engineering, Information technology or related field or relevant experience.\nAt least 10 years' experience in analysis, integration design involving P2P, E-Invoicing, CMMS & ERPs.\nRequirements Engineering, Project Management courses will be preferred.\nConsideration given to equivalent combination of education and experience.\nShow more\nShow less",
      "job_skills":"SQL, Oracle, Postgres, MySQL, SOAP, JMeter, Postman, REST\/SOAP APIs, Apache Kafka, Active MQ, IBM MQ, XML, JSON, CSV, ELK stack, Agile, SOA, Micro services",
      "Category":"Data Science"
  },
  {
      "job_title":"Data & Integration Analyst",
      "company":"Maxor National Pharmacy Services, LLC",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-integration-analyst-at-maxor-national-pharmacy-services-llc-3787392018",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Overview\nThe\nData & Integration Analyst\nis responsible for implementing, supporting, and maintaining inbound\/outbound data file exchanges. Enable and integrate clients and 3 rd party vendors onto Maxor\u201a\u00c4\u00f4s PBM platform. Assist in documenting and creating efficient\/automated solutions to promote operational capability while also improving client data integrity. Reporting to the Sr. Director of Eligibility and Accumulators the Data & Integration Analyst will meet all service standards to ensure client satisfaction.\nPosition Location\nThis is a remote-based position.\nOur Company\nWe're Maxor and we're building a different kind of pharmacy company. We're transforming the pharmacy industry to create healthier lives through purposeful engagement across Pharmacy Benefit Management, Pharmacy Management, Specialty Pharmacy, 340B, Rebate and Formulary Management, and Pharmacies. We put people first and are committed to providing outstanding service across all aspects of our business. We believe there's a better way to deliver pharmacy and healthcare services to people across the country, and we'd love for you to help us do it.\nOur Locations\nThe Maxor workforce brings robust experience, diverse perspectives and passion from over 1,000 employees working all over the US in pharmacies, hospitals, home offices, or corporate offices.\nResponsibilities\nSupport new and existing clients through implementation\/conversion\/integration processes working directly with clients, account managers and implementation teams though full data-life-cycle development.\nServe as a Subject Matter Expert (SME) on integration points with Maxor\u201a\u00c4\u00f4s PBM platform, application, file integration functions\/standards and back end data models.\nExecute advanced\/dynamic SQL scripts to generate flat files or reports to support backend file processing, reconciliation analysis, and internal\/external reporting.\nReview, analyze, and implement complex file mappings and data conversions to support standard and custom file integrations between Maxor and our clients.\nPlan, document, implement new or improved automated\/ETL solutions\nConduct system testing of new features, integrations and backend features\nWith a focus on quality and timeliness, maintain ownership for assigned goals\nEnsure quality, service level, productivity and customer standards are consistently met.\nHandle routine work stream assignments along with, but not limited to, member and file research, assisting with file processing\/data analysis, advise\/consult with our internal teams and clients\nComply with Maxor\u201a\u00c4\u00f4s Ethical Business Conduct policy and Maxor\u201a\u00c4\u00f4s Compliance Program.\nComplete required training, as assigned, within the established timeframes.\nMust be able to cope with the mental and emotional stress of the position.\nPromote teamwork and best practices\nMaintain regular attendance in accordance with established policies.\nPerform other job-related duties as assigned.\nQualifications\nEducation:\nBachelor\u201a\u00c4\u00f4s Degree in business, computer science, operations, engineering or related field required.\nExperience:\nExperience in data cleansing\/mapping\/formatting, ETL frameworks, and\/or database relational models. Previous experience with health care enrollment\/eligibility\/accumulator fundamentals and Pharmacy Benefits Managers (PBMs) data\/file\nExchange\/integration Experience Preferred.\nKnowledge, Skills, and Abilities:\n5+ years of experience in data exchange, integration, ETL frameworks, data visualization and\/or relational database models\/design.\n5+ years of experience as Data\/Integration\/EDI Analyst with relevant PBM\/Heath Benefit\/Health IT experience.\nStrong business acumen with healthcare and pharmacy benefit management industry knowledge preferred.\nA desire to problem solve, think critically, analyze and interpret data.\nWillingness to solution across business and technical domains.\nAbility to identify assumptions, be inquisitive and reach conclusions.\nAbility to communicate, document, share and acquire knowledge.\nAbility to adapt, continuously improve, enjoy building new tools and process.\nProven ability to develop effective working relationships with internal and external stakeholders.\nMotivated by goal oriented delivery, ability to understand overall business objectives and drive towards results.\nWHY CHOOSE A CAREER AT MAXOR?\nDid you know that patients see their pharmacist an average of 12 times a year? Pharmacy is at the heart of healthcare. Come join Maxor and make a direct impact on patients\u201a\u00c4\u00f4 lives. Improve your own wellbeing with our robust benefits and flexible work environment. At Maxor, you have a career with limitless possibilities and the charge to make a difference. A company of 1,000 diverse people and almost 100 years of pharmacy experience, we offer the stability of a Fortune 500 company with the energy and innovation of a startup. We provide services and technology that fuel the entire pharmacy ecosystem, but we are more than pharmacy services. We enable pharmacy care .\nWE OFFER\n: A diverse, progressive culture that supports a \u201a\u00c4\u00fadress for your day\u201a\u00c4\u00f9 attire and a collaborative, team oriented environment. Our industry leading compensation and health benefits include:\nComprehensive mental health and wellbeing resources\nNationwide Blue Cross Blue Shield PPO with employee friendly plan design, including $850 individual annual medical deductible, $25 office visit copays, Low biweekly premiums\nCompany paid basic life\/AD&D, Short-term and Long-term disability insurance\nRx, dental, vision, short-term disability, and FSA\nEmployer-matched 401k Plan\nIndustry leading PTO plan\nAnd MORE!\nApply today at :\nhttps:\/\/careers-maxor.icims.com\/\nMaxor is an EOE, including disability\/vets\nShow more\nShow less",
      "job_skills":"Data Integration, SQL, ETL frameworks, Data visualization, Relational database models, Data cleansing, Data mapping, Data formatting, Health care enrollment, Eligibility, Accumulators, Pharmacy Benefits Managers (PBMs), EDI",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Data Analyst",
      "company":"Aston Carter",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-aston-carter-3790547635",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Description:*\nEssential Job Functions:*\nSupport clients: Work and communicate closely with their clients throughout the report\/dashboard development process. Provide status updates. Help clients understand their report\/dashboard. Provide on-going maintenance and support.\nSupport projects: Participate in outcome evaluation, program evaluation, and quality improvement studies. Attend meetings, answer data-related questions, and offer suggestions.\nCreate reports and dashboards: Create ad-hoc and routine reports. Design and develop dashboards to display key metrics and trends.\nManage data: Collect, organize, store, and share a wide variety of data.\nTransform data: Clean and optimize data for analyses.\nEnsure data quality: Audit data, data transformation processes, workflow, deliverables and outputs.\nPerform analyses: Perform statistical analyses (descriptive and inferential analyses).\nPresent findings: Present data and findings in a clear and concise manner, using appropriate reporting and data visualization tools.\nCreate and maintain documentation: Create FDD, document report requirement, business logic and workflow. Create data dictionaries. Ensure documentation is up-to-date.\nMaintain up-to-date knowledge on information management systems, processes and data.\nManage compliance reporting: Maintain up-to-date knowledge of CMS, DHCS and internal compliance reporting requirement. Translate reporting requirement into reports. Work with clients to ensure accuracy of data. Submit report to external and internal agencies in a timely manner. Attend compliance trainings, meetings, and data validation webinars.\nSupport system enhancement\/implementation: Perform data-related research and testing. Stay informed of system and process changes. Identify impact on existing reports and dashboards. Modify existing reports and dashboards accordingly.\nPrioritize work and keep supervisor informed: Work on multiple projects at the same time. Organize and prioritize work effectively. Inform management when requirement or due date cannot be met.\nAdheres to all quality, compliance and regulatory standards to achieve organization outcomes.\nRequired Education: *\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Analytics, Healthcare Informatics, Statistics, Computer Science, or related field.\nRequired Experience:*\nAt least 5 years of experience analyzing and compiling data, preferably in a health plan setting.\nRequired Skills\/Abilities:*\nAbility to manipulate and analyze data to produce accurate results. Present results in data visualizations, dashboards, and reports.\nKnowledge in CMS Medicare Advantage (Part C), CMS Prescription Drug Coverage (Part D), and CMS Special Needs Plan (SNP), and DHCS Medi-Cal Managed Care reporting requirements.\nKnowledge in authorization, claims, and encounter data. Clinical code knowledge (ICD, CPT, etc) related to utilization data.\nAdvanced skills in Microsoft Office, SQL Transactional SQL (T-SQL), SQL Server Reporting Services (SSRS), and Tableau.\nExperience in SQL Server Integration Services (SSIS), Visual Basic for Applications (VBA).\nMust have analytical, communication, documentation, interpersonal, planning, presentation, problem-solving and research skills.\nAbout Aston Carter:\nPlease Note: Scammers are posing as Aston Carter. We'll never contact you via Gmail, Telegram, or WhatsApp and we'll never solicit money from you.\nAt Aston Carter, we\u201a\u00c4\u00f4re dedicated to expanding career opportunities for the skilled professionals who power our business. Our success is driven by the talented, motivated people who join our team across a range of positions \u201a\u00c4\u00ec from recruiting, sales and delivery to corporate roles. As part of our team, employees have the opportunity for long-term career success, where hard work is rewarded and the potential for growth is limitless. Established in 1997, Aston Carter is a leading staffing and consulting firm, providing high-caliber talent and premium services to more than 7,000 companies across North America. Spanning four continents and more than 200 offices, we extend our clients\u201a\u00c4\u00f4 capabilities by seeking solvers and delivering solutions to address today\u201a\u00c4\u00f4s workforce challenges. For organizations looking for innovative solutions shaped by critical-thinking professionals, visit [AstonCarter.com.](AstonCarter.com) Aston Carter is a company within Allegis Group, a global leader in talent solutions. The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law. If you would like to request a reasonable accommodation, such as the modification or adjustment of the job application process or interviewing process due to a disability, please call 888-237-6835 or email [astoncarteraccommodation@astoncarter.com](mailto:%20astoncarteraccommodation@astoncarter.com) for other accommodation options. However, if you have questions about this position, please contact the Recruiter located at the bottom of the job posting. The Recruiter is the sole point of contact for questions about this position.\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Visualization, Tableau, Data Manipulation, Data Cleaning, Data Analysis, Statistical Analysis, SQL, TSQL, SSRS, SQL Server Integration Services, Visual Basic for Applications, Microsoft Office, Programming, CMS Medicare Advantage, CMS Prescription Drug Coverage, CMS Special Needs Plan, DHCS MediCal Managed Care, Authorization Data, Claims Data, Encounter Data, Clinical Code Knowledge, ICD, CPT, Reporting, Dashboard Creation, Data Transformation, Data Quality Assurance, Compliance Reporting, FDD Creation, Data Dictionary Creation, Documentation, Communication, Documentation, Interpersonal Skills, Planning, Presentation, ProblemSolving, Research Skills, SQL Transactional SQL",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Data Analyst \/ Medical Coder (Medical Policies\/Regulations) - REMOTE in CA",
      "company":"RemoteWorker US",
      "job_location":"Garland, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-medical-coder-medical-policies-regulations-remote-in-ca-at-remoteworker-us-3783422233",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"JOB DESCRIPTION Job Summary Designs and implements processes and solutions associated with a wide variety of data sets used for data\/text mining, analysis, modeling, and predicting to enable informed business decisions. Gains insight into key business problems and deliverables by applying statistical analysis techniques to examine structured and unstructured data from multiple disparate sources. Collaborates across departments and with customers to define requirements and understand business problems. Uses advanced mathematical, statistical, querying, and reporting methods to develop solutions. Develops information tools, algorithms, dashboards, and queries to monitor and improve business performance. Creates solutions from initial concept to fully tested production and communicates results to a broad range of audiences. Effectively uses current and emerging technologies. KNOWLEDGE\/SKILLS\/ABILITIES With limited supervision, the Sr. Analyst, Data is responsible for data compilation, data management, data analysis, and reporting. Extracts and compiles various sources of information and large data sets from various systems or applications. Set up process for monitoring, tracking and trending information and data using various systems or applications. Prepares well-organized, easily understood reports, analysis, and summary of findings for use by management. Assists in preparation of regularly produced reports to support executive decision-making. Researches and analyze report results identifying opportunities and trends. Works with internal, external and enterprise individuals as needed to research, develop, and document new standard reports or processes. Consolidates data from multiple sources, using industry-based tools or manually; able to process data effectively using Microsoft Excel. Supports management and other team members as requested on all things data related. JOB QUALIFICATIONS Required Education Associate degree or equivalent combination of education and experience Required Experience 3-5 years Preferred Education Bachelor's Degree or equivalent combination of education and experience Preferred Experience 5-7 years Experience with Medical Policies, Regulatory Guidelines, Medical Coding, Payment Integrity and All Plan Letters. Strong Excel - VLOOKUP, Pivot Tables. Basic SQL skills - SQL queries. CPC certification . Strong communication skills. To all current Molina employees: If you are interested in applying for this position, please apply through the intranet job listing. Molina Healthcare offers a competitive benefits and compensation package. Molina Healthcare is an Equal Opportunity Employer (EOE) M\/F\/D\/V. Pay Range: $69,477 - $135,480 a year* *Actual compensation may vary from posting based on geographic location, work experience, education and\/or skill level.\nShow more\nShow less",
      "job_skills":"Data Mining, Data Analysis, Data Modeling, Statistical Analysis, Business Intelligence, Decision Making, Data Compilation, Data Management, Data Reporting, SQL, Microsoft Excel, VLOOKUP, Pivot Tables, CPC certification, Communication skills, Medical Policies, Regulatory Guidelines, Medical Coding, Payment Integrity, All Plan Letters",
      "Category":"Data Science"
  },
  {
      "job_title":"Hybrid Work - Need Sr. Data Analyst in Dallas TX - 10+ years experienced only",
      "company":"Steneral Consulting",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/hybrid-work-need-sr-data-analyst-in-dallas-tx-10%2B-years-experienced-only-at-steneral-consulting-3691183672",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job:\nSr. Data Analyst\nLocation:\nDallas, TX 75202 hybrid onsite 1-2 days\/week\nTerm:\n6+ mos. (high probability to extend)\nSenior Data Analyst\nPrimary responsibilities of the Senior Data Analyst include supporting and analyzing data anomalies for multiple environments including but not limited to\nData Warehouse, ODS, Data Replication\/ETL Data Management\ninitiatives. The candidate will be in a supporting role and will work closely with Business, DBA, ETL and Data Management teams providing analysis and support for complex Data related initiatives. This individual will also be responsible for assisting in initial setup and on-going documentation\/configuration related to\nData Governance and Master Data Management\nsolutions. This candidate must have a passion for data, along with good SQL, analytical and communication skills.\nResponsibilities\nInvestigate and Analyze data anomalies and data issues reported by Business\nWork with ETL, Replication and DBA teams to determine data transformations, data movement and derivations and document accordingly\nWork with support teams to ensure consistent and pro-active support methodologies are adhered to for all aspects of data movements and data transformations\nAssist in break fix and production validation as it relates to data derivations, replication and structures\nAssist in configuration and on-going setup of Data Virtualization tool\nAssist in keeping documentation up to date as it relates to Data Standardization definitions, Data Dictionary and Data Lineage\nGather information from various Sources and interpret Patterns and Trends\nQualifications\n4+ years of SQL experience working in OLTP, Data Warehouse and Big Data databases\n4+ years in a Data Analyst role\nStrong attention to Detail\n2+ years writing medium to complex stored procedures (SQL)\nAbility to collaborate effectively and work as part of a team\nExtensive background in writing complex SQL queries\nExtensive working knowledge of all aspects of Data Movement and Processing, including ETL, API, OLAP and best practices for data tracking\nGood Communication skills\nSelf-Motivated\nWorks well in a team environment\nDenodo Experience a plus\nBig Data Experience (Hadoop, MongoDB, Exadata)\nShow more\nShow less",
      "job_skills":"SQL, Data Warehouse, ETL, Data Replication, Data Management, Data Governance, Master Data Management, Analytical Skills, Communication Skills, Data Anomalies, Data Issues, Data Transformations, Data Movement, Data Derivations, Data Standardization, Data Dictionary, Data Lineage, Data Sources, Patterns, Trends, OLTP, Big Data, Data Analyst, Stored Procedures, Team Collaboration, SQL Queries, Data Movement, Data Processing, API, OLAP, Data Tracking",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Quality Analyst (KM - PPL)",
      "company":"KellyMitchell Group",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-quality-analyst-km-ppl-at-kellymitchell-group-3759391808",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Summary:\nOur client is seeking a Data Quality Analyst. In this role, the ideal candidate will be responsible for leading the data analyst team that is involved in data quality initiatives spanning ICG and global functions. This candidate will join our clients Data Management Team.\nThis role is located in Irving, Texas. Candidate must be willing to work at least 1 day in office.\nDuties:\nLead the Data Analyst Team that is involved in data quality initiatives spanning ICG and global functions\nWork with cross functional teams to develop, test, implement, and maintain data quality rules covering the trade life cycle across markets data\nAnalyze data quality exceptions to identify root cause and business impact for data quality issues raised\nEnhance data quality process automation, governance, and reporting\nPrepare and present written and verbal updates to senior management\nEnsure adherence to the best practices supporting program, project, and data management standards\nAssess risk when business decisions are made\nDesired Skills\/Experience:\nBachelor\u201a\u00c4\u00f4s degree or equivalent experience\n8+ years of experience in data focused initiatives across pre-trade and post-trade activities\n5+ years of experience in writing SQL queries and reviewing stored procedures\nExposure to capital markets is beneficial\nExperience working with database, reporting, and analytics\nExperience in FIX and XML\nExperience in issue tracking and governance with systems like JIRA and HPQC\nProven stakeholder management and team leadership skills\nData and results oriented with excellent attention to detail\nStrong sense of urgency and ability to manage competing priorities while delivering results quickly and efficiently\nExceptional level of motivation and diligence coupled with excellent communication skills\nBenefits:\nMedical, Dental, & Vision Insurance Plans\n401K offered\nKMID: 126315\nShow more\nShow less",
      "job_skills":"Data Quality Analysis, Data Management, SQL, FIX, XML, JIRA, HPQC, Stakeholder Management, Team Leadership",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr Data Solutions Analyst",
      "company":"National Life Group",
      "job_location":"Addison, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-solutions-analyst-at-national-life-group-3771069738",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Senior Data Solutions Analyst\nOverview\nAt National Life Group we are in the process of changing how we think about, organize, and use data. In order to get the most value from our data it is critical that we have timely, accurate, consistent and well-defined data throughout the organization. Success depends on strong commitment & collaboration from all areas of the organization. The Analytical Governance Team is key to enabling this transformation.\nThe Senior Data Solutions Analyst Is a Key Member Of Our Analytics Center Of Excellence, Which Provide Two Main Functions To The Organization\nFacilitation of enterprise reporting & analytics by administering tools, providing business ready data sets, & assisting in delivering high quality information to decision makers.\nSupport of data projects & the data governance framework through advising on deliverables related to new and existing analytical solutions.\nObviously, we are looking for someone who loves data! Beyond that, a successful candidate will embrace the type of work that comes with a transformative effort. They will also contribute to the culture of National Life \u201a\u00c4\u00ec where servant leadership, company values & applying learnings to performance are valued above all else.\nThe Senior Data Solutions Analyst role is a great opportunity to join a fast-growing team that is central to National Life\u201a\u00c4\u00f4s data transformation. You will be exposed to different teams who work as part of the data delivery chain. Through this work you will get exposure and guidance from senior and executive leaders across the enterprise and a chance to collaborate with peers from other departments.\nResponsibilities\nJob Responsibilities:\nAfter getting up to speed on National Life\u201a\u00c4\u00f4s processes they will support the two functions above, primarily through owning end-to-end one of our analytical applications and providing ad-hoc analysis for key stakeholders. A typical day-to-day experience will vary, but will be some combination of:\nOwning the end-to-end experience of one of our analytical applications, including user training, user experience, incidents, upgrade support, etc.\nProviding general support of data & analytics as a subject matter expert for a specific functional domain\nCreating, enhancing, enforcing & promoting data governance policies & practices\nOwning functions within the analytical governance processes to facilitate delivering data solutions to production environments\nRequirements & Qualifications\nBachelor's degree in Math, Economics, Engineering, or related quantitative field\n3-5 years of experience with data governance, data management or data analytics\nStrong communication skills, and the ability to explain technical solutions to non-technical audiences\nExperience with relational databases (e.g. Microsoft SQL) and writing queries\nAbility to learn data & technology as it relates to business functions\nAnalytical and critical thinking skills, i.e. a problem solver\u201a\u00c4\u00f4s mindset\nExperience administering Analytical tools, specifically Tableau & Alteryx, preferred\nThe base compensation range represents the low and high end of the range for this position. Actual compensation will vary and may be above or below the range based on various factors including but not limited to qualifications, skills, competencies, location, and experience. The range listed is just one component of our total compensation package for employees.\nOther rewards may include an annual bonus, quarterly bonuses, commissions, and other long-term incentive compensation, depending on the position. National Life offers a competitive total rewards package which includes: a 401(k) retirement plan match; medical, dental, and vision insurance; a company funded wellness account for director and below employees; 10 paid holidays; a generous paid time off plan (22 days of combined time-off for non-exempt employees and exempt employees have discretion in managing their time, including scheduling time off in the normal course of business, but in no event will exempt employees receive less sick time than required by state or local law); 6 weeks of paid parental leave; and 6 weeks of paid family leave after a year of full-time employment\nNational Life Group\u00ac\u00c6 is a trade name of National Life Insurance Company, Montpelier, VT \u201a\u00c4\u00ec founded in 1848, Life Insurance Company of the Southwest, Addison, TX \u201a\u00c4\u00ec chartered in 1955, and their affiliates. Each company of National Life Group is solely responsible for its own financial condition and contractual obligations. Life Insurance Company of the Southwest is not an authorized insurer in New York and does not conduct insurance business in New York. Equity Services, Inc., Member FINRA\/SIPC, is a Broker\/Dealer and Registered Investment Adviser affiliate of National Life Insurance Company. All other entities are independent of the companies of National Life Group.\nFortune 1000 status is based on the consolidated financial results of all National Life Group companies.\nNational Life Group\n1 National Life Dr\nMontpelier, VT 05604\nSocial Media Policy\nSite Disclosure and Privacy Policy\nShow more\nShow less",
      "job_skills":"Tableau, Alteryx, SQL, Analytical Governance, Data Governance, Data Management, Data Analytics, Data Solutions, Business Analytics, Servant Leadership, Problem Solving, Relational Databases, Microsoft SQL, Queries, Business Functions",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst for Betterware US",
      "company":"Pop-Up Talent",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-for-betterware-us-at-pop-up-talent-3749335730",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Data Analyst for Betterware US\nJob Type: Full-time, Hybrid (Dallas, TX), TBD how many days it is required to be in the office.\nCOMPANY OVERVIEW:\nBetterware (NASDAQ: BWMX) is a leading home goods and organization company in Mexico - see www.betterware.com.mx\nWe are now expanding our presence to the United States and opening our first US office in Dallas, Texas. This is an opportunity to join the startup team of Betterware in the country.\nJOB SUMMARY:\nBetterware seeks a We are seeking a talented and motivated Data Analyst. The ideal candidate will be a strategic thinker with a hands-on attitude and will be responsible for analyzing various aspects of our business, primarily focusing on sales and marketing. The Data Analyst will collaborate closely with cross-functional teams to extract actionable insights from data and build reports and dashboards to ensure accurate information. This role requires strong analytical and communication skills and the ability to work in a fast-paced environment with a high degree of flexibility and adaptability.\nRESPONSIBILITIES:\nGenerate and maintain comprehensive sales reports and dashboards, providing clear visualizations and insights to stakeholders.\nSupport the Product team in delivering insights related to our product categories and target consumers.\nGather, analyze, and interpret data related to product performance, identifying trends, opportunities, and potential areas for improvement.\nEnsure the accuracy and effectiveness of the compensation plan by accurately calculating commissions and incentives for the sales team.\nGenerate ad hoc reports to address specific business questions and provide timely insights to support decision-making.\nWork closely with the Corporate Business Intelligence team to ensure data integrity and correct data collection methods.\nCollaborate with the other internal teams to streamline data integration processes and automate reporting where applicable.\nStay up to date with industry trends and best practices in data analysis, bringing innovative ideas to the team.\nREQUIREMENTS:\nBachelor's degree in Data Science, Statistics, Business, Business Analytics, Computer Science, or a related field.\nPrevious experience of at least 2 years as a Data Analyst, preferably in a fast-paced environment.\nProficiency in data analytics and visualization tools such as Tableau, Power BI, or similar.\nStrong analytical skills with the ability to transform complex data into actionable insights.\nAdvanced Excel skills.\nFamiliarity with statistical analysis techniques and tools.\nExcellent communication skills to convey findings and insights to non-technical stakeholders.\nKnowledge of SQL, Knime, or other querying languages is preferred.\nWe offer a competitive salary, a comprehensive benefits package, and the opportunity to work in a dynamic and growing organization. We would love to hear from you if you are a strategic thinker with a track record of driving growth and innovation. Apply now to join our team and help us take Betterware to the next level!\nSalary Range:\n$75,000 - $85,000\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Visualization, Tableau, Power BI, SQL, Knime, Advanced Excel, Statistical Analysis, Communication Skills, Sales and Marketing, Business Intelligence, Industry Trends",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"United Way of Metropolitan Dallas",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-united-way-of-metropolitan-dallas-3582342556",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"United Way of Metropolitan Dallas is looking for a Data Analyst to work cross-functionally with departments organization-wide to drive continuous improvement, learning, and data-informed decision making. Key areas of focus will include conducting in-depth analysis on revenue, donor retention, performance of key activities, community needs, and organizational impact. Using data from a variety of sources, the Data Analyst will utilize Microsoft PowerBI, Salesforce, and other systems to develop visualizations, dashboards, and reports containing actionable data and strategic insight to help United Way further its mission in the community.\nWork with staff organization-wide to understand departmental analytics needs, creating analytics which answer business questions, identify challenges\/opportunities, and measure effectiveness\nAnalyze and interpret data to identify patters and trends which impact organizational decision making\nBuild compelling visualizations, using tools such as Microsoft PowerBI, to support storytelling and translate data into actionable information\nPresent data trends and complex information in consumable formats tailored to various internal and external audiences\nCreate and maintain automated reports and dashboards which provide users organization-wide with self-service access to in-depth information\nDevelop dashboards, reports, and other analytical tools for use in forecasting, data maintenance and process improvement\nWrite\/update SQL queries needed for data analysis and reporting needs\nTest and validate data presented\nPerform system maintenance as needed to ensure consistent operation of the organization\u201a\u00c4\u00f4s data mart and reporting systems\nConduct training sessions and assist staff with maximizing usage of reporting and dashboarding systems\nBe a resource and advocate for data-inform decision making by teaching and empowering others to use existing data and modify processes to expand data available\nTo perform the job successfully, competitive applicants should demonstrate the following competencies\nMission-Focused Create real social change that leads to improving lives in our community\nRelationship-Oriented Able to communicate effectively to develop, grow and sustain productive relationships. Knows how to capture and record relevant information and how to interpret and utilize the information to forge partnerships, collaborate, cultivate, grow, sustain and strengthen internal and external relationships\nResults-Driven Dedicated to shared and measurable goals; creating, resourcing, scaling, and leveraging strategies and innovations for broad impact\nStewards Our actions, behaviors, and decisions on behalf of our donors must be transparent, meet the highest ethical standards, and align with organizational goals\nREQUIRED KNOWLEDGE, SKILLS AND ABILITIES\nBachelor\u201a\u00c4\u00f4s Degree in Business Analytics, Information Technology, or other data-driven discipline\n5+ years of experience in a hands-on data analytics role, having autonomously manipulated and drawn actionable conclusions from large amounts of data\nAdvanced knowledge and experience working with Microsoft PowerBI and DAX\nAdvanced knowledge and experience with SQL queries and server administration\nAdvanced knowledge and experience with Microsoft Office Suite, including Excel formulas, pivot tables, and charting functions\nProven experience creating compelling dashboards and visualizations for professional presentation\nPrior experience building and maintaining automated reporting systems\nExperience with Salesforce NPSP\nStrong data analysis and evaluation skills (quantitative and qualitative)\nAbility to plan project timelines and deliver results according to deadlines\nAbility to work independently, to prioritize and execute multiple projects\nHigh attention to detail\nExcellent written and verbal communication skills\nDriven to understand various business processes and the connection to the data needed\/produced\nDriven to continuously learn new skills and information\nShow more\nShow less",
      "job_skills":"Data Analytics, DataDriven Decision Making, Data Visualization, Microsoft PowerBI, Salesforce, SQL, Microsoft Office Suite, Excel, Pivot Tables, Dashboarding, Salesforce NPSP, Quantitative Analysis, Qualitative Analysis, Project Management, Prioritization, Communication Skills, Business Process Understanding, Learning and Development",
      "Category":"Data Science"
  },
  {
      "job_title":"Associate Data Analyst, Revenue Management",
      "company":"Priceline",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/associate-data-analyst-revenue-management-at-priceline-3774917522",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"This role is eligible for our hybrid work model: Two days in-office\nAssociate Data Analyst - Revenue and Inventory Management\nWe\u201a\u00c4\u00f4re a data-driven organization, which makes our Analytics and Data Science teams the brains of our operation. On the cutting edge of customer and business analytics, they make sure all our decisions and innovations are based on the latest insights.\nWhy This Job\u201a\u00c4\u00f4s a Big Deal\nAs an Associate Business Analyst at Priceline Partner Solution, you will closely examine supply quality and booking performance. Through insightful data analysis you will uncover opportunities that drive performance improvements. You will partner with stakeholders to measure performance and work in close collaboration with account management and accommodations teams to deliver innovative solutions. The ideal candidate for this role has prior experience in an e-commerce or travel environment, strong analytical skills with an excellent track record of execution.\nIn This Role You Will Get To\nHold ownership for monitoring business metrics, explain trends and drivers\nBe at the forefront of action identifying and solving booking issues\nCoordinate and connect with internal and external teams to alert and resolve issues\nPrepare and analyze pricing and distribution data to support maximize yielding\nBecome a subject matter expert on rate verification and distribution flow process\nProvide concurrent analytical support for initiatives across variety of teams such as Account Management, Supply, Finance and Business Intelligence\nWork with other analysts with other business units and teams\nWho You Are\n2+ years of analysis\/consulting experience, travel or ecommerce\/hospitality industry preferred\nAble to interpret data and trends and to translate analysis in a compelling way to improve performance\nDemonstrate ability to extract value from data and reducing this data to intuitive models, charts and bullet points for communication\nExcel and Tableau required. Preferably with SQL and BigQuery\nA self-starter who is inquisitive and able to dissect data to uncover the root cause of an issue\nAbility to work and thrive in a multi-tasked, fast-paced environment\nExhibit the highest level of professionalism, integrity, and ethical values\nBachelor\u201a\u00c4\u00f4s Degree in Statistics \/ Math \/ Business \/ Hotel education background\nThere are a variety of factors that go into determining a salary range, including but not limited to external market benchmark data, geographic location, and years of experience sought\/required. In addition to a competitive base salary, certain roles may be eligible for an annual bonus and\/or equity grant.\nThe salary range for this position is $50000-$60000\nWho We Are\nWE ARE PRICELINE.\nOur success as one of the biggest players in online travel is all thanks to our incredible, dedicated team of talented employees. Priceliners are focused on being the best travel deal makers in the world, motivated by our passion to help everyone experience the moments that matter most in their lives. Whether it\u201a\u00c4\u00f4s a dream vacation, your cousin\u201a\u00c4\u00f4s graduation, or your best friend\u201a\u00c4\u00f4s wedding - we make travel affordable and accessible to our customers.\nOur culture is unique and inspiring (that\u201a\u00c4\u00f4s what our employees tell us). We\u201a\u00c4\u00f4re a grown-up, startup. We deliver the excitement of a new venture, without the struggles and chaos that can come with a business that hasn\u201a\u00c4\u00f4t stabilized.\nWe\u201a\u00c4\u00f4re on the cutting edge of innovative technologies. We keep the customer at the center of all that we do. Our ability to meet their needs relies on the strength of a workforce as diverse as the customers we serve. We bring together employees from all walks of life and we are proud to provide the kind of inclusive environment that stimulates innovation, creativity and collaboration.\nPriceline is part of the Booking Holdings, Inc. (Nasdaq: BKNG) family of companies, a highly profitable global online travel company with a market capitalization of over $80 billion. Our sister companies include Booking.com, BookingGo, Agoda, Kayak and OpenTable.\nIf you want to be part of something truly special, check us out!\nFlexible work at Priceline\nPriceline is following a hybrid working model, which includes two days onsite as determined by you and your manager (ideally selecting among Tuesday, Wednesday, or Thursday). On the remaining days, you can choose to be remote or in the office.\nDiversity and Inclusion are a Big Deal!\nTo be the best travel dealmakers in the world, it\u201a\u00c4\u00f4s important we have a workforce that reflects the diverse customers and communities we serve. We are committed to cultivating a culture where all employees have the freedom to bring their individual perspectives, life experiences, and passion to work.\nPriceline is a proud equal opportunity employer. We embrace and celebrate the unique lenses through which our employees see the world. We\u201a\u00c4\u00f4d love you to join us and add to our rich mix!\nApplying for this position\nWe're excited that you are interested in a career with us. For all\ncurrent employees\n, please use the internal portal to find jobs and apply.\nExternal candidates are required to have an account before applying. When you click Apply, returning candidates can log in, or new candidates can quickly create an account to save\/view applications.\nShow more\nShow less",
      "job_skills":"Data analysis, Customer analytics, Business analytics, Data visualization, Excel, Tableau, SQL, BigQuery, Statistical analysis, Business intelligence, Rate verification, Distribution flow process, Pricing, Distribution, Yield management, Multitasking, Fastpaced environments, Communication, Problemsolving, Root cause analysis, Team collaboration, Ethical values",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst",
      "company":"Spectrum Search Group",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-at-spectrum-search-group-3766758622",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Position\nTitle: Senior Analyst of Financial Planning & Analysis (FP&A)\nLocation:\nHouston, Texas (In-Office Position)\nAbout Us:\nWe are currently working with a dynamic e-commerce retail giant\n, that is on the brink of an exhilarating expansion journey. As they gear up to double the number of retail stores in new states across the U.S. and plan strategic acquisitions of other sport-related retail stores, we are seeking a talented and driven\nSenior Analyst of FP&A\nto join our finance team.\nWhy Join Us:\nThriving Expansion: Be part of a team driving the ambitious goal of doubling the number of retail stores, and expanding our footprint across new states.\nStrategic Acquisitions: Contribute to the exciting plans of acquiring other sport-related retail stores, influencing the future landscape of the industry.\nFast-Paced, Fun Environment: Immerse yourself in a dynamic work culture with a 40-50 hour work week, where every day brings new challenges and opportunities.\nEducation:\nBachelor\u201a\u00c4\u00f4s Degree in Accounting, Finance, Business Administration, or equivalent required.\nWork Experience:\nJob Description:\nTwo+ (2) years of experience, including planning, forecasting, analyzing reporting, and business partnering.\nPrevious FP&A or Corporate Finance experience required.\nRetail\/e-commerce experience is a plus.\nSkills:\nPartner effectively with internal teams and external stakeholders.\nStrategic thinking coupled with the ability to deliver tactical analysis.\nProven track record of delivering high-impact results.\nExcellent written, verbal, listening, and presentation skills.\nAnalytical and process-improvement-oriented mindset.\nAdvanced Excel skills.\nResponsibilities:\nAnalyze and support annual planning and monthly forecasting processes.\nProvide financial planning support for internal business partners.\nDeliver weekly, monthly, and quarterly executive reporting.\nInteract regularly with senior management to enable business strategies.\nConsolidate and analyze departmental\/function plans and forecasts.\nEstablish clear ownership, timelines, and deliverables.\nLeverage internal and external networks to maximize business goals.\nDrive accurate forecasting and long-term vision.\nIdentify and drive process improvements.\nActively participate in new FP&A initiatives.\nPhysical Requirements & Attendance:\nCompensation:\nUp to $105,000 plus bonus.\nShow more\nShow less",
      "job_skills":"Financial Planning & Analysis (FP&A), Corporate Finance, Retail\/ecommerce, Strategic Thinking, Tactical Analysis, HighImpact Results, Written Communication, Verbal Communication, Listening Skills, Presentation Skills, Analytical Mindset, Process Improvement, Advanced Excel, Annual Planning, Monthly Forecasting, Financial Planning Support, Executive Reporting, Senior Management Interaction, Departmental Plan Consolidation, Forecast Consolidation, Internal & External Network Leverage, Accurate Forecasting, LongTerm Vision, Process Improvement, New FP&A Initiatives",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst II-Mid-level",
      "company":"ReviveRX",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-ii-mid-level-at-reviverx-3787930410",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Summary\/Objective\nThis position supports the product and strategy team by collecting, processing, and analyzing datasets to extract meaningful insights. Statistical methods and data visualization tools are utilized to present findings.\nEssential Functions\nInvolved in projects related to implementing data-driven solutions, particularly focused on AI and LLM based projects, machine learning, and chatbot technologies.\nEnhances efficiency, user experience, and overall success through advanced analytics and innovative technologies.\nPlays a crucial role in creating operational dashboards and KPIs for different departments.\nIndicates a comprehensive approach to data analytics and visualization, aligning with organizational objectives and contributing to enhanced operational insights.\nWorks on assigned daily and weekly tasks to maintain automations and business intelligence (BI) processes.\nUses a ticketing system to ensure a systematic approach in addressing new requests and monitors the progress of tasks, providing a clear and organized way to manage workflows and product orders.\nCollaborates with team leads and team members in setting priorities for the tickets, ensuring efficient task management and timely completion.\nConducts trend analysis to identify patterns, anomalies, and potential areas for improvement. Stays informed about industry trends and best practices in data analysis.\nDevelops and implements predictive models to forecast trends and outcomes.\nEvaluates model performance and iterates as needed for continuous improvement.\nCreates visually appealing and understandable dashboards and reports.\nCommunicates findings effectively to both technical and non-technical audiences.\nPerforms ETL by extracting data from various sources, transforming it into a consistent format, and loading it into a destination for analysis.\nWrites scripts or codes to perform statistical analysis on datasets.\nPerforms other related duties as required and assigned.\nSkills And Attributes\nCapability to generate innovative ideas and think outside conventional boundaries to foster creativity.\nAdaptability to adjust and thrive in changing environments.\nStrong analytical and problem-solving skills.\nAbility to quickly grasp and comprehend new information or skills.\nAttention to detail and ability to work independently or in a team.\nSupervisory Responsibility\nThis position has no supervisory responsibly.\nWork Environment\nThis is a remote position which would ideally be conducted in a home office setting. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines.\nPhysical Demands\nThis position requires frequent sitting, walking, standing, reading, seeing, speaking, hearing, listening, organizing, interpreting data and information, operating office equipment, typing using a computer keyboard and mouse, viewing a computer screen monitor, and use of a telephone. Some positions may require lifting, occasional bending or kneeling. The working environment consists of an indoor and climate-controlled setting the majority of the time. The employee may regularly lift and\/or move objects up to 25 pounds.\nTravel\nTravel is primarily local during the business day, although some out-of-area and overnight travel may be expected.\nRequired Education And Experience\nBA\n2-4 years\u201a\u00c4\u00f4 experience in healthcare or Tech environment.\nStrong knowledge of Receiving, Warehouse, and Material Handling operations, methods, and practices.\nAdditional Eligibility Qualifications\nPower BI or Data Visualization Certification preferred.\nOther Duties\nPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice\nPowered by JazzHR\nfp3q8HxeJT\nShow more\nShow less",
      "job_skills":"Data analysis, Data visualization, Machine learning, Chatbot technology, Advanced analytics, Business intelligence (BI), Ticketing system, Trend analysis, Predictive modeling, Data extraction, Data transformation, Data loading, Statistical analysis, Problemsolving, Critical thinking, Attention to detail, Team work, Communication, Adaptability, Power BI, Data Visualization Certification",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Reporting Analyst",
      "company":"Pacifica Continental",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-reporting-analyst-at-pacifica-continental-3730573706",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"DATA REPORTING ANALYST\nImportant company located in Houston, TX is looking for aData Reporting Analyst.\nEstablish and maintain internal data analytic processes, perform routine quality control reviews. Work closely and collaboratively with other functions (Finance, Operations, HSSE, Commercial, Human Capital, Corporate Integrity, others). Ensure reporting changes are updated, documented, grammatically correct and validated. Review documents and data provided for completeness and accuracy. Participate departmental project coordination and process management. Research standard industry best practices and effectively communicate continuous improvement metrics. Interpret and present data in a meaningful way to provide business insights. Continually working to identify opportunities to improve processes, ensuring all data analysis processes are effective, efficient, and fit for purpose.\nRequirements\nTechnical writing and research experience; experience in Sustainability \/ HSSE Compliance reporting\nTeam-oriented\nExcellent attention to detail and highly organized\nMaintain confidentiality within department and business sensitive information\nAbility to work independently and appropriately escalate matters to line manager\nYou have a strong working knowledge of Office 365, including Word, Excel, PowerPoint\nYou have the ability to think critically and are comfortable to challenge the status quo, always striving to identify and recommend process improvements\nAbility to communicate across levels of the organization concisely and effectively\nYou can multi-task and work to tight deadlines in a fast-paced environment\nYou have a flexible approach to work and respond positively to change and ambiguity\nSelf-motivated, proactive and comfortable working with ever changing work scenarios\n5+ Years Relevant data analytics experience, preferably in the oil and gas industry\nBenefits\nHealth Care Plan (Medical, Dental & Vision)\nRetirement Plan (401k, IRA)\nLife Insurance (Basic, Voluntary & AD&D)\nPaid Time Off (Vacation, Sick & Public Holidays)\nFamily Leave (Maternity, Paternity)\nShort Term & Long Term Disability\nShow more\nShow less",
      "job_skills":"Data Analytics, Sustainability Reporting, HSSE Compliance Reporting, Office 365, Word, Excel, PowerPoint, Technical Writing, Research, Process Improvement, Communication, MultiTasking, Time Management, Flexibility, SelfMotivation, Proactivity",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst I",
      "company":"HonorVet Technologies",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-i-at-honorvet-technologies-3785509394",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position: -Data Analyst I\nLocation: -Houston, TX 77002\nDuration- 6+ Months\nShift Timing: - Monday to Friday 7:00am-3:30pm EST\nJob Description: -\nUpdate database and share site with data for all new, recertified, or amended profiles.\nUpdate share site with current approvals and Notification of Treatment Standards forms.\nTechnical regulatory review of all new, amended, and recertified waste profile\ndata (DOT, RCRA, Land Ban, and miscellaneous notes). Review for internal profile inconsistencies.\nEfficiently track and run reports that could require an advanced knowledge of Excel.\nValidation of shipment data for waste tracking.\nCertificates, Licenses, Registrations Or Other Requirements\nRCRA and DOT Regulatory compliance or Quality or Government Regulation\nExperience Preferred.\nManifesting and profiling hazardous and non-hazardous waste experience.\nPreferred.\nPre-assignment and\/or pre-hire customer-specific drug and\/or alcohol testing\nMay Be Required By Certain Customer-contract Requirements.\nSuch testing may include urinalysis, oral swab, drug hair follicle testing and\/or alcohol testing.\nOther Skills\nStrong understanding of Microsoft Excel or similar database software\nKnowledge of word processors, like Microsoft Word\nExcellent typing and transcription skills, including typing at fast speeds.\nAbility to research and collect data.\nAccuracy and attention to detail\nStrong verbal and written communication skills\nTime management and organization\nMulti-tasking\nEducation and Experience\nEducation: High school diploma or G.E.D (accredited)\nShow more\nShow less",
      "job_skills":"Data Analysis, Microsoft Excel, Microsoft Word, DOT, RCRA, Land Ban, Hazardous Waste, NonHazardous Waste, Manifesting, Profiling, Shipment Data, Validation, Regulatory Compliance, Quality Assurance, Government Regulation, Typing, Transcription, Research, Data Collection, Accuracy, Attention to Detail, Verbal Communication, Written Communication, Time Management, Organization, Multitasking, High School Diploma, G.E.D",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Reporting Analyst",
      "company":"BW Energy",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-reporting-analyst-at-bw-energy-3725162774",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Establish and maintain internal data analytic processes, perform routine quality control reviews\nWork closely and collaboratively with other functions (Finance, Operations, HSSE, Commercial, Human Capital, Corporate Integrity, others)\nEnsure reporting changes are updated, documented, grammatically correct and validated\nReview documents and data provided for completeness and accuracy\nParticipate departmental project coordination and process management\nResearch standard industry best practices and effectively communicate continuous improvement metrics\nInterpret and present data in a meaningful way to provide business insights\nContinually working to identify opportunities to improve processes, ensuring all data analysis processes are effective, efficient, and fit for purpose.\nRequirements\nTechnical writing and research experience; experience in Sustainability \/ HSSE Compliance reporting\nTeam-oriented\nExcellent attention to detail and highly organized\nMaintain confidentiality within department and business sensitive information\nAbility to work independently and appropriately escalate matters to line manager\nYou have a strong working knowledge of Office 365, including Word, Excel, PowerPoint\nYou have the ability to think critically and are comfortable to challenge the status quo, always striving to identify and recommend process improvements\nAbility to communicate across levels of the organization concisely and effectively\nYou can multi-task and work to tight deadlines in a fast-paced environment\nYou have a flexible approach to work and respond positively to change and ambiguity\nSelf-motivated, proactive and comfortable working with ever changing work scenarios\n5+ Years Relevant data analytics experience, preferably in the oil and gas industry\nBenefits\nHealth Care Plan (Medical, Dental & Vision)\nRetirement Plan (401k, IRA)\nLife Insurance (Basic, Voluntary & AD&D)\nPaid Time Off (Vacation, Sick & Public Holidays)\nFamily Leave (Maternity, Paternity)\nShort Term & Long Term Disability\nShow more\nShow less",
      "job_skills":"Data Analytics, Quality Control, Data and Document Review, Process Coordination, Process Management, Industry Best Practices, Data Interpretation, Data Presentation, Business Insights, Process Improvement, Technical Writing, Research, Sustainability Reporting, HSSE Compliance Reporting, Team Orientation, Attention to Detail, Organization, Confidentiality, Independent Work, Escalation, Office 365, Word, Excel, PowerPoint, Critical Thinking, Challenge Status Quo, Process Improvements, Communication, MultiTasking, Tight Deadlines, FastPaced Environment, Flexibility, Change Adaptability, Ambiguity Tolerance, SelfMotivation, Proactivity",
      "Category":"Data Science"
  },
  {
      "job_title":"Power BI Analyst",
      "company":"Storm4",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/power-bi-analyst-at-storm4-3779389199",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"\u201a\u00f6\u00b0 Role: Power BI Analyst\n\uf8ff\u00fc\u00ed\u00ba Industry: Residential Solar\n\uf8ff\u00fc\u00e5\u00e9 Location: Houston, TX (Hybrid)\nAn incredible opportunity to join an exciting Solar start-up specializing in owning and operating residential solar projects in the United States.\nThey are looking for a passionate and motivated Asset Operations Analyst to provide stakeholders with the analysis of asset performance to support the decision-making process. Responsibilities include creating reports to monitor and control production performance, analysing FinOps data and working with multiple teams to ensure financing relations.\n\u201a\u00f6\u00b0\nREQUIRED:\n3+ years of experience in an analyst role\nBusiness performance analysis and data analytics experience\nAdvanced Power BI and Excel experience\nExperience working with DAX code\n\u201a\u00f6\u00b0\nCREDENTIALS:\nAdvanced working skillset with PowerBI\nAdvanced working skillset in MS Excel\nProficient with SQL, Data Warehousing and other automated reporting\nFinancial modelling experience\n\uf8ff\u00fc\u00ec\u00df Sounds like you? Please click on the \u201a\u00c4\u00f2Easy Apply\u201a\u00c4\u00f4 button.\n\u201a\u00f6\u00b0 Storm4 is a specialist GreenTech recruitment firm with clients across Europe, APAC and North America. To discuss open opportunities or career options, please visit our website at www.storm4.com and follow the Storm4 LinkedIn page for the latest jobs and int\nel.\nShow more\nShow less",
      "job_skills":"Power BI, Excel, DAX, SQL, Data Warehousing, Automated Reporting, Financial Modelling",
      "Category":"Data Science"
  },
  {
      "job_title":"POWER BI & REPORTING ANALYST",
      "company":"Shell Energy",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/power-bi-reporting-analyst-at-shell-energy-3767675933",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description\nAt Shell Energy Solutions, we believe there\u201a\u00c4\u00f4s a better way to power your business and home.\nAligned with Shell\u201a\u00c4\u00f4s ambition to be a significant global power business and to become net zero by 2050, our cleaner, affordable, and simple solutions help companies manage their energy spend and plan their sustainability roadmap - a fresh approach for environmentally conscious businesses that are looking to boost their sustainability credentials. We also have set out to deliver the very best experience to our customers across all our channels.\nShell Energy Solutions mission is delivering cleaner energy solutions for a brighter tomorrow by guiding customers toward a better energy future, enabling customer choice and by providing market-leading energy solutions.\nGoing above and beyond for our customers is what we\u201a\u00c4\u00f4re all about and we have set out to deliver the very best experience to our customers across all our channels. But bigger challenges lie ahead, and we need to keep moving forward. Are you ready to help us get there?\nWHERE YOU FIT IN\nWe are looking for a savvy Power BI and Reporting Analyst, with previous experience in the retail energy space, to join our growing team of enterprise data and analytics experts. The hire will be responsible for advancing our reporting and analytics footprint. The ideal candidate is an experienced BI Analyst who enjoys optimizing data reporting processes and driving insights.\nThe Power BI Reporting Analyst will support our business users in creating data insights and reports. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of solving complex problems, is driven to enable users to succeed, and can build effective stakeholder relationships.\nReporting into the Data Platform Manager, the role requires self-motivated, dedicated and responsible individual with the ability to perform well under pressure.\nJob Duties & Responsibilities\nCreate and maintain new dashboards and data models based on defined business requirements.\nInterface with business stakeholders and leadership to understand and define reporting needs.\nAid in the establishment of an enterprise Center of Excellence around reporting.\nAssemble large, complex data sets that meet functional \/ non-functional reporting requirements.\nWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their reporting needs.\nBuild data views, models, and reports to expose and drive data insights.\nWork with data and analytics experts to strive for greater functionality in our reporting practices.\nCreate and maintain documentation including requirements, design, and user manuals.\nAnalyze existing business processes and identify opportunities for improvement.\nOther duties as assigned\nEssential Skills And Experience\nSuccessful job applicants will be able to perform these functions. Reasonable accommodations will be made to enable individuals with disabilities to perform the essential functions.\n5+ years of experience in a related role.\n3+ years of experience using Microsoft PowerBI.\n2+ years of experience working in the retail energy space.\nAdvanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\nExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\nA successful history of manipulating, processing and extracting value from large, disconnected datasets.\nStrong analytical and problem-solving skills; must be able to provide timely and accurate data analysis.\nComfortable working in a target-driven and fast-changing environment, and able to respond to changing business needs\nProficient use of Microsoft Office programs including Word, Outlook and strong Excel skills\nExcellent analytical, organization and time management skills, with the ability to maintain a strict level of attention to detail\nStrong business writing skills and experience developing communication in various formats.\nLearner mindset and eye for continuous improvement needs.\nOrganization and time management skills, with the ability to maintain a strict level of attention to detail\nAbility to work well within a team environment and demonstrate a vested interest in team goals and objectives\nExcellent interpersonal, verbal, and written communication skills, with the ability to establish and maintain positive and effective working relationships\nSelf-motivated with the desire to consistently improve performance and gain further knowledge\nAbility to meet deadlines, learn quickly and demonstrate effective problem solving and follow-up skills\nComply with company policies and procedure\nLOCATION AND WORK SCHEDULE\nRequired to be in-person in Houston, TX through a hybrid workplace environment\nBenefits Of Working With Shell Energy\nCompetitive Compensation\nHealth Care - Medical\/Dental\/Vision\/Prescription Drug Coverage\n401(k) with Company Matching Contributions\nFlexible Spending Accounts (FSA)\nHealth Savings Accounts (HSA)\nDisability Programs (STD & LTD)\nEmployee Basic Term Life Insurance\nGenerous Vacation & Company Holidays\nFlexible hybrid working schedule\nTraining and coaching\nTuition Reimbursement\nPaid Parental Leave\nAnd much more!\nSHELL ENERGY VALUES\nShell is a company with shared values. Honesty, integrity, and respect aren't simply a strapline: they are part of everything we do. What's more, Shell is an equal opportunities company, and we place the highest possible value on the diversity of our people and our inclusive approach. Join us and you\u201a\u00c4\u00f4ll belong to a world where you are proud of your achievements and propel your career with global opportunities. We care deeply about fostering a truly diverse workplace.\nJob descriptions are not intended as, nor should be construed to be, exhaustive lists of all responsibilities, skills, efforts, or working conditions associated with a job. They are intended to be accurate reflections of those principal job duties and responsibilities essential for making fair pay decisions about the job.\nShow more\nShow less",
      "job_skills":"Power BI, Data Analytics, Reporting, SQL, Data Manipulation, Data Extraction, Data Analysis, ProblemSolving, Microsoft Office Suite, Communication Skills, Teamwork, Attention to Detail, Learning Mindset, Time Management, Flexibility, Adaptability, Stress Resilience, Collaboration",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Data Analyst \/ Medical Coder (Medical Policies\/Regulations) - REMOTE in CA",
      "company":"RemoteWorker US",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-medical-coder-medical-policies-regulations-remote-in-ca-at-remoteworker-us-3780836767",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"JOB DESCRIPTION Job Summary Designs and implements processes and solutions associated with a wide variety of data sets used for data\/text mining, analysis, modeling, and predicting to enable informed business decisions. Gains insight into key business problems and deliverables by applying statistical analysis techniques to examine structured and unstructured data from multiple disparate sources. Collaborates across departments and with customers to define requirements and understand business problems. Uses advanced mathematical, statistical, querying, and reporting methods to develop solutions. Develops information tools, algorithms, dashboards, and queries to monitor and improve business performance. Creates solutions from initial concept to fully tested production and communicates results to a broad range of audiences. Effectively uses current and emerging technologies. KNOWLEDGE\/SKILLS\/ABILITIES With limited supervision, the Sr. Analyst, Data is responsible for data compilation, data management, data analysis, and reporting. Extracts and compiles various sources of information and large data sets from various systems or applications. Set up process for monitoring, tracking and trending information and data using various systems or applications. Prepares well-organized, easily understood reports, analysis, and summary of findings for use by management. Assists in preparation of regularly produced reports to support executive decision-making. Researches and analyze report results identifying opportunities and trends. Works with internal, external and enterprise individuals as needed to research, develop, and document new standard reports or processes. Consolidates data from multiple sources, using industry-based tools or manually; able to process data effectively using Microsoft Excel. Supports management and other team members as requested on all things data related. JOB QUALIFICATIONS Required Education Associate degree or equivalent combination of education and experience Required Experience 3-5 years Preferred Education Bachelor's Degree or equivalent combination of education and experience Preferred Experience 5-7 years Experience with Medical Policies, Regulatory Guidelines, Medical Coding, Payment Integrity and All Plan Letters. Strong Excel - VLOOKUP, Pivot Tables. Basic SQL skills - SQL queries. CPC certification . Strong communication skills. To all current Molina employees: If you are interested in applying for this position, please apply through the intranet job listing. Molina Healthcare offers a competitive benefits and compensation package. Molina Healthcare is an Equal Opportunity Employer (EOE) M\/F\/D\/V. Pay Range: $69,477 - $135,480 a year* *Actual compensation may vary from posting based on geographic location, work experience, education and\/or skill level.\nShow more\nShow less",
      "job_skills":"Data analysis, Data management, Data mining, Data compilation, Data reporting, Microsoft Excel, VLOOKUP, Pivot Tables, SQL, Statistical analysis, Mathematical methods, Reporting methods, Algorithm development, Dashboard creation, Querying, Communication, Medical policies, Regulatory guidelines, Medical coding, Payment integrity, All plan letters",
      "Category":"Data Science"
  },
  {
      "job_title":"Reports Analyst",
      "company":"John Moore Services",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/reports-analyst-at-john-moore-services-3580674497",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"We are looking for an enthusiastic\nReports Analyst\nwith the operational skills to design, develop, program, maintain, and publish reports. This individual will have at least 4 years of experience along with the skills to collect and interpret data from various internal and external sources; merge data sources; prepare and compile data. The ability to understand how information flows across different business processes and data systems is advantageous.\nTHIS IS A 3 MONTH CONTRACT POSITION\nResponsibilities\nEvaluate current reports and processes to determine new reports possibilities or enhancements to existing services.\nDemonstrate the familiarity in using reporting tools; designing or developing specific databases for collection, reporting, tracking and presenting data\nStrong proficiency in Excel is required, with the ability to create, construct, and interpret data from Excel\nExperience Must Include\nAccess\nSQL\nPivot tables\nPower Pivot\nSharePoint\nVBA would be a plus\nShow more\nShow less",
      "job_skills":"Reports Analyst, Data collection, Data interpretation, Data merging, Data preparation, Data compilation, Data analysis, Reporting tools, Database design, Database development, Excel, Data creation, Data construction, Data interpretation, Access, SQL, Pivot tables, Power Pivot, SharePoint, VBA",
      "Category":"Data Science"
  },
  {
      "job_title":"Analyst, HR Reporting Ppl. Analytics II",
      "company":"LyondellBasell",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/analyst-hr-reporting-ppl-analytics-ii-at-lyondellbasell-3757007438",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"LyondellBasell\nBasic Function\nThe People Analyst role will provide functional expertise in the establishment of the People Analytics function globally, and partner with People and Culture (HR) Functional leaders to drive data-based decision-making by integrating data into tactical operations and strategic planning across the employee lifecycle.\nRoles & Responsibilities\nCollaborates with ELR, HR, Compliance, and Legal partners to identify data and reporting needs; prepares and maintains reports, analytical tools and dashboards based on stakeholder and business needs\nPartner with IT Data & Analytics CoE and HRMS Reporting Analyst to create reports and\/or dashboards\nEnsures the integrity and consistency of data within the HR Acuity Case Management System and resolves issues as needed to generate accurate, consistent and meaningful analysis and reporting\nGenerate insights based on data analyses and communicate the results to HR management to provide actionable information and insights\nAnalyze and interpret data thru the lens of the HR function supported ensuring the analysis is relevant and aligned with the overall HR function strategy\nProvide functional expertise and offer solutions in quantitative and\/or qualitative data analysis, interpretation, and presentation of results to help inform, influence, support, and execute decisions\nContribute to the operational redesign, development, and implementation of people analytics function globally\nInteract as a connection point between the business and other supporting areas of HR which may include assistance with process improvement solutions and streamlining of information\nDesign and implement reporting tools and processes as required\nPromote data governance and stewardship, data quality and advancement of HR technology capabilities\nPerform data quality reviews utilizing quality assurance methods to identify problems and errors\nTrain clients on reporting functionality, data dashboard navigation, and building stories with data\nEnsure compliance with data privacy regulations and best practices\nTracks case volume, aging, and post-disposition closing activities to ensure resolutions are fully implemented and inform capacity and resource planning and the triage and prioritization of cases\nDesigns and implements case management training programs for new and existing user, including use of reporting tools, dashboards, and best practices\nAssist in preparation of Employee and Labor Relations related reports as needed\nMin. Qualifications\nBachelor\u201a\u00c4\u00f4s degree or equivalent knowledge and experience in a related field\n10 years of experience involving the management, tracking, analysis, and reporting of large amounts of data\nExperience with HRMS, case management, or other data and information management system within a human resources, legal, finance, compliance, employee relations, or other related function\nExperience developing data queries, dashboard, writing and presenting reports, and turning data into information to identify trends and inform decision making\nPassion for data, problem solving, strategic thinking and storytelling\nDemonstrated knowledge in reporting (including report generation, scheduling, etc) dashboards, scorecards, and data visualization\nStrong written and verbal communication skills\nStrong customer service background including translation of requests into requirements andcommunication of technical information to a non-technical audience\nStrong stakeholder management including managing expectations\nKnowledge of data privacy regulations and experience navigating how to effectively use data while protecting individuals\u201a\u00c4\u00f4 privacy\nIntermediate to Advanced Excel skills\nPreferred Qualifications\nProficiency in leveraging data for analyzing business results\nAnalytical experience including the ability to gain insights from data\nWorking knowledge of Human Capital Systems (HCM)\nWorking knowledge and understanding of SAP\nWorking knowledge or familiarity of the Acuity case management or similar tools\nCompetencies\nBuilds effective teams\nCollaborates\nCultivates innovation\nCustomer focus\nDemonstrates courage\nDrives results\nEnsures accountability\nInstills trust and exemplifies integrity\nWe are LyondellBasell \u201a\u00c4\u00ec a leader in the global chemical industry creating solutions for everyday sustainable living. Through advanced technology and focused investments, we are enabling a circular and low carbon economy. Across all we do, we aim to champion our employees, and unlock value for customers, investors and society. LyondellBasell places high priority on diversity, equity and inclusion and is strongly committed to our planet, the communities where we operate and our future workforce. As one of the world\u201a\u00c4\u00f4s largest producers of polymers and a leader in polyolefin technologies, we develop, manufacture and market high-quality and innovative products for applications ranging from sustainable transportation and food safety to clean water and quality healthcare. For more information, please visit www.lyondellbasell.com or follow @ LyondellBasell on LinkedIn.\nShow more\nShow less",
      "job_skills":"Data Analytics, Reporting, Data Quality Assurance, Data Visualization, Data Governance, Case Management, HRMS, SAP, Acuity, Excel, HCM",
      "Category":"Data Science"
  },
  {
      "job_title":"Analyst, Data Accuracy Response Team",
      "company":"Palo Alto Networks",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/analyst-data-accuracy-response-team-at-palo-alto-networks-3783916444",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Company Description\nOur Mission\nAt Palo Alto Networks\u00ac\u00c6 everything starts and ends with our mission:\nBeing the cybersecurity partner of choice, protecting our digital way of life.\nOur vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we\u201a\u00c4\u00f4re looking for innovators who are as committed to shaping the future of cybersecurity as we are.\nOur Approach to Work\nWe lead with flexibility and choice in all of our people programs. We have disrupted the traditional view that all employees have the same needs and wants. We offer personalization and offer our employees the opportunity to choose what works best for them as often as possible - from your wellbeing support to your growth and development, and beyond!\nAt Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together!\nJob Description\nYour Career\nPalo Alto Networks\u00ac\u00c6 is the fastest-growing security company in history. If you are a motivated, intelligent, creative, and hardworking individual, then this is the place for you! One of the keys to our success is our relentless focus on leveraging data to drive insights and decision making. Our Data Accuracy Response Team is tasked with ensuring our data is regulated, accurate, and reliable on a day to day basis. This includes managing urgent escalations, executing and monitoring changes in data, and observing trends to guide system improvements. The Data Governance Analyst is the front line in ensuring that these goals come to fruition. This position reports to the Director, Sales Operations for Data Integrity and Policy and will have a high degree of interaction with the Analytics, Business Operations, and IT functions across Palo Alto Networks.\nYour Impact\nCollaborate with internal stakeholders to solve service requests\/issue resolution related to Data Governance\nEfficiently manage and execute against overall ticket queue to adhere to SLA requirements\nResearch and analyze public data to validate changes to account hierarchies, deduplication, and firmographic, etc.\nEnforce data standards, policies, and processes\nPerform mass data analysis and updates of account information to increase account accuracy\nExecute regular and periodic data maintenance and validation activities\nHandle issues and escalations to closure\nMonitor service request trends\nAssist in SLA design, development, and execution\nCollaborate with the Data Integrity and Policy Team on documentation of data standard and policies\nQualifications\nYour Experience\nInterest in the concerns and topics related to data maintenance\nCan execute tasks with high attention to detail and a commitment to accuracy\nOrganized, proactive individual that can operate independently in solving complex problems with little guidance\nStrong interpersonal skills for internal collaboration\nSkillfully manage requestor escalations through appropriate channels\nProficient in public data research and analysis\nExperience with SFDC is required\nExperience using data management tools such as SOQL\/ETL a big plus\nExperience working with Google Suite or similar platforms\nComfortable working in a fast-paced, dynamic work environment\nAbility to speak fluently in business language\nSpanish fluency considered a significant advantage\nAdditional Information\nThe Team\nOur Strategy & Operations team at Palo Alto Networks works on a set of strategic initiatives to drive process improvement projects to deliver improved efficiency and scale through simplification, automation and innovation across Sales Operations tools and processes.\nYou will be part of a growing, passionate, and dynamic team with an opportunity to work on challenging and exciting projects \u201a\u00c4\u00ec centered on what we believe is one of the most significant mission statements in the world.\nOur Commitment\nWe\u201a\u00c4\u00f4re trailblazers that dream big, take risks, and challenge cybersecurity\u201a\u00c4\u00f4s status quo. It\u201a\u00c4\u00f4s simple: we can\u201a\u00c4\u00f4t accomplish our mission without diverse teams innovating, together.\nWe are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.\nPalo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.\nAll your information will be kept confidential according to EEO guidelines.\nThe compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales\/commissioned roles) is expected to be between $81,900\/yr to $132,450\/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.\nShow more\nShow less",
      "job_skills":"Data Governance, Data Analysis, Data Management, Salesforce (SFDC), SOQL\/ETL, Google Suite, Data Standards, Data Policies, Data Validation, Data Accuracy, Data Maintenance, Data Integrity, Escalation Management, Public Data Research, Data Updates, Business Language, Spanish, Problem Solving, Interpersonal Skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Business Analyst - Salesforce (Hybrid)",
      "company":"Stryker",
      "job_location":"Flower Mound, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-business-analyst-salesforce-hybrid-at-stryker-3755979603",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Why join Stryker?\nWe are proud to be named one of the World\u201a\u00c4\u00f4s Best Workplaces and a Best Workplace for Diversity by Fortune Magazine! Learn more about our award-winning organization by visiting stryker.com\nAs a Senior Business Analyst, you will be responsible for the overall results in planning, requirements gathering, functional design, testing\/validation, and deployment of business sponsored system enhancements, projects, and issue resolutions.\u201a\u00c4\u00d8You will work with CRM Analysts, Subject Matter Experts, and Business Process Owners. You will gather and analyze data to ensure complete documentation of user stories (business requirements) and functional designs to align with defined business ROIs and success criteria.\u201a\u00c4\u00d8 You will also work with IT resources to translate business requirements to functional requirements to design system capabilities, while leveraging best practices.\nWho We Want:\nCollaborative partners.\nPeople who build and leverage cross-functional relationships to bring\ntogether ideas, data and insights to drive continuous improvement in functions.\nDedicated achievers.\nPeople who thrive in a fast-paced environment and will stop at nothing to\nensure a task or project is complete and meets regulations and expectations.\nStrategic thinkers.\nPeople who enjoy analyzing data, can review current state review application designs for the purposes of planning,\nforecasting, advising, budgeting, reporting and requirements gathering.\nWhat You Will Do:\nDeliver system enhancements and projects.\nEnsure the quality and data integrity of operational CRM systems.\nTranslate business requirements into working applications.\nDelivery of data governance and systems administration.\nPartner with CRM Analysts, SMEs, and Business Process Owners to analyze requests and strategize ROI-based prioritizations.\nFocus on Service business processes enabled through our commercial systems.\nCoordinate with IT counterparts on system enhancements and reported incidents \u201a\u00c4\u00ec accountable for timely and accurate delivery.\nAssist with Regression testing and stay connected to divisional and global CRM launches on our shared platform.\nResearch industry analysis around CRM and apply to job functions.\nStay up-to-date on CRM platform upgrades.\nWhat You Need:\nBachelor\u201a\u00c4\u00f4s degree\u201a\u00c4\u00d8in MIS, IT or Business Operations preferred.\nMinimum\u201a\u00c4\u00d82-5\u201a\u00c4\u00d8years of professional experience required.\nTechnical knowledge of Salesforce.com and Service Max; Service Max certification preferred.\nExperience of working in CRM, ERP and Business Applications preferred.\nAbility to work effectively in a matrix organization structure with significant emphasis on collaboration and persuasion, rather than relying entirely on command and control.\nExperience with process mapping preferred.\nDemonstrated ability to understand, evaluate and recommend changes to business processes preferred.\nKnowledge of Agile Development methodologies preferred.\n$65,400.00 - $132,300.00 salary plus bonus eligible + benefits. Actual minimum and maximum may vary based on location. Individual pay is based on skills, experience, and other relevant factors.\nAbout Stryker\nOur benefits:\n12 paid holidays annually\nHealth benefits include: Medical and prescription drug insurance, dental insurance, vision insurance, critical illness insurance, accident insurance, hospital indemnity insurance, personalized healthcare support, wellbeing program and tobacco cessation program.\nFinancial benefits include Health Savings Account (HSA), Flexible Spending Accounts (FSAs), 401(k) plan, Employee Stock Purchase Plan (ESPP), basic life and AD&D insurance, and short-term disability insurance.\nFor a more detailed overview of our benefits or time off, please follow this link to learn more: US Stryker employee benefits\nAbout Stryker\nStryker is one of the world\u201a\u00c4\u00f4s leading medical technology companies and, together with its customers, is driven to make healthcare better. The company offers innovative products and services in Medical and Surgical, Neurotechnology, Orthopaedics and Spine that help improve patient and healthcare outcomes. Alongside its customers around the world, Stryker impacts more than 130 million patients annually. More information is available at stryker.com.\nKnow someone at Stryker?\nBe sure to have them submit you as a referral prior to applying for this position. Learn more about our employee referral program on our referral page\nStryker is driven to work together with our customers to make healthcare better. Employees and new hires in sales and field roles that require access to customer accounts as a function of the job may be required, depending on customer requirements, to obtain various vaccinations as an essential function of their role.\nR508028\nShow more\nShow less",
      "job_skills":"Salesforce.com, Service Max, CRM, ERP, Agile Development, Process Mapping, Data Governance, Business Systems Administration, Business Requirements Gathering, Functional Design, Testing, Validation, Deployment",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst",
      "company":"Vizient, Inc",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-at-vizient-inc-3739149651",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"When you\u201a\u00c4\u00f4re the best, we\u201a\u00c4\u00f4re the best. We instill an environment where employees feel engaged, satisfied and able to contribute their unique skills and talents while living and working as their authentic selves. We provide extensive opportunities for personal and professional development, building both employee competence and organizational capability to fuel exceptional performance through an inclusive environment both now and in the future.\nJob Summary\nIn this role, you will analyze customer supply chain purchasing data. You will work directly with Provista\u201a\u00c4\u00f4s largest customers to identify savings opportunities, increase contract utilization and revenue, and provide customized solutions and insights to complex analytical questions.\nResponsibilities\nProduce high quality, accurate analyses, even when dealing with imperfect data.\nInteract with account managers and\/or customers to explain the analytics process and interpret the results.\nCustomize analyses as needed to address customer needs.\nTrack initiative results by customer to help quantify the value of the advisory analytics engagement.\nParticipate in the development and standardization of procedures, methodologies, and tools for conducting analyses and collecting data.\nInteract with internal and external contacts to resolve data issues.\nWork independently with minimal supervision, consulting with supervisor(s) on an as needed basis.\nDemonstrate teamwork and collaboration with customer service orientation.\nRequirements\nRelevant degree preferred.\n5 or more years relevant experience required.\nAdvanced knowledge of MS Excel and SQL required.\nHighly organized with exceptional attention to detail.\nStrong analytical, database, and spreadsheet skills required.\nStrong written and verbal communication skills.\nAbility to meet rigorous deadlines, balance multiple priorities and achieve high levels of productivity while maintaining a high level of accuracy.\nBroad knowledge of Vizient portfolio of products and services a plus.\nExperience with Power BI a plus.\nEstimated Hiring Range\n$68,500.00 - $99,400.00\nThis position is also incentive eligible.\nVizient has a comprehensive benefits plan! Please view our benefits here:\nhttp:\/\/www.vizientinc.com\/about-us\/careers\nEqual Opportunity Employer: Females\/Minorities\/Veterans\/Individuals with Disabilities\nThe Company is committed to equal employment opportunity to all employees and applicants without regard to race, religion, color, gender identity, ethnicity, age, national origin, sexual orientation, disability status, veteran status or any other category protected by applicable law.\nShow more\nShow less",
      "job_skills":"Data Analysis, Supply Chain Management, MS Excel, SQL, Power BI, Database Management, Spreadsheet Skills, Analytical Skills, Communication Skills, Project Management, Teamwork, Customer Service",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Workday Analyst",
      "company":"Sayva Solutions",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-workday-analyst-at-sayva-solutions-3772996885",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Title\nSenior Workday Analyst\nAbout The Opportunity\nWe're collaborating with multi-regional healthcare organization to identify a Senior Workday Analyst to design, develop and implement solutions to enhance performance . This individual will also develop custom reports, expand content capabilities, and work on special projects to meet client\/stakeholder needs. Heavy focus on configuration, integration, customization, and data management.\nSalary:\n$115,000-130,000 base + $10,000-15,000 bonus. W2 direct hire with full benefits.\nPlease note this range is an estimate and actual pay may vary based on qualifications and experience.\nLocation:\nOnsite 5 days per week in Irvine, TX or Irving, CA or Las Vegas, NV\nResponsibilities\nOversee day-to-day administration, upgrades and maintenance of Workday. Create, manage and support system standards, policies, procedures and documentation.\nCollaborate with, and occasionally lead, functional and cross functional teams to inform, prepare and assist in the review, testing and implementation of all system upgrades or patches and document the process, results and outcomes.\nProvide Workday production support, including, but not limited to, researching and resolving system problems, unexpected results or process flaws; performs scheduled activities; recommends solutions or alternate methods to meet business objectives.\nAnalyzes multiple databases and aggregate workforce data to produce data visualization dashboards and reports. Ensure ideal system configuration to support business processes.\nAudit, monitor and maintain data integrity. Identify, research and implement process improvements, as well as recommend training to address corrective measures. Develops reports related to on-going and ad hoc requests for workforce data.\nWrite, maintain and support a variety of complex custom and BIRT reports or queries utilizing system and organizational tools on a weekly, monthly, quarterly and\/or annual basis according customer needs. Assist in the management of security administration.\nIdentify root causes and provide updates and recommendations to leadership that will deliver a decrease in frequency and severity of system issues reported by end users. In addition, keeps up- to-date on system patches and new features and functionality.\nQualifications:\nBachelor\u201a\u00c4\u00f4s Degree in Computer Science, Human Resource, or related field and\/or equivalent combination of education and experience. In lieu of degree, +2 years of experience is required.\n3-5 years of experience with Human Resources Information Systems.\nMust have hands on Workday configuration, upgrade, integration, and customization experience.\nPreferred Qualifications\nExperience in a multi-regional healthcare, retail, or dental company.\nKnowledge of additional HR systems in addition to Workday.\nFamiliar with project management structure\/methodology.\nPHR\/SPHR or SHRM-CP\/SHRM-SCP\nMaster\u201a\u00c4\u00f4s Degree in Business, Statistics, MIS, or OD\nAbout Sayva:\nSayva Solutions is an accounting, finance, technology, and human resources professional services firm whose focus is on long term relationships created through teamwork and doing what is in the best interest of others. By working with Sayva to identify your next career move, you will get the benefit of working with an experienced team who not only has a strong network of trusted clients, but expertise in the markets, and functions, we serve. We can provide insight on what your market value is, what companies have to offer, and what opportunities align best with your professional and personal goals. We are your trusted advisor throughout your search process and can help ensure you are prepared for interviews, have the information to make the best decisions, and receive a strong offer to land you that perfect job. Making a career move is not easy and can be stressful; Sayva can be your partner in making the process smooth, transparent, and rewarding.\nShow more\nShow less",
      "job_skills":"Workday, System configuration, Data visualization, BIRT, HRIS, Project management, PHR\/SPHR, SHRMCP\/SHRMSCP, SQL, MIS, OD, Accounting, Finance, Human resources",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst",
      "company":"Vizient, Inc",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-at-vizient-inc-3741969335",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"When you\u201a\u00c4\u00f4re the best, we\u201a\u00c4\u00f4re the best. We instill an environment where employees feel engaged, satisfied and able to contribute their unique skills and talents while living and working as their authentic selves. We provide extensive opportunities for personal and professional development, building both employee competence and organizational capability to fuel exceptional performance through an inclusive environment both now and in the future.\nIn this role, you will support aptitude\u201a\u00c4\u00f4s Strategic Supplier Partnerships and Operations teams. You will perform complex analyses and develop solutions based on thorough and comprehensive research and technical expertise. You will interpret spend and clinical data to include identifying cost and clinical opportunities, preparing statistical and ad-hoc reporting, and drafting presentations. You will also provide reporting to verify and validate contract optimization and cost savings opportunities.\nResponsibilities\nSupport a team of consultants in the Strategic Supplier Partnership team.\nConduct analyses, research and\/or provide project, technical, or operational support.\nDesign and create charts, graphs, tables, and reports that supplement provider data and provide valuable insight to our providers through identification of unique data stories.\nEstablish strong working relationships and active communication with key internal and external stakeholders to effectively manage expectations.\nDeliver on a wide range of data analysis requests, including benchmarking, contracts and conversion, gap or needs assessment analysis, and supplier bid review.\nPresent recommendations to management and\/or external stakeholders and provides guidance in selecting alternatives with impact to the team or functional area\u201a\u00c4\u00f4s bottom line.\nQualifications\nRelevant degree preferred.\n5 or more years of relevant experience required.\nExpert knowledge in MS Excel and MS PowerPoint is required.\nExcellent communication and interpersonal skills.\nAdvanced Excel and PowerPoint skills.\nIntermediate to advanced knowledge of Access, SQL and\/or VBA, Power BI, Tableau, Salesforce CRM Analytics, or other data visualization tool highly preferred.\nSalesforce experience a plus.\nWillingness to travel.\nEstimated Hiring Range\n$68,500.00 - $99,400.00\nThis position is also incentive eligible.\nVizient has a comprehensive benefits plan! Please view our benefits here:\nhttp:\/\/www.vizientinc.com\/about-us\/careers\nEqual Opportunity Employer: Females\/Minorities\/Veterans\/Individuals with Disabilities\nThe Company is committed to equal employment opportunity to all employees and applicants without regard to race, religion, color, gender identity, ethnicity, age, national origin, sexual orientation, disability status, veteran status or any other category protected by applicable law.\nShow more\nShow less",
      "job_skills":"MS Excel, MS PowerPoint, Access, SQL, VBA, Power BI, Tableau, Salesforce CRM Analytics, Data visualization tools, Salesforce, Communication skills, Interpersonal skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Competition Analyst \/ Senior Competition Analyst",
      "company":"National Life Group",
      "job_location":"Addison, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/competition-analyst-senior-competition-analyst-at-national-life-group-3775690552",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Role And Description Of Duties\nCome join one of America\u201a\u00c4\u00f4s fastest growing insurance companies. We are looking for a talented individual to join our competitive analysis team. The primary responsibility of this role is to improve and maintain National Life Group\u201a\u00c4\u00f4s competitive intelligence, using industry and market data to identify and recommend opportunities to increase the marketing effectiveness of National Life Group\u201a\u00c4\u00f4s Life and Annuity products.\nIn this role, you will own assigned portions of the competitive intelligence platform and be responsible for innovating, improving, organizing, integrating, communicating, and maintaining competitive intelligence content to maximize utility to stakeholders. This includes compiling research and interpreting findings to build out our competitive story, while meeting frequently with key stakeholders to establish priorities and conduct research using competitive intelligence tools. You will report on findings and make recommendations utilizing slide decks, dashboards, databases, email, and presentations to deliver impactful results in a timely manner.\nSpecific Duties\nRetrieval, curation, and analysis of competitive intelligence from stakeholders, industry contacts and competitive intelligence tools.\nPrepare and give presentations for internal and external stakeholders regarding competitive positioning of National Life Group and its life and annuity products.\nCreation and execution of competitive benchmarking projects with regularly scheduled updates.\nCreation and maintenance of internal databases and other platforms to house quantitative and qualitative competitive product information.\nSome travel to attend competitive intelligence and relevant industry conferences.\nAssist internal and external sales force in competitive positioning.\nRequired Skills & Background\n3+ years of relevant experience with competitive intelligence and analysis\nWorking knowledge of Life Insurance and Annuities products preferred\nDesire to learn about all facets of our life and annuity markets.\nStrong analytical skills\nStrong presentation skills\nAptitude for market research\nInitiative\nSoftware\nMicrosoft Office (Excel and Outlook in Particular)\nThe base compensation range represents the low and high end of the range for this position. Actual compensation will vary and may be above or below the range based on various factors including but not limited to qualifications, skills, competencies, location, and experience. The range listed is just one component of our total compensation package for employees.\nOther rewards may include an annual bonus, quarterly bonuses, commissions, and other long-term incentive compensation, depending on the position. National Life offers a competitive total rewards package which includes: a 401(k) retirement plan match; medical, dental, and vision insurance; a company funded wellness account for director and below employees; 10 paid holidays; a generous paid time off plan (22 days of combined time-off for non-exempt employees and exempt employees have discretion in managing their time, including scheduling time off in the normal course of business, but in no event will exempt employees receive less sick time than required by state or local law); 6 weeks of paid parental leave; and 6 weeks of paid family leave after a year of full-time employment\nNational Life Group\u00ac\u00c6 is a trade name of National Life Insurance Company, Montpelier, VT \u201a\u00c4\u00ec founded in 1848, Life Insurance Company of the Southwest, Addison, TX \u201a\u00c4\u00ec chartered in 1955, and their affiliates. Each company of National Life Group is solely responsible for its own financial condition and contractual obligations. Life Insurance Company of the Southwest is not an authorized insurer in New York and does not conduct insurance business in New York. Equity Services, Inc., Member FINRA\/SIPC, is a Broker\/Dealer and Registered Investment Adviser affiliate of National Life Insurance Company. All other entities are independent of the companies of National Life Group.\nFortune 1000 status is based on the consolidated financial results of all National Life Group companies.\nNational Life Group\n1 National Life Dr\nMontpelier, VT 05604\nSocial Media Policy\nSite Disclosure and Privacy Policy\nShow more\nShow less",
      "job_skills":"Data Analysis, Market Research, Competitive Intelligence, Presentation Skills, Microsoft Office, Email, Dashboards, Slide Decks, Databases, Market Analysis, Life Insurance Products, Annuity Products, Quantitative Analysis, Qualitative Analysis, Sales Positioning",
      "Category":"Data Science"
  },
  {
      "job_title":"BI Analyst",
      "company":"Verdant Infotech Solutions",
      "job_location":"Copper Canyon, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/bi-analyst-at-verdant-infotech-solutions-3785511211",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"BI Analyst \/ No H1B\nVisa: No H1b ( Need genuine consultants)\nDuration: 6+ Months\nLocation: Fort Lauderdale, FL (Hybrid, need local of Fort Lauderdale)\nInterview: 2 Videos\nNeed: Updated LinkedIn with profile pic.\nJob Description\nREQUIRED SKILLS\n5 + YOE\nBI Analyst Exp\nShow more\nShow less",
      "job_skills":"BI Analyst, Data Analytics, 5+ years of experience",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior PowerBI Engineer and Data Analyst \/ Irving, TX",
      "company":"Motion Recruitment",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-powerbi-engineer-and-data-analyst-irving-tx-at-motion-recruitment-3771014914",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Our client is searching for a PowerBI \/ Data Analyst offering a Hybrid experience in Irving, Texas. This full-time position as an analyst that primarily works with PowerBI, DAX, SQL, and Azure.\nThis position is housed within the Automotive, Powersports, and Marine markets; specifically, they work within support of those markets to assist in maximization on performance. This position offers an office experience like no other as this client truly cares about their company culture. This BI\/Analyst role would have the chance for career growth in that you would be joining a growing office. This position is local to Irving, TX. This position offers flexibility as the remote portion of the position is approximately 1-2 days per week.\nRequired Skills & Experience\n2+ years with Data Analytics, PowerBI, and DAX\nAdvanced capabilities with SQL Development and Querying\nWorking knowledge Azure\nHas extensive experience dashboarding (building out from scratch and adding new features)\nReporting with SSIS\/SSRS\nDesired Skills & Experience\nETL processing is a plus\nAny additional Data Science or Statistical Modeling experience is welcome\nPrevious experience with NetSuite\nGreat to have Financial reporting experience or GAAP\nWhat You Will Be Doing\nTech Breakdown\n90% Hands-On\n10% Mentorship\nThe Offer\nBonus eligible\nYou Will Receive The Following Benefits\nMedical, Dental, and Vision Insurance\nPTO\nStock Options\nApplicants must be currently authorized to work in the US on a full-time basis now and in the future.\nPosted By:\nKatherine Spalding\nShow more\nShow less",
      "job_skills":"PowerBI, DAX, SQL, Azure, Data Analytics, SSIS, SSRS, ETL, NetSuite, Financial reporting, GAAP, Data Science, Statistical Modeling",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst I",
      "company":"WinMax",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-i-at-winmax-3742062438",
      "search_city":"Hollywood",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Title:Data Analyst I, Req# 26599518\nLocation:Austin,TX (Hybrid)\nContract:5+ Month\nJob Description\neCommerce Data Analyst\nCollect, structure, and manage product content and data for eCommerce and web data\ncollection projects. Extract content and data from different data sources and format in\nexcel. Work with vendors to map websites for automated data collection. Organize and\nstructure product data in different languages in files for automated data transfers.\nReview excel files with product data content, images, and videos for accuracy and\nstructure.\nSkills\nExcel, Box, Quip, Web Crawling, Data Extraction, Data Management, APIs, project\nmanagement, eCommerce project management, international ecommerce, telco\necommerce\nAdditional Details\nLarge-scale data entry\nShow more\nShow less",
      "job_skills":"Data Analysis, Excel, Box, Quip, Web Crawling, Data Extraction, Data Management, APIs, Project Management, eCommerce Project Management, International eCommerce, Telecommunications eCommerce, Largescale Data Entry",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst II",
      "company":"WinMax",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-ii-at-winmax-3759969751",
      "search_city":"Hollywood",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Title:Data Analyst II, Req# 27505019\nLocation: Austin,TX(Hybrid)\nContract: 5+ Month\nJob Description\nWW Digital Channel eCommerce Analytics Specialist\n(Analytics Platform)\nhe WW Digital Channel Team drives the development of digital strategies across client channels. It is creating a consistent brand experience in the digital world, whether it is on a partner\u201a\u00c4\u00f4s website or on global marketplaces or on social commerce. The WW Digital Channel Team serves as the center of expertise on eCommerce and will be instrumental in unlocking client\u201a\u00c4\u00f4s potential in maximizing customer experience, brand presence and sales growth across digital channels.\nWe are seeking an eCommerce Analytics Specialist to ideate, define, analyze, and optimize site analytics and KPIs for direct-to-consumer mobile, tablet and desktop digital experiences across global set of small-and-medium partners.\nThis analytics specialist role will focus on both end customer experiences across different eCommerce platforms and merchant tools working with client services, digital content, or analytics. This candidate will work with large external agencies, engineering teams, global client sales teams, UX designers, and various other cross-functional partners to propose, formulate, and deliver key insights to help improve the customer experience resulting in improved KPIs.\nCandidates with strong experience with Google Analytics setup, reporting, custom event creation, and custom reporting are ideal. Candidates who also have knowledge and experience working with business partners in identifying optimization opportunities in the buy funnel of an ecommerce site.\nKey Responsibilities\nOwn the reporting and setup for analytics for our Partner sites\nLeverage Google Analytics Universal and GA4 to analyze KPIs for optimization opportunities\nWork with large agencies and system integrators to implement, maintain integrations with GA4\nDevelop key metrics to measure and continually optimize the partner eCommerce sites\nBe abreast on market trends and new technology capabilities regarding ecommerce analytics to evaluate and recommend solutions\nBe abreast of GA4 features and improvements.\nKey Requirements\nExperience in ecommerce digital marketing\nExperience with Google Analytics Universal (required)\nExperience with Google Analytics 4 (nice to have)\nExperience with A\/B testing and other testing metrics\n2+ years experience in data crunching from top-tier consulting, investment banking, private equity or strategy\/business for a fast-growing global tech company\nAbility to move fast and be efficient, making decisions on objective evidence rather than subjective gut feel\nInnate desire to take ownership, make an impact and influence outcomes\nExcellent organizational skills, attention to detail and ability to work independently\nDrive Decision-Making: Use coding, analytics, and advanced modeling to understand project success, areas of opportunity, and make informed, strategic business decisions.\nLeverage Advanced Analytics to optimize marketing, sales performance, and make continuous improvements to the program.\n2+ years experience in a data-driven analytics or strategy role\nExperience building models, forecasts, budgets and dynamic reports with SQL, Tableau and Excel that provide meaningful direction and insight\nSkills that foster collaboration and team spirit\nExperience with data visualization and presentation (Tableau, Microsoft BI, or similar software)\nExperience preparing and delivering presentations tailored for a specific audience\nExperience setting, managing and reporting against multi-year plans, budgets, KPIs, milestones, roadmaps, etc.\nExcellent written, presentation and oral communication skills\nAction-oriented and enjoy working in a fast paced, dynamic environment\nEducation\nBachelors Degree\nOther Requirements\nShopify Site administration (nice to have)\nAdobe Analytics (nice to have)\nShow more\nShow less",
      "job_skills":"Data Analysis, eCommerce Analytics, Digital Marketing, Google Analytics, GA4, A\/B Testing, SQL, Tableau, Excel, Data Visualization, Team Collaboration, Business Intelligence, Presentation Skills, Budgeting, Roadmap Planning, Communication Skills, Shopify, Adobe Analytics",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Tech Mahindra",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-tech-mahindra-3786467407",
      "search_city":"Hollywood",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Role - data analyst\/scientist\nLocation - Austin TX - Onsite from day one\ndata analyst\/scientist with experience in web analytics using clickstream data analysis. Same skills as the other roles: Tableau and SQL, but they need to also have worked with clickstream data in the web analytics space for 2+ years\n\u00ac\u2211 Develop and maintain data analysis models and reports.\n\u00ac\u2211 Create dashboards and visualizations to communicate data insights to stakeholders.\n\u00ac\u2211 Work with cross-functional teams to identify and solve data-driven problems.\n\u00ac\u2211 Stay up-to-date on the latest data analytics trends and technologies.\n\u00ac\u2211 Maintain & improve standard, guidelines & templates with regards to reporting & visualization.\nShow more\nShow less",
      "job_skills":"Data analysis, Data visualization, SQL, Tableau, Clickstream data analysis, Reporting, Data modeling, Machine learning, Data mining, Statistics, Data warehousing, Data governance",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Infotree Global Solutions",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-infotree-global-solutions-3693757332",
      "search_city":"Lawton",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Collect, structure, and manage product content and data for eCommerce and web data collection projects. Extract content and data from different data sources and format in excel. Work with vendors to map websites for automated data collection. Organize and structure product data in different languages in files for automated data transfers. Review excel files with product data content, images, and videos for accuracy and structure.\nSkills:\nExcel, Box, Quip, Web Crawling, Data Extraction, Data Management, APIs, project management, eCommerce project management, international ecommerce, telco ecommerce\nAdditional Details\nLarge-scale data entry\nShow more\nShow less",
      "job_skills":"Data Collection, Data Entry, Data Extraction, Data Management, Excel, APIs, Project Management, eCommerce Project Management, International eCommerce, Telco eCommerce, Web Crawling",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"VeeAR Projects Inc.",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-veear-projects-inc-3782262400",
      "search_city":"Lawton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Title: Data Analyst\nDuration: 12+ months contract (possible extension)\nLocation: Austin, TX (Onsite)\nJob Description:\nData analyst\/scientist with experience in web analytics using clickstream data analysis.\nTableau and SQL, but they need to also have worked with clickstream data in the web analytics space for 2+ years.\nShow more\nShow less",
      "job_skills":"Data Analysis, Web Analytics, Clickstream Data Analysis, Tableau, SQL",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Quantitative Analyst",
      "company":"Hilltop Holdings",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-quantitative-analyst-at-hilltop-holdings-3778894474",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Hilltop Holdings Inc. (NYSE:HTH) is a Texas-based diversified financial holding company specializing in banking, mortgage origination, and financial advisory through its wholly owned subsidiaries, PlainsCapital Bank, PrimeLending, and HilltopSecurities.\nHilltop Holdings is looking for a Sr. Quantitative Analyst to lead various model development, implementation initiatives and related UAT related to CECL activities across Hilltop Holdings, which includes PlainsCapital Bank, PrimeLending, Hilltop Securities. These activities will be coordinated across a number of key stakeholders throughout the organization, including Finance, Accounting, Credit, Treasury, Enterprise Risk, and IT. The position will report to the Manager, Credit Analytics.\nResponsibilities:\nAssist in reviewing and running of the quantitative models and their related components (including PD, LGD, EAD, etc.) used for the Current Expected Credit Loss (CECL) estimate for each month and quarter. Review and analyze CECL results for trends and shifts.\nAssist in reviewing and running of the quantitative models to support Stress Testing processes.\nHelp develop sensitivity and scenario analysis to estimate the effects of changes in economic forecasts and other model assumptions on expected credit losses to inform decisions at ACL Working Group and Credit Committee meetings.\nCollaborate with Credit Underwriting, Special Assets, and Loan Review teams to test, verify, and document risk rating scorecard and core loan system inputs used in the allowance for credit loss estimates for each period are complete and accurate.\nAssist in economic and industry trends research to inform recommendations of U.S and regional economic forecasts for each month and each quarter to senior management during Asset Liability Committee.\nPerform various data analysis using credit data information to explain internal risk rating migrations, including transition matrices and segmentation analysis by vintage, delinquency, or other credit metrics. Ensure a high degree of data quality and accuracy.\nBuild and run data queries from multiple loan systems and prepare data to be used as input for quantitative models in the ACL calculation.\nSupport in preparing and maintaining of ACL documentation each quarter, including attribution and accounting memos, materials for working groups, executives and committees, model documentation and user guides, SOX control reviews and other credit presentations as needed.\nEngage data governance partners to establish processes and procedures to maintain the credit data warehouse each calendar period.\nPartner with enterprise data team to develop and maintain database structures to ensure efficient production of management reports and dashboards using Power BI and Tableau.\nSupport in undertaking on-going performance monitoring tests and procedures for credit models used in ACL processes, produce recurring reports evaluating the on-going performance of the models and recommend enhancements as appropriate.\nHelp coordinate interim reviews and annual audits of ACL processes with Model Risk Management (MRM) and internal\/external auditors.\nDevelop and maintain linear, time series, and\/or survival\/logistic regression models used in various forecasting exercises\nOwn various tasks within the model development process, including new model exploration and specification, data analysis, exploration, and collaboration to verify\/validate model hypothesis, development testing and implementation of test models into production systems, and on-going monitoring, maintenance, and reporting\nPresent and defend model results to executive leadership, internal stakeholders, including Model Risk Management\nCoordinates deliverables for model risk management validations and periodic reviews and assists in the assessment and mitigation of model risk.\nEnsure a high degree of data quality and accuracy in all model results and reporting\nOther duties and functions as needed.\nQualifications:\nBachelor of Arts \/Bachelor of Science or equivalent degree in finance, mathematics, statistics, economics, engineering, or related quantitative discipline required. (Graduate degree is a plus).\n5 years\u201a\u00c4\u00f4 (Undergraduate degree) or 3 plus years\u201a\u00c4\u00f4 (Graduate degree) experience in loss forecasting, risk modeling, credit risk management or stress testing at a commercial bank or similar financial institution or public accounting firm.\nExperience working with complex data structures, queries, reporting, and related data systems and demonstrate at least intermediate level skill with SQL. MS SQL Server is a plus.\nExperience using Tableau or Power BI to manipulate, analyze, and visualize large, complex data sets and advance level in excel.\nAbility to prioritize and manage multiple tasks successfully, be detail oriented and operate under scheduled project deadlines.\nDemonstrate excellent written and verbal communication skills with an ability to influence others.\nPrior experience with credit risk vendor models such as Moody\u201a\u00c4\u00f4s Impairment Studio, CMM, RiskCalc, MPA or CreditLens.\nShow more\nShow less",
      "job_skills":"SQL, MS SQL Server, Tableau, Power BI, Excel, Mathematical Modeling, Statistical Analysis, Financial Analysis, Risk Management, Stress Testing, Credit Risk, Loan Analysis, Data Analysis, Data Mining, Data Visualization, Economic Forecasting, Moody's Impairment Studio, CMM, RiskCalc, MPA, CreditLens, Regression Analysis, Time Series Analysis, Survival Analysis, Logistic Regression, Data Warehousing, Data Governance, Model Development, Model Validation, Model Risk Management, Model Documentation, Model Implementation, Model Maintenance, Model Monitoring, Model Reporting, Quantitative Finance",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst Staff - Level 4",
      "company":"Lockheed Martin",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-staff-level-4-at-lockheed-martin-3789751845",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"We are\nLockheed Martin\nThe position is on the Performance & Decision Analytics Data Staging team within the F-35 Sustainment DSA organization.\nResponsibilities to include: Perform in the role of Product Owner and Technical Lead to drive the execution\/creation and deliver of the D005 Contract Deliverable: 1) Aid in the Assessment of Data Model Elements\/Attributes 2) Construct and deliver contractually obligated data set 3) compare and contrast historical changes\/performance over time of data elements\/attributes 4) Document processes and procedures to construct data model attributes & attributes 5) Delivery of Data Set and GR&A Documentation.\nPerform Modeling, Simulation & Analysis (MS&A) in support of F-35 Sustainment.\nOperate in a big data (high volume, high velocity, high complexity) environment and apply modeling & simulation technical principles, concepts and techniques to assess Performance Based Logistics (PBL) metrics using commercial, government, and LM developed tools\nSupport coordination and development of problem statements, modeling approaches and ground rules and assumptions (GR&A)\nWork as a technical lead and provide guidance to perform analysis to establish data sets that would be used to perform sustainment modeling activities.\nAnalyze F-35 fielded performance developing solutions to assigned problems for the purpose of forecasting, root cause analysis, evaluation of potential solutions, and assessment of corrective actions.\nMust be a US Citizen; This position is located at a facility that requires special access.\nA level 4 employee\nTypically has 9 - 15 years\nof professional experience.\nWhat\u201a\u00c4\u00f4s In It For You\nOur employees play an active role in strengthening the quality of life where we live and work by volunteering more than 850,000 hours annually. Here are some of the benefits you can enjoy:\nMedical\nDental\n401k\nPaid time off\nWork\/life balance\nCareer development\nMentorship opportunities\nRewards & recognition\nLearn more about Lockheed Martin\u201a\u00c4\u00f4s comprehensive benefits package here.\nThis position is in Fort Worth, TX\nDiscover Fort Worth.\nShow more\nShow less",
      "job_skills":"Performance Based Logistics (PBL), Data Modeling, Modeling Simulation & Analysis (MS&A), Big Data, Technical Principles, Concepts, Techniques, Data Sets, Ground Rules and Assumptions (GR&A), F35, Forecasting, Root Cause Analysis, Corrective Actions",
      "Category":"Data Science"
  },
  {
      "job_title":"Report Analyst",
      "company":"Williams-Sonoma, Inc.",
      "job_location":"Arlington, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/report-analyst-at-williams-sonoma-inc-3784070742",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"About Williams Sonoma - Arlington, TX\nSince it was founded in 1956, Williams - Sonoma has grown from Chuck Williams\u201a\u00c4\u00f4 single store in Sonoma, CA into one of the largest retailers in the country, with some best known and most beloved brands in home furnishings, including Williams \u201a\u00c4\u00ec Sonoma. Pottery Barn and West Elm.\nOur Distribution Centers serve as vital connections between factories and our retail, online and mail-order customers around the world. The Supply Chain environment is dynamic and fast-paced, and the network is expanding rapidly. If you have a background in distribution, manufacturing, engineering, transportation, finance, human resources or home delivery \u201a\u00c4\u00ec and are looking for a job with a strong opportunity for gaining new skills and for advancement \u201a\u00c4\u00ec our Supply Chain Organization could be just the place for you.\nWilliams-Sonoma, Inc Supply Chain Overview\nIn 2023, Williams-Sonoma was recognized as a Great Place to Work \u00ac\u00c6 and Forbes Best Employers for Diversity, honors which reflect that we are truly a people-first organization. Our operation includes:\nOver 4,000 Full-Time Associates across the Supply Chain\n15.1M square feet of small parcel, personalization, furniture, and manufacturing space in the domestic US, Williams-Sonoma has developed an agile and capable distribution network consisting of the following:\nLarge package \/ furniture distribution centers located in Southern California, Northern California, Texas, Georgia, and New Jersey totaling 9.2M square feet plus another 1.2M square feet of standalone final-mile furniture hubs.\nSmall package eCommerce distribution centers located in Mississippi, Arizona, and Tennessee totaling 3.9M square feet, consisting of over 1,000 full-time associates and 1,500 seasonal\/temporary associates in Mississippi and Tennessee\nManufacturing facilities located in North Carolina and Mississippi totaling 861k square feet with over 1,500 full-time employees producing approximately $900 million - $1 billion in sales of upholstered furniture3 Sutter Street Upholstery Factories located in North Carolina and Mississippi with over 1,400 FTE\u201a\u00c4\u00f4s producing approximately $900 million to $1 Billion in sales of Upholstered furniture\nTransportation Department for Ocean, Air, Trucking, and Rail consisting of over 30 transportation professionals located in Memphis, TN\n700 associates in our Sourcing offices in 10 countries in Asia and Europe including China, Vietnam, Singapore, India, Italy, and Turkey\nThe\nReport Analyst\nposition is located in\nArlington, TX\n.\nYou'll be excited about this opportunity because you will\n....\nResolutions for potential problems resulting in inefficiencies\nAbility to make recommendations for future Business Unit KPI\u201a\u00c4\u00f4s\nAbility to generate forecasting tools\nGenerate reports to execute on analysis of performance and results to create improvements within operations\nIdentifies underperforming areas and suggest recommendations for cost improvement\nWorks with all departments to identify optimal performance areas\nDevelop and document internal processes\nAssist in providing internal and external data requests\nTranslate stakeholder\u201a\u00c4\u00f4s requirements into reporting deliverables\nAssist analyst team with dashboard and report generation\nMay be assigned special ad hoc duties as assigned\nInterpret data, analyze results using statistical techniques and provide ongoing reports\nDevelop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality\nAcquire data from primary or secondary data sources and maintain databases\/data systems\nCheck out some of the required qualifications we are looking for in amazing candidates\u201a\u00c4\u00b6\n.\nHigh School Diploma or Equivalent\nAdvanced proficiency with MS Office Suite\nQlikView and\/or Crystal SAP experience\nExhibits exceptional organizational, analytical and problem-solving skills\nAbility to frequently communicate orally, write, read, comprehend, reason, and perform basic mathematic calculations and analyze1-4 years of data analysis experience\nExtensive experience, working knowledge of computers, especially in data extract\/reporting software, and power BI\nExpertise in delivery technologies and data access, including familiarity with metadata, data organization, data quality assessment and data profiling\nWe prefer some of these qualities as well\u201a\u00c4\u00b6.\nBachelor\u201a\u00c4\u00f4s degree preferred or 5 years of progressive experience in Supply Chain\nOur company benefits are second to none in the industry\u201a\u00c4\u00b6.\nGenerous discount on all Williams-Sonoma, Inc. brand products\n401(k) plan and other investment opportunities\nPaid vacations, Employee Assistance Programs, Time Off to Volunteer, Matching Gifts Community Service Program, and Holidays (in some locations)\nHealth benefits, dental and vision insurance, including same-sex domestic partner benefits, Legal and Identity Protection Plans and Pet Insurance\nFor more information on our benefits offerings, please visit MyWSIBenefits.com\nEOE\nShow more\nShow less",
      "job_skills":"MS Office Suite, QlikView, Crystal SAP, Power BI, Data extract\/reporting software, Metadata, Data organization, Data quality assessment, Data profiling, Statistics, Forecasting, Data Analytics, Data collection",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"IDR, Inc.",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-idr-inc-3765249608",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"IDR is seeking a\nData Analyst\nto join one of our top clients in Fort Worth, TX. If you are looking for an opportunity to join a large organization and work within an ever-growing team-oriented culture, please apply today!\nPosition Overview For The Data Analyst\nWorking with IT Solutions to build out a Data Warehouse systems\nWill report to the Sr. Data Analyst\nBuilding dashboards day-today\nQuality control for analytics\nRequired Skills for the Data Analyst:\n2+ years of experience working as a Data Analyst\n2+ years of experience building out dashboards using Power BI and Excel\nPrior experience writing\/utilizing SQL queries from scratch\nProfessional experience working in a Microsoft environment using Azure\nPrior experience working with AI predictive models\nBachelor\u201a\u00c4\u00f4s Degree or equivalent\nWhat\u201a\u00c4\u00f4s in it for you?\nCompetitive compensation package\nFull Benefits; Medical, Vision, Dental, and more!\nOpportunity to get in with an industry leading organization\nClose-knit and team-oriented culture\nWhy IDR?\n20+ Years of Proven Industry Experience in 4 major markets\nEmployee Stock Ownership Program\nDedicated Engagement Manager who is committed to you and your success\nMedical, Dental, Vision, and Life Insurance\nClearlyRated\u201a\u00c4\u00f4s Best of Staffing\u00ac\u00c6 Client and Talent Award winner 10 years in a row\nShow more\nShow less",
      "job_skills":"Data Analysis, Power BI, Excel, SQL, Microsoft Azure, AI Predictive Modeling",
      "Category":"Data Science"
  },
  {
      "job_title":"Oracle ERP business Analyst",
      "company":"Akkodis",
      "job_location":"Lewisville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/oracle-erp-business-analyst-at-akkodis-3782058325",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"The ideal candidate will be responsible for performing as a Junior to midlevel Oracle ERP Business Analyst\nRole: Oracle ERP Business Analyst\nLocation: Dallas, Texas, United States onsite-hybrid\nDuration: Contract to hire\nPay 45\/hr on w2 and conversion salary is 85000\/year\nTop 3-5 Technical Skills:\nSKILLS:\nOracle ERP\nBusiness Analysis\nData Management to support large-scale, complex planning projects, with a focus on continuous improvement and process optimization.\nEngaging with the business stakeholders to understand the business process, data, and challenges, and partner with the business product owners on user story development.\nPerforming a fit-gap analysis to identify which business needs\nReporting & Dashboards- Needs to be able to create HR reports and dashboards.\nPreferred Skills:\n\u00ac\u2211 Accounting\/Costing, TRS & HRIS reporting highly valuable\nEqual Opportunity Employer\/Veterans\/Disabled\nTo read our Candidate Privacy Information Statement, which explains how we will use your information, please visit https:\/\/www.akkodis.com\/en-us\/candidate-privacy\/\nThe Company will consider qualified applicants with arrest and conviction records.\nShow more\nShow less",
      "job_skills":"Oracle ERP, Business Analysis, Data Management, User Story Development, FitGap Analysis, Reporting & Dashboards, HR Reporting, Accounting\/Costing, TRS & HRIS Reporting",
      "Category":"Data Science"
  },
  {
      "job_title":"BI analyst",
      "company":"Verdant Infotech Solutions",
      "job_location":"Copper Canyon, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/bi-analyst-at-verdant-infotech-solutions-3785510298",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Title: BI analyst\nLocation: fort Lauderdale, FL ( Need Local of fort Lauderdale who can go on site) ( We can try from Southern FL other cities but prefer first from Fort Lauderdale)\nVias: USC and GC ( Need Genuine only)\nDuration: Long term\nInterview: 2 Videos but must be comfortable to go onsite if needed.\nNote: Need updated LinkedIn with Profile pic.\nJob Description\nHave a technical skill-set with experience in at least 2 of the following: SQL, Tableau, Excel or PowerBI.\nHave a positive, aspirational personality, with the ability to be both flexible and innovative.\nBe equally friendly and passionate, as you will be working with others to cultivate data.\nHave deep technical knowledge in business intelligence, data warehouses, data analysis and visualisation tools and technologies.\n|\n,\n5208 Windsor Ln, Copper Canyon, Texas, 75077\nShow more\nShow less",
      "job_skills":"SQL, Tableau, Excel, PowerBI, Data warehouses, Data analysis, Data visualization, Business intelligence",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr Analyst - Advanced Business Analytics",
      "company":"Ally",
      "job_location":"Lewisville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-analyst-advanced-business-analytics-at-ally-3750635960",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Ally and Your Career\nAlly Financial only succeeds when its people do - and that\u201a\u00c4\u00f4s more than some clich\u221a\u00a9 people put on job postings. We live this stuff! We see our people as, well, people - with interests, families, friends, dreams, and causes that are all important to them. Our focus is on the health and safety of our teammates as well as work-life balance and diversity and inclusion. From generous benefits to a variety of employee resource groups, we strive to build paths that encourage employees to stretch themselves professionally. We want to help you grow, develop, and learn new things. You\u201a\u00c4\u00f4re constantly evolving, so shouldn\u201a\u00c4\u00f4t your opportunities be, too?\nThe Opportunity\nAs a part of the Passthrough Lender Management team, the Analytics Analyst is responsible for portfolio risk management and identifying growth and profit opportunities. Provide support on stages of database implementation and\/or database related deployments. Individual will have the ability to work independently and to resolve complex database issues and work with development teams to tune SQL queries with emphasis on troubleshooting performance and non-performance related issues either independently or in conjunction with other teams including proactive monitoring of the databases, manage backup\/recovery functions and ability to develop data requirements and configure database parameters accordingly. In addition, the position may include completing due diligence \/ financial analysis on comprehensive and administrative reviews associated with lenders, management of third-party vendors, and projects as assigned. Responsibilities include passthrough lender interface \/ service, monitoring of company lending portfolio with concentration on areas of risk mitigation. Requires critical analysis and frequent contact with passthrough lender personnel, matrix partners, outside stakeholders, and vendors. Considered analytical or procedural experts representing a unit or team on cross-function process or project deliverables.\nThe Work Itself\nProvide analytical and data support in the design and review of strategy tests and current operations.\nAnalyze monthly operating results and monthly variances; identify problems and research potential recommendations for corrective actions.\nPerform portfolio analytics, special projects, drill --down analysis and other duties as needed.\nApply sound control processes into daily\/weekly\/monthly processes to effectively identify, assess and manage risk.\nMaintain code logic to pull, sanitize, aggregate, conform, and produce operational and portfolio-level reports accurately.\nCollaboratively work with matrix & vendor partners to ensure alignment with strategic imperatives.\nPerform special analytics projects and other duties as assigned.\nInterface with various stakeholders within asset performance, credit risk, finance and strategy and analytics organizations to provide timely and accurate analysis.\nAble to deliver accurate results within expected deadlines.\nSkills\nThe Skills You Bring\nBachelor\u201a\u00c4\u00f4s degree preferred; BS or BA in Finance, Economics, Accounting, Information Technology or related field.\n3+ years' experience in similar or equivalent position preferred.\nExperience and knowledge of consumer financing industry (e.g. auto, card, mortgage etc.).\nDemonstrate a solid understanding of data mining and analytical techniques.\nCandidate should possess outstanding analytical and problem-solving skills.\nMinimum 2 years of practical experience working with large datasets with SAS and\/or SQL knowledge.\nQuick learner and has demonstrated ability to initiate, develop and execute small to medium scale projects.\nWork well within a team of analysts and collaborate with individuals with technical and non-technical backgrounds.\nCandidate must have strong attention to detail.\nExcellent written and verbal communication skills, including the ability to effectively present material\nData visualization and communication skills required.\nExpertise with business software like Excel, SQL, Tableau, PowerBI, Visio, PowerPoint\nExtraction of meaningful data from multiple databases, analyze data, independently identify trends, and translate these findings to drive business informed decisions\nHow We'll Have Your Back\nAlly's compensation program offers market-competitive base pay and pay-for-performance incentives (bonuses) based on achieving personal and company goals. Our Total Rewards program includes industry-leading compensation and benefits plus additional incentives that are designed to meet your needs and those of your family so you can get the most out of your career and your life, including:\nTime Away: 11 paid holidays, 20 paid time off days, and 8 hours of volunteer time off, yearly (paid time off is prorated based on start date)\nPlanning for the Future: plan for the near and long term with an industry-leading 401K retirement savings plan with matching and company contributions, student loan pay downs and 529 educational save up assistance programs, tuition reimbursement, employee stock purchase plan, and financial learning center and financial coach access.\nSupporting your Health & Well-being: flexible health and insurance options including medical, dental and vision, employee, spouse and child life insurance, short- and long-term disability, pre-tax Health Savings Account with employer contributions, Healthcare FSA, critical illness, accident & hospital indemnity insurance, and a total well-being program that helps you and your family stay on track physically, socially, emotionally, and financially.\nBuilding a Family: adoption, surrogacy and fertility assistance as well as paid parental and caregiver leave, Dependent Day Care FSA back-up child and adult\/elder care days and childcare discounts.\nWork-Life Integration: other benefits including Mentally Fit Employee Assistance Program, subsidized and discounted Weight Watchers\u00ac\u00c6 program and other employee discount programs.\nOther compensations: depending on the role for which you are considered, you may be eligible for travel allowances, relocation assistance, a signing bonus and\/or equity.\nTo view more detailed information about Ally\u201a\u00c4\u00f4s Total Rewards, please visit this link: https:\/\/www.ally.com\/content\/dam\/pdf\/corporate\/ally-total-rewards-snapshot.pdf\nWho We Are:\nAlly Financial is a customer-centric, leading digital financial services company with passionate customer service and innovative financial solutions. We are relentlessly focused on \"Doing it Right\" and being a trusted financial-services provider to our consumer, commercial, and corporate customers. For more information, visit www.ally.com.\nAlly is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to age, race, color, sex, religion, national origin, disability, sexual orientation, gender identity or expression, pregnancy status, marital status, military or veteran status, genetic disposition or any other reason protected by law.\nWe are committed to working with and providing reasonable accommodation to applicants with physical or mental disabilities. For accommodation requests, email us at work@ally.com. Ally will not discriminate against any qualified individual who is capable of performing the essential functions of the job with or without reasonable accommodation.\nBase Pay Range\n: An individual's position in the range is determined by the scope and responsibilities of the role, work experience, education, certification(s), training, and additional qualifications. We review internal pay, the competitive market, and business environment prior to extending an offer.\nEmerging\n85000\nExperienced\n117500\nExpert\n150000\nIncentive Compensation: This position is eligible to participate in our annual incentive plan.\nShow more\nShow less",
      "job_skills":"SAS, SQL, Data mining, Data analytics, Problemsolving, Data visualization, Communication, Tableau, PowerBI, Visio, PowerPoint, Excel",
      "Category":"Data Science"
  },
  {
      "job_title":"Research Analyst - Hybrid Position located in Lewisville, TX",
      "company":"BayMark Health Services",
      "job_location":"Lewisville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/research-analyst-hybrid-position-located-in-lewisville-tx-at-baymark-health-services-3784855783",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description\nPosition at BayMark Health Services\nResearch Analyst\nJob Summary\nThe Research Analyst works directly with healthcare data to produce actionable insights in support of BayMark\u201a\u00c4\u00f4s Clinical Outcomes and Research Program. This position will also support scholarly activities (e.g., data analysis, presentation and manuscript creation) for BayMark\u201a\u00c4\u00f4s internal and extramurally-funded (NIH) research projects. To accomplish these goals, the Research Analyst will work extensively with electronic health record systems, statistical software (e.g., SPSS), and Microsoft Office. This position will work under direct supervision of the Director of Clinical Outcomes and Research. Minimal travel expected.\nEssential Duties & Responsibilities\nExtract and compile clinical data from electronic sources into usable formats (e.g., Excel).\nRegularly access and extract data from multiple electronic health records (EHR) systems.\nCollate EHR data reports contained within electronic systems.\nMerge data from multiple sources into one usable data record (e.g., Excel) for patient outcomes tracking and analysis.\nEvaluates and maintains data quality by regularly assessing the accuracy, consistency, integrity, and validity of data.\nOngoing evaluation of data quality from sources accessed\/created in Essential Job Function 1.\nIdentifies missing data, incorrect data, or general inconsistencies to be addressed.\nEnsures proper data handling and storage consistent with HIPAA\/42 CFR Part 2 requirements.\nAssists Director of Clinical Outcomes and Research with identifying processes to maintain and increase data quality throughout the Company.\nAssists with data analysis, identification of data trends, and creation of charts, graphs, reports, and presentations.\nFamiliarization with common statistical methodologies and techniques relevant to healthcare data.\nAssists with statistical analysis of data using common statistical and data-query packages (e.g., Excel, SPSS, Power BI).\nCreates charts\/graphs within Excel or other data visualization programs as needed for reports, dashboards, manuscripts\/grant applications, and\/or other presentations.\nAssists with the preparation of presentations for internal meetings, stakeholders, policymakers, and\/or conference presentations.\nServes as a project manager\/assistant for ongoing research and outcomes projects.\nAssists with documentation, scheduling, and general oversight of research projects.\nAttends recurring project meetings\nOther Duties & Responsibilities.\nOperates within budgetary constraints.\nAdheres to company policies and procedures.\nOther duties as assigned.\nRegular attendance is to be maintained.\nAdherence to a code of conduct conducive with BayMark Health Services policy is expected.\nMeet or exceed delivery of Company Service Standards in a consistent fashion.\nInteract with all staff in a positive and motivational fashion supporting the Company\u201a\u00c4\u00f4s mission.\nConduct all business activities in a professional and ethical manner.\nQualifications\nMinimum age requirement of 18.\nMinimum 2 years college. (Bachelor or Master degree preferred)\nMinimum 2 years of experience as a research assistant or similar position.\nKnowledge and skills with Microsoft products and general computer literacy with strong proficiency with Excel.\nKnowledge of basic statistical methodologies and techniques.\nIntrinsically motivated with demonstrated organizational skills.\nVery high level of attention to details.\nExcellent interpersonal and communication (both verbal and written skills).\nInquisitive\/curious about research and addiction healthcare.\nGood with numbers and able to draw insights from large amounts of information\/data.\nSatisfactory references from employers and\/or professional peers.\nAbility to work in an interdisciplinary setting.\nSatisfactory criminal background check and drug screen.\nSelf-directed with ability to work with little supervision.\nAbility to provide satisfactory written documentation in a timely manner.\nFlexible and cooperative in fulfilling all obligations.\nBenefits\nCompetitive salary\nComprehensive benefits package including medical, dental, vision and 401(K)\nGenerous paid time off accrual\nExcellent growth and development opportunities\nCOVID-19 Considerations\nEveryone will be asked to be in compliance with the most recent COVID guidelines from CDC, State, County and City.\nHere Is What You Can Expect From Us\nBayMark Health Services,\nprogressive substance abuse treatment organization, is committed to the highest quality of patient care in a comfortable outpatient clinic setting. Our ultimate goal is to address the physical, emotional, and mental aspects of opioid use disorder to help each of our patients achieve long-term recovery and an improved quality of life.\nBayMark Health Services\nis committed to Equal Employment Opportunity (EEO) and to compliance with all Federal, State and local laws that prohibit employment discrimination on the basis of race, color, age, natural origin, ethnicity, religion, gender, pregnancy, marital status, sexual orientation, citizenship, genetic disposition, disability or veteran\u201a\u00c4\u00f4s status or any other classification protected by State\/Federal laws.\nShow more\nShow less",
      "job_skills":"EHR, SPSS, Microsoft Office, Excel, Power BI, Statistical Analysis, Data Visualization, Research Assistant, Microsoft Products, Data Management, Data Quality Assurance, Data Query Packages, Charting and Graphing, Statistical Methodologies, DataQuery Packages, Data Analysis, Project Management, Budget Management, Attention to Detail, Interpersonal Communication, Verbal Communication, Written Communication, Analytical Skills, ProblemSolving, Collaboration, SelfDirected Work, Written Documentation, Employee Benefits",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst - Advanced Business Analytics",
      "company":"Ally",
      "job_location":"Lewisville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-advanced-business-analytics-at-ally-3779824984",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Ally and Your Career\nAlly Financial only succeeds when its people do - and that\u201a\u00c4\u00f4s more than some clich\u221a\u00a9 people put on job postings. We live this stuff! We see our people as, well, people - with interests, families, friends, dreams, and causes that are all important to them. Our focus is on the health and safety of our teammates as well as work-life balance and diversity and inclusion. From generous benefits to a variety of employee resource groups, we strive to build paths that encourage employees to stretch themselves professionally. We want to help you grow, develop, and learn new things. You\u201a\u00c4\u00f4re constantly evolving, so shouldn\u201a\u00c4\u00f4t your opportunities be, too?\nThe Opportunity\nReporting to the Director of Strategy & Analytics, this position's primary responsibilities will include strategy development and performance analysis to optimize portfolio results. The ideal candidate must be passionate about delivering results, must be an innovative and strategic thinker, willing to challenge status quo, can learn quickly, is self-motivated, detail oriented, and can sift through voluminous amounts of information to pinpoint which items are relevant to understanding Business results. They will be able to apply knowledge of business and balanced judgment in interpretation of data (analytics).\nThe Work Itself\nProvide analytical and data support in the design and review of strategy tests and current operations.\nAnalyze monthly operating results and monthly variances; identify problems and research potential recommendations for corrective actions.\nPerform portfolio analytics, special projects, drill down analysis and other duties as needed.\nApply sound control processes into daily\/weekly\/monthly processes to effectively identify, assess, and manage risk.\nMaintain code logic to pull, sanitize, aggregate, conform, and produce operational and portfolio-level reports accurately.\nCollaboratively work with matrix & vendor partners to ensure alignment with strategic imperatives.\nPerform special analytics projects and other duties as assigned.\nInterface with various stakeholders within asset performance, credit risk, finance and strategy and analytics organizations to provide timely and accurate analysis.\nAble to deliver accurate results within expected deadlines.\nSkills\nThe Skills You Bring\nBachelor\u201a\u00c4\u00f4s degree preferred; BS or BA in Finance, Economics, Accounting, Mathematics, Information Technology or related field.\n3+ years' experience in similar or equivalent position preferred.\nExperience and knowledge of consumer financing industry (e.g. auto, card, mortgage etc.).\nCandidate should possess outstanding analytical and problem-solving skills.\nMinimum 2 years of practical experience working with large datasets with SQL and\/or SAS knowledge.\nQuick learner and has demonstrated ability to initiate, develop and execute small to medium scale projects.\nWork well within a team of analysts and collaborate with individuals with technical and non-technical backgrounds.\nCandidate must have strong attention to detail.\nExcellent written and verbal communication skills, including the ability to effectively present material\nBasic knowledge of statistics and models preferred\nExperience with designing and implementing champion challenger strategies preferred.\nAdvanced knowledge in developing analysis queries and procedures in SQL and\/or SAS preferred.\nHow We'll Have Your Back\nAlly's compensation program offers market-competitive base pay and pay-for-performance incentives (bonuses) based on achieving personal and company goals. Our Total Rewards program includes industry-leading compensation and benefits plus additional incentives that are designed to meet your needs and those of your family so you can get the most out of your career and your life, including:\nTime Away: 11 paid holidays, 20 paid time off days, and 8 hours of volunteer time off, yearly (paid time off is prorated based on start date)\nPlanning for the Future: plan for the near and long term with an industry-leading 401K retirement savings plan with matching and company contributions, student loan pay downs and 529 educational save up assistance programs, tuition reimbursement, employee stock purchase plan, and financial learning center and financial coach access.\nSupporting your Health & Well-being: flexible health and insurance options including medical, dental and vision, employee, spouse and child life insurance, short- and long-term disability, pre-tax Health Savings Account with employer contributions, Healthcare FSA, critical illness, accident & hospital indemnity insurance, and a total well-being program that helps you and your family stay on track physically, socially, emotionally, and financially.\nBuilding a Family: adoption, surrogacy and fertility assistance as well as paid parental and caregiver leave, Dependent Day Care FSA back-up child and adult\/elder care days and childcare discounts.\nWork-Life Integration: other benefits including Mentally Fit Employee Assistance Program, subsidized and discounted Weight Watchers\u00ac\u00c6 program and other employee discount programs.\nOther compensations: depending on the role for which you are considered, you may be eligible for travel allowances, relocation assistance, a signing bonus and\/or equity.\nTo view more detailed information about Ally\u201a\u00c4\u00f4s Total Rewards, please visit this link: https:\/\/www.ally.com\/content\/dam\/pdf\/corporate\/ally-total-rewards-snapshot.pdf\nWho We Are:\nAlly Financial is a customer-centric, leading digital financial services company with passionate customer service and innovative financial solutions. We are relentlessly focused on \"Doing it Right\" and being a trusted financial-services provider to our consumer, commercial, and corporate customers. For more information, visit www.ally.com.\nAlly is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to age, race, color, sex, religion, national origin, disability, sexual orientation, gender identity or expression, pregnancy status, marital status, military or veteran status, genetic disposition or any other reason protected by law.\nWe are committed to working with and providing reasonable accommodation to applicants with physical or mental disabilities. For accommodation requests, email us at work@ally.com. Ally will not discriminate against any qualified individual who is capable of performing the essential functions of the job with or without reasonable accommodation.\nBase Pay Range\n: An individual's position in the range is determined by the scope and responsibilities of the role, work experience, education, certification(s), training, and additional qualifications. We review internal pay, the competitive market, and business environment prior to extending an offer.\nEmerging\n85000\nExperienced\n117500\nExpert\n150000\nIncentive Compensation: This position is eligible to participate in our annual incentive plan.\nShow more\nShow less",
      "job_skills":"SQL, SAS, Statistics, Financial Analytics, Business Intelligence, Data Visualization, Data Interpretation, Problem Solving, Attention to Detail, Project Management, Stakeholder Management, Communication Skills, Teamwork, Analytical Thinking, Strategic Thinking, Business Knowledge, Champion Challenger Strategies, SQL Queries, SAS Procedures",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst - Advanced Business Analytics",
      "company":"Ally",
      "job_location":"Lewisville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-advanced-business-analytics-at-ally-3775716688",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Ally and Your Career\nAlly Financial only succeeds when its people do - and that\u201a\u00c4\u00f4s more than some clich\u221a\u00a9 people put on job postings. We live this stuff! We see our people as, well, people - with interests, families, friends, dreams, and causes that are all important to them. Our focus is on the health and safety of our teammates as well as work-life balance and diversity and inclusion. From generous benefits to a variety of employee resource groups, we strive to build paths that encourage employees to stretch themselves professionally. We want to help you grow, develop, and learn new things. You\u201a\u00c4\u00f4re constantly evolving, so shouldn\u201a\u00c4\u00f4t your opportunities be, too?\nThe Opportunity\nReporting to the Director of Strategy & Analytics, this position's primary responsibilities will include strategy development and performance analysis to optimize portfolio results. The ideal candidate must be passionate about delivering results, must be an innovative and strategic thinker, willing to challenge status quo, can learn quickly, is self-motivated, detail oriented, and can sift through voluminous amounts of information to pinpoint which items are relevant to understanding Business results. They will be able to apply knowledge of business and balanced judgment in interpretation of data (analytics).\nThe Work Itself\nProvide analytical and data support in the design and review of strategy tests and current operations.\nAnalyze monthly operating results and monthly variances; identify problems and research potential recommendations for corrective actions.\nPerform portfolio analytics, special projects, drill down analysis and other duties as needed.\nApply sound control processes into daily\/weekly\/monthly processes to effectively identify, assess, and manage risk.\nMaintain code logic to pull, sanitize, aggregate, conform, and produce operational and portfolio-level reports accurately.\nCollaboratively work with matrix & vendor partners to ensure alignment with strategic imperatives.\nPerform special analytics projects and other duties as assigned.\nInterface with various stakeholders within asset performance, credit risk, finance and strategy and analytics organizations to provide timely and accurate analysis.\nAble to deliver accurate results within expected deadlines.\nSkills\nThe Skills You Bring\nBachelor\u201a\u00c4\u00f4s degree preferred; BS or BA in Finance, Economics, Accounting, Mathematics, Information Technology or related field.\n3+ years' experience in similar or equivalent position preferred.\nExperience and knowledge of consumer financing industry (e.g. auto, card, mortgage etc.).\nCandidate should possess outstanding analytical and problem-solving skills.\nMinimum 2 years of practical experience working with large datasets with SQL and\/or SAS knowledge.\nQuick learner and has demonstrated ability to initiate, develop and execute small to medium scale projects.\nWork well within a team of analysts and collaborate with individuals with technical and non-technical backgrounds.\nCandidate must have strong attention to detail.\nExcellent written and verbal communication skills, including the ability to effectively present material\nBasic knowledge of statistics and models preferred\nExperience with designing and implementing champion challenger strategies preferred.\nAdvanced knowledge in developing analysis queries and procedures in SQL and\/or SAS preferred.\nHow We'll Have Your Back\nAlly's compensation program offers market-competitive base pay and pay-for-performance incentives (bonuses) based on achieving personal and company goals. Our Total Rewards program includes industry-leading compensation and benefits plus additional incentives that are designed to meet your needs and those of your family so you can get the most out of your career and your life, including:\nTime Away: 11 paid holidays, 20 paid time off days, and 8 hours of volunteer time off, yearly (paid time off is prorated based on start date)\nPlanning for the Future: plan for the near and long term with an industry-leading 401K retirement savings plan with matching and company contributions, student loan pay downs and 529 educational save up assistance programs, tuition reimbursement, employee stock purchase plan, and financial learning center and financial coach access.\nSupporting your Health & Well-being: flexible health and insurance options including medical, dental and vision, employee, spouse and child life insurance, short- and long-term disability, pre-tax Health Savings Account with employer contributions, Healthcare FSA, critical illness, accident & hospital indemnity insurance, and a total well-being program that helps you and your family stay on track physically, socially, emotionally, and financially.\nBuilding a Family: adoption, surrogacy and fertility assistance as well as paid parental and caregiver leave, Dependent Day Care FSA back-up child and adult\/elder care days and childcare discounts.\nWork-Life Integration: other benefits including Mentally Fit Employee Assistance Program, subsidized and discounted Weight Watchers\u00ac\u00c6 program and other employee discount programs.\nOther compensations: depending on the role for which you are considered, you may be eligible for travel allowances, relocation assistance, a signing bonus and\/or equity.\nTo view more detailed information about Ally\u201a\u00c4\u00f4s Total Rewards, please visit this link: https:\/\/www.ally.com\/content\/dam\/pdf\/corporate\/ally-total-rewards-snapshot.pdf\nWho We Are:\nAlly Financial is a customer-centric, leading digital financial services company with passionate customer service and innovative financial solutions. We are relentlessly focused on \"Doing it Right\" and being a trusted financial-services provider to our consumer, commercial, and corporate customers. For more information, visit www.ally.com.\nAlly is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to age, race, color, sex, religion, national origin, disability, sexual orientation, gender identity or expression, pregnancy status, marital status, military or veteran status, genetic disposition or any other reason protected by law.\nWe are committed to working with and providing reasonable accommodation to applicants with physical or mental disabilities. For accommodation requests, email us at work@ally.com. Ally will not discriminate against any qualified individual who is capable of performing the essential functions of the job with or without reasonable accommodation.\nBase Pay Range\n: An individual's position in the range is determined by the scope and responsibilities of the role, work experience, education, certification(s), training, and additional qualifications. We review internal pay, the competitive market, and business environment prior to extending an offer.\nEmerging\n85000\nExperienced\n117500\nExpert\n150000\nIncentive Compensation: This position is eligible to participate in our annual incentive plan.\nShow more\nShow less",
      "job_skills":"SQL, SAS, Data analytics, Portfolio analytics, Risk management, Financial analysis, Business intelligence, Statistics, Modeling, Project management, Communication, Teamwork, Problem solving, Attention to detail",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Business Analyst",
      "company":"ARTERIORS Home",
      "job_location":"Lewisville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-business-analyst-at-arteriors-home-3785044817",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Arteriors is a team of smart, imaginative (and sometimes quirky) people who embody loyalty to our customers, our brand, and each other. We\u201a\u00c4\u00f4ve stripped away the red tape and provided an environment that thrives on new ideas brought to fruition.\nThe\nSr. Business Analyst\nis responsible for ensuring consistent, efficient operation and continuous improvement in all areas of the business by acting as an effective bridge between the functional departments and IT.\u00ac\u2020 The right candidate for this position will be a creative, self-motivated individual who truly invests in our culture while leveraging their documented experience supporting an ERP system and key business processes (order-to-cash, quote-to-order, procure-to-pay, etc.) to ensure business continuity and operational excellence in all areas.\nThis is a hybrid role that requires 3 days in office and 2 days work from home.\nKey Responsibilities\nCreates a collaborative relationship with the internal customers through:\nDemonstrating personal accountability for delivering tasks\/assignments as agreed.\nOverseeing small projects to ensure transparency and alignment on deliverables.\nBecoming an SME on key departmental processes, challenges, and future needs.\nProvide excellent service to our end users on all system-related issues.\nDeveloping a strong, positive relationship with all other departments and intra-departmental IT teams.\nEmbraces the growth of world-class IT application systems and support through:\nCreating, analyzing, validating, and communicating detailed requirements for development.\nSharing your significant experience with our technology and business needs.\nDeveloping process documentation and training materials.\nFacilitating design sessions with stakeholders to understand problems and define solutions.\nAdhering to change management and departmental operational protocols.\nManaging competing priorities through excellent time management, prioritization, and communication.\nFacilitating, Mentoring, and Training as needed to support end users on all systems.\nProvide subject matter expertise in systems, SaaS, applications, and processes to enable departmental planning efforts for large and small projects.\nProvide significant experience and subject matter expertise on one or more core, cross-functional ERP business processes like order-to-cash, procure-to-pay, plan-to inventory, record-to-report, source-to-pay, count-to-reconcile, forecast-to-monitor, or, inspect-to-comply, etc.\nWorks effectively with peers and across relevant departments, ensuring mutual understanding of the task purpose and the impact on Arteriors.\nActively clarifies opportunities and overcomes obstacles through:\nEnthusiastically working to identify the root cause of problems utilizing valid data and established problem-solving techniques to ensure problems will not reoccur\nDemonstrates individual ownership by:\nClarifying expectations and completion deadlines\nFollowing through on commitments and keeps others apprised appropriately\nAnticipating both internal and external customer needs.\nPromotes Arteriors as an industry leader through the highest professional image and conduct.\nProactively seeks continued education and learning opportunities to achieve job mastery.\nSkill Requirements\nExcellent communication skills both verbal and written.\nEffective working both independently and in group settings.\nExcellent problem-solving capacity founded on data and critical thinking.\nQuick study that can learn and absorb information quickly without an abundance of training.\nAbility to present technical details in laymen terms with appropriate brevity.\nProficient with general windows computer usage (i.e., MS Office, o365, Email, VPN use etc.)\nGeneral programming familiarity as related to production support or development participation preferable.\nBasic SQL experience on MSSQL or equivalent preferable.\nExperience\nMinimum 5+ years\u201a\u00c4\u00f4 experience working as a business analyst\u00ac\u2020with similar responsibilities.\nMinimum 2+ years\u201a\u00c4\u00f4 experience in an IT service-oriented role\/capacity\u00ac\u2020for an organization of 50+\nMinimum 5+ years\u201a\u00c4\u00f4 of core ERP experience, ideally working with Navision and\/or Business Central on-premises and\/or in cloud.\nEducational Requirements\nBaccalaureate degree in Computer Science, Information Systems or reasonable equivalency or equivalent combination of experience\/training.\nIn addition to the Skill Requirements, Educational Requirements, and Experience, the ideal candidate will possess the following characteristics:\nYou are calm and collected under pressure. You think on your feet while ensuring the best possible level of service.\nYou are motivated and driven. You appreciate a challenge and thrive in environments that allow you to make decisions that impact the bottom line.\nYou have a strong sense of time management and can easily prioritize your day with little guidance from others.\nYou communicate clearly. You write well and can explain just about anything to anyone. You have no problem with communicating in writing and on the phone.\nYou consider yourself to be a social butterfly. You\u201a\u00c4\u00f4ve never met a stranger and can start a conversation with almost anyone.\nYou believe in personal accountability. You see the value in both, giving and receiving, constructive feedback and you often seek new opportunities to improve and develop your skills.\nMedical, dental and vision insurance available the first day of the month after hire date\n401k with employer matching\nUnlimited Paid Time Off\nPaid Volunteer Days, allowing you to give back to your community\n9 paid holidays with early release before holidays\nAnnual bonus potential and merit increase potential\nGenerous employee discount\nEmployee referral bonus\nShow more\nShow less",
      "job_skills":"Microsoft Office, O365, Email, VPN, SQL, MSSQL, Navision, Business Central, Windows, ERP",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Research Analyst (Hybrid Work Opportunity)",
      "company":"College of the Mainland",
      "job_location":"Texas City, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-research-analyst-hybrid-work-opportunity-at-college-of-the-mainland-3737686224",
      "search_city":"Dickinson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position Details\nPosition Information\nPosting Number\nAS323P\nPosition Title\nSenior Research Analyst (Hybrid Work Opportunity)\nContract Length\n12 months\nClass Summary\nResponsible for performing highly advanced statistical work to include planning, developing, and presenting statistical data and reports. Responsible for supporting assessment and institutional effectiveness processes through data and analytics.\nCandidates Eligible to Apply\nInternal\/External\nPosition Type\nExempt Staff\nEmployment Status\nFull Time\nPosition Funding Type\nRegular\nPosting Detail Information\nMinimum Education\/Training\/Experience\nBachelor\u201a\u00c4\u00f4s degree or higher in mathematics, statistics, social science, computer\/information systems, or a related field.\nPreferred Education\/Training\/Experience\nMaster\u201a\u00c4\u00f4s degree preferred. Experience involving data-driven analysis and visualization, institutional research or related experiences that require quantitative and qualitative analysis and mathematical skills. Preferred experience in a community college setting.\nMinimum Knowledge & Skills\nKnowledge of and experience with Excel, including functions, formulas, and pivot tables\nExperience with statistical software such as Statistical Analysis Software ( SAS ) or Statistical Package for the Social Science ( SPSS )\nExperience with data visualization tools such as Tableau or Power BI\nExperience using tools such as Access or Microsoft SQL Server Management Studio\nDemonstrated ability to analyze and summarize research into coherent reports for utilization in decision-making\nKnowledge of the general principles of developing and analyzing quantitative and qualitative surveys\nKnowledge of descriptive and inferential statistics and interpretation of results\nStrong knowledge and experience in providing effective customer service\nPreferred Knowledge & Skills\nnone\nLicensing\/Certification Requirements\nnone\nJob Duties\nDevelops and maintains processes to support the transformation of data into information for decision-making.\nExtract and utilize a data from various systems to support planning and institutional effectiveness.\nResponds to ad-hoc requests for information from internal and external entities.\nCollects, compiles, analyzes, and interprets data.\nWorks directly with College personnel to support data gathering, analysis, visualization, and summary feedback in a manner that is efficient, timely, and professional.\nDesigns and implements quantitative and qualitative research studies.\nAssists in the preparation of mandatory state and federal reports.\nManages multiple projects, sets priorities, meets deadlines, and works independently.\nFollows procedures to ensure validity, applicability, efficiency, and accuracy.\nProvides training on accessing and using data and information for decision-making.\nPerforms miscellaneous job-related duties as assigned.\nPhysical Requirements\nNo or very limited physical effort required.\nNo or very limited exposure to physical risk.\nWork is normally performed in a typical interior\/office work environment.\nMinimum Salary Range\n$53,532\nMid Point Salary Range\n.\nMaximum Salary Range\n$72,269\nPosting Open Date\n07\/13\/2023\nPosting Close Date\nPosting Will Be Open Until Filled\nYes\nSpecial Instructions to Applicant\nPlease NOTE : All applications must contain complete job histories, which include job title, dates of employment (month\/year), name of employer, supervisors name and phone numbers and a description of duties performed. If this information is not submitted, your application may be considered incomplete. Applications with \u201a\u00c4\u00faSee attached\u201a\u00c4\u00f9 or \u201a\u00c4\u00faSee resume\u201a\u00c4\u00f9 will not be accepted in lieu of a complete application. Omission of data can be the basis for disqualification; you may state \u201a\u00c4\u00faunknown\u201a\u00c4\u00f9 for any incomplete fields. A scanned copy of unofficial transcript(s) must be attached to the online application.\nEEO Statement\nCollege of the Mainland is an affirmative action\/equal opportunity institution and does not discriminate on the basis of race, color, sex, age, national origin, religion, disability or veteran status.\nCollege of the Mainland does not discriminate on the basis of disability in the recruitment and admission of students, the recruitment and employment of faculty and staff, and the operation of its programs and activities, as specified by federal laws and regulations within Section 504 of the Rehabilitation Act of 1973 and the Americans with Disabilities Act of 1990 and 1992.\nQuick Link to Share for Direct Access to Posting\nhttps:\/\/jobs.com.edu\/postings\/3293\nShow more\nShow less",
      "job_skills":"Excel, Statistical Analysis Software (SAS), Statistical Package for the Social Science (SPSS), Tableau, Power BI, Access, Microsoft SQL Server Management Studio, Quantitative and qualitative surveys, Descriptive and inferential statistics, Data visualization, Data analysis, Data interpretation, Data transformation, Data mining, Decisionmaking, Reporting, Research, Project management, Customer service",
      "Category":"Data Science"
  },
  {
      "job_title":"Quality Analyst",
      "company":"Baylor Genetics",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/quality-analyst-at-baylor-genetics-3752385082",
      "search_city":"Dickinson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Details\nDescription\nSUMMARY:\nThe Quality Analyst will be responsible for quality and compliance within the clinical laboratory setting.\nQualifications\nEducation:\nBachelor\u201a\u00c4\u00f4s degree in relevant science field.\nExperience:\nMinimum 1 year of experience in Genetics, Quality Control Labs\nWorking knowledge of CLIA, CAP, California, and NYS standards and regulations .\nDuties And Responsibilities\nParticipate in various quality assurance audits and projects, completing assigned tasks and responsibilities.\nDocument evidence obtained to support work performed and report any identified findings for stakeholder review.\nParticipate in non-conforming event investigations to determine root cause. Consult with stakeholders to identify action plans for remediation.\nCommunicate transparently and appropriately with identified stakeholders.\nGather, analyze, and manage quality related data.\nAssist in the development of presentations and reports for leadership.\nParticipate in internal laboratory assessments to ensure all guidance is current, reviewed, and signed by the Medical Director(s).\nPerform additional assignments per management\u201a\u00c4\u00f4s direction.\nAdheres to Code of Conduct as outlined in the Baylor Genetics Compliance Program\nPerforms other job-related duties as assigned.\nPhysical Demands And Work Environment\nFrequently required to sit\nFrequently required to stand\nFrequently required to utilize hand and finger dexterity\nFrequently required to talk or hear\nFrequently required to utilize visual acuity to operate equipment, read technical information, and\/or use a keyboard\nOccasionally exposed to bloodborne and airborne pathogens or infectious materials\nEEO Statement\nBaylor Genetics is proud to be an equal opportunity employer dedicated to building an inclusive and diverse workforce. We do not discriminate based on race, religion, color, national origin, sex, sexual orientation, age, gender identity, veteran status, disability, genetic information, pregnancy, childbirth, or related medical conditions, or any other status protected under applicable federal, state, or local law.\nShow more\nShow less",
      "job_skills":"Quality Assurance, Audits, Data Analysis, Reporting, CAP, CLIA, NYS standards, Medical Director, Baylor Genetics Compliance Program, Code of Conduct",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst",
      "company":"High Road Partners",
      "job_location":"Katy, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-at-high-road-partners-3746468314",
      "search_city":"San Felipe",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position Title:\nSenior Analyst\nLocation:\nKaty, TX\nIndustry Segment\n: Production and Material\nPosition Description:\nSupport supply and demand production; analyzing information for continuous improvement; developing and forecasting to align goals.\nRequirements:\nBachelor\u201a\u00c4\u00f4s degree, 5 years analyzing supply chain. SAP or similar, MRP, DRP, BI. Excel, Access. Prefer: APICS, CPIM or similar.\nPosition ID # EB-5247184638\nFor more information regarding this position, please send your resume to Jon Fricke at jfricke@highroadpartnersinc.com and reference the\nPosition ID # EB-5247184638\nin the subject line.\nShow more\nShow less",
      "job_skills":"SAP, MRP, DRP, BI, Excel, Access, APICS, CPIM",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Risk Analyst",
      "company":"PamTen Inc",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-risk-analyst-at-pamten-inc-3775974028",
      "search_city":"Dallas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Describe the technical knowledge and experience required to accomplish the job duties and responsibilities.\nProficiency in Microsoft Excel, Word, PowerPoint, VISIO.\nStrong ability to perform data analysis using excel techniques.\nExperience with Governance, Risk, Compliance systems (Archer eGRC) a plus.\nExperience \/ Educational Requirements \/ Licenses Or Certifications\nBachelor's degree in accounting, Finance, Information systems, or Computer Science. (Nice to have)\nCertifications: CISA, CISSP, CISM or CRMA preferred. (Nice to have)\nMinimum of 5-10 years of experience with COSO, COBIT, and GRC methodologies and frameworks.\nStrong working knowledge of industry standard IT change management practices, data architecture principles, release testing, and QA procedures.\nKaizen, Lean, or Six Sigma certifications are desirable.\nShow more\nShow less",
      "job_skills":"Microsoft Excel, Microsoft Word, Microsoft PowerPoint, Microsoft Visio, Data analysis, Governance Risk Compliance systems, Archer eGRC, Bachelor's degree in accounting, Bachelor's degree in finance, Bachelor's degree in information systems, Bachelor's degree in computer science, CISA certification, CISSP certification, CISM certification, CRMA certification, COSO, COBIT, GRC, IT change management, Data architecture, Release testing, QA procedures, Kaizen, Lean, Six Sigma",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Process Analyst with Security Clearance",
      "company":"ClearanceJobs",
      "job_location":"El Paso, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-process-analyst-with-security-clearance-at-clearancejobs-3753486308",
      "search_city":"Socorro",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Responsibilities PeopleTec is currently seeking a Data Process Analyst to support our El Paso, TX (Fort Bliss) location. Our team is looking for an exceptionally motivated self-starting professional with a background supporting front-end\/UI software development, intelligence analysis, and\/or big data projects . The candidate will support our growing team of cyber, space, and engineering professionals who design, implement, test, and deploy end-to-end 2D\/3D geospatial solutions. The Data Entry Analyst is responsible for ensuring the accurate entry of operational and intelligence data from operational reporting into collaboration environments like Command and Control of the Information Environment (C2IE). Th Data Entry Analyst supports an operational joint task force with a critical National defense mission in a fast-paced environment. This Data Entry Analyst is uniquely gifted to enjoy detailed data entry processes and solve different problems each day. This position involves collaborating with intelligence, operational, & data professionals across multiple echelons of Command. Qualifications Required Skills\/Experience :\nDevelop statistical material and reports\nBuild briefing products that provide situational awareness for the counter-narcotics mission\nTransfer data from various formats & locations (e.g., paper, storyboards, other databases) into a common collaboration environment like C2IE\nCreate spreadsheets and other products that are used to make data-driven decisions based on data trends & synthesis\nClean, process, and retrieve data from a variety of databases & sources to ingest into the collaboration environment\nPerform regular backups to ensure data preservation\nSort and organize paperwork after entering data to ensure it is not lost\nCollaborate with operational staff (e.g., intelligence, operations, IT, Command) to gain user requirements for data insights\nTravel: 0 %\nMust be a U.S. Citizen\nAn active DoD Secret clearance is required to perform this work. Candidates are required to have an active Secret clearance upon hire, and the ability to maintain this level of clearance during their employment. Education Requirements :\nHigh school degree or equivalent & proven experience as data entry professional Desired Skills :\nHave general knowledge and access to decision support systems (i.e., C2IE, Advana) and the experience working with data in the environment\nExposure to\/experience in USG organizations that have a counter-narcotics mission\nAS or BS in data, statistics, or another relevant subject Projected Timeframe to Employee :\nFeb 1, 2024 Overview People First. Technology Always. PeopleTec, Inc. is an employee-owned small business founded in Huntsville, AL that provides exceptional customer support by employing and retaining a highly skilled workforce. Culture: The name \"PeopleTec\" was deliberately chosen to remind us of our core value system - our people. Our company's foundation was built on placing our employees and customers first. With an award-winning atmosphere, we have matured into a company that boasts the best and brightest across multiple technical fields. Career: At PeopleTec, we value your long-term goals. Whether it's through our continuing-education opportunities, our robust training programs, or our \"People First\" benefits package, PeopleTec truly believes that our best investments are our people. Come Experience It. #cjpost #dpost EEO Statement PeopleTec, Inc. is an Equal Employment Opportunity employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in its job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may use the following email address, and\/or phone number (256.319.3800) to contact us about your interest in employment with PeopleTec, Inc. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, genetic information, citizenship, ancestry, marital status, protected veteran status, disability status or any other status protected by federal, state, or local law. PeopleTec, Inc. participates in E-Verify.\nShow more\nShow less",
      "job_skills":"Data Entry, Statistical Analysis, Briefing, Data Transfer, Spreadsheet Creation, Datadriven Decision Making, Data Cleaning, Data Retrieval, Data Ingestion, Data Backup, Data Preservation, Collaboration, IT, Command, Decision Support Systems, C2IE, Advana, Government Organizations, Counternarcotics, Data Science, Statistics",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Management Analyst - Entry Level",
      "company":"MillenniumSoft Inc",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-management-analyst-entry-level-at-millenniumsoft-inc-3679049161",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position : Data Management Analyst \u201a\u00c4\u00ec Entry Level\nLocation : San Antonio, TX\nDuration : 3 Months contract\nTotal Hours\/week : 40.00\n1 st Shift\nClient: Medical Device Company\nJob Category: Human Resource\nLevel Of Experience: Entry Level\nEmployment Type: Contract on W2 (Need US Citizens Or GC Holders Only)\nJob Description\nThe purpose of this position is to support the Data Management Team, the Data Ops Team various Associate Service Center teams and company stakeholders.\nReview and resolve incoming cases, escalations and partner with analysts and specialists as a tier 2 level support.\nResponsibilities\nKey Responsibilities are but not limited to:\nExperience using Workday HCM\nSupport a diverse population of over 38,000 associates.\nBecome an expert on the system\/s supporting Data Management\/ Data Operations.\nWork with Data Operations team to identify potential data integrity issues and advise on appropriate audit and mitigation strategies to ensure data quality.\nIdentify and research issues\/system defects. Analyze, problem-solve and formulate resolutions through application of SOPs and best practices.\nLiaise with Payroll or various country stakeholders with special requirements to ensure complete and accurate data changes.\nLead or participate in continuous improvement initiatives to ensure services are effectively delivered.\nResponsible for ensuring timely and quality delivery of support client Service Level Agreements (SLAs).\nAggressively problem solve Workday to payroll system integration errors seeking out root cause analysis and resolving in partnership with Payroll and payroll vendor.\nLead and\/or support special projects\nActively partner with internal stakeholders to flag any gaps in knowledge at tier 0 (HROne) and tier 1 (call scripts), support ASC Teams as required, and assist with system navigation as needed.\nMaintains Workday inbox tasks, responsible for monitoring the assignments.\nDemonstrate ability to plan, meet deadlines, and manage competing priorities\nCommunication to users via email, case and Teams instructing users how to use systems.\nManage and support any escalated or high quality CIC cases.\nOperate in a diversified environment of language variation.\nSupport Payroll activities through audits of new hires, Vacation on Term payouts, and Severance Payouts.\nSupport business needs by supporting RIF activities through administrative support.\nShow more\nShow less",
      "job_skills":"Workday HCM, Data Management, Data Operations, Data Integrity, Audit, Mitigation, Resolution, SOPs, Payroll, Integration, Root Cause Analysis, Project Management, System Navigation, Communication, Case Management, Teams, CIC, Language Variation, RIF",
      "Category":"Data Science"
  },
  {
      "job_title":"Data and Reporting Functional Analyst",
      "company":"Tata Consultancy Services",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-and-reporting-functional-analyst-at-tata-consultancy-services-3771444567",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title\nData and Reporting Functional Analyst\nTechnical\/Functional Skills\nSAS, Tableau, Microsoft Office\nExperience Required\n8-10+ years\nRoles & Responsibilities\nPerform data analysis using SAS, extract data and develop metrics and insights\nUse statistical methods to analyze data and generate useful business reports\nWork with management team to create a prioritized list of needs for each business segment\nIdentify and recommend new ways to save money by streamlining business processes\nUse data to create models that depict trends in the customer base and the consumer population as a whole\nWork with stakeholders to outline the specific data needs\nGeneric Managerial Skills\nAbility to collaborate effectively and work as part of a team\nStrong customer focus, excellent problem solving and analytical skills\nShow more\nShow less",
      "job_skills":"SAS, Tableau, Microsoft Office, Data analysis, Statistical methods, Business reporting, Data modeling, Stakeholder engagement, Collaboration, Customer focus, Problem solving, Analytical skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Management Analyst - Entry Level (Must Have Workday Exp)",
      "company":"MillenniumSoft Inc",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-management-analyst-entry-level-must-have-workday-exp-at-millenniumsoft-inc-3674082036",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position : Data Management Analyst \u201a\u00c4\u00ec Entry Level (Must Have\nWorkday Exp)\nLocation : San Antonio, TX\nDuration : 3 Months\nTotal Hours\/week : 40.00\n1 st Shift\nClient: Medical Device Company\nJob Category: Human Resource\nLevel Of Experience: Entry Level\nEmployment Type: Contract on W2 (Need US Citizens Or GC Holders Only)\nJob Description\nThe purpose of this position is to support the Data Management Team, the Data Ops Team various Associate Service Center teams and company stakeholders.\nReview and resolve incoming cases, escalations and partner with analysts and specialists as a tier 2 level support.\nResponsibilities\nKey Responsibilities are but not limited to:\nExperience using Workday HCM\nSupport a diverse population of over 38,000 associates.\nBecome an expert on the system\/s supporting Data Management\/ Data Operations.\nWork with Data Operations team to identify potential data integrity issues and advise on appropriate audit and mitigation strategies to ensure data quality.\nIdentify and research issues\/system defects. Analyze, problem-solve and formulate resolutions through application of SOPs and best practices.\nLiaise with Payroll or various country stakeholders with special requirements to ensure complete and accurate data changes.\nLead or participate in continuous improvement initiatives to ensure services are effectively delivered.\nResponsible for ensuring timely and quality delivery of support client Service Level Agreements (SLAs).\nAggressively problem solve Workday to payroll system integration errors seeking out root cause analysis and resolving in partnership with Payroll and payroll vendor.\nLead and\/or support special projects\nActively partner with internal stakeholders to flag any gaps in knowledge at tier 0 (HROne) and tier 1 (call scripts), support ASC Teams as required, and assist with system navigation as needed.\nMaintains Workday inbox tasks, responsible for monitoring the assignments.\nDemonstrate ability to plan, meet deadlines, and manage competing priorities\nCommunication to users via email, case and Teams instructing users how to use systems.\nManage and support any escalated or high quality CIC cases.\nOperate in a diversified environment of language variation.\nSupport Payroll activities through audits of new hires, Vacation on Term payouts, and Severance Payouts.\nSupport business needs by supporting RIF activities through administrative support.\nShow more\nShow less",
      "job_skills":"Workday HCM, Data Management, Data Operations, Data Quality, SOPs, Best Practices, Payroll, Service Level Agreements (SLAs), Root Cause Analysis, Special Projects, Internal Stakeholders, HROne, Teams, CIC, Language Variation, RIF",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Management Analyst - Entry Level",
      "company":"MillenniumSoft Inc",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-management-analyst-entry-level-at-millenniumsoft-inc-3681499953",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position : Data Management Analyst\nLocation : San Antonio, TX\nDuration : 3 Months Contract\nTotal Hours\/week : 40.00\n1sh shift\nDescription\nThe purpose of this position is to support the Data Management Team and Data Ops Specialist as well as Customer Interaction Center (CIC) in case escalation and form completion as a tier 2 level support.\nResponsibilities\nKey Responsibilities are but not limited to:\nSupport a diverse population of over 38,000 associates\nBecome an expert on the system\/s supporting Data Management\/ Data Operations.\nWork with Data Operations team to identify potential data integrity issues and advise on appropriate audit and mitigation strategies to ensure data quality.\nIdentify and research issues\/system defects. Analyze, problem-solve and formulate resolutions through application of SOPs and best practices\nLiaise with payroll or countries with special requirements to complete data changes.\nLead or participate in continuous improvement initiatives to ensure services are effectively delivered\nResponsible for ensuring timely and quality delivery to support client Service Level Agreements (SLAs)\nAggressively problem solve Workday to payroll system integration errors seeking out root cause analysis and resolving in partnership with payroll vendor.\nLead and\/or support special projects\nActively partner with internal stakeholders to flag any gaps in knowledge at tier 0 (HROne) and tier 1 (call scripts), support ASC Teams as required, and assist with system navigation as needed.\nMaintains Workday inbox tasks, responsible for monitoring the assignments\nDemonstrated ability to plan, meet deadlines, and manage competing priorities\nCreate written communications instructing users how to use systems.\nManage and support any escalated or high-quality CIC cases.\nOperate in a diversified environment of language variation\nSupport Payroll activities through audits of new hires, Vacation on Term payouts, and Severance Payouts.\nSupport business needs by supporting RIF activities through administrative support\nShow more\nShow less",
      "job_skills":"Data Management, Data Operations, Workday, Payroll, Tier 2 Support, SOPs, System Integration, Root Cause Analysis, System Navigation, Communication, Audits, Administrative Support",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst\/Data Coordinator",
      "company":"MillenniumSoft Inc",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-data-coordinator-at-millenniumsoft-inc-3681909483",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position : Data Analyst\/Data Coordinator\nLocation : San Antonio, TX\nDuration : 12 Months\nTotal Hours\/week : 40.00\n1 st Shift\nClient: Medical Device Company\nLevel Of Experience: Mid-Level\nEmployment Type: Contract on W2 (Need US Citizens or GC Holders Only)\nMonday-Friday 8am -5pm\nJob Description\nAs directed by the Complaints Management, the Data Coordinator is accountable for preparing, designing, and maintaining customer focused quality metrics reports to support but not limited to escalation process, monthly reviews, Quarterly Business Review with customers, Management Reviews.\nThis position actively utilizes statistical problem-solving techniques to drive continuous improvement activities and bring visibility to customer and quality trending issues.\nAdditional responsibilities are delegated by Complaints Management.\nPrimary Responsibilities And Duties\nManage the quality data reporting elements for the US and Canada regions. Lead efforts in gathering data and preparing it for periodic formal submittal to USLT and Strategic Key\nAccounts Group\nPrepare customer specific metrics, to support and address customer needs\nDesign metrics reports to give visibility quality KPIs\nDesign metrics to meet the needs of management and provided report training as needed\nCreate and generate reports necessary to track, trend and analyze all North America KPIs, metrics, and measurements\nProcess and analyze data in context, looking for patterns to help management make timely informed decisions and for escalation to the business unit\nConsistent application of Quality System standards to assigned Quality System area.\nDevelops solutions to routine assigned activities of moderate scope & complexity. Ensures quality conduct of projects, including design, data summary and interpretation, report and manuscript preparation and review adherence to applicable regulation.\nMaintain and manage the US and Canada quality dashboard\nCoordinate periodical Business Complaints data review to identify and address trends.\nProvide metrics training and reporting training as directed by the Management.\nMaintains annual competencies through training and documentation of training\nParticipate in all required training classes, including but not limited to, C2C training.\nParticipate in interdepartmental Lean, Six Sigma and other continuous improvement projects as needed\nMay facilitate Quality metric presentations(internal and external)\nMay perform other duties as required\nScope Of Responsibility\nDemonstrate timely and accurate analytics practices.\nMaintain in-depth knowledge of company, department and quality products polices and processes.\nWorks in close coordination with other departments to meet resolution and quality expectations\nMaintain the quality data reporting elements for US and Canada, assist and improve the customer experience in relation to product complaints.\nParticipate in training activities\nRequirements\nConsistent application of Quality System standards to assigned Quality System area\nSubject matter expert of Quality Systems regulatory requirements and application to company\/unit requirements\nAdvanced knowledge in Excel and Access\nComprehensive knowledge of Quality System standards and regulations including 21\nCFR 803 & 820, ISO 13485, and Canadian Regulations Skills\nExcellent verbal and written communication skills\nDemonstrated analytical capability\nContinuous and versatile learner\nAbility to work well in a team-oriented environment\nAbility To manage multiple priorities and demonstrate independent and strategic thinking\nEducation\/Degree\nBachelor\u201a\u00c4\u00f4s degree or 6 years\u201a\u00c4\u00f4 relative experience in lieu of a degree\nExperience (indicate the number of years)\nA minimum of 4 years relevant experience or a combination of equivalent education and relevant experience\nA minimum of 2 year of experience in data management and the preparation of materials for meetings and presentations\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Management, Data Reporting, Statistical ProblemSolving, Quality Metrics, Microsoft Excel, Microsoft Access, Quality System Standards, 21 CFR 803 & 820, ISO 13485, Canadian Regulations, Verbal Communication, Written Communication, Analytical Skills, Team Collaboration, Multitasking, Strategic Thinking, Bachelor's Degree, 4+ Years of Relevant Experience, 2+ Years of Data Management Experience",
      "Category":"Data Science"
  },
  {
      "job_title":"Security Reference Management Analyst",
      "company":"AllianceBernstein",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/security-reference-management-analyst-at-alliancebernstein-3773747343",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Description\nAs a leading global investment management firm, AB fosters diverse perspectives and embraces innovation to help our clients navigate the uncertainty of capital markets. Through high-quality research and diversified investment services, we serve institutions, individuals, and private wealth clients in major markets worldwide. Our ambition is simple: to be our clients\u201a\u00c4\u00f4 most valued asset-management partner.\nWith over 4,400 employees across 51 locations in 25 countries, our people are our advantage. We foster a culture of intellectual curiosity and collaboration to create an environment where everyone can thrive and do their best work. Whether you're producing thought-provoking research, identifying compelling investment opportunities, infusing new technologies into our business, or providing thoughtful advice to clients, we\u201a\u00c4\u00f4re looking for unique voices to help lead us forward. If you\u201a\u00c4\u00f4re ready to challenge your limits and build your future, join us.\nJob Description Summary\nWe are seeking a Nashville, TN based Senior Analyst to join our Security Reference Management team in Global Technology & Operations. We\u201a\u00c4\u00f4re looking for someone who has experience in reference data management and understands the various attributes that make up a fixed income, equity and derivative security used for investment purposes.\nTeam\/Group Description\nSecurity Reference Management (SRM) provides security reference data on fixed income, equity, and derivative instruments to internal departments for the management of clients and fund investment activities. The security reference data is maintained within our security master database by the SRM team and then feeds downstream to our internal systems for trading, investment, risk, compliance, accounting, and reporting. The team is responsible to ensure security reference data is accurate, timely and complete to meet the needs of our business activities.\nRole Description\nThe Senior Analyst for Security Reference Management is a key role for our firm providing reference data on fixed income, equity, and derivative instruments that supports our investment activities. The Senior Analyst will support the day-to-day activities, such as building and maintaining security reference data and reviewing discrepancies within our security master database and other internal downstream systems. The Senior Analyst will be responsible to handle complex and challenging data issues.\nApplications And Business Or Enterprise Functions The Role Supports\nA Senior Analyst for Security Reference Management will build and maintain securities for fixed income, equity, and derivative instruments in two security master systems \u201a\u00c4\u00ec majority in CADIS (EDM) for automated securities and small portion in APEX for manual securities. The Senior Analyst will have experience using industry know reference data providers, such as Bloomberg, Interactive Data, CUSIP Web, Refinitiv, and\/or DTC. The Senior Analyst will have experience supporting other internal downstream systems, such multiple Accounting Systems and Trading\/Order Management systems. The Senior Analyst will support the following internal Departments, but not limited to: Portfolio Management Group, Traders, Middle Office, Trade Support, Client Guidelines, Client Reporting, Private Client, Insurance Operations, Pricing & Valuation, and Corporate Actions. The Senior Analyst will use Microsoft Excel and Microsoft Outlook daily.\nKey Job Responsibilities Include, But Are Not Limited To\nEnsure newly added securities have enough information in our security master database (CADIS(EDM)\/APEX) to support investment activities.\nResearch, input, and validate reference data in our security master database (CADIS (EDM)\/APEX). In doing so, the Senior Analyst will need to understand how and why the data is reflected the way it is in our database and update accordingly based on research they have performed.\nMaintain multiple workflows on daily basis, such as security exceptions in CADIS(EDM), DART Requests (Direct Access Request Tracking application), and E-Mails.\nSupport various accounting systems, such as Portfolio Management System, CAMRA, and EPA (Enterprise Portfolio Accounting) to ensure our security reference data is accurately represented.\nWork with internal Departments, such as Portfolio Management, Trading, Client Reporting, Performance, Research, Legal\/Compliance to resolve discrepancies or challenges with our reference data.\nMaintain daily and\/or monthly Quality Control Reports and ad-hoc data cleanup projects that may include credit ratings, industry classifications, accrual information, security identifiers, and security description.\nCan document a process and create formal procedures.\nCan work independently but also work in a team setting.\nCan provide support to team members as a subject matter expert.\nWork closely with Management and other Operational areas within AB to ensure integrity, accuracy, and consistency with our reference data.\nThe team supports multiple shifts within the US Market. This role will cover one of the following: US start of Day (8am-4pm CST), US Day (9am-5pm CST), US end of Day (10am-6pm CST), or US end of Day batch support (11am-7pm CST).\nOn occasion, the Senior Analyst will have to support US Holidays, which is rotated within the team. This coverage can be done working from home.\nThis is a hybrid role, working both in the office and at home.\nWhat makes this role unique or interesting\n(if applicable)\n?\nA Senior Analyst in this position will be exposed to every major financial instrument under fixed income, equity, and derivative. They will have a solid understanding on the makeup of each instrument type and how it impacts the overall business and investment activities. The Senior Analyst will have an opportunity to work closely with various departments that support investment activities, such as operations, front, middle and back-office.\nProfessional development value of this role\n(i.e., what learning and professional growth does the role offer the candidate?)\nA Senior Analyst will be expected to manage their own career development but will receive Management feedback and learn from new and challenging assignments. They will have the opportunity to engage in Professional Development and financial courses which will further their growth professionally and knowledge of the industry. The Senior Analyst, after performing at an expected level, will have the opportunity to support the team as a subject matter expert, document processes, and conduct training. They will also have opportunity to engage in more analytical\/project level work involving process improvement, risk reduction and efficiency.\nJob Qualifications (The Ideal Candidate Should Have The Following)\nOur Team Members typically have track records of outstanding professional performance, academic achievement, along with excellent analytical skills, financial skills, technical skills, and strong communication skills. The ideal candidate should be able to demonstrate the ability to work in a collaborative environment and to present results to both expert and non-expert audiences.\nQualifications, Experience, Education\nBachelor\u201a\u00c4\u00f4s Degree in finance, economics, or accounting\n2-5 years of data analysis experience\nExperience working at a financial, mortgage, banking, or asset management institution\nStrong understanding and experience with building out fixed income, equity, and derivative securities\nExperience using Bloomberg or other reference data providers like DTC, CUSIP Web, Interactive Data, or Refinitiv\nExperience using Markit Enterprise Data Management (EDM) is preferred\nSkills\nCan work well within a team and collaborate with members outside the team\nCan interpret security reference data in fixed income, equity, and derivatives\nOrganized and detailed oriented\nManage multiple tasks in a fast-paced environment\nMeet time sensitive deadlines\nBe a problem solver\nAble to work with a range of internal clients\nIntermediate experience using Microsoft Excel, such as VLOOKUP and Pivot Tables\nSan Antonio, TexasNashville, Tennessee\nShow more\nShow less",
      "job_skills":"Bloomberg, Interactive Data, CUSIP Web, Refinitiv, Markit Enterprise Data Management (EDM), APEX (Application Performance Exchange), CADIS (Corporate Action Data Interrogation System), Knowledge of financial instruments, Data analysis, Financial skills, Communication skills, Microsoft Excel, VLOOKUP, Pivot Tables",
      "Category":"Data Science"
  },
  {
      "job_title":"HR Specialist\/ Analyst",
      "company":"MillenniumSoft Inc",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/hr-specialist-analyst-at-millenniumsoft-inc-3681911637",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Position : HR Specialist\/ Analyst\nLocation : San Antonio, TX\nDuration : 3+ Months Contract\nTotal Hours\/week : 40.00\n1 st Shift\nSummary\nPosition Summary (Purpose & Fundamental Goals of the Position):\nThe purpose of this position is to research, analyze, and support reporting of all Human Resources related data. This role is responsible for managing incoming reporting requests and ensuring accurate and timely delivery of HR Reporting and Analytics to create a positive customer experience. Team member will develop, build and streamline standard and ad-hoc report requests including managing scheduled reports and coaching requesters on self-service. The position will be a Subject Matter Expert in our HCM and other Reporting systems. This position supports the broader HR Organization as well as non-HR business initiatives requiring HR data. The position provides expertise and is a point of contact cross functionally.\nAnyone who\u201a\u00c4\u00f4s experience is as an HR Generalist will not have the skills or experience needed. The role is an Analyst who happens to work with HR data, not an HR Generalist who sometimes looks at data.\nKey Responsibilities (Top Tasks & Outcomes for Which This Position Will be Accountable)\nServe as the subject matter expert for Reporting and Analytics programs, policies and processes\nDefine, build and test new report requests in Workday\nProvide internal customers with recommendations from the Report Catalog and coach them on proper process to request and self-serve\nIdentify and recommend methods to update, simplify and enhance processes, procedures and technologies\nSupport the Payroll team with reports from the Payroll System\nProvide technical support and guidance on core ASC Reporting and Analytics HR processes (respond to and resolve increasingly complex issues)\nAct in a consultative and project coordinator role to functional teams to define and implement program delivery. Identify process and systems implications of, and solutions to, new or modified programs and policies\nPrimary interface to HR and Non-HR functional departments to appropriately escalate inquiries\/concerns\nLead or participate in continuous improvement initiatives to ensure services are effectively delivered\nUse online case management tool to manage incoming requests and provide timely closure of cases ensuring quality customer service\nProvide on the job training to members of other Associate Service Center teams\nDevelop and publish Regional and Global metrics summarizing volume and performance against targets\nProvide input into appropriate metrics and reports around compliance, performance, and data analytics\nProvide data for internal and external audit\nQualifications\nBachelor\u201a\u00c4\u00f4s Degree required with a professional HR\/Business Administration qualification or Diploma preferred\nMinimum of two 2 years\u201a\u00c4\u00f4 experience Reporting and Analytics required\nKnowledge, Skills & Abilities\nIntermediate to Advanced level of Microsoft Excel knowledge and experience required\nWorkday experience is strongly desirable\nVisier experience is strongly desirable\nSAP experience is strongly desirable\nMicrosoft Office experience including SharePoint required\nCase Management system experience preferred\nAbility to pay close attention to details and use time effectively\nStrong problem solving and analytical skills. Ability to receive requests and create solutions\nExcellent oral and written communication skills\nProficient in Reporting and Analytics end to end HR processes\nApplicable Operational Languages\nEnglish with at least one other language preferred\nShow more\nShow less",
      "job_skills":"Workday, Visier, SAP, SharePoint, Microsoft Office, Case Management system, Microsoft Excel, Reporting, Analytics, Payroll System, HR processes, Data analytics, English",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Catalog and Lineage Central Governance Analyst",
      "company":"PwC",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-catalog-and-lineage-central-governance-analyst-at-pwc-3785062692",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nIFS - Information Technology (IT)\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data\/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nAdditional Responsibilities\nSupporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture.\nCustom Orgs\nGlobal LoS\n:\nInternal Firm Services\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nComputer and Information Science, Data Processing\/Analytics\/Science\nAdditional Educational Preferences\nOther related fields of study with relevant experience may be considered.\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success as a team leader:\nPossessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects;\nDisplaying knowledge of data management and governance policies, standards, metrics, controls, and processes;\nHaving knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers;\nPossessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies;\nShowcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture;\nExhibiting proven knowledge and working experience in Microsoft Purview;\nCreating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers;\nShowcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;\nDisplaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog;\nConducting periodic reviews of the data catalogue to corroborate compliance with the DG standards;\nFacilitating the capture of metadata as core change and operational deliverables;\nDemonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers;\nDesigning, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview;\nIdentifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports;\nPossessing ability to create and maintain automated workflows for periodic metadata refresh;\nComplete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR\/HIPPA\/SPI (as applicable);\nHelping manage the inventory of data-related controls on systems that support segment processes and customers;\nShowcasing thorough understanding of data steward\/data owner operating model;\nAbility in designing and rolling out training programs to train the trainer\/end-users;\nBeing a collaborative team player; and,\nHaving a business outcome focused problem-solving mindset.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"Azure Purview, Data governance, Data management, Metadata management, Data lineage, Policy and standards, Data catalog, Data stewards, Data owners, GDPR, HIPPA, Data element, Data asset, Data classification, Taxonomy, Hierarchies, Business glossary, Data dictionary, Data discovery, Data processing, Data analytics, Data science, Unisense",
      "Category":"Data Science"
  },
  {
      "job_title":"Quality Analyst",
      "company":"Graphic Packaging International, LLC",
      "job_location":"Queen City, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/quality-analyst-at-graphic-packaging-international-llc-3774089858",
      "search_city":"Texarkana",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"The Quality Analyst manages all aspects of quality around the Texarkana Mill\u201a\u00c4\u00f4s folding carton paperboard by providing guidance, implementing improvements, and responding to customer issues. This role also acts as a change agent for continuous improvement utilizing lean manufacturing and six sigma principles.The Quality Analyst manages all aspects of quality around the Texarkana Mill\u201a\u00c4\u00f4s folding carton paperboard by providing guidance, implementing improvements, and responding to customer issues. This role also acts as a change agent for continuous improvement utilizing lean manufacturing and six sigma principles.\nDuties & Responsibilities\nDemonstrate and promote safety as a core value by creating a safe work environment where no one gets hurt.\nProvide leadership in continuous improvement that drives the enhancement of existing procedures and develop new systems\/procedures to achieve mill goals and customer expectations.\nWork with Quality Systems\/CI Manager and Operating Departments to identify process gaps from best practice and then implements solutions to close those gaps.\nAct as change agent to drive continuous improvement, which includes root cause analysis and problem solving.\nEducate operation employees to ensure working knowledge of continuous improvement methods, processes, and procedures.\nPerforms analyses on manufacturing processes and implements improvements based on trials coordination and data analysis.\nResponsible to develop and implement non-capital and possible capital cost reduction projects.\nOrganize, lead, and manage project teams to deliver process improvement results.\nDevelop a good understanding of Mill\u201a\u00c4\u00f4s Product Lines and their requirements.\nLead Folding Carton Specifications efforts and assist in development of new grades and\/or testing.\nCompile and analyze quality testing and process data to determine root cause for quality issues and improvement opportunities.\nConduct research, investigate and respond to customer complaints and issues. Also, assist in development of corrective actions and review effectiveness of these corrective actions.\nInterface with customers on all levels to determine and address quality issues.\nUnderstand board properties, testing, visual defects and end customer expectations in order to provide guidance on to Quality, Production, Sales, and Customer Technical Services.\nFulfill weekend duty responsibilities which includes visually evaluating production, detail review of quality parameters and reports, dispositioning product, managing lab technicians and handling test and quality issues.\nReview and update ISO documents.\nPlan and conduct new hire and quality training of personnel as required.\nMust document and clearly convey results of work within the mill\u201a\u00c4\u00f4s work systems.\nOther duties, as assigned.\nRequired Characteristics\nBachelor\u201a\u00c4\u00f4s Degree in Engineering, Paper Science or related field with three (3) years of continuous improvement experience in paper or related industry\nOR\nTen (10) years of progressive experience in a continuous improvement role including five (5) years of experience in paper or related industry\nStrong interpersonal and customer service skills\nDemonstrated project facilitation skills\nProficient in Microsoft applications\nDemonstrated statistical analysis skills \u201a\u00c4\u00ec SPC, multivariable testing, measurement system analysis, hypothesis testing\nDemonstrated ability to communicate professionally with people at all levels of the organization, external contacts, and customers\nComprehensive knowledge of quality or continuous improvement processes\nDemonstrated ability to balance priorities to meet short and long-term objectives\nStrong organizational skills with the desire to accept the challenge of working in continually changing internal and external business conditions\nProven oral and written communication skills\nKnowledge Lean Manufacturing or Six Sigma\nMust pass drug test and background check\nMust be legally authorized to work in the United States\nDesired Characteristics\nComprehensive knowledge of the processes and operations of an integrated paper mill\nWorking knowledge of the operation of an integrated mill\nExperience in SBS or CUK industry\nExperience in poly extrusion\nDemonstrated experience with quality or continuous improvement software applications, i.e. Minitab\nComprehensive understanding of ISO 9001\nShow more\nShow less",
      "job_skills":"Statistical analysis skills, SPC, Multivariable testing, Measurement system analysis, Hypothesis testing, Microsoft applications, Minitab, ISO 9001, Lean Manufacturing, Six Sigma, Root cause analysis, Problem solving, Project facilitation skills, Data analysis, Quality testing",
      "Category":"Data Science"
  },
  {
      "job_title":"Analyst II - Business Services",
      "company":"Texas Tech University",
      "job_location":"Lubbock, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/analyst-ii-business-services-at-texas-tech-university-3771453205",
      "search_city":"Lubbock",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Lubbock\nAnalyst II - Business Services\n35781BR\nOps Div Capital Projects & Admin\nPosition Description\nAnalyzes and coordinates office services such as personnel, budget preparation and control, fiscal affairs, equipment utilization, records control, and special management studies.\nMajor\/Essential Functions\nReview and approve contractor pay applications and design professionals invoices for accuracy, discrepancies, and alignment with contractual agreements.\nProcess Fund Verifications and Reconciliations to ensure that Project costs recorded in TMA match Banner expense reports related to the project account(s). Provide detail and adjustment justification where costs do not match.\nPerform financial reviews and assessments on all capital projects and any projects and financial transactions deemed necessary by Capital Projects and Administration. Any adverse findings in reviews and assessments should be promptly reported and the records be available to select responsible parties.\nReconcile P-Card transactions for buyers within Operations Division ensuring accuracy in amount, FOPs, received status, and vendor.\nPerforms other duties as necessary.\nRequired Qualifications\nBachelor's degree in job related field plus two (2) years responsible related experience; or a combination of related education and\/or experience to equal six (6) years.\nPreferred Qualifications\nExtensive knowledge of, and experience with government or other non-profit accounting, particularly in a fund accounting environment. Excellent analytical and organizational skills. Strong written and oral communication skills.\nIn-depth knowledge of Microsoft Office Suite, particularly Outlook, Excel, and Word. Working knowledge of Cognos and the TMA Work Order System.\nSafety Information\nAdherence to robust safety practices and compliance with all applicable health and safety regulations are responsibilities of all TTU employees.\nDoes this position work in a research laboratory?\nNo\nRequired Attachments\nCover Letter, Professional\/Personal References, Resume \/ CV\nJob Type\nFull Time\nPay Basis\nHourly\nMinimum Hire Rate\n18.48\nPay Statement\nCompensation is commensurate upon the qualifications of the individual selected and budgetary guidelines of the hiring department, as well as the institutional pay plan. For additional information, please reference the institutional pay plan by visiting www.depts.ttu.edu\/hr\/payplan.\nTravel Required\nNone\nShift\nDay\nGrant Funded?\nNo\nJob Group\nInformation and Records Clerks\nEEO Statement\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, age, disability, genetic information or status as a protected veteran.\nAir Force Specialty Code\n3A1X1\nArmy Military Occupational Specialty Code\n42L, 42E\nMarine Military Occupational Specialty Code\n0111, 0101\nNavy Enlisted Classification Code\n1802, 641X\nShow more\nShow less",
      "job_skills":"Microsoft Office Suite, Outlook, Excel, Word, Cognos, TMA Work Order System, Fund accounting, Project management, Budgeting, Financial analysis, Cost reconciliation, Reporting, Contract management, Vendor management, Analytical skills, Organizational skills, Communication skills, Problemsolving skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Catalog and Lineage Central Governance Analyst",
      "company":"PwC",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-catalog-and-lineage-central-governance-analyst-at-pwc-3785061779",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nIFS - Information Technology (IT)\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data\/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nAdditional Responsibilities\nSupporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture.\nCustom Orgs\nGlobal LoS\n:\nInternal Firm Services\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nComputer and Information Science, Data Processing\/Analytics\/Science\nAdditional Educational Preferences\nOther related fields of study with relevant experience may be considered.\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success as a team leader:\nPossessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects;\nDisplaying knowledge of data management and governance policies, standards, metrics, controls, and processes;\nHaving knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers;\nPossessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies;\nShowcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture;\nExhibiting proven knowledge and working experience in Microsoft Purview;\nCreating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers;\nShowcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;\nDisplaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog;\nConducting periodic reviews of the data catalogue to corroborate compliance with the DG standards;\nFacilitating the capture of metadata as core change and operational deliverables;\nDemonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers;\nDesigning, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview;\nIdentifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports;\nPossessing ability to create and maintain automated workflows for periodic metadata refresh;\nComplete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR\/HIPPA\/SPI (as applicable);\nHelping manage the inventory of data-related controls on systems that support segment processes and customers;\nShowcasing thorough understanding of data steward\/data owner operating model;\nAbility in designing and rolling out training programs to train the trainer\/end-users;\nBeing a collaborative team player; and,\nHaving a business outcome focused problem-solving mindset.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"Purview, SQL, Azure, Data Governance, Metadata Management, Data Lineage, Data Catalog, Data Classification, Data Domain Discovery, Taxonomy, Hierarchies, Data Asset Identification, Data Asset Ownership, Usage and Access Control Policies, Business Glossary, Data Dictionary, Data Stewardship, Data Ownership, Data Steward\/Data Owner Operating Model, Training Programs, ProblemSolving Mindset, Communication Skills, Leadership Skills, Team Player, Business Outcome Focused",
      "Category":"Data Science"
  },
  {
      "job_title":"Power BI Data Analyst",
      "company":"Korn Ferry",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/power-bi-data-analyst-at-korn-ferry-3785871646",
      "search_city":"Houston",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"We have partnered with our global technology company client in search for a Power Business Intelligence Analyst for their corporate office for a long-term contract. Our client is open to hybrid or remote consultant and seeking an someone available to start by next week.\nResponsibilities\nPower BI expert that can help us build reports with data sets that already exist\nAutomation and clean up of what exists\nAbility to manually load budgets and excel based datasets\nAbility to create ad hoc reporting in BI by linking excel files\/data sets\nAbility to build in calculations in a BI reports\nAbility to put together data sets out of ERP systems and put them in a data warehouse. This person will build formulas and reporting.\nSkills Required\nBI Power User\nFinance background\nEducation & Work\nExperience\nBachelors degree in related discipline\n5+ years experience\nTitle Power BI Data Analyst\nLocation Open\nClient Industry Technology\nAbout Korn Ferry\nKorn Ferry unleashes potential in people, teams, and organizations. We work with our clients to design optimal organization structures, roles, and responsibilities. We help them hire the right people and advise them on how to reward and motivate their workforce while developing professionals as they navigate and advance their careers. To learn more, please visit Korn Ferry at\nwww.Kornferry.com\nShow more\nShow less",
      "job_skills":"Power BI, ERP systems, Data warehouse, Financial analysis, Excel, Data sets, Automation, Calculations, Reporting, Data visualization",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Globe Life",
      "job_location":"McKinney, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-globe-life-3777031051",
      "search_city":"Pinehurst",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nData Analyst\nPrimary Duties & Responsibilities\nJob Summary Responsible for analyzing data, identifying trends, and providing insights to improve the overall efficiency and effectiveness of our lead generation process. The ideal candidate will have a strong background in data analysis, with experience in marketing analytics and lead generation. Primary Duties & Responsibilities Collect and analyze data related to lead generation performance, including conversion rates, lead quality, and sales pipeline metrics. Identify trends and patterns in data and provide recommendations to improve lead generation efforts. Develop reports and dashboards to communicate key performance indicators to the lead generation team and senior management. Work closely with the lead generation team to optimize lead generation campaigns and tactics and provide feedback on best practices. Monitor and maintain lead data integrity and ensure that all leads are properly qualified and segmented. Collaborate with other teams, including marketing, sales, and customer service, to ensure that lead generation efforts are aligned with overall business goals. Develop and implement processes and procedures to improve lead generation efficiency and effectiveness. Stay up to date with industry trends and best practices in lead generation and provide recommendations for new tools and technologies to improve performance.\nRequired Skills\nKnowledge, Skills, & Abilities Strong analytical skills, with the ability to analyze data, identify trends, and develop insights. Experience with data visualization tools, such as Tableau or Power BI. Proficiency in Excel with the ability to create and modify pivot tables and use lookup functions. Excellent communication and collaboration skills, with the ability to work effectively with cross-functional teams. Excellent analytical skills, with the ability to identify trends and patterns in data to inform lead generation strategies. Strong organizational skills, with the ability to manage multiple projects and priorities. Knowledge of SQL and database management is a plus.\nRequired Knowledge & Experience\nEducation & Work Experience required Bachelor's degree in data science, statistics, mathematics, related field, or equivalent work experience. Minimum of 3 years of experience in data analysis or a related field, with a focus on marketing analytics and lead generation.\nLocation: 3700 S. Stonebridge Dr., McKinney, Texas\nApply Now\nCurrent employees apply here.\nShow more\nShow less",
      "job_skills":"Data analysis, Data visualization, Tableau, Power BI, Excel, Pivot tables, SQL, Database management, Analytics, Lead generation, Marketing analytics",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Business Analyst",
      "company":"American National",
      "job_location":"Galveston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-business-analyst-at-american-national-3782564992",
      "search_city":"Texas City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Posting\nAmerican National seeks a Senior Business Analyst to provide support services that facilitate the system change process for the numerous multiplatform systems that support Retirement Services Administration. This is an in-office position in Galveston, Texas.\nWhat Will You Do?\nInteracts and works with personnel in the Retirement Services business units and the Corporate Technology Services programming staff at specific points during the application development life cycle.\nInteracts and works with external vendor system personnel on both system enhancement and issue resolution as needed.\nProvides the necessary business requirements and quality assurance deliverables that ensure efficient and successfully delivers system enhancements. Successful implementation of complex system changes is required to meet corporate and department strategic objectives.\nSupports projects that are related to pension new product development, the Information Systems Advisory Committee (ISAC) prioritized projects, new system implementations, and new software release upgrades.\nPerforms tasks independent of projects, such as ongoing system enhancements, maintenance requests, system table changes, and production problems that are large in size.\nTrains and provides in-direct supervision and guidance to the junior business analysts on team assignments when required.\nUpdates the system tables, tests to ensure the system is functioning as per actuarial and business specifications, exercises regression testing, and successfully migrates table changes to the production environment.\nProvides production system support to Retirement Services business units when requested through the help desk.\nQualifications\nBachelor's degree.\nFive or more years of experience.\nAmerican National offers eligible employees and their families medical, dental, vision, and basic life insurance. Employees are able to enroll in our company\u201a\u00c4\u00f4s 401k plan. Employees also receive annually a bank of paid time off and paid holidays. We aspire to see people for what they bring to our corporate culture by supporting an inclusive work environment, including an emphasis on a healthy work-life balance, development opportunities, and a casual dress code.\nAmerican National is an established, stable, and successful multi-line insurance corporation that has provided financial strength and a sense of security to employees, customers and business partners since 1905. With focus on our organization\u201a\u00c4\u00f4s values and cultural richness: Financial Strength, Integrity, Respect, Service and Teamwork (FIRST) and Agility, Collaboration, and Engagement (ACE) we continue to pursue our vision to be a leading provider of financial products and services for current and future generations.\nHiring Practices\nThe preceding job posting was designed to indicate the general nature and level of work performed by employees assigned to this position. It is not intended to be interpreted as a comprehensive list of all duties, responsibilities, and qualifications. We are dedicated to building a diverse, inclusive, and authentic workplace, so if you\u201a\u00c4\u00f4re excited about this role, but your past experience doesn\u201a\u00c4\u00f4t align perfectly with the job qualifications, we still encourage you to apply. You may be just the right candidate for this position or other opportunities at American National.\nAmerican National\u201a\u00c4\u00f4s recruitment policies help us place individuals in a timely and efficient manner. Only the most qualified candidates will be contacted by our recruiting team. Candidates may check the status of their application(s) by logging into our Career Portal . Learn more about our company, by following us on social media: LinkedIn , Facebook , Instagram\nAmerican National is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, genetic information or any other legally protected categories. American National is committed to providing access, equal opportunity and reasonable accommodation for individuals with disabilities in employment, its services, programs, and activities.\nShow more\nShow less",
      "job_skills":"System Analysis, Project Management, Business Requirements Gathering, Quality Assurance, System Implementation, System Upgrades, System Maintenance, Table Changes, Production Problem Resolution, Regression Testing, Data Migration, Production System Support, Actuarial and Business Specifications Testing, Training and Supervision, Help Desk Support, 401k Plan, Paid Time Off, Paid Holidays, Casual Dress Code, LinkedIn, Facebook, Instagram",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Quality Analyst",
      "company":"TekIntegral",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-quality-analyst-at-tekintegral-3746817059",
      "search_city":"Akron",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Role: Data Quality Analyst\nLocation: Hybrid in Austin, Tx\nDuration: Long term contract\nWork auth: USC\/GC\nLinkedIn: Yes\nJob Details\nWe are seeking a Data Quality Analyst to work a long-term hybrid role (2 days\/week on-site) at our Austin, Texas client. You will be responsible for analyzing, assessing, and documenting diverse data from its source through many complex transformations to all applications that consume the data to assist the Data Management and Support (DMS) Team with continuous improvement in its mission. Additionally, you will identify the issues from the profiling, follow up with the business, document the business rules, and assist with the processes involved in the continuous improvement of the quality of the data and other capabilities of the DMS Team. Strong skills to identify and resolve data issues and effectively apply a broad range of professional concepts, practices, and methods in moderately complex and diverse circumstances are required. Work is performed under moderate supervision of the Data Management and Support Team Lead with moderate latitude for the use of initiative and independent judgment.\nEssential Functions\nExpand and continuously refine the data quality program.\nEnsures adherence to the data quality programs and standards.\nEnsures that the data quality corrective action plan is thoroughly documented.\nPromote the importance and awareness of an enterprise data quality program.\nLeverages data management knowledge to define and maintain data quality, reference data, and meta-data processes.\nParticipates in the development of data quality rules, thresholds, and standard\/quality expectations for data elements that support critical business processes.\nContinuously execute and monitor the Data Quality Lifecycle daily.\nProfiles data for statistical analysis and assessment of data to document the effectiveness of data quality controls and identify improvement opportunities.\nIdentifies and implements best practices and tools based on the business needs.\nImplement controls to mitigate data quality risks including continuously monitoring data quality results, reports, and dashboards.\nImpeccable oral and written communication skills are essential for effectively interacting with data users, managers, and other stakeholders.\nComplies with all applicable agency policies and procedures, including safety and standards of conduct.\nPerforms other duties as assigned\nCommunicates respectfully and works harmoniously with all co-workers, customers, and vendors.\nProvides exceptional customer service.\nIs flexible; able to work under pressure and able to adapt to change; and able to work on multiple problems and tasks.\nTakes initiative to prevent and solve problems.\nRequirements\nBachelor\u201a\u00c4\u00f4s degree in computer science, engineering, statistics, economics, finance, library science, or related business fields.\n3 years of experience creating functional and technical documentation, business glossaries, and diagrams, that communicate the desired message to business and technical audiences.\n3 years of experience working with enterprise-grade databases - preferably SQL Server and Oracle.\n3 years of experience developing and writing complex SQL scripts\/queries \u201a\u00c4\u00ec preferably Oracle and SQL Server.\n2 years of experience, within the last 5 years, developing data quality rules, thresholds, and standard metrics\/quality expectations for data elements that support critical business processes.\n2 years of experience, within the last 5 years, with an enterprise-grade data quality tool such as Informatica Data Quality, SAS Data Quality, Omni-Gen Data Quality, etc.\n2 years of experience, within the last 5 years, in the Data Quality field developing and implementing best practices and tools based on the business needs.\nLeads and participates in discussions with cross-functional teams.\nPreferred Qualifications\n3 years of experience working with complex Excel functions, including but not limited to VLookUp, Macros, Pivot Tables, etc.\n2 years of experience with the Microsoft SQL Server BI Stack (RDMS, SSIS, SSRS)\nExperience or familiarity with Alteryx & Tableau.\nExperience or familiarity with Benefits Administration, Pension Administration, and Payroll oriented data in the PeopleSoft HRMS package or similar package.\nStrong analytical and product management skills, including a thorough understanding of how to interpret customer business needs and translate them into application and operational requirements.\nDemonstrated problem-solving skills in a technical environment\nStrong written and verbal communication skills; Editing and proofing skills for complex and technical documents. Ability to understand and clearly communicate technical information to non-IT personnel.\nStrong organizational skills and the ability to prioritize assignments.\nGeneral knowledge of the legislature and legislative process.\nFamiliarity with HIPAA and other data security and confidentiality requirements.\nAbility to work independently on difficult, complex tasks.\nAbility to use discretion on matters of a confidential or sensitive nature.\nKnowledge of health care claims data.\nShow more\nShow less",
      "job_skills":"Data Quality, Data Management, Data Analysis, SQL Server, Oracle, Informatica Data Quality, SAS Data Quality, OmniGen Data Quality, Excel, Microsoft SQL Server BI Stack, Alteryx, Tableau, PeopleSoft HRMS, HIPAA, Health Care Claims Data",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"MNTN",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-mntn-3772929921",
      "search_city":"Virginia",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"At MNTN, we've built a culture based on quality, trust, ambition, and accountability \u201a\u00c4\u00ec but most importantly, we really enjoy working here. We pride ourselves on our self-service platform and are constantly seeking to improve the user experience for our customers and scale for efficiency. Our startup spirit powers our growth mindset and supports our teammates as they build the future of ConnectedTV. We're looking for people who naturally want to do more, own more, and make an impact in their careers \u201a\u00c4\u00ec and we're seeking someone to be part of our next stage of growth.\nAs a Data Analyst, you will develop data products and reporting tools and investigate our large data lake. The responsibilities of this role are to create reporting tools, integrate reporting platforms, and generally bring life to the numbers for our clients and internal teams. We are looking for a strong, motivated, team-oriented individual who is a gifted communicator who can adapt their message to unique audiences.\nWhat You'll Do:\nBecome an expert on MNTN platforms, UI, databases, and data pipelines\nAnalyze and audit data for integrity and recommended\/forecast insights associated with our product iterations\nConduct analytics and reports to present our data to internal customers and stakeholders\nVerify and QA various facets of our data pre and post-development to ensure our business needs are met\nInvestigate\/triage\/debug data incidents and provide recommendations for resolution\nWhat You'll Bring:\nA bachelor's degree in a quantitative\/analytical or marketing field (preferred)\n3+ years experience in data analytics or similar\nExperienced with high volume (100M+ records) environments or data warehousing\nExtensive SQL experience with the ability to write scalable, maintainable queries, preferably in Postgres\nExperience working in Product Development teams, supporting products from inception to deployment, and ongoing iterations\nAdvanced Excel\/spreadsheet and analytical skills\nDemonstrated ability to interpret in-depth analyses, uncover actionable insight, and effectively communicate to the broader organization\nDemonstrated ability to create data visualizations for use in communication with others through reports and dashboards\nA mentality for problem-solving\nSolid communication and presentation skills\nA self-starter attitude and ability to work in a fast-paced but fun environment\nAbility to multi-task, be extremely detail-oriented, and thrive in an entrepreneurial environment characterized by growth and change\nMNTN Perks:\nWork from home anywhere in the US\nOpen-ended vacation policy with an annual vacation allowance\nThree-day weekend every month of the year\nCompetitive compensation\n100% healthcare coverage\n401k plan\nFlexible Spending Account (FSA) for dependent, medical, and dental care\nAccess to coaching, therapy, and professional development\nAbout MNTN:\nOur recruiters will always reach out using an email address ending with @mountain.com. If you're contacted by someone without that address and they mention a Reference Code (which we never use), then\nthat ain't us folks.\nTell those trolls to take a hike\u201a\u00c4\u00ecyou're waiting to climb a MNTN.\nMNTN provides advertising software for brands to reach their audience across Connected TV, web, and mobile. MNTN Performance TV has redefined what it means to advertise on television, transforming Connected TV into a direct-response, performance marketing channel. Our web retargeting has been leveraged by thousands of top brands for over a decade, driving billions of dollars in revenue.\nOur solutions give advertisers total transparency and complete control over their campaigns \u201a\u00c4\u00ec all with the fastest go-live in the industry. As a result, thousands of top brands have partnered with MNTN, including Petsmart, Build with Ferguson Master, Simplisafe, Yieldstreet and National University.\nShow more\nShow less",
      "job_skills":"SQL, Postgres, Data Warehousing, Data Visualization, Advanced Excel, Product Development Team Experience, Indepth Analysis, Tableau, Communication",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Quality Assurance Analyst (GMP)",
      "company":"FUJIFILM Diosynth Biotechnologies",
      "job_location":"College Station, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-quality-assurance-analyst-gmp-at-fujifilm-diosynth-biotechnologies-3729958266",
      "search_city":"College Park",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"The work we do at FDB has never been more important\u201a\u00c4\u00eeand we are looking for talented candidates to join us. We are growing our locations, our capabilities, and our teams, and looking for passionate, mission-driven people like you who want to make a real difference in people\u201a\u00c4\u00f4s lives. Join FDB and help create the next vaccine, cure, or gene therapy in partnership with some of the most innovative biopharma companies across the globe. We are proud to cultivate a culture that will fuel your passion, energy, and drive - what FDB call Genki.\nCollege Station, Texas may be a small, university town, but the lively cultural scene and local amenities make it a great place for families as well as those who want the ease of small-town life and the convenience of living close to the vibrant pulse of big cities. Eighty-seven percent of Texas' population lives within a 180-mile radius, so we are in the center of it all in Texas. And our site is nestled in the hub of innovation, representing a source of pride for the area.\nSummary\n:\nThe Senior Quality Assurance (QA) Analyst, under minimal direction, will be responsible for review and\/or approval of basic and technical documentation, drafting and reviewing of internal Quality policies and procedures, performing product related activities, performing Quality audit functions, performing product release activities, identifying process and Quality System improvements, and acting as a QA liaison internally and externally. They will also provide daily guidance, work prioritization and support to other departments, such as manufacturing or QC, in absence of or in conjunction with their manager.\nExternal US\nEssential Functions:\nReview and\/or approve basic and technical documentation with minimal supervisory oversight.\nDraft and review internal Quality policies, procedures and reports.\nPerform inspection of final product containers and review and\/or approval of executed process records and data.\nPerform Quality audit functions.\nIdentify process and Quality System improvement opportunities.\nProvide daily guidance for the compliance of the QA department to national and international standards and regulations.\nSupport Regulatory, client, and internal audits.\nAll other duties as assigned.\nRequired Skills & Abilities:\nExcellent written and oral communication skills.\nExcellent organizational, analytical, data review and report writing skills.\nAbility to set personal performance goals and provide input to departmental objectives.\nAbility to multitask and easily prioritize your work.\nAbility to work independently with little supervision.\nProficient in Microsoft Excel, Word and PowerPoint.\nAll candidates must have a working knowledge of cGMP regulations for the production of drug, biologics or vaccine products.\nWorking Conditions & Physical Requirements:\nThe physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee is regularly required to:\nExperience prolonged standing, some bending, stooping, and stretching.\nLifting up to 25 pounds on occasion.\nUse hand-eye coordination and manual dexterity sufficient to operate a keyboard, photocopier, telephone, calculator, and other office equipment is required.\nAttendance is mandatory.\nQualifications:\nMaster\u201a\u00c4\u00f4s Degree with at least three (3) years of Pharmaceutical or other regulated Industry experience.\nBachelor\u201a\u00c4\u00f4s Degree with at least five (5) years of Pharmaceutical or other regulated Industry experience.\nAssociate degree and at least seven (7) years of Pharmaceutical or other regulated Industry experience.\nPreferred Qualifications:\nCertified Quality Auditor\nDegree in Biology or Chemistry\nJoin us! FDB is advancing tomorrow\u201a\u00c4\u00f4s medicine, impassioning employees to chase the impossible and continually expand their potential. We are a company of emboldened goal seekers \u201a\u00c4\u00ec driven by an innate desire to better ourselves, our families, our workplace, our company, our community, and the world at large.\nWe are an equal opportunity and affirmative action employer.\u201a\u00c4\u00d8 All qualified applicants will receive consideration without regard to race, color, national origin, sex, gender identity, sexual orientation, religion, disability, protected veteran status or any other characteristic protected by applicable federal, state, or local law. If an accommodation to the application process is needed, please email FDBTHR@fujifilm.com or call 979-431-3500.\nTo all agencies: Please, no phone calls or emails to any employee of FUJIFILM about this requisition. All resumes submitted by search firms\/employment agencies to any employee at FUJIFILM via-email, the internet or in any form and\/or method will be deemed the sole property of FUJIFILM, unless such search firms\/employment agencies were engaged by FUJIFILM for this requisition and a valid agreement with FUJIFILM is in place. In the event a candidate who was submitted outside of the FUJIFILM agency engagement process is hired, no fee or payment of any kind will be paid.\nShow more\nShow less",
      "job_skills":"Microsoft Excel, Microsoft Word, Microsoft PowerPoint, cGMP regulations, Quality System, Auditing, Biology, Chemistry, Quality Assurance, Data Analysis, Report Writing, Communication, Multitasking, Prioritization, Teamwork, Independence, Supervision",
      "Category":"Data Science"
  },
  {
      "job_title":"Engineer Senior - Data, Reporting, Project Analyst (F-35 Fleet Tracking)",
      "company":"BAE Systems, Inc.",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/engineer-senior-data-reporting-project-analyst-f-35-fleet-tracking-at-bae-systems-inc-3765251455",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nAs a part of the US Structures and Prognostics Health Management (SPHM) team within the growing BAE Systems F-35 Lightning II program the team member will have the following roles and responsibilities.\nKey Roles, Responsibilities, And Expectations\nUnderstand, manipulate, and summarize large amounts of data\nGenerate reports using Microsoft Excel and Word on a quarterly basis\nWork independently with a high level of attention to detail\nLearn and\/or understand internal processes, tools, and standards\nProvide recommendations on process improvement\nDevelop solutions to identify trends and data anomalies\nCommunicate issues and concerns to team leadership in a clear and concise manner\nPrioritize assigned tasks in order to accomplish the required objectives\n#ASFS\nRequired Education, Experience, & Skills\nBachelor's Degree\nComprehensive knowledge of Microsoft Office Tools\nExcel: pivot tables, vlookup\nExperience manipulating and summarizing data\nExperience with relational databases\nPlease note that pursuant to a government contract, this specific position requires US citizenship status\nPreferred Education, Experience, & Skills\nPossess excellent written and oral communication skills\nAnalytical thinker with a demonstrated ability of solving complex problems\nExperience with the application of the Agile workflow methodologies\nExperience in project management is a plus\nExperience with the Atlassian toolset (Confluence, JIRA, Bitbucket)\nExperience with SQL\nExcel Macros (VBA)\nAerospace structures knowledge is a plus\nPay Information\nFull-Time Salary Range: $81500 - $138600\nPlease note: This range is based on our market pay structures. However, individual salaries are determined by a variety of factors including, but not limited to: business considerations, local market conditions, and internal equity, as well as candidate qualifications, such as skills, education, and experience.\nEmployee Benefits: At BAE Systems, we support our employees in all aspects of their life, including their health and financial well-being. Regular employees scheduled to work 20+ hours per week are offered: health, dental, and vision insurance; health savings accounts; a 401(k) savings plan; disability coverage; and life and accident insurance. We also have an employee assistance program, a legal plan, and other perks including discounts on things like home, auto, and pet insurance. Our leave programs include paid time off, paid holidays, as well as other types of leave, including paid parental, military, bereavement, and any applicable federal and state sick leave. Employees may participate in the company recognition program to receive monetary or non-monetary recognition awards. Other incentives may be available based on position level and\/or job specifics.\nAbout BAE Systems Intelligence & Security\nBAE Systems, Inc. is the U.S. subsidiary of BAE Systems plc, an international defense, aerospace and security company which delivers a full range of products and services for air, land and naval forces, as well as advanced electronics, security, information technology solutions and customer support services. Improving the future and protecting lives is an ambitious mission, but it\u201a\u00c4\u00f4s what we do at BAE Systems. Working here means using your passion and ingenuity where it counts \u201a\u00c4\u00ec defending national security with breakthrough technology, superior products, and intelligence solutions. As you develop the latest technology and defend national security, you will continually hone your skills on a team\u201a\u00c4\u00eemaking a big impact on a global scale. At BAE Systems, you\u201a\u00c4\u00f4ll find a rewarding career that truly makes a difference.\nIntelligence & Security (I&S), based in McLean, Virginia, designs and delivers advanced defense, intelligence, and security solutions that support the important missions of our customers. Our pride and dedication shows in everything we do\u201a\u00c4\u00eefrom intelligence analysis, cyber operations and IT expertise to systems development, systems integration, and operations and maintenance services. Knowing that our work enables the U.S. military and government to recognize, manage and defeat threats inspires us to push ourselves and our technologies to new levels.\nOur Commitment To Diversity, Equity, And Inclusion\nAt BAE Systems, we work hard every day to nurture an inclusive culture where employees are valued and feel like they belong. We are conscious of the need for all employees to see themselves reflected at every level of the company and know that in order to unlock the full potential of our workforce, everyone must feel confident being their best, most sincere self and be equipped to thrive. We provide impactful professional development experiences to our employees and invest in social impact partnerships to uplift communities and drive purposeful change. Here you will find significant opportunities to do meaningful work in an environment intentionally designed to be one where you will learn, grow and belong.\nShow more\nShow less",
      "job_skills":"Microsoft Excel, Microsoft Word, Agile, Confluence, Jira, Bitbucket, SQL, VBA, Data Manipulation, Data Summarization, Relational Databases, Microsoft Office Tools, Pivot Tables, Vlookup, Excel Macros",
      "Category":"Data Science"
  },
  {
      "job_title":"Full Time : GCP Data Analyst : Austin , TX ( Onsite )",
      "company":"Nexwave",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/full-time-gcp-data-analyst-austin-tx-onsite-at-nexwave-3778212340",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Role: GCP Data Analyst\nLocation: Austin, TX\nFull Time\nclean-up and organize unstructured data from different sources\ndiscover correlations and insights from a unstructured set of data\nindependently run researches and analyses on different data sources\nuse (even in a basic way) tools and framework to process and visualize data\nwith a knowledge for community and people orgs domains as a plus.\nThanks & Regards\nC Naveen\nPhone: 9725979189 Ext 403\nEmail : cnaveen@nexwaveinc.com\nLinkedin :https:\/\/www.linkedin.com\/in\/naveen-chowdary-65b610115\/\n5490 McGinnis Village Place Suite 237 Alpharetta GA 30005\nWeb: www.nexwaveinc.com\nUSA II INDIA II Canada II UK II Germany\nDisclaimer:\nThis e-mail and any attachments to it may be confidential and are intended solely for the use of the individual to whom it is addressed. The information contained in this e-mail and any attachment(s) must not be published, copied, disclosed, or transmitted in any form to any person or entity unless expressly authorized by the sender. If you have received this mail in\nERROR\n, please reply to us with\n\"Remove\"\nin the subject. We respect your online privacy and our apologies for any inconvenience caused.\nShow more\nShow less",
      "job_skills":"Data Analytics, GCP, Data visualization, Data processing, Unstructured data, Data sources, Tools and frameworks, Community and people orgs domains",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst\/Scientist",
      "company":"VeeAR Projects Inc.",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-scientist-at-veear-projects-inc-3782205706",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Job Description\nData analyst\/scientist with experience in web analytics using clickstream data analysis.\nTableau and SQL, but they need to also have worked with clickstream data in the web analytics space for 2+ years\nShow more\nShow less",
      "job_skills":"Data analysis, Web analytics, Clickstream data, Tableau, SQL",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Governance Analyst - Houston, TX",
      "company":"Talent Groups",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-governance-analyst-houston-tx-at-talent-groups-3790379044",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Note: This role is HYBRID (4\/1) in Houston, TX.\nTop Skills: MS Dynamics, Data Accuracy, Attention to Detail, large data experience. Power BI(user level), Excel.\nThe candidate will support the Sales Operations Data Governance initiatives maintaining accuracy and conformity of our system data. Data initiatives include, but not limited to account and location information within Microsoft Dynamics. All data is required to follow predefined standardization. Activities include working from dashboards or directly within systems addressing inaccuracies that need remediation.\nResponsibilities\n\u201a\u00c4\u00a2 Ability to self-diagnose challenges with clear decision making.\n\u201a\u00c4\u00a2 Cleanse and enrich data within Microsoft Dynamics\n\u201a\u00c4\u00a2 Utilize external data sources during review process.\n\u201a\u00c4\u00a2 Communicate with Sales as needed.\n\u201a\u00c4\u00a2 Provide additional administrative support as required.\nExpectations\n\u201a\u00c4\u00a2 Computer skills using Microsoft Office and ability to learn a variety of sales focused tools.\n\u201a\u00c4\u00a2 Excellent organizational\/administrative skills.\n\u201a\u00c4\u00a2 Can-do attitude \/ self-starter.\n\u201a\u00c4\u00a2 Ability to learn new tools and skills quickly.\n\u201a\u00c4\u00a2 Ability to multi-task in a fast-paced environment.\n\u201a\u00c4\u00a2 Customer service with a strong problem-solving approach.\n\u201a\u00c4\u00a2 A constant example of modeling Crown\u201a\u00c4\u00f4s purple values.\nEducation\/Certifications\n\u201a\u00c4\u00a2 College Degree preferred.\nExperience\/Minimum Requirements\n\u201a\u00c4\u00a2 3-5 years of relevant data governance and\/or data analytic experience.\n\u201a\u00c4\u00a2 Experience working with large data sets.\n\u201a\u00c4\u00a2 Working in office environment with strong attention to detail.\n\u201a\u00c4\u00a2 MS Dynamics\nWork Plans: This role falls into our hybrid work model working in your assigned office 4 days per week. There is an expectation of collaboration with teammates and stakeholders for moments that matter.\nShow more\nShow less",
      "job_skills":"MS Dynamics, Data accuracy, Attention to detail, Large data experience, Power BI, Excel, Data governance, Data cleansing, Data enrichment, External data sources, Sales communication, Administrative support, Microsoft Office, Sales tools, Organizational skills, Administrative skills, Cando attitude, Selfstarter, Fast learning, Multitasking, Customer service, Problemsolving, College degree, Data governance experience, Data analytic experience",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Data Analyst",
      "company":"Aston Carter",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-aston-carter-3790796522",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Description:*\nEssential Job Functions:*\nSupport clients: Work and communicate closely with their clients throughout the report\/dashboard development process. Provide status updates. Help clients understand their report\/dashboard. Provide on-going maintenance and support.\nSupport projects: Participate in outcome evaluation, program evaluation, and quality improvement studies. Attend meetings, answer data-related questions, and offer suggestions.\nCreate reports and dashboards: Create ad-hoc and routine reports. Design and develop dashboards to display key metrics and trends.\nManage data: Collect, organize, store, and share a wide variety of data.\nTransform data: Clean and optimize data for analyses.\nEnsure data quality: Audit data, data transformation processes, workflow, deliverables and outputs.\nPerform analyses: Perform statistical analyses (descriptive and inferential analyses).\nPresent findings: Present data and findings in a clear and concise manner, using appropriate reporting and data visualization tools.\nCreate and maintain documentation: Create FDD, document report requirement, business logic and workflow. Create data dictionaries. Ensure documentation is up-to-date.\nMaintain up-to-date knowledge on information management systems, processes and data.\nManage compliance reporting: Maintain up-to-date knowledge of CMS, DHCS and internal compliance reporting requirement. Translate reporting requirement into reports. Work with clients to ensure accuracy of data. Submit report to external and internal agencies in a timely manner. Attend compliance trainings, meetings, and data validation webinars.\nSupport system enhancement\/implementation: Perform data-related research and testing. Stay informed of system and process changes. Identify impact on existing reports and dashboards. Modify existing reports and dashboards accordingly.\nPrioritize work and keep supervisor informed: Work on multiple projects at the same time. Organize and prioritize work effectively. Inform management when requirement or due date cannot be met.\nAdheres to all quality, compliance and regulatory standards to achieve organization outcomes.\nRequired Education: *\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Analytics, Healthcare Informatics, Statistics, Computer Science, or related field.\nRequired Experience:*\nAt least 5 years of experience analyzing and compiling data, preferably in a health plan setting.\nRequired Skills\/Abilities:*\nAbility to manipulate and analyze data to produce accurate results. Present results in data visualizations, dashboards, and reports.\nKnowledge in CMS Medicare Advantage (Part C), CMS Prescription Drug Coverage (Part D), and CMS Special Needs Plan (SNP), and DHCS Medi-Cal Managed Care reporting requirements.\nKnowledge in authorization, claims, and encounter data. Clinical code knowledge (ICD, CPT, etc) related to utilization data.\nAdvanced skills in Microsoft Office, SQL Transactional SQL (T-SQL), SQL Server Reporting Services (SSRS), and Tableau.\nExperience in SQL Server Integration Services (SSIS), Visual Basic for Applications (VBA).\nMust have analytical, communication, documentation, interpersonal, planning, presentation, problem-solving and research skills.\nAbout Aston Carter:\nPlease Note: Scammers are posing as Aston Carter. We'll never contact you via Gmail, Telegram, or WhatsApp and we'll never solicit money from you.\nAt Aston Carter, we\u201a\u00c4\u00f4re dedicated to expanding career opportunities for the skilled professionals who power our business. Our success is driven by the talented, motivated people who join our team across a range of positions \u201a\u00c4\u00ec from recruiting, sales and delivery to corporate roles. As part of our team, employees have the opportunity for long-term career success, where hard work is rewarded and the potential for growth is limitless. Established in 1997, Aston Carter is a leading staffing and consulting firm, providing high-caliber talent and premium services to more than 7,000 companies across North America. Spanning four continents and more than 200 offices, we extend our clients\u201a\u00c4\u00f4 capabilities by seeking solvers and delivering solutions to address today\u201a\u00c4\u00f4s workforce challenges. For organizations looking for innovative solutions shaped by critical-thinking professionals, visit [AstonCarter.com.](AstonCarter.com) Aston Carter is a company within Allegis Group, a global leader in talent solutions. The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law. If you would like to request a reasonable accommodation, such as the modification or adjustment of the job application process or interviewing process due to a disability, please call 888-237-6835 or email [astoncarteraccommodation@astoncarter.com](mailto:%20astoncarteraccommodation@astoncarter.com) for other accommodation options. However, if you have questions about this position, please contact the Recruiter located at the bottom of the job posting. The Recruiter is the sole point of contact for questions about this position.\nShow more\nShow less",
      "job_skills":"Communication, SQL, SQL Server Reporting Services (SSRS), SQL Transactional SQL (TSQL), Tableau, Data visualization, SQL Server Integration Services (SSIS), Visual Basic for Applications (VBA), Microsoft Office, Data analysis, CMS Medicare Advantage (Part C), CMS Prescription Drug Coverage (Part D), CMS Special Needs Plan (SNP), DHCS MediCal Managed Care reporting, Authorization, Claims, Encounter data, Clinical code knowledge (ICD CPT etc), Data management, Report development, Dashboard development, Statistical analysis, Data presentation, Documentation, Problemsolving, Research skills, Interpersonal skills, Analytical skills, Planning, Presentation",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Catalog and Lineage Central Governance Analyst",
      "company":"PwC",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-catalog-and-lineage-central-governance-analyst-at-pwc-3785059797",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nIFS - Information Technology (IT)\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data\/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nAdditional Responsibilities\nSupporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture.\nCustom Orgs\nGlobal LoS\n:\nInternal Firm Services\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nComputer and Information Science, Data Processing\/Analytics\/Science\nAdditional Educational Preferences\nOther related fields of study with relevant experience may be considered.\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success as a team leader:\nPossessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects;\nDisplaying knowledge of data management and governance policies, standards, metrics, controls, and processes;\nHaving knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers;\nPossessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies;\nShowcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture;\nExhibiting proven knowledge and working experience in Microsoft Purview;\nCreating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers;\nShowcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;\nDisplaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog;\nConducting periodic reviews of the data catalogue to corroborate compliance with the DG standards;\nFacilitating the capture of metadata as core change and operational deliverables;\nDemonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers;\nDesigning, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview;\nIdentifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports;\nPossessing ability to create and maintain automated workflows for periodic metadata refresh;\nComplete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR\/HIPPA\/SPI (as applicable);\nHelping manage the inventory of data-related controls on systems that support segment processes and customers;\nShowcasing thorough understanding of data steward\/data owner operating model;\nAbility in designing and rolling out training programs to train the trainer\/end-users;\nBeing a collaborative team player; and,\nHaving a business outcome focused problem-solving mindset.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"High School Diploma, Bachelor's Degree, Computer and Information Science, Data Processing\/Analytics\/Science, Data Governance, Metadata Management, Purview, Data Catalog, Data Lineage, Data Steward, Data Owner, GDPR, HIPAA, Sensitive Data, Data Domain, Technical Metadata, Unisense, Training, Problem Solving",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst - 100% remote within Texas",
      "company":"Texas Health and Human Services",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-100%25-remote-within-texas-at-texas-health-and-human-services-3785827255",
      "search_city":"Fort Lee",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Job Description\nUnder the general supervision of the Product Support Manager in the Public Health Applications under HHSC IT Application Services, with moderate latitude for the use of initiative and independent judgment. Performs data-related functions including data conversions, data analysis, data management, data compilation and data quality implementations. Work involves developing new software applications or enhancements to existing applications for statistical analysis. Work involves analyzing all aspects of technical environments, coordinating with business customers and other IT areas (System Services, CTO, PMO, etc.), monitoring technical tasks to meet user requirements and developing technology acquisition plans to deliver the best product for customers. Performs detail analysis and design duties and performs complex data analysis and research work. Trains and mentors others, as needed.\nEssential Job Functions\nInterface and consult with customers and technical staff (agency and vendor) to provide solutions to support user needs. Coordinates and Communicates: A liaison between Program and technical team (agency and vendor). Manages data enhancement and operational work request project. Writes complex computer programs\/scripts using appropriate technology, best technical practices and standards for statistical modeling and graphic analysis. Prepares concise, comprehensive technical reports to present and interpret data, identify alternatives, and make and justify recommendations on data revisions. Advises management of the status and progress of projects and other tasks being conducted. Reports status\/risks to project manager and Product Delivery and Support Manager. Develops data collection project estimates, user requirements definitions with customers, preliminary analysis\/design strategies, testing strategies, alternatives, and resource requirement. Facilitates the development of technical deliverables, monitors technical assignments to ensure timely delivery. Performs walkthroughs and reviews of technical deliverables. (40%)\nResponsible on guiding various stakeholders in appropriate and effective use of data and strategies that optimize statistical efficiency and quality. Coordinates with other IT areas in the implementation of development projects. Serves as the primary technical member to incorporate potential data sources. Coordinates application data related tasks with other team members. Serves as a technical resource for advanced and difficult questions and problems. Educates and mentors team on data analysis, data integrity, extraction, and compilation. (30%)\nDevelop and maintain functional and technical specifications by preparing detailed structured data flow analysis, plans, diagrams, verification of procedures, and relational database management designs for new or revised automated systems operations. (20%)\nOther duties as assigned but not limited to continuing education opportunities to enhance both technical and people skills, actively participating and\/or serving in a supporting role to meet the agency\u201a\u00c4\u00f4s obligations for disaster response and\/or recovery or Continuity of Operations (COOP) activation. Such participation may require an alternate shift pattern assignment and\/or location. (10%)\nKnowledge Skills Abilities\nKnowledge of relational databases and database design.\nKnowledge of data visualization development, including data model creation, advanced calculations, and interactive visualizations.\nKnowledge of database management.\nStrong skills in reporting software.\nStrong skills in meeting facilitation and presentations for meetings involving cross functional teams and including external stakeholders.\nSkills in analyzing business processes and developing business cases for new or modified customer-related products and services.\nSkills in organization and team management.\nSkills in effective team facilitation.\nSkills in effective listening.\nSkills in effective verbal and written communication.\nSkills in graphical, tabular, and geographical presentation of data.\nAbility to translate complex data into user-friendly information.\nAbility to plan, assign, and monitor the work of others.\nAbility to plan, organize and conduct data analytic projects.\nAbility to analyze systems and procedures and to explain abstract concepts in concrete terms.\nAbility to compile, review, and analyze data; work in team environment; and manage multiple tasks.\nAbility to analyze, design, document, code, test, implement, and monitor automated processes on computers.\nAbility to express ideas clearly and concisely, both written and verbally, and to address audiences.\nRegistration Or Licensure Requirements\nInitial Selection Criteria:\nRequired minimum of three years\u201a\u00c4\u00f4 experience in data analysis and design work including with SQL\nPreferred graduation from an accredited college or university in computer science, computer information systems, management information systems, or a related field. May substitute work experience on a year for year basis\nPreferred experience working professionally with a broad range of stakeholders\nPreferred experience in validating of various data extracts or data conversions to ensure the results are accurate and as expected\nAdditional Information\nApplicants must provide information relevant to the experience requirements in the specific job history section of the application. Agency salary policy, budget and candidate\u201a\u00c4\u00f4s qualifications will dictate final salary offer.\nThis position can telework full time from any location in Texas consistent with HHS telework policies. Applicants from outside Texas must be willing to relocate within 60 days of hire.\nMOS Code\nMilitary occupation(s) that relate to the initial selection criteria and registration or licensure requirements may include: 25B IT, 275, 0171, 3DOX2. For more information, see the Texas State Auditor\u201a\u00c4\u00f4s Military crosswalk at http:\/\/\/www.hr.sao.state.ts.us\/Compensation\/JobDescriptions.aspx.\nTop 10 Tips for Success when Applying to Jobs at HHSC and DSHS\nHHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work.\nI-9 Form - Click here to download the I-9 form.\nIn compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.\nShow more\nShow less",
      "job_skills":"Data conversions, Data analysis, Data management, Data compilation, Data quality, Statistical analysis, SQL, Database design, Data visualization, Database management, Reporting software, Meeting facilitation, Presentations, Business processes, Business cases, Team management, Team facilitation, Listening, Verbal communication, Written communication, Data presentation, Userfriendly information, Project planning, Project monitoring, Systems analysis, Abstract concepts, Data analytic projects, Automated processes, Expressing ideas, Addressing audiences",
      "Category":"Data Science"
  },
  {
      "job_title":"Strategic Intelligence Business Analyst",
      "company":"McLane Company, Inc.",
      "job_location":"Temple, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/strategic-intelligence-business-analyst-at-mclane-company-inc-3783873753",
      "search_city":"Temple",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Assist with the development of specialized information beneficial to the company in responding defensively to unique circumstances and acting offensively on issues important to the company to ensure McLane maintains a competitive advantage. Analyze competitors, customers, distributors, regulators, technologies, and the macro-economic environment.\nBenefits\nDay 1 Benefits available: medical, dental, and vision insurance, FSA\/HSA and company-paid life insurance.\nGet paid early. Get paid fast.\n401(k) with annual company match.\nPaid holidays, vacation time, sick leave accrual, college tuition reimbursement, and more!\nEssential Job Functions \/ Principal Accountabilities\nConduct detailed and comprehensive research from a variety of sources, collect data, and analyze information to discover and identify market trends as well as key information driving competitive forces.\nUpdate a library of accessible information related to research from external sources and internal sources.\nResearch new sources of insights to continuously improve intelligence and solve new problems as they arise.\nAssist in actionable deep-dive research to help the Commercial Finance team understand costs and pricing levers within current and potential markets and apply statistical measures to forecast volume, inflation, and workflow.\nAssist in identifying risks and opportunities for the company before they become obvious.\nLeverage data to connect the dots and uncover hidden insights.\nCommunicate complex data analysis in a clear and concise manner.\nCollaborate with stakeholders to develop and execute data-driven strategies within a teamwork environment.\nPerform other duties as assigned.\nMinimum Qualifications And Requirements\nBachelor\u201a\u00c4\u00f4s degree in accounting, economics, statistics, finance or related field. Master\u201a\u00c4\u00f4s degree in business or related degree. Four years of related experience may substitute for the degree on a year-by-year basis.\nTwo or more years\u201a\u00c4\u00f4 experience in analyzing pricing strategies and forecasting revenue and market share preferred.\nDemonstrate understanding of basic business\/marketing concepts.\nExcellent oral, written and presentation skills with ability to explain complex concepts clearly to a variety of audiences, including senior management.\nAbility to conduct and present research findings.\nAbility to manage multiple, simultaneous projects and data sources.\nAbility to take quick, decisive, informed action on issues or problems judged as critical.\nAbility to use creative problem solving and analytical skills to understand the advantages and limits of different analytical approaches and studies, and their findings.\nProficient in Microsoft Outlook, Excel, Word, PowerPoint. Tableau and other relevant software applications.\nWilling to obtain strategic and competitive intelligence professional certification through professional organization(s) as determined by management.\nWorking Conditions\nOffice environment\nCandidates may be subject to a background check and drug screen, in accordance with applicable laws.\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\nPrimary Location\nUnited States-Texas-Temple\nWork Locations\nMC999 HO McLane Home Office\nJob\nFinance\/Accounting\nSchedule\nFull-time\nShift\n1st - Day\nEmployee Status\nRegular\nShow more\nShow less",
      "job_skills":"Business Intelligence, Data Analysis, Market Research, Tableau, Data Visualization, Presentation Skills, Microsoft Office Suite, Statistical Analysis, Strategic Thinking, Economic Analysis, Problem Solving, Research",
      "Category":"Data Science"
  },
  {
      "job_title":"IT Application Analyst Senior",
      "company":"City of Austin",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/it-application-analyst-senior-at-city-of-austin-3785383708",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Minimum Qualifications\nEducation and\/or Equivalent Experience:\nGraduation with a Bachelor\u201a\u00c4\u00f4s degree from an accredited college or university with major course work in a field related to the job plus two (2) years experience.\nExperience may substitute for education up to four (4) years.\nLicenses Or Certifications\nNone.\nNotes to Applicants\nThe IT Application Analyst Sr. plays a pivotal role within the Information Systems team of the Business Technology Unit. The team\u201a\u00c4\u00f4s mission is to fortify the department\u201a\u00c4\u00f4s commitment to informed decision-making through data. To provide that data, the Information Systems team collects, analyzes, stores, and disseminates actionable information to all stakeholders by utilizing tools such as Qlik Sense. Recently, the Information Systems team\u201a\u00c4\u00f4s mission has expanded to facilitate data transparency by providing access and analysis of a wide breadth of both law enforcement and organizational data within Austin\u201a\u00c4\u00f4s Open Data Hub. To aid with the team\u201a\u00c4\u00f4s mission, a core priority is seamless and error-free data delivery by utilizing the Sparx Systems Enterprise Architect tool to provide internal system integrity. This position will engage closely with their team and collaborate across various business units to ensure the mission\u201a\u00c4\u00f4s successful accomplishment. We are seeking a team member who not only has a passion for working with data but is also adept at translating that passion into tangible actions and impactful outcomes.\nCity Of Austin Application\nA complete and detailed City of Austin employment application is required to help us better evaluate your qualifications. For each position, please describe your specific experience as it relates to the minimum and preferred qualifications. Please be thorough in completing the employment application and list all experience and education that is relevant to this position. Starting salary will be based on overall relevant experience and education. Application must include job titles, job duties performed, full or part time status. Your work history should include the duties you performed, any supervisory or lead responsibilities, and any equipment or computer software used.\nCbi\nMust pass a Criminal Justice Information Systems ( CJIS ) fingerprint-based background check and maintain CJIS eligibility. Due to CJIS requirements related to system access, the following will result in being disqualified for this position: Felony Convictions, Felony Deferred Adjudication, Class A & B Misdemeanor Deferred Adjudication, Class B Misdemeanor Convictions, an Open Arrest for Any Criminal Offense (Felony or Misdemeanor), and Family Violence Convictions. Please\nClick here\nto find more information.\nSecondary Employment\nAll Austin Police employees are prohibited from accepting or engaging in any secondary employment that might conflict or interfere with an employee\u201a\u00c4\u00f4s duty and responsibility to the Department.\nAPD must review all secondary employment.\nEmployees are required to submit a Secondary Employment Application for review and approval upon being hired with APD , as well as current APD employees considering Secondary employment.\nBenefits\nWorking with the Austin Police Department provides a number of health and welfare benefits, such as medical, paid leave time, retirement plan, training opportunities and more. Please\nclick here\nto find more information.\nTo learn more about working with the City of Austin,\nclick here to watch a short video!\nTravel\nIf you are selected for this position and meet the Driver Safety Standards in the City of Austin\nDriver Safety Program,\nyou may drive when necessary to multiple locations as part of your regular job duties. Otherwise, you are responsible for getting to and from these locations.\nEEO \/AA Statement\nThe City of Austin is committed to compliance with the Americans with Disabilities Act. If you require reasonable accommodation during the application process or have a question regarding an essential job function, please call (512) 974-3210 or Texas Relay by dialing 7-1-1.\nThe City of Austin will not discriminate against any applicant or employee based on race, creed, color, national origin, sex, gender identity, age, religion, veteran status, disability, or sexual orientation. In addition, the City will not discriminate in employment decisions on the basis of an individual\u201a\u00c4\u00f4s AIDS , AIDS Related Complex, or HIV status; nor will the City discriminate against individuals who are perceived to be at risk of HIV infection, or who associate with individuals who are believed to be at risk.\nPay Range\nCommensurate\nHours\n7:00 a.m. - 4:00 p.m. or, 8:00 p.m. - 5:00 p.m. or, 9:00 a.m. to 6:00 p.m.\n(opportunity to telework in adherence to the City Policy at 80%-100%)\nJob Close Date 12\/26\/2023 Type of Posting External Department Police Regular\/Temporary Regular Grant Funded or Pooled Position Not Applicable Category Professional Location 402 Deep Eddy Ave, Austin, TX 78703 Preferred Qualifications\nExperience supporting and migrating legacy . NET applications.\nExperience with leading or contributing to establishing Microsoft\u201a\u00c4\u00f4s Power Platform solutions.\nDuties, Functions and Responsibilities\nEssential duties and functions, pursuant to the Americans with Disabilities Act, may include the following. Other related duties may be assigned.\nResearches, analyzes, architects, develops, implements and configures technological solutions Administers, monitors, and maintains one or more IT systems Investigates and analyzes complex business requirements Provides impact analysis and recommends appropriate solutions Identifies opportunities for asset reuse across multiple projects Responds to issues from the user community Prepares and maintains documentation related to the development and maintenance of systems Participates in the development of business process models and data flow diagrams for all levels of the organization Performs bug tracking and quality assurance tasks Develops and maintains disaster recovery plans Develops and\/or delivers training Creates and prepares reports and analysis Installs new software releases and\/or upgrades Establishes IT policies, procedures and security requirements\nResponsibilities - Supervisor And\/or Leadership Exercised\nMay provide technical or project leadership, training, and technical guidance to others.\nKnowledge, Skills and Abilities\nMust possess required knowledge, skills, abilities, and experience and be able to explain and demonstrate, with or without reasonable accommodations, that the essential functions of the job can be performed.\nKnowledge of existing IT systems and their relationships to each other and interfaces to outside systems\nKnowledge of IT policies, procedures, and security requirements\nKnowledge of database design principles\nKnowledge of creating process models and data flow diagrams\nSkill with computers and computer systems\nSkill in analyzing information and evaluating alternatives\nSkill in documenting and maintaining application and process or configuration information\nSkill in providing system\/application administration\nSkill in identifying complex problems and reviewing related information\nSkill in developing, prioritizing, organizing and accomplishing specific goals and plans\nSkill in using a structured query language\nSkill in providing mentoring, guidance, and training of personnel\nSkill in coordination of activities of others\nAbility to serve as a technical lead for development and support of one or more IT systems\nAbility to apply analytical reasoning to complex problems\nAbility to multitask and to work effectively in a team or as an individual contributor\nAbility to communicate effectively orally and in writing\nAbility to meet deadlines and effectively communicate the status of assignments\nCriminal Background Investigation This position has been approved for a Criminal Background Investigation. EEO\/ADA\nThe City of Austin is committed to compliance with the Americans with Disabilities Act. If you require reasonable accommodation during the application process or have a question regarding an essential job function, please call (512) 974-3210 or Texas Relay by dialing 7-1-1.\nThe City of Austin will not discriminate against any applicant or employee based on race, creed, color, national origin, sex, gender identity, age, religion, veteran status, disability, or sexual orientation. In addition, the City will not discriminate in employment decisions on the basis of an individual\u201a\u00c4\u00f4s AIDS , AIDS Related Complex, or HIV status; nor will the City discriminate against individuals who are perceived to be at risk of HIV infection, or who associate with individuals who are believed to be at risk.\nInformation For City Employees: If you are an employee within the department, are in good standing and meet both the minimum and preferred qualifications, then you will receive an initial interview.\nSupplemental Questions\nRequired fields are indicated with an asterisk (*). * This position requires a criminal background investigation (CBI). By selecting the following, you are acknowledging that you understand if you are selected as a top candidate for this position, you will need a successful Criminal Justice Information System (CJIS) to be hired. * Please describe your experience supporting and migrating legacy .NET applications.\nThe minimum qualifications for this position include graduation from an accredited four-year (4) college or university with major course work in a field related to the job plus two (2) years experience.Experience may substitute for education up to four (4) years. Do you meet these qualifications?\nYes\nNo\nI acknowledge and understand this position requires a Criminal Justice Information System (CJIS-Criminal Background Investigation).\n(Open Ended Question)\nPlease describe your experience with leading or contributing to establishing Microsoft's Power Platform solutions.\n(Open Ended Question)\nOptional & Required Documents\nRequired Documents Optional Documents\nShow more\nShow less",
      "job_skills":"Qlik Sense, Sparx Systems Enterprise Architect, .NET, Microsoft's Power Platform, Structured Query Language (SQL), IT Policies, Data Analysis, Troubleshooting, Bug Tracking, Disaster Recovery, Software Installation, Project Leadership, Training, Technical Writing, System Administration, Software Development, Database Design, Process Modelling, Dataflow Diagrams",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst V",
      "company":"Texas Health and Human Services",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-v-at-texas-health-and-human-services-3741955024",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nThe Data Analyst V performs highly complex (senior-level) data analysis, data research, database management, and application development assignments for the Aging and Disability Services (ADS) section in the Office of Data, Analytics, and Performance (DAP) in order to detect data trends and anomalies, optimize health outcomes, and provide HHSC programs and executive management with information necessary to make data-informed management decisions and explore potential program efficiencies. Work involves conducting detailed analysis of data sets, performing data needs assessment, data acquisition, cleaning and standardization, extraction, transformation and loading into database systems; designing, coding, testing, implementing and maintaining computer applications to increase efficiency through the automation of routine tasks; and mentoring ADS team members in the use of compiled data sets. Works under limited supervision, with moderate latitude for the use of initiative and independent judgment.\nEssential Job Functions\nAttends work on regular and predictable schedule in accordance with agency leave policy and performs other duties as assigned.\nEJF 1 Data Quality\/Integrity: Provides suggestions regarding systematic changes that will improve the efficiency and quality of data analysis processes. Assesses data quality by identifying any missing, erroneous, incongruent, or duplicate data in data sets used by the unit. Coordinates with other internal groups within DAP or other areas to improve data quality. Consults and provides requirements for the improvement of data collection systems and the methods used to perform data analytics. 25%\nEJF 2 Data Analysis: Determines the most effective method to address a given data request, construct a performance measure, or monitor various service trends. Compiles and manipulates data points using SQL, SAS, or other languages from a variety of source formats, to support complex analyses related to monitoring Medicaid Long-term Care programs. Cleans and prepares data to produce datasets required for data analysis. 20%\nEJF 3 Reporting: Oversees the interpretation of analysis results to inform the team\u201a\u00c4\u00f4s presentations and reports of the results. Prepares comprehensive standard and ad-hoc reports, in written, graphical and oral format, for internal and external audiences. Ensures accuracy of data included in reports. 20%\nEJF 4 Customer Focus and Communication: The Analyst engages with a variety of people across the agency, to build strong relationships and to find creative solutions to analytic projects. Utilizes communication skills to gather the information necessary from customers to assess and address their needs. Explains analysis results in clear and non-scientific language as necessary to ensure that customers can leverage the information in decision-making. Coordinates with program subject matter experts and leadership to both ensure accuracy in approach for the analysis and to inform staff of findings in a timely manner. 20%\nEJF 5 Special projects and assignments as assigned\/required: Serves on agency committees and workgroups as an SME consultant for long-term care data. Prepares and updates standard operating procedures and processes for long-term care reporting. 15%\nKnowledge Skills Abilities\nKnowledge of the process of computer application development.\nKnowledge of data analysis techniques.\nKnowledge of scientific research methods, statistical techniques, mathematics, geographical concepts and their application to data analytics.\nKnowledge of the various Texas Health and Human Service (HHS) programs.\nKnowledge of patient level health and demographic data (e.g., Census, Vital, Medicaid, and CHIP data including eligibility, enrollment, medical claims and encounters).\nKnowledge of the principals, practices and techniques of database design and development, database structures and theories and current database technologies.\nKnowledge of medical records systems or clinical coding practices.\nKnowledge of computer programming principles, spreadsheet macros, and database design.\nSkill in using SAS, SPSS, SQL, R, ACCESS, Business Objects or other statistical and database management software.\nSkill in using EXCEL or other spreadsheet software.\nSkill in graphical, tabular and geographical presentation of data.\nSkill in communicating with individuals at all management levels on technical issues.\nSkill in database management with Oracle, SQL Server or similar large database systems.\nAbility to design, develop, code, test, implement, maintain and document computer applications.\nAbility to manage, manipulate, and analyze complex databases.\nAbility to plan, organize, and conduct data analytic projects.\nAbility to work in a team and to communicate effectively.\nAbility to develop and interpret statistical data charts, maps, and tables.\nAbility to interpret and publish data analytic findings.\nAbility to exercise independent judgment and show initiative.\nAbility to maintain detailed and organized documentation of data analytic projects.\nAbility to train staff in the use of data systems.\nRegistration Or Licensure Requirements\nN\/A\nInitial Selection Criteria\nGraduation from an accredited 4-year college or university with major coursework in a social science, business, statistical or related field. Education and experience may be substituted for each other, up to four years. Three or more years of experience with acquisition, collection, management, analyses and dissemination of health and human services-related data and\/or other large datasets preferred.\nAdditional Information\nMilitary occupation(s) that relate to the initial selection criteria and registration or licensure requirements for this position may include: 35F, IT, 23, 02111, 8E000. For more information see the Texas State Auditor\u201a\u00c4\u00f4s Military Crosswalk at http:\/\/www.hr.sao.state.tx.us\/Compensation\/JobDescriptions.aspx\nMOS Code\n35F, IT, 23, 02111, 8E000\nTop 10 Tips for Success when Applying to Jobs at HHSC and DSHS\nHHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work.\nI-9 Form - Click here to download the I-9 form.\nIn compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.\nShow more\nShow less",
      "job_skills":"Data analysis, Data research, Database management, Application development, SQL, SAS, R, ACCESS, Business Objects, Data management, Oracle, SQL Server, Spreadsheet software, Statistical software, Data visualization, Data presentation, Data acquisition, Data cleaning, Data standardization, Data extraction, Data transformation, Data loading, Database design, Database development, Database technologies, Medical records systems, Clinical coding, Computer programming, Spreadsheet macros, Statistical techniques, Mathematics, Geographical concepts, Data analytic projects, Data analytics, Team work, Communication, Independent judgment, Initiative, Documentation, Training",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst IV",
      "company":"Texas Health and Human Services",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-iv-at-texas-health-and-human-services-3774211132",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nPerforms (senior-level) highly advanced professional organizational and policy analysis work, conducting organizational studies and evaluations, analyzing systems and procedures, conducting work simplification studies, and preparing operations and procedures manuals to assist management in operating more efficiently and effectively. This position will function as a team lead overseeing the analysis, development, and maintenance of processes and procedures for the Health and Human Services Commission (HHSC), Financial Services Division (FSD), Provider Finance Division (PFD), Cost Report Review Unit (CRRU) to support the Directed Payment Programs (DPP). Work also involves reviewing and analyzing data collected from DPP Medicaid Cost \/ Accountability Reports to ensure desk reviews are conducted in accordance with Government Auditing Standards (as applicable), Texas Administrative Code, and Agency policies and procedures. This position will also assist the CRRU management and team members by conducting data analysis, data validation, quality assurance of desk review procedures, and assist management in ensuring consistency throughout the desk review process. Work is performed under the direction of the Director of the CRRU with latitude for the use of initiative and independent judgment.\nEssential Job Functions\nEFJ: Collects, queries, and analyzes DDP Medicaid Cost \/ Accountability Report data using standard statistical tools, applications, methods, and techniques. 25%\nEFJ: Interpret historical, current, and projected data to identify problems, causes, and areas for which process and procedural or system changes are indicated. 30%\nEFJ: Identify, document, make recommendations, and implement approved recommendations to ensure desk reviews are completed in accordance with Government Auditing Standards (as applicable), Texas Administrative Code, and Agency policy and procedures. 20%\nEFJ: Oversee and\/or design, evaluate, recommend, and approve changes to reports, Cost Report data collection system, desk review process, and data analysis. Develop solutions to Medicaid Cost \/ Accountability Reports issues and concerns, develop change strategies and plans, and conduct training for implementation of solutions, strategies, and plans. 20%\nEFJ: Facilitate meetings with stakeholders from all areas and levels of the agency to gather necessary information for guidance documents. Consult with internal and external customers to identify data analytics needs. 5%\nKnowledge Skills Abilities\nKnowledge of organizational development and management practices as applied to the analysis, evaluation, development, and implementation of programs, policies, and procedures; methods and procedures analysis techniques; work simplification methods; forms and records design and control procedures; and statistical analysis.\nAbility to analyze or evaluate problems to develop, recommend, or present alternative solutions; to conduct or coordinate studies; to develop, interpret, or implement policies and procedures; to design programs or training; to prepare concise reports; and to communicate effectively.\nKnowledge of Government Auditing Standards (as applicable), Generally Accepted Accounting Principles.\nKnowledge of the Texas Administrative Code, applicable rules and regulations; policies and procedures of the Commission; and related legislative practices and procedures.\nKnowledge of office management practices, administrative procedures, accounting methods, and accounting systems.\nSkilled in numerical and record analysis, handling multiple projects, and meeting deadlines.\nAbility to identify problems, prepare concise reports, identify problems, evaluate alternatives, and make sound decisions.\nSkilled in the use of MS Office applications; advanced skill level with Microsoft Excel.\nSkilled with reporting tools such as Business Objects, Tableau, or databases (SQL, etc.) but not limited to.\nKnowledge of Health and Human Services programs, services, and procedures.\nAbility to interpret, develop, and implement policies and procedures.\nSkill in interpersonal relationships, teamwork, and establishing and maintaining effective working relationships with people at various levels of expertise.\nAbility to learn and teach complex, detailed concepts.\nAbility to concentrate for extended periods of time on detailed documents or projects.\nRegistration Or Licensure Requirements\nNone\nInitial Selection Criteria\nExperience in data analysis, research, compilation, and\/or reporting work. Graduation from an accredited four-year college or university with major coursework in data science, business analytics, computer science, computer information systems, management information systems, accounting, finance, mathematics, statistics, economics, or a related field.\nExperience with Medicaid or other medical claims or cost report data preferred.\nAdditional Information\nRequisition Number 589336\nApplicants must be located in Austin, Texas as this position will work a hybrid telework schedule.\nMOS Code\nNo military equivalents.\nTop 10 Tips for Success when Applying to Jobs at HHSC and DSHS\nHHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work.\nI-9 Form - Click here to download the I-9 form.\nIn compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.\nShow more\nShow less",
      "job_skills":"Data analysis, Data science, Business analytics, Computer science, Computer information systems, Management information systems, Accounting, Finance, Mathematics, Statistics, Economics, Government Auditing Standards, Generally Accepted Accounting Principles, Texas Administrative Code, Business Objects, Tableau, SQL, Microsoft Excel, MS Office applications, Medicaid, Cost Report data collection system",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst, CSS Workforce Analytics",
      "company":"Atlassian",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-css-workforce-analytics-at-atlassian-3770101608",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Overview\nWorking at Atlassian\nAtlassians can choose where they work \u201a\u00c4\u00ec whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.\nAre you an analytics champion with a deep toolset who thrives on helping business partners strategize, understand, visualize and measure data-driven initiatives? Do you relish the opportunity to dive headfirst into large, end-to-end projects and make contributions across analytics, strategy and operations? Are you energized working closely with the business to turn data into beautiful, high impact visualizations to power leadership decisions? If so, this role is for you!\nAs a Data Analyst on our Customer Support Services team, you will partner closely with key business leads, focus on some of the most exciting challenges Atlassian faces.\nResponsibilities\nIn this role you will:\nWork with a strong group of data scientists as we advance our core data artifacts to the next level (Tableau, Databricks, etc.) functionally, aesthetically and operationally\nDevelop strong collaborative partnerships with business and operations leaders\nProvide technical expertise in data visualization, deep business acumen, stakeholder engagement and operational insights via analysis\nWork with a cross functional team to drive improvement and efficiency in a rapidly scaling and dynamic customer support environment, bringing analytic capabilities and insights to bear\nAddress business challenges, performance bottlenecks and growth opportunities with analytic solutions\nPlaying the role of analytic visualization expert in cross functional teams, focused on measurement of new strategies or initiatives, sizing of opportunities, and understanding of complex systems; always with a mind towards actionable insights and business impact\nSome Skills And Tools You'll Use Are\nAnalytics: Data visualization, Statistics, data distributions, summary\/aggregation methods, operational metric development, ongoing OKR measurement\nTools: Tableau, SQL, Excel, etc.\nCollaboration: Confluence, Jira\nQualifications\nYour background:\nYou've been working with data for 2+ years and have a BS degree in Statistics, Mathematics, Economics, Computer Science or other quantitative field.\nYou have experience in building business impacting analytic solutions and experience using data to influence business and operational teams.\nYou\u201a\u00c4\u00f4re know for producing clean, clear data visualizations that power decisions for senior stakeholders.\nYou have strong communication skills (non-technical) and core tech skills.\nYou love collaboration, working with other smart data professionals and acting both as a student and teacher with team members.\nTo keep pace with our rapid growth you enjoy and are capable of learning new things quickly. You can take an ambiguous assignment and move rapidly to deliver iterative value. You use multiple tools and methods to find trends and correlations by mining data, and couple that with intuition and light-weight tests to prioritize how to drive forward on complicated problems.\nYou have strong business acumen, love driving strategy, making big changes, and influencing others. You have a history of driving measurable impact in close collaboration with operational colleagues.\nYou combine curiosity with critical thinking and good judgment, and like asking \"why\" to unravel a seemingly complex problem and get to the root cause.\nYou know how to gather, document, and interpret business requirements; always knowing how to ask the \u201a\u00c4\u00f2why\u201a\u00c4\u00f4 underpinning all requests.\nYou\u201a\u00c4\u00f4re a senior \u201a\u00c4\u00f2pillar of the team\u201a\u00c4\u00f4, confident in your business acuity, analytics expertise and communication \/ coordination skills to push through ambiguity and up-skill those around you.\nWhen you encounter a problem you come up with multiple solutions, weigh the tradeoffs and efforts, identify the best path forward, and exercise good judgment to drive ahead.\nCompensation\nAt Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are:\nZone A: $121,500 - $162,000\nZone B: $109,400 - $145,800\nZone C: $100,900 - $134,600\nThis role may also be eligible for benefits, bonuses, commissions, and equity.\nPlease visit go.atlassian.com\/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.\nOur Perks & Benefits\nAtlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more.\nVisit\ngo.atlassian.com\/perksandbenefits\nto learn more.\nAbout Atlassian\nAt Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.\nWe believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.\nTo provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.\nTo learn more about our culture and hiring process, visit\ngo.atlassian.com\/crh\n.\nShow more\nShow less",
      "job_skills":"Data visualization, Statistics, Analytics, Tableau, SQL, Databricks, Confluence, Jira, Excel",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Data Analyst, Applications Engineering",
      "company":"Tesla",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-applications-engineering-at-tesla-3779620425",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"What To Expect\nData Analyst, IT Applications Engineering The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth. As the Data analyst, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical data operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.\nWhat You'll Do\nDesign, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result.\nCollecting and processing large data sets from various sources, such as databases, APIs, and third-party tools\nDeveloping and implementing data models and algorithms to analyze complex data sets\nIdentifying trends and patterns in data to develop insights and recommendations that inform business decisions\nCreating reports and visualizations that effectively communicate data insights to stakeholders\nCollaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings\nDeveloping and maintaining data pipelines and databases to ensure data accuracy and integrity\nStaying up to date with industry trends and best practices in data analysis and reporting\nDesign and execute experiments to test hypotheses and validate findings\nGathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks\nEnsures data quality and implements tools and frameworks for automating the identification of data quality issues\nProvides ongoing support, monitoring, and maintenance of deployed products.\nWork with systems that handle sensitive data with strict controls and change management processes\nProvide timely and accurate estimates for newly proposed functionality enhancements\nDevelop, enforce, and recommend enhancements to Applications in the area of standards, methodologies, compliance, and quality assurance practices; participate in design and code walkthroughs\nUtilize technical and domain knowledge to develop and implement effective solutions; provide hands on mentoring to team members through all phases of the Systems Development Life Cycle (SDLC) using Agile practice\nOn-call support, where needed\nWhat You'll Bring\nStrong experience with relational and multi-parallel processing databases like Vertica, SQL Server, and MySQL. NoSQL databases experience is a plus\nBackground in data warehousing, data modeling, data access, and data storage techniques\nStrong proficiency in query writing is required\nExperience with design, development, and implementation of highly scalable, high-volume software systems and components, source of truth systems for different business areas, developing and maintaining web services in an agile environment\nStrong experience in stellar dashboards and reports creation for C-Level executives\nAbility to support multiple on-going projects in a fast-paced environment\nStrong analytical and problem-solving ability to design an effective solution.\nStrong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands\nPassion for Tesla\u201a\u00c4\u00f4s products and belief in Tesla\u201a\u00c4\u00f4s mission to accelerate the transition to sustainable energy\nLocation \u201a\u00c4\u00ec Austin, Texas (USA)\nNice to have:\nExperience with data science tools such as Pandas, Numpy, R, Tensorflow\nWork experience with Informatica\nExperience in Big Data processing using Apache Hadoop\/Spark ecosystem applications like Hadoop, Hive, or Spark\nWork experience with Tableau or any visualization tool\nBenefits\nCompensation and Benefits\nAlong with competitive pay, as a full-time Tesla employee, you are eligible for the following benefits at day 1 of hire:\nAetna PPO and HSA plans > 2 medical plan options with $0 payroll deduction\nFamily-building, fertility, adoption and surrogacy benefits\nDental (including orthodontic coverage) and vision plans, both have options with a $0 paycheck contribution\nCompany Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Aetna medical plan with HSA\nHealthcare and Dependent Care Flexible Spending Accounts (FSA)\nLGBTQ+ care concierge services\n401(k) with employer match, Employee Stock Purchase Plans, and other financial benefits\nCompany paid Basic Life, AD&D, short-term and long-term disability insurance\nEmployee Assistance Program\nSick and Vacation time (Flex time for salary positions), and Paid Holidays\nBack-up childcare and parenting support resources\nVoluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft & legal services, and pet insurance\nWeight Loss and Tobacco Cessation Programs\nTesla Babies program\nCommuter benefits\nEmployee discounts and perks program\nTesla\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Science, Vertica, SQL Server, MySQL, NoSQL, Data Warehousing, Data Modeling, Data Access, Data Storage, Query Writing, Agile, Pandas, Numpy, R, Tensorflow, Hadoop, Hive, Spark, Apache, Informatica, Tableau",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst\/Report Writer",
      "company":"Allnessjobs",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-report-writer-at-allnessjobs-3750175058",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Data Analyst\/Report Writer ( They Must Work With Any State Department of Education Client )\nLocation: Austin Texas\nClient: Texas Education Agency\nJob ID : 70123042\nExp: Minimum 10+ Years Must\nVisa : USC, GC , GC EAD, H4EAD\nNOTE: 100% Remote Work is Allowable within Texas . Out of State Candidate ok as Long as they are ok to Relocate to Texas\nPossibility of 100% Remote Work Allowable for Right Candidate\nCandidate Must Have Work Experience with Any State Department of Education\nSkills Must : Data Validation,Microsoft Excel,SAS,Creating and Maintaining Documentation,PowerBI,Sharepoint Experience with Permissions,Adobe Acrobat,SmartSheets\nData reporting analysts transform data into information that can be utilized to make business decisions and actions. Their work involves acquiring data from other sources, creating reports on a regular basis, correcting any code issues, and ensuring that databases remain error-free and organized.\nProjects Include\nValidate and transform Accountability System for Educator Preparation data found in Word, PDF, Excel, and PowerBI dashboards to confirm accuracy of historic data set.\nWrite, Review, troubleshoot, and document PowerBI, SAS program code, and compiled reports to explore inconsistencies in data reporting on the Accountability System for Educator Preparation dashboards.\nCreate and organize SharePoint folders, roles, and permissions for storing data and documents. Migrate and document data and other files.\nGather, document, and use user requirements to migrate data for a team.\nCreate, update, and maintain Smartsheets for tracking work.\nThe analyst works under general supervision with limited latitude for the use of initiative and independent judgment.\nMinimum Requirements\nData Validation\nMicrosoft Excel\nSAS\nCreating and Maintaining Documentation\nPowerBI\nSharepoint Experience with Permissions\nAdobe Acrobat\nSmartSheets\nEducation Data\nShow more\nShow less",
      "job_skills":"Data Validation, Microsoft Excel, SAS, Creating and Maintaining Documentation, PowerBI, SharePoint Experience with Permissions, Adobe Acrobat, Smartsheets, Word, PDF, Data reporting, Data analysis, Data transformation, Data migration, Data organization, Data visualization, Business intelligence, PowerBI dashboards, SAS program code, SharePoint folders, SharePoint roles, SharePoint permissions, User requirements, Smartsheets",
      "Category":"Data Science"
  },
  {
      "job_title":"Systems Analyst 2 - Austin, TX (Remote Within Texas)",
      "company":"My3Tech",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/systems-analyst-2-austin-tx-remote-within-texas-at-my3tech-3751439147",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Systems Analyst 2\nAustin, TX 78751 (Remote Within Texas)\n3 months Contract with possibility to extension\n4-7 years of experience in the field or in a related area.\nFamiliar with standard concepts, practices, and procedures within a particular field.\nRelies on limited experience and judgment to plan and accomplish goals.\nA certain degree of creativity and latitude is required.\nWorks under limited supervision with considerable latitude for the use of initiative and independent judgment.\nUnderstands business objectives and problems, identifies alternative solutions, performs studies and cost\/benefit analysis of alternatives. Analyzes user requirements, procedures, and problems to automate processing or to improve existing computer system: Confers with personnel of organizational units involved to analyze current operational procedures, identify problems, and learn specific input and output requirements, such as forms of data input, how data is to be; summarized, and formats for reports. Writes detailed description of user needs, program functions, and steps required to develop or modify computer program. Reviews computer system capabilities, specifications, and scheduling limitations to determine if requested program or program change is possible within existing system.\nThe Systems Analyst plays a pivotal role for the IT Project Management Center of Excellence (PMCoE). This position works on the front line for customer services, support to the IT project management community. The Systems Analyst is responsible for researching, developing, and documenting project management processes and procedures that comply with applicable internal and external policies, standards and best practices. They will support all project and portfolio management systems, responding to customer service requests for systems, process and project management related information. Performing advanced information technology (IT) project management analysis work for projects and systems and will create reports for the IT project management community to improve the quality of project management reporting and provides feedback to foster an environment of continuous improvement.\nCandidate Skills And Qualifications\nYears\nRequired\/Preferred\nExperience\n5\nRequired\nPerform analysis work on project management systems including requirements gathering.\n5\nRequired\nDevelop reports to monitor progress for metrics.\n5\nRequired\nPreparing and defining the goals of the system and devises flow charts and diagrams describing logical operational steps of programs.\n5\nRequired\nAdvanced Excel skills to include compiling multiple datasets to gather, assemble, correlate, interpret, and analyze large data sets\n4\nPreferred\nExperience using MS Power BI, Power Automate, and\/or Tableau\n4\nPreferred\nAdvanced skill in critical thinking and problem solving\n4\nPreferred\nAbility to work independently and manage multiple reporting projects simultaneously\nThanks,\nVivek Jannaram\nSr US IT Recruiter\nMy3 Tech Inc,\n1601 N Harrison Ave, STE # 2B, Pierre, SD 57501\nDirect: 605-599-1262 | Board: 605-220-5981 Ext-118 |\nE Mail: vivek.j@my3tech.com\nShow more\nShow less",
      "job_skills":"Advanced Excel, MS Power BI, Power Automate, Tableau, SQL, Data Analysis, Reporting, Metrics, Flowcharts, Systems Analysis, Project Management, Process Improvement, Critical Thinking, Problem Solving, Independent Work, Multiple Projects Management",
      "Category":"Data Science"
  },
  {
      "job_title":"Systems Analyst 2\/ Technical Business Analyst - Data Warehousing\/ SAS-Austin, Texas-Hybrid",
      "company":"Stellent IT",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/systems-analyst-2-technical-business-analyst-data-warehousing-sas-austin-texas-hybrid-at-stellent-it-3762864607",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Systems Analyst 2\/ Technical Business Analyst - Data Warehousing\/ SAS\nAustin, Texas-Hybrid\nPhone+Skype\n6+month\nJob Description\nMinimum Requirements:\nCandidates that do not meet or exceed the minimum stated requirements (skills\/experience) will be displayed to customers but may not be chosen for this opportunity\nExpertise in requirement gathering, customer engagement, customer communication and project management\nExperience with data warehousing design\/development\nExperience developing detailed technical documentation\nExperience documenting solutions and accurately conveying to technical SMEs\nExperience with SAS (Statistical Analytical System) programming\nExperience with data warehouse architecture standards, process, and methodology, with good knowledge of data integration, data quality, multi-dimensional design and ETL tools\nIdentify, create, and participate in the implementation of business process improvements and systems that deliver tangible value\nExperience with Agile development experience with Scrum, Kanban\nExperience understanding complex issues and facilitating resolution\nPreferred\nExperience with highly complex application security requirements\nExperience with Oracle (18+) data warehousing development\nExperience with Oracle database programming (SQL, TSQL, PL\/SQL, BTEQ)\nPublic sector experience (Federal, State or Local Government)\nProficient with the Microsoft Office products, including Outlook, TEAMS, Microsoft Project, Word, Visio, Excel and PowerPoint\nShow more\nShow less",
      "job_skills":"Requirement Gathering, Customer Engagement, Project Management, Data Warehousing, SAS Programming, Data Integration, Data Quality, ETL Tools, Business Process Improvement, Agile Development, Scrum, Kanban, Oracle Data Warehousing, Oracle Database Programming (SQL TSQL PL\/SQL BTEQ), Public Sector Experience, Microsoft Office Suite (Outlook TEAMS Microsoft Project Word Visio Excel and PowerPoint)",
      "Category":"Data Science"
  },
  {
      "job_title":"Systems Analyst",
      "company":"IDR, Inc.",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/systems-analyst-at-idr-inc-3777173245",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"IDR is seeking a Systems Analyst to join one of our top clients in the public sector industry. If you are looking for an opportunity to join a large organization and work within an ever-growing team-oriented culture, please apply today!\nPosition Overview\/Responsibilities For The Systems Analyst\nPeoplesoft Technical Functional Analyst completes software development tasks including features, new functionality, and upgrades.\nThis position works with technical support staff, functional analysts, or network specialists to develop code fixes, to perform modifications and\/or updates to existing systems per design documents or to implement new interfaces or processes.\nThe individual will be able to Identify, investigate and resolve production problems and participate in code reviews to ensure compliance with development standards and system\/business requirements.\nDesigns, codes, and modifies complex computer programs, subroutines, triggers, stored procedures, objects, classes, and scripts. Performs necessary testing of assigned programs, including the generation of test data, writing test scripts\/execution sequences, examining test results, debugging detected errors, etc. Performs customer service, coordination, and communications in a complex HHSC organization.\nRequired Skills For The Systems Analyst\n8+ years\u201a\u00c4\u00f4 experience supporting PeopleSoft FSCM 9.2\n8+ years\u201a\u00c4\u00f4 experience with the following: PeopleCode, Application Packages, Application Engine, COBOL, SQR, and Integration Broker (REST, SOAP, JSON, and XML)\nProfessional experience working in the public sector industry\nWhat\u201a\u00c4\u00f4s in it for you?\nCompetitive compensation package\nFull Benefits; Medical, Vision, Dental, and more!\nOpportunity to get in with an industry leading organization\nClose-knit and team-oriented culture\nWhy IDR?\n25+ Years of Proven Industry Experience in 4 major markets\nEmployee Stock Ownership Program\nDedicated Engagement Manager who is committed to you and your success\nMedical, Dental, Vision, and Life Insurance\nClearlyRated\u201a\u00c4\u00f4s Best of Staffing\u00ac\u00c6 Client and Talent Award winner 10 years in a row\nShow more\nShow less",
      "job_skills":"PeopleSoft, PeopleCode, COBOL, SQR, Application Engine, Integration Broker, REST, SOAP, JSON, XML, FSCM",
      "Category":"Data Science"
  },
  {
      "job_title":"Quality Analyst",
      "company":"AbbVie",
      "job_location":"Waco, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/quality-analyst-at-abbvie-3756016330",
      "search_city":"Waco",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Summary\nGeneralist position that supports the Quality Systems department\u201a\u00c4\u00f4s overall needs.\nJob Details\nThis position is responsible for the following:\nResponsible for the compilation and analysis of data required to support Annual product reviews, which includes, but is not limited to revisions to Product Specifications, Manufacturing and QC Master Records; Final Release Inspection results; Stability results; GTW records, Product Complaint information etc.\nResponsible for the preparation of annual product review reports according to product schedule.\nAssist with the compilation and analysis of data for Quality metrics for the site to support Quality Management review meetings at the site and Quarterly Corporate Segment review meetings.\nAssists with review and approval of site metrics and data for PI meetings.\nAssist with performing of Internal audits in adherence with the annual Internal audit schedule.\nProvide support to the front and or back room during site audits and inspections as needed.\nPerform other duties as assigned.\nEducation and Experience:\nMinimum requirements for this position are:\nEducation\nBachelor\u201a\u00c4\u00f4s Degree in a science or related field preferred, or equivalent combination of education and experience required.\nExperience:\nThree (3) to five (5) years of experience in a laboratory or quality role.\nExperience: Systems\nAdvanced Microsoft Office\nExperience: Regulatory\nExperience In a Regulated Environment Preferred.\nExperience: Aseptic\nExperience in the manufacture of pharmaceuticals.\nEssential Knowledge, Skills & Abilities:\nExcellent analytical and problem-solving skills; ability to analyze data.\nExcellent oral and written communication skills.\nTechnical writing skills and trouble shooting skills.\nAbility to define problems, collect data, establish facts and draw valid conclusions.\nAbility to work effectively with peers and supervisors.\nWorking knowledge of cGMP\u201a\u00c4\u00f4s and QA systems.\nAbbVie is committed to operating with integrity, driving innovation, transforming lives, serving our community, and embracing diversity and inclusion. It is AbbVie\u201a\u00c4\u00f4s policy to employ qualified persons of the greatest ability without discrimination against any employee or applicant for employment because of race, color, religion, national origin, age, sex (including pregnancy), physical or mental disability, medical condition, genetic information, gender identity or expression, sexual orientation, marital status, status as a protected veteran, or any other legally protected group status.\nShow more\nShow less",
      "job_skills":"Advanced Microsoft Office, cGMP, QA systems, Analytical skills, Problemsolving skills, Data analysis, Oral communication skills, Written communication skills, Technical writing skills, Trouble shooting skills, Data collection, Conclusion drawing skills, Teamwork skills, Laboratory experience, Quality assurance experience, Regulatory experience, Aseptic manufacturing experience, Pharmaceutical manufacturing experience",
      "Category":"Data Science"
  },
  {
      "job_title":"Project Manager\/ Business Analyst",
      "company":"Intellectt Inc",
      "job_location":"Abbott, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/project-manager-business-analyst-at-intellectt-inc-3726855731",
      "search_city":"Waco",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Hi, greetings of the day\nThis is Rajitha. K from Intellectt Inc., working as a Technical Recruiter. Currently, we have an immediate opening with one of our direct clients, please find the below Job description and if interested kindly do share your resume at rajitha@intellectt.com\nRole: Project Manager I\nLocation: Abbott Park, IL - 60064-3500\nDuration: 3 Months on W2 (Possibility of extension)\nShift Timings: 8:00am to 4:30pm\nSkills Looking For\nWork under two different projects and support two managers.\nLearning and development background will be nice to have as they will be working on these projects.\nThere are new cohorts that are brought in to participate in this program. This individual will project manage all the steps they need to take.\nThere may be 3 to 4 cohorts overlapping each other and they need to be able to juggle between them.\nPerform some administrative work: set up emails for the individuals for communications and send out welcome emails to them.\nWill not work on setting up calendar invites etc. They will manage the program as well as the execution steps.\nStrong Project management skills required; manage the projects, schedule timelines and see through the execution.\nManage emails coming in and answering the questions from participants. Sometimes they will get requests to move participants to different cohorts and they will need to be able to do that.\nAble to juggle between different projects and be detail-oriented.\nManage dashboards, power BI, manage other e-learning platforms\nProject manage updates to the dashboard.\nProject manage execution to the e-learning, create dashboards for that to help the manager to manage that project.\nMust be well-versed in Power BI, Excel, and SharePoint.\nWill also consider candidates if they have project coordination experience.\nStrong Customer service skills. As they will be dealing a lot with internal employees and external suppliers who provide them with content.\nEducation And Experience\nBachelors required\nAt least 3 to 5 years of experience.\nTop Skills\nProject Management experience and have led the projects through the execution.\nTechnical skills: Power BI, Excel, SharePoint.\n--\nThanks & Regards,\nRajitha K\nEmail: rajitha@intellectt.com\nDirect Number: 732 532 2478; Ext :267\nShow more\nShow less",
      "job_skills":"Project Management, Power BI, Excel, SharePoint, Project Coordination, Dashboard Management, Elearning Platform Management, Customer Service",
      "Category":"Data Science"
  },
  {
      "job_title":"Supply Chain Data Analyst",
      "company":"Staffmark Group",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/supply-chain-data-analyst-at-staffmark-group-3787398543",
      "search_city":"McKinney",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Staffmark Workforce Solutions offers this exciting contract opportunity at a global leader in electronics, mobile devices, and appliances located in Plano, TX.\nSupply Chain Data Analyst\nResponsibilities:\nSupport Collaborative Planning, Forecasting, and Replenishment (CPFR) supply chain process by interfacing with key customer contacts during weekly planning meetings. Must be able to communicate effectively with customers.\nAnalyze weekly Purchase Sales Inventory (PSI) to identify sales target status, drive product manufacturing, and ensure timely fulfillment of delivery to achieve sales plans, product development, and strategic product launches.\nManage system-based tools that provide real-time information regarding sales, order forecast, and channel inventory; extract data to conduct channel inventory analysis and reconciliation.\nProvide daily\/weekly updates of product arrival schedules from factories and against customer delivery commitments. Reviewing and identifying variances compared to outstanding sales orders and forecasts, to plan for future product availability and inventory.\nMonitor team performance on weekly\/quarterly KPIs to identify exception cases and analyze those metrics for potential process improvements to drive operational efficiency.\nMay communicate daily between headquarters and internal cross-functional teams and handle escalation on production allocation, delivery requirements, and inventory management.\nRespond to ad-hoc reporting requests from internal and external customers in a time-sensitive environment.\nRequirements:\nA bachelor\u201a\u00c4\u00f4s degree with 2-4 years of experience preferably in finance, business, or supply chain management; MBA preferred.\nExperience in the telecommunications and\/or wireless industry requiring management of finance, logistics, distribution, program management, and\/or business planning, or equivalent work experience in planning, finance, or operations (Preferred)\nExperience should include researching and resolving customer product development, launch, delivery, and logistics issues; driving process improvement to streamline business cadence.\nData Analytics, Forecasting, and direct Customer interface experience preferred.\nNecessary Skills\/Attributes for this position the following skills and abilities must be demonstrated at a proficient level:\nThe ability to develop and maintain excellent working relationships with all appropriate levels within and outside the company.\nProven success in a highly dynamic and fast-paced environment.\nMust have advanced MS Excel and MS PowerPoint knowledge and skills; experience in developing KPI and executive dashboards preferred.\nExperience using advanced supply chain management, enterprise planning, or financial planning systems is highly desired (Oracle, SAP, etc.).\nExperience building standardized reports in Tableau or other reporting tools preferred.\nThe ability to work either independently or in a team environment to achieve personal and team project goals, including the completion of assignments within and exceeding established time frames.\nForecasting - The ability to prepare sellout volume projections for Marketing promotions, prepare weekly sellout forecasts, and use Data Analytics to identify developing trends and problem areas.\nThe ability to learn new Planning and Analytics Tools.\nStaffmark talent working with this client receive competitive compensation and a great benefits package including medical, dental, vision, 401K, and Paid Time Off plus more!\nClick \"Apply Now\" and a dedicated recruiter will be in touch to discuss this amazing opportunity.\nAfter you have applied, download our Staffmark Group WorkNOW App to receive real-time job offers and apply for additional opportunities. You can download it from the App Store or get it on Google Play.\nAbout Staffmark\nStaffmark is committed to providing equal employment opportunity for all persons regardless of race, color, religion (including religious dress and grooming practices), sex, sexual orientation, gender, gender identity, gender expression, age, marital status, national origin, ancestry, citizenship status, pregnancy, medical condition, genetic information, mental and physical disability, political affiliation, union membership, status as a parent, military or veteran status or other non-merit based factors. We will provide reasonable accommodations throughout the application, interviewing and employment process. If you require a reasonable accommodation, contact us. Staffmark is an E-Verify employer. This policy is applicable to all phases of the employment relationship, including hiring, transfers, promotions, training, terminations, working conditions, compensation, benefits, and other terms and conditions of employment.\nAll employees are directed to familiarize themselves with this policy and to act in accordance with it. All decisions with respect to employment matters and other phases of employer-temporary employee relationships will be in keeping with this policy and in accordance with all applicable laws and regulations.\nShow more\nShow less",
      "job_skills":"CPFR, Purchase Sales Inventory (PSI), Oracle, SAP, Tableau, Microsoft Excel, Microsoft PowerPoint, Forecasting, Data Analytics, Supply Chain Management, Tableau, KPI, ERP, Finance, Logistics, Distribution, Program Management, Business Planning, Planning, Operations, Customer Interface",
      "Category":"Data Science"
  },
  {
      "job_title":"Systems Analyst I, II, III, Senior",
      "company":"Global Credit Union",
      "job_location":"Spokane, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/systems-analyst-i-ii-iii-senior-at-global-credit-union-3774147758",
      "search_city":"Spokane",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Overview\nReports to:\nDomain Manager, Systems Analysis\nFunctions Supervised:\nNone\nPrimary Functions:\nCollaborates as a member of a Product Development Team in the analysis of system specific user stories and technical processes of product capabilities. An active collaborator with Product Development Team members in the development of products to achieve strategic business outcomes.\nDuties And Responsibilities\nIdentify and solve business problems by collaborating in the development and implementation of value driven business solutions\nDevelops a working knowledge of credit union product capabilities\nDevelops general knowledge of current and emerging technology solutions\nIdentify, define, and document user stories and specifications\nDocument system architectures, data flows, and relationships to business processes\nPrioritize user stories to facilitate feature development\nCollaborate with software engineers on technical design and development\nCollaborate with Product Development Team members on test case documentation\nCollaborate with Product Development Team members on test case execution and acceptance\nDocument and track user stories related to defects and resolution\nWork closely with other analysts to collaborate in knowledge sharing activities\nPerform other duties as assigned in support of team efforts and results\nQualifications\nEducation:\nBachelor\u201a\u00c4\u00f4s degree required in a discipline such as computer science, information systems, or equivalent work experience. Certifications in Agile, SCRUM, MCSE, and\/or CISA preferred.\nCreditable Experience in Lieu of Education:\nEquivalent technical education and\/or related work experience.\nExperience\/Skills:\nAbility to effectively communicate both verbally and in writing at a variety of levels to include business stakeholders, vendors, technical teams, customers, and management. Three or more years of professional experience as a System Analyst. Working knowledge of Agile and DevOps practices and methodologies to include SCRUM and Kanban. Working knowledge of Software Development Lifecycle, operating systems, tools to test software applications\/systems, development\/modeling tools, technical workflow design, and time management skills. Able to work independently and as part of a large or small team.\nTenure:\nAssignment to the Systems Analyst I category 10, Systems Analyst II category 09, Systems Analyst III category 08, or Senior Systems Analyst category 07 will be determined by the candidate's education or experience. Advancement requires management recommendation and will be based on the candidate's certifications and\/or performance.\nCompensation\nSalary Pay Range:\nSystems Analyst I (Category 10): $57,484 - $90,825 annually\nSystems Analyst II (Category 09): $63,233 - $101,804 annually\nSystems Analyst III (Category 08): $72,717 - $119,983 anually\nSenior Systems Analyst (Category 07): $80,000 - $137,981 annually\nStarting base salary will be determined based on candidate experience, qualifications, education, and local or state wage requirements, if applicable and will fall within the range provided above.\nIn accordance with our Salary Administration policy, new hire base salaries generally fall within the minimum to midpoint of the listed range.\nBenefits\nShort-term and long-term incentives\nComprehensive medical, dental and vision insurance plan that has HSA and FSA options\n401(k) plan with a 5% match\nEmployee Assistance Program (EAP)\nLife and disability coverage\nVoluntary cash benefits for accident, hospitalization and critical illness\nTuition Reimbursement\nGenerous leave programs to include Paid Time Off accrual, Paid Sick Leave, Paid Holidays\nClick here to view Global\u201a\u00c4\u00f4s comprehensive Benefits Programs .\nEqual Opportunity Employer\nShow more\nShow less",
      "job_skills":"Agile, DevOps, SCRUM, Kanban, Software Development Lifecycle, Operating systems, Software testing tools, Development tools, Modeling tools, Technical workflow design, Time management",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst-Compensation - REMOTE",
      "company":"Mercy",
      "job_location":"Chesterfield, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-compensation-remote-at-mercy-3790400891",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"We\u201a\u00c4\u00f4re a Little Different\nOur mission is clear. We bring to life a healing ministry through our compassionate care and exceptional service.\nAt Mercy, we believe in careers that match the unique gifts of unique individuals \u201a\u00c4\u00ec careers that not only make the most of your skills and talents, but also your heart. Join us and discover why Modern Healthcare Magazine named us in its \u201a\u00c4\u00faTop 100 Places to Work.\u201a\u00c4\u00f9\nOverview\nThis is a REMOTE position.\nThe Senior Analyst-Compensation Analyst provides professional and administrative support to the regional Compensation function. Provides compensation services for designated Mercy client departments on a regional or ministry-wide basis. Serves a project lead on large scale initiatives. Administers selected compensation programs and functions. Makes difficult compensation related decisions regarding unusual, complex and challenging issues and initiates or recommends appropriate actions. Interprets and enforces compensation and HR policies and practices. Maintains confidentiality of personnel information and exhibits independent judgment and decision making. Performs all work in accordance with Mercys mission, vision, values and service standards.\nQualifications\nExperience: Four years of experience analyzing\/managing data using spreadsheets and other data management tools. Working in a human resources environment preferred.\nRequired Education: Bachelors Degree in human resources, business, finance or related field or equivalent experience.\nPreferred Experience: One or more years experience supporting Compensation functions.\nWe Offer Great Benefits\nDay-one comprehensive health, vision and dental coverage, PTO, tuition reimbursement and employer-matched retirement funds are just a few of the great benefits offered to eligible co-workers, including those working 32 hours or more per pay period!\nWe\u201a\u00c4\u00f4re bringing to life a healing ministry through compassionate care.\nAt Mercy, our supportive community will be behind you every step of your day, especially the tough ones. You will have opportunities to pioneer new models of care and transform the health care experience through advanced technology and innovative procedures. We\u201a\u00c4\u00f4re expanding to help our communities grow. Join us and be a part of it all.\nWhat Makes You a Good Match for Mercy?\nCompassion and professionalism go hand-in-hand with us. Having a positive outlook and a strong sense of advocacy is in perfect step with our mission and vision. We\u201a\u00c4\u00f4re also collaborative and unafraid to do a little extra to deliver excellent care \u201a\u00c4\u00ec that\u201a\u00c4\u00f4s just part of our commitment. If that sounds like a good fit for you, we encourage you to apply.\nShow more\nShow less",
      "job_skills":"Spreadsheets, Human resources, Compensation, Data management tools, Healthcare",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Business Analyst - Medicaid (Remote)",
      "company":"S2Tech",
      "job_location":"Chesterfield, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-business-analyst-medicaid-remote-at-s2tech-3780864751",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Job Details\nDescription\nSenior Business Analyst \u201a\u00c4\u00ec Medicaid\nLocation: Remote\nAbout Us\nKnown for \u201a\u00c4\u00faDelighting the Client\u201a\u00c4\u00f9 through performance, innovation and an employee-centric culture, S2Tech is a fast-growing IT consulting company serving clients in over a quarter of the United States. We are widely recognized as a leading provider of both technical and business services in support of Health and Human Services related projects. Feel free to learn more at www.s2tech.com .\nWhy S2Tech?\n:\nStable privately-owned company with a strong reputation for building long-term client relationships through the delivery of consistent value-based service\n25 year history of providing IT and Business services to private customers and government programs throughout the United States\nExpansive client portfolio and active projects \u201a\u00c4\u00ec employees benefit from innovative project exposure and in-house skill development training\/courses\nCorporate culture that emphasizes the importance of family and promotes healthy work-life balance\nOffer competitive pay and a range of benefits including:\nMedical \/ Dental \/ Vision Insurance \u201a\u00c4\u00ec insurance premium assistance provided\nAdditional Insurance (Life, Disability, etc.)\nPaid Time Off (Vacation & Sick Leave)\n401(k) Retirement Savings Plan & Health Savings Account\nVarious training courses to promote continuous learning\nCorporate Wellness Program\nBe part of a company that gives back through its non-profit organization, Fortune Fund, which was launched in 2001. The goal of the Fortune Fund is to close the rural\/urban divide by ensuring children in rural communities in India and the United States understand the importance of education & are aware of professional career opportunities allowing them to link their professional & educational goals\nJob Overview\nWe are seeking an accomplished Senior Business Analyst with extensive Medicaid experience to join our team in support of a Project Management Office (PMO) project. In this role, you will be integral to supporting multiple concurrent modular modernization implementations. The successful candidate will play a key role in ensuring the seamless integration of modernization efforts with a focus on optimizing Medicaid processes and compliance.\nResponsibilities\nMedicaid Program Analysis: Conduct comprehensive analysis of existing Medicaid programs, policies, and procedures to identify areas for modernization and improvement. Collaborate with cross-functional teams to align modernization efforts with business requirements.\nRequirements Gathering and Documentation: Lead requirements gathering sessions with business users, subject matter experts, and IT teams for modernization initiatives. Develop detailed business requirement documents (BRDs) and functional specification documents (FSDs) that guide modernization efforts.\nPMO Project Support: Work closely with the Project Management Office to ensure that modernization projects align with organizational goals and standards. Provide regular updates on the status of modernization implementations and address any issues or roadblocks.\nData Analysis: Utilize advanced data analysis techniques to extract insights relevant to both Medicaid and modernization efforts. Collaborate with data teams to ensure the availability of accurate and relevant data for modernization projects.\nProcess Improvement: Identify opportunities for process improvement within both Medicaid and modernization initiatives. Develop strategies to enhance operational efficiency, reduce costs, and improve the overall success of modernization projects.\nStakeholder Communication: Facilitate effective communication between business and technical teams, ensuring a shared understanding of modernization goals and requirements. Provide regular updates to stakeholders on the progress of modernization projects within the PMO framework.\nQualifications\nBachelor's degree in Business, Information Technology, or a related field. Advanced degree preferred\nCertified Business Analysis Professional (CBAP) or equivalent certification\nMinimum of 8 years of experience as a Business Analyst, with at least 5 years focused on Medicaid programs\nProven experience working within a Project Management Office and supporting concurrent modular modernization implementations\nStrong understanding of Medicaid regulations, policies, and processes\nExcellent analytical, communication, and problem-solving skills\nAbility to work collaboratively in a team environment and manage multiple priorities\nS2Tech is committed to hiring and retaining a diverse workforce. We are an equal opportunity employer making decisions without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or any other protected class.\nShow more\nShow less",
      "job_skills":"Medicaid, Business Analysis, Requirements Gathering, Documentation, Data Analysis, Process Improvement, Stakeholder Communication, Project Management Office (PMO), Medicaid Modernization, Business Requirements Documents (BRDs), Functional Specification Documents (FSDs), Advanced Data Analysis Techniques, CrossFunctional Teams, Subject Matter Experts, IT Teams, Business Users",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Accounting Analyst",
      "company":"Kforce Inc",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-accounting-analyst-at-kforce-inc-3785043524",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nKforce has a client in Saint Louis, MO that is seeking a Senior Accounting Analyst. This position report to the Accounting Manager. Responsibilities:\nPerform month-end close process related to main EcoSystems (Valuation & Property Services and Financial Services)\nWork closely with Business leaders to understand key drivers for month-end performance vs. Plan and lead business projects to support business leaders with financial needs\nPreparation of Management Discussion and Analysis commentary related to the above EcoSystems month-end performance\nPrepare Month-end close Journal Entries\nSupport Integration of acquired entities into related Ecosystem\nAddressing management questions related to respective Ecosystem performance\nEffective communication of month-end results to management\nEnsure the accuracy and integrity of the financial statements by: Preparation of monthly Balance Sheet reconciliations including but not limited to Accrued Liabilities, Credit Cards and Intercompany Balances; Ensure adequate supporting documentation is in place to support financial results; Ensure accounting data for respective EcoSystems is accurately coded and complete\nResearch, Analyze and document issues arising in the course of business\nInitiate or collaborate to drive processes and procedures improvements related to areas of responsibility\nSupport Accounting Management with Colibri's External audits by researching and responding to accounting and financial questions\nRequirements\nBachelor's degree in Accounting is required\nCPA is a plus\n5 years of relevant experience, including an established record of success in progressively senior accounting\/finance positions\nHighly results-oriented with ability to demonstrate impeccable integrity and honesty\nMust be highly organized, analytical and detail oriented\nProcess improvement-oriented thinking and demonstrate intellectual curiosity (entrepreneurial spirit)\nStrong accounting experience (revenue reconciliations is a plus), ideally in a fast-paced, entrepreneurial company\nStrong organizational and time management skills that allow projects and goals to be completed timely\nAudit experience is a plus\nAdvanced knowledge of Microsoft Excel, Strong proficiency with Microsoft Office Suite\nERP Experience (Oracle Netsuite is a plus)\nEmbrace, support and exemplify our Core Values: Love, Trust, Joy, Boldness and Teamwork\nThe pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.\nWe offer comprehensive benefits including medical\/dental\/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.\nNote: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.\nThis job is not eligible for bonuses, incentives or commissions.\nKforce is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nSalary: $55 - $65 per hour\nShow more\nShow less",
      "job_skills":"Accounting, Balance Sheet, Business Projects, CPA, Colibri, Core Values, Credit Cards, Detailoriented, ERP, Financial Services, Financial Statements, Intercompany Balances, Journal Entries, Management Discussion and Analysis, Microsoft Excel, Microsoft Office Suite, Monthend close process, NetSuite, Oracle, Performance, Process improvement, Property Services, Reconciliation, Revenue, Valuation",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Brooksource",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-brooksource-3763821614",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Associate Data Analyst\nSt. Louis, MO\n(Required to go onsite 3X\/week - no remote candidates will be considered)\nContract-to-hire\n$60-65k\nAs the Associate Data Analyst, you will analyze data to promote client growth alongside a product analytics team of a Fortune 15 company. You will utilize SQL to support in the reporting of client specific analyses, as well as support in the buildout of client dashboard templates. You will have the ability to present findings to various stakeholders and collaborate cross functionally with business teams. This is a great opportunity to access mentorship and training in various technologies.\nMinimum Qualifications:\n\u00ac\u2211 Bachelor\u201a\u00c4\u00f4s Degree OR relevant equivalent experience (Military, technical bootcamp, etc.)\n\u00ac\u2211 Solid understanding and hands on experience with SQL\n\u00ac\u2211 Familiarity or ability to tell a data story through visualization tools, Tableau is a plus\n\u00ac\u2211 Data Presentation experience through classroom or internship projects\n\u00ac\u2211 Passion for working with clients and collaborating with high-level stakeholders\nResponsibilities:\n\u00ac\u2211 Write SQL to create new queries and dashboards that will become standard for client visits\n\u00ac\u2211 Analyze client data and visualize this analysis within Tableau dashboards\n\u00ac\u2211 Present data and conclusions to stakeholders on a daily basis\n\u00ac\u2211 Aid in general project coordination tasks including coordinating client events to ensure they are properly supported\nWhat\u201a\u00c4\u00f4s In It For You?\n\u00ac\u2211 Opportunity to start your career at a Fortune 15 Healthcare Company\n\u00ac\u2211 You will be trained and mentored by senior technologists\n\u00ac\u2211 You will attend networking events with senior leadership\n\u00ac\u2211 Weekly paychecks\nShow more\nShow less",
      "job_skills":"SQL, Tableau, Data Visualization, Data Presentation, Data Analysis",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Warehouse Analyst",
      "company":"Elevance Health",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-warehouse-analyst-at-elevance-health-3783398869",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Description\nBioPlus Specialty Pharmacy is now part of CarelonRx (formerly IngenioRx), and a proud member of the Elevance Health family of companies. Together, CarelonRx and BioPlus offer consumers and providers an unparalleled level of service that\u201a\u00c4\u00f4s easy and focused on whole health. Through our distinct clinical expertise, digital capabilities, and broad access to specialty medications across a wide range of conditions, we deliver an elevated experience, affordability, and personalized support throughout the consumer\u201a\u00c4\u00f4s treatment journey.\nData Warehouse Analyst\nLocation:\nThe preferred location of this role is in St. Louis, MO. This position is part of Elevance Health hybrid work model (remote and office). Ideal candidate can will lives within 50 miles of one of our PulsePoint Locations.\nThe\nD\nata Warehouse Analyst\nis responsible for partnering with internal and external business clients and IT to fulfill information needs and support business decisions.\nHow You Will Make An Impact\nMaintains information policies and procedures to support current and future data information needs and ensures proper data definitions, ownership, use and integrity of data.\nAnalyzes business user needs, documents information requirements, facilitates the identification of potential gaps in available data and collaborates with business areas to determine best means for acquiring the data needed.\nCollaborates with IT resources on the creation and maintenance of the content of the data warehouse, establishes and maintains general knowledge of data warehouse data structure design, definitions, capabilities, SQL, and data integrity issues, completes metadata assessment and reviews feedback to determine changes, ensures that data definitions are clear and current, and communicates changes to data definitions to all users.\nCollaborates with IT resources and data owners to define business objectives and definitions for databases including business rules, sources, purge archive criteria, and reload schedule.\nAnalyzes transactional data stores and develops data warehouse models to optimize the warehouse data stores for reporting and analytics.\nPrototypes, builds, and tests extraction, transformation, and load (ETL or ELT).\nPrototypes, builds, and tests data quality processes and related jobs.\nEnsures data warehouse metadata is collected and maintained.\nPrototypes, builds, and tests Power BI reports and dashboards.\nMinimum Requirements\nRequires Bachelor's degree in related field and a minimum of 1 year experience in data analysis, data modeling, and working with automated data warehouse systems; or any combination of education and experience which would provide an equivalent background.\nPreferred Skills, Capabilities And Experiences\nKnowledge of and skill in Power BI functionality\nKnowledge of and skill in Tableau functionality\nKnowledge of and skill in relational database platforms including DB2, SQL Server, and Oracle\nGood understanding of Data Warehouse architecture and design and ETL processes\nStrong analytical and problem-solving skills\nExperience in SQL, GQL, SAS, and Tableau\nStrong analytical and problem-solving ability strongly preferred.\nPlease be advised that Elevance Health only accepts resumes for compensation from agencies that have a signed agreement with Elevance Health. Any unsolicited resumes, including those submitted to hiring managers, are deemed to be the property of Elevance Health.\nWho We Are\nElevance Health is a health company dedicated to improving lives and communities \u201a\u00c4\u00ec and making healthcare simpler. We are a Fortune 25 company with a longstanding history in the healthcare industry, looking for leaders at all levels of the organization who are passionate about making an impact on our members and the communities we serve.\nHow We Work\nAt Elevance Health, we are creating a culture that is designed to advance our strategy but will also lead to personal and professional growth for our associates. Our values and behaviors are the root of our culture. They are how we achieve our strategy, power our business outcomes and drive our shared success - for our consumers, our associates, our communities and our business.\nWe offer a range of market-competitive total rewards that include merit increases, paid holidays, Paid Time Off, and incentive bonus programs (unless covered by a collective bargaining agreement), medical, dental, vision, short and long term disability benefits, 401(k) +match, stock purchase plan, life insurance, wellness programs and financial education resources, to name a few.\nElevance Health operates in a Hybrid Workforce Strategy. Unless specified as primarily virtual by the hiring manager, associates are required to work at an Elevance Health location at least once per week, and potentially several times per week. Specific requirements and expectations for time onsite will be discussed as part of the hiring process. Candidates must reside within 50 miles or 1-hour commute each way of a relevant Elevance Health location.\nThe health of our associates and communities is a top priority for Elevance Health. We require all new candidates in certain patient\/member-facing roles to become vaccinated against COVID-19. If you are not vaccinated, your offer will be rescinded unless you provide an acceptable explanation. Elevance Health will also follow all relevant federal, state and local laws.\nElevance Health is an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to age, citizenship status, color, creed, disability, ethnicity, genetic information, gender (including gender identity and gender expression), marital status, national origin, race, religion, sex, sexual orientation, veteran status or any other status or condition protected by applicable federal, state, or local laws. Applicants who require accommodation to participate in the job application process may contact elevancehealthjobssupport@elevancehealth.com for assistance.\nShow more\nShow less",
      "job_skills":"Power BI, Tableau, DB2, SQL Server, Oracle, Data Warehouse architecture, ETL processes, SQL, GQL, SAS",
      "Category":"Data Science"
  },
  {
      "job_title":"Supply Chain Analyst - Remote | WFH",
      "company":"Get It Recruit - Transportation",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/supply-chain-analyst-remote-wfh-at-get-it-recruit-transportation-3769085521",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Are you a process-driven, data-oriented individual looking for a collaborative role? We are seeking a highly motivated Supply Chain Analyst to join our dynamic team. As a crucial member of our Global Manufacturing Organization, you'll play a pivotal role in establishing key processes and communication methodologies in our growing organization.\nKey Responsibilities\nData Analysis\nEvaluate existing data and KPIs to provide proactive recommendations and inform leadership decisions.\nEnsure accuracy in reporting by validating and auditing data capture processes.\nCommunications and Dashboards\nDevelop tracking processes supporting operational standards and long-term planning.\nCraft a communication roadmap catering to the needs of our expanding matrix organization, offering clear and sustainable insights to drive actionable decisions within leadership.\nCross-functional Collaboration\nCollaborate with various teams across the organization to ensure seamless data capture and communication, from Product Pipeline to Sales Targets.\nConfidently raise questions, make recommendations, and drive results across platforms to meet' needs.\nContinuous Improvement and Strategy\nFocus on platform establishment, stabilization, and identifying improvement opportunities for our Manufacturing and Supply Chain operations.\nDocument processes to align with strategic objectives, leading value stream mapping sessions for optimized product and information flow.\nProject Management\nLead cross-functional projects to support key strategic initiatives.\nQualifications\nBachelor's Degree in Business Analytics, Supply Chain, Logistics, Data Science, or related field.\nMBA preferred; Supply Chain certification is a plus.\n3+ years of experience in similar roles, including Global Operations.\nProficiency in digital data analysis platforms and creating data visual tools like Excel, Tableau, or Power BI.\nStrong attention to detail, problem-solving skills, and experience in process improvement and project management methodologies.\nPhysical Requirements\nAbility to alternate between sitting and standing\nLifting or Carrying up to 10 lbs as needed\nProficiency in keyboarding and fine manipulation\nEffective verbal communication and hearing abilities\nNear visual acuity for computer use\nLocation: St. Louis, MO, United States or Remote\nPosition Type: Full-Time\/Regular\/Salary\/Exempt\nSalary: Competitive base\nBenefits: Employee Stock Options, 401K, Healthcare, Dental, Vision, Life, HSA\/FSA\nAbout Us\nWe are committed to enhancing agricultural performance with eco-friendly and sustainable solutions. From innovative enzyme products to rejuvenating foliar treatments, our focus is to make a positive impact on both plants and the planet. We strive to bring together scientists and processes to create practical, novel solutions aimed at enriching our environment.\nApply\nTo apply, please complete the application and submit your resume and cover letter through the open job posting on Bamboo HR. References may be required upon request.\nJoin us in making a difference through innovation and collaboration!\nEmployment Type: Full-Time\nShow more\nShow less",
      "job_skills":"Data Analysis, Proactive Recommendations, Data Capture Processes, Auditing, Communications, Dashboards, Operational Standards, Sustainable Insights, Actionable Decisions, CrossFunctional Collaboration, Seamless Data Capture, Problem Solving, Process Improvement, Project Management, Business Analytics, Supply Chain, Logistics, Data Science, Global Operations, Excel, Tableau, Power BI, Visual Tools",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Data Governance Analyst",
      "company":"Accounting Career Consultants & HR Career Consultants",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-governance-analyst-at-accounting-career-consultants-hr-career-consultants-3768713926",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Why is This a Great Opportunity?\n-great boss\n-autonomy in role\n-tremendous flexibility\n-high-level exposure role\n-tons of growth\n-top company\n-strong comp package\nJob Description:\n-Expertise in Data Management: Demonstrate a profound understanding of master data management, data standards, data quality, and data lineage, ensuring a comprehensive approach to Data Governance.\n-Partnership and Documentation: Collaborate closely with functional stakeholders to develop and document Data Governance best practices, standards, principles, and policies that align with organizational objectives.\n-Data Quality Reporting: Contribute to the development of data quality reports and dashboards, providing valuable insights to stakeholders and ensuring the health of data aligns with business goals.\n-Continuous Improvement: Embrace a continuous improvement mindset, identifying opportunities to enhance processes and systems that align with Data Governance policies and standards.\n-Promotion of Data Governance Tools: Actively facilitate and promote the adoption of data governance tools, processes, and procedures among functional business users, ensuring widespread understanding and compliance.\nQualifications:\n-2+ years of data governance experience\n-self-starter\n-strong\nShow more\nShow less",
      "job_skills":"Data Management, Data Governance, Master Data Management, Data Standards, Data Quality, Data Lineage, Data Governance Best Practices, Data Governance Standards, Data Governance Principles, Data Governance Policies, Data Quality Reporting, Data Quality Dashboards, Continuous Improvement, Data Governance Tools, Data Governance Processes, Data Governance Procedures",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Migration Analyst - Hybrid",
      "company":"Swank Motion Pictures, Inc.",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-migration-analyst-hybrid-at-swank-motion-pictures-inc-3766477789",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Swank Motion Pictures is looking for a technical business analyst to join an existing and growing team working on innovative and leading-edge technologies. We are looking for someone with strong data analysis skills necessary to work on multiple projects simultaneously with minimal oversight in an agile\/iterative IT environment. These projects are primarily custom software development and business process improvements. This position is a liaison between non-technical business stakeholders and technology teams. This position is in the IT department and will interact with multiple levels of management within the company. This position is intended to be a year-long position with the opportunity of becoming a permanent role within the group. At Swank Motion Pictures, we are not just looking for employees; we are investing in future leaders. For the Data Migration Analyst role, we offer a pathway for professional growth and development. As our company evolves, there will be abundant opportunities for you to expand your skill set, take on new challenges, and advance your career. We are committed to fostering a culture of learning and innovation where your contributions will be recognized and your professional aspirations supported.\nResponsibilities\nThis position has the primary responsibility to analyze corporate data and assist in its migration from one system to another. Corporate data includes but is not limited to accounts, contacts, agreements, orders, and invoices. The data migration analyst will elicit, verify, and document business-defined data migration rules; analyze data based on those rules for consistency, cleanliness, and outliers; perform quality control checks against data transfer files; and share findings from those checks with the data migration team. The Data Migration Analyst will be expected to develop and maintain comprehensive documentation, including data mappings, transformation rules, and workflow diagrams, to ensure clarity and consistency throughout the data migration process. This individual will be an integral part of a team consisting of data architects, system specialists, and project managers. The Data Migration Analyst will collaborate closely with data governance teams to uphold meaningful data quality and compliance standards across all stages of the migration process. This position is a hybrid position \u201a\u00c4\u00ec the individual must be willing to be in the office at least 2 days per week.\nRequirements\nSkills Needed\nInterpersonal skills to negotiate priorities and collaborate with both business and IT peers\nInterview skills to ask the proper questions for gathering essential requirements and listen attentively to their feedback\nAnalytical skills to critically evaluate data of different types, discern data patterns, and identify data outliers using a high level of attention to detail\nCommunication skills to effectively share ideas and requirements with both technical and non-technical audiences through meetings, working group sessions, whiteboard sessions using data visualization skills and too\nCreativity skills to be flexible and think outside the box when solving problems\nOrganizational skills to meet deadlines, ensure quality deliverables, and cope with rapidly changing information in a hybrid work environment\nExperience Needed\n3 to 5 years of experience executing business analysis with a focus on data analysis and migration\nExperience working with and analyzing large amounts of data via Excel \u201a\u00c4\u00ec SQL experience is nice to have but not required\nAn understanding of best practices for eliciting, analyzing, documenting, validating, and managing requirements, along with knowing when to apply them\nExperience facilitating meetings with both business and IT stakeholders from any level within the organization\nExperience eliciting requirements via one-on-one interviews, group meetings, brainstorming sessions, and other methods as needed\nExperience collaborating with Project Management, Development, and Quality Assurance personnel on software development projects\nDetailed expertise using Microsoft Word, PowerPoint, and Excel a must; familiarity with Atlassian Jira and Confluence preferred but not required\nEducational Requirements\nBachelor\u201a\u00c4\u00f4s degree in technology related field required\nBenefits\nWe are pleased to offer:\nComprehensive compensation and healthcare packages, including medical, dental, vision, and life insurance products\n401(K) plan with employer match\nCompetitive paid time off: vacation, personal time, holidays and winter break\nCompany sponsored volunteer & community outreach opportunities\nOrganizational growth potential through our company sponsored online learning platform\nEOE, including disability\/vets\nShow more\nShow less",
      "job_skills":"Data analysis, Data migration, Business process improvement, Interpersonal skills, Interview skills, Analytical skills, Communication skills, Creativity skills, Organizational skills, Microsoft Word, PowerPoint, Excel, Atlassian Jira, Confluence, SQL",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst",
      "company":"City of Kansas City, MO",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-at-city-of-kansas-city-mo-3782774365",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Salary:\n$5,794-$8,833\/month\nFull-time position available with the General Services Department, in the Facilities Services Division, located at 414 E 12th St.\nSalary Range: $5,794-$8,833\/month\nNormal Work Days\/Hours: Monday-Friday 8:00 a.m.-5:00 p.m.\nApplication Deadline Date: December 18, 2023\nResponsibilities\nPlans and supervises training programs for less experienced staff in budget administration, systems and procedures, research and organization and management analysis.\nSupervises and participates in the conduct of continuous revenue and expenditure studies and projections and prepares analysis reports.\nCollects and analyzes cost data and other information to evaluate efficiency and procedures and makes recommendations to promote effective and economic operations.\nReviews project proposals, establishes work plans and determines time frames, funding limitations, and procedures for accomplishing project.\nDetermines staffing requirements and allotments to various phases of project.\nContracts with and coordinates project activities of external consultants and interdepartmental work teams and with other projects.\nEstablishes and maintains effective client relationships.\nManages the preparation of presentations, analyses, policy manuals and other projects.\nUnderstands and applies statistical techniques (econometric modeling, present value, regression analysis, time series, etc.) to assist in problem solving.\nPlans for the construction and maintenance of reporting systems, portfolio maintenance, billing, and reimbursement.\nAssists with the construction and maintenance of reporting systems, data maintenance, data collection, data decimation portfolio maintenance, billing, and reimbursement.\nApplies GIS techniques to better identify, analyze, and understand patterns and relationships.\nPerforms related duties as required.\nQualifications\nREQUIRES an accredited Master's degree in public or business administration, urban or regional planning, economics, organizational\/development psychology, project management\/or geography and 3 (OR an accredited Bachelor's degree and 5) years of professional experience in corporate\/municipal finance, research, accounting planning, project\/program management, or geographical information systems analytics.\nOther Information\nURGENT!!! CRITICAL RECRUITMENT INFORMATION\nApplications and\/or resumes are evaluated on the information received by the application deadline. Please ensure that your application or resume clearly demonstrates how you meet the minimum qualifications for the position for which you are applying, this includes providing all relevant educational dates and a detailed description of relevant work experience, including months\/years of employment. Applications and\/or resumes may not be considered if information is incomplete.\nIn order for a resume to be used in lieu of an application the resume must have been submitted online via the City's Applicant Tracking System.\nPositions requiring a high school diploma\/GED certificate must be obtained from a school\/program accredited by the Department of Education and recognized by the U.S. Secretary of Education.\nThe minimum education requirement for positions that allow for experience equivalency for an accredited degree is a high school diploma. Unless otherwise specified, an accredited degree must be obtained from a college or university listed with the U.S. Department of Education and recognized by the U.S. Secretary of Education.\nFor positions with a salary grade of EX6 or higher that require an accredited degree, qualifying professional experience must be obtained AFTER the accredited degree is obtained.\nSuccessful completion of a pre-employment criminal history\/background check is required for all positions. Some positions require a post offer drug screen and\/or physical.\nIf appointed, non-residents must obtain residency inside Kansas City, Missouri's city limits within nine months.\nThe City of KCMO is an equal opportunity employer that values diversity and inclusion in the workplace. The City is committed to providing a workplace environment for its employees and citizens free from discrimination based on race, color, sex (including pregnancy), national origin, religion, age, disability, marital status, genetic information, sexual orientation, or gender identity. For more information, please see our EEO Policy\nThe City of KCMO is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please call 816-513-1908 or send an e-mail to accommodations@kcmo.org .\nIf claiming military veterans' preference points, you must attach a copy of your DD-214 or a DD-256 (for reservists).\nTo claim veterans' points you must have served 180 days of regular active duty service and be discharged or released under honorable conditions during peacetimes or 90 days of active duty service, one (1) day during \"wartime\" and a last discharge or release under honorable conditions. (DOD) 38 U.S. Code\n4211).\nShow more\nShow less",
      "job_skills":"Budget administration, Systems and procedures, Research, Organization and management analysis, Revenue and expenditure studies, Projections, Cost data analysis, Efficiency and procedures evaluation, Project proposals review, Work plans establishment, Time frames determination, Funding limitations establishment, Project accomplishment procedures, Staffing requirements determination, Project phases allotments, External consultants coordination, Interdepartmental work teams coordination, Other projects coordination, Client relationships establishment, Presentations preparation, Analyses preparation, Policy manuals preparation, Econometric modeling, Present value analysis, Regression analysis, Time series analysis, Statistical techniques, GIS techniques, Reporting systems construction, Portfolio maintenance, Billing, Reimbursement, Data maintenance, Data collection, Data decimation",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Analyst",
      "company":"City of Kansas City, MO",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-analyst-at-city-of-kansas-city-mo-3788149194",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Salary:\n$5,794-$8,833\/month\nFull-time position available with the Finance Department, Accounts Division located at 414 East 12th Street\nSalary Range: $5,794-$8,833\/month\nNormal Work Days\/Hours: Monday-Friday, 8:00 a.m.-5:00 p.m. *Telework schedule available on an Episodic basis, meaning only in the event of an emergency after completion of 6-month probationary period.\nApplication Deadline Date: January 02, 2023\nResponsibilities\nPerforms accounting for and tracking fixed assets for other City departments\nReviews and processes fixed asset accounts.\nMaintains inventory records.\nReconciles accounts.\nAnalyzes expenditures and leases payments to determine which assets should be classified as City assets and the proper method of accounting for them.\nWorks with departments to assure inventory record keeping is accurate.\nMaintains historical data as to what the applicable life and book value is for each asset.\nMaintains accurate entries for depreciation and prepare entries annually that will need to be prepared annually for external audit purposes, and the underlying depreciation schedules will need to be prepared to differentiate between government wide expenses and program expenses.\nCollaborates with the arbitrage accountant to review all new bond issues to ensure that assets purchased and\/or constructed from bond proceeds are properly recorded.\nDetermines which funds the assets should be reported in and what programs they will be associated with.\nMaintains a database of all leases citywide to calculate assets and liabilities to be compliant with the Government Accounting Standards Board's Statement No. 87.\nPerforms responsible and advanced professional accounting work of an administrative nature covering all phases of account maintenance, audit, or expenditure control of fiscal transactions and requires advanced spreadsheet skills.\nUses advanced governmental accounting standards and Generally Acceptable Accounting Principles (GAAP), and prepares and analyzes financial statements.\nWorks independently and follows written procedures with general supervision.\nQualifications\nREQUIRES an accredited Master's degree in public or business administration, urban or regional planning, economics, accounting, finance or a related field and 3 OR an accredited Bachelor's degree and 5 years of professional experience in public or business administration, corporate or municipal finance, budget, research, accounting or a related field, including 2 years of experience at the Analyst level.\nOther Information\nURGENT!!! CRITICAL RECRUITMENT INFORMATION\nQUESTIONS REGARDING AVIATION POSITIONS SHOULD BE DIRECTED TO THE AVIATION DEPARTMENT AT 816-243-3010.\nApplications and\/or resumes are evaluated on the information received by the application deadline. Please ensure that your application or resume clearly demonstrates how you meet the minimum qualifications for the position for which you are applying, this includes providing all relevant educational dates and a detailed description of relevant work experience, including months\/years of employment. Applications and\/or resumes may not be considered if information is incomplete.\nIn order for a resume to be used in lieu of an application the resume must have been submitted online via the City's Applicant Tracking System.\nPositions requiring a high school diploma\/GED certificate must be obtained from a school\/program accredited by the Department of Education and recognized by the U.S. Secretary of Education.\nThe minimum education requirement for positions that allow for experience equivalency for an accredited degree is a high school diploma. Unless otherwise specified, an accredited degree must be obtained from a college or university listed with the U.S. Department of Education and recognized by the U.S. Secretary of Education.\nFor positions with a salary grade of EX6 or higher that require an accredited degree, qualifying professional experience must be obtained AFTER the accredited degree is obtained.\nSuccessful completion of a pre-employment criminal history\/background check is required for all positions. Some positions require a post offer drug screen and\/or physical.\nIf appointed, non-residents must obtain residency inside Kansas City, Missouri's city limits within nine months.\nThe City of KCMO is an equal opportunity employer that values diversity and inclusion in the workplace. The City is committed to providing a workplace environment for its employees and citizens free from discrimination based on race, color, sex (including pregnancy), national origin, religion, age, disability, marital status, genetic information, sexual orientation, or gender identity. For more information, please see our EEO Policy\nThe City of KCMO is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please call 816-513-1908 or send an e-mail to accommodations@kcmo.org .\nIf claiming military veterans' preference points, you must attach a copy of your DD-214 or a DD-256 (for reservists).\nTo claim veterans' points you must have served 180 days of regular active duty service and be discharged or released under honorable conditions during peacetimes or 90 days of active duty service, one (1) day during \"wartime\" and a last discharge or release under honorable conditions. (DOD) 38 U.S. Code\n4211).\nShow more\nShow less",
      "job_skills":"Accounting, Spreadsheet skills, Governmental accounting standards, Generally Accepted Accounting Principles (GAAP), financial statements, Database management, Budgeting, Research, Lease payments, Depreciation, Bond issues, Compliance, Fiscal transactions, Audit, Expenditure control",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Warehouse Production Support Analyst (R1282)",
      "company":"Sompo International",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-warehouse-production-support-analyst-r1282-at-sompo-international-3657202947",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"The Production Support Data Analyst is a hands-on position focused on supporting the data accuracy and completeness of the enterprise data warehouse. The position will work within IT to help Sompo International in the maintenance of the company\u201a\u00c4\u00f4s data warehouse that measures performance of all aspects of the company\u201a\u00c4\u00f4s operations.\nROLE RESPONSIBILITIES\nWork with business stakeholders to gather information required for root cause analysis of reported issues\nCoordinates with all necessary IT teams to analyze and resolve data issues for the enterprise data warehouse\nWhen necessary, creates source to target mapping documents to capture additional application data elements for loading from source systems into the enterprise data warehouse\nCollaborates with ETL team to ensure that source to target mappings are correctly translated into ETL code and that ETL code operates in line with STM requirements\nPerforms data validation to confirm data is moved into the data warehouse correctly\nWorks with reporting teams to assist them in understanding any reported variances between the data warehouse and source system application\nTECHNICAL QUALIFICATIONS\n4 + years of data analysis experience for a data warehouse\n2 years P&C Insurance subject matter experience (Policy and Claims)\nAdvanced SQL knowledge\nExtensive knowledge of Data Warehousing, ETL and BI Architectures, concepts, and frameworks\nCapable of creating and tuning Semantic layer Reporting Views\nCapable of facilitating data discovery sessions involving business subject matter experts\nKnowledge of RDBMS platforms (e.g. SQL Server, DB2) with experience in generating DDL\nGENERAL QUALIFICATIONS\nKnowledge of Guidewire Policy Center, Guidewire Claims Center, SAP FS-RI & SAP FS-CD applications and their data is a plus\nStrong interpersonal skills and ability to work as part of a team\nEDUCATION REQUIREMENTS\nBS in Computer Science, Information Management or Statistics or equivalent\nSalary Range\n: $75,000 - $120,000 Actual compensation for this role will depend on several factors including the cost of living associated with your work location, your qualifications, skills, competencies, and relevant experience.\nAt Sompo International, we recognize that the talent, skills, and commitment of our employees drive our success. This is why we offer competitive, high-quality compensation and benefit programs to eligible employees.\nOur compensation program is built on a foundation that promotes a pay-for-performance culture, resulting in higher incentive awards, on average, when the Company does well and lower incentive awards when the Company underperforms. The total compensation opportunity for all regular, full-time employees is a combination of base salary and incentives that gets adjusted upfront based on overall Company performance with final awards based on individual performance.\nWe continuously evaluate and update our benefit programs to ensure that our plans remain competitive and meet the needs of our employees and their dependents. Below is a summary of our current comprehensive U.S. benefit programs:\nTwo medical plans to choose from, including a Traditional PPO & a Consumer Driven Health Plan with a Health Savings account providing a competitive employer contribution.\nPharmacy benefits with mail order options.\nDental benefits including orthodontia benefits for adults and children.\nVision benefits.\nHealth Care & Dependent Care Flexible Spending Accounts.\nCompany-paid Life & AD&D benefits, including the option to purchase Supplemental life coverage for employee, spouse & children.\nCompany-paid Disability benefits with very competitive salary continuation payments.\n401(k) Retirement Savings Plan with competitive employer contributions.\nCompetitive paid-time-off programs, including company-paid holidays.\nCompetitive Parental Leave Benefits & Adoption Assistance program\nEmployee Assistance Program\nTax-Free Commuter Benefit\nTuition Reimbursement & Professional Qualification benefits\nSompo International is an equal opportunity employer committed to a diverse workforce. M\/F\/D\/V\nVisit our website at www.sompo-intl.com\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Warehousing, ETL, BI Architectures, SQL, RDBMS, DDL, Guidewire Policy Center, Guidewire Claims Center, SAP FSRI, SAP FSCD, Reporting Views, Data Discovery",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst I",
      "company":"Lockton",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-i-at-lockton-3774281918",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Your Responsibilities\nDescription:\nCollects data and analyzes client information\nWork collaboratively with managers and other teammates to collect data, ensuring reporting is accurate, timely, and of high quality.\nAudits data results and reports findings to supervisors\nPrepares standard and ad hoc reports\nFacilitates process and complete pricing comparisons for request for proposals (RFPs)\nAnalyzes client data in conjunction with other consultants to recommend plan design changes, programs or formulary changes\nIntegrates data from multiple data sets into relevant systems for reports publication.\nFollows policies, procedures, and\/or reports that make the overall practice more efficient and effective\nSupports standard data sets monthly within relevant systems\nCoordinates new client set-up, including file submission and testing, with consultants and system administrators\nGathers new reporting requirements from business users and coordinate development\/deployment with system administrators\nQualifications\nQualifications:\nBachelor's degree required. Major in Actuarial Science, Mathematics, Statistics or Finance.\nMS Excel experience required. In addition, experience using SQL and MS Access a plus.\nUnderstands data sources, processes, formulas and output General knowledge of healthcare issues and their associated impacts on plan sponsors and plan members.\nAbility to understand data integrity and correctness.\nExcellent written and oral communication skills to effectively present information to Associates at all levels of the Lockton organization.\nStrong proactive style.\nProven ability to manage multiple projects simultaneously.\nUnderstands industry trends and governmental regulations\nAbility to complete continuing education requirements as needed\nAbility to attend company, department, and team meetings as required, including industry training sessions\nAbility to comply with all company policies and procedures, proactively protecting confidentiality of Client and company information\nAbility to efficiently organize work and manage time in order to meet deadlines\nAbility to travel by automobile and aircraft\nAbility to use office equipment such as a computer, keyboard, calculator, photocopier, and facsimile machine\nAbility to work on a computer for a prolonged amount of time\nAbility to work outside of normal business hours as needed\nLegally able to work in the United States\nShow more\nShow less",
      "job_skills":"Actuarial Science, Data Analysis, SQL, MS Excel, MS Access, Project Management, Financial Analysis, Statistics, Mathematics, Data Integrity, Data Integration, Policy Compliance, Healthcare Issues, Industry Trends, Governmental Regulations, Communication Skills, Teamwork",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst III",
      "company":"Lockton",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-iii-at-lockton-3720808018",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Your Responsibilities\nDescription:\nWe are looking for a data analyst to be responsible for creating complex analysis of medical, pharmacy, and biometric data using SQL and Tableau . The ideal candidate will be motivated, results-driven, flexible, detail-oriented, and collaborative. Our fast-paced environment has a supportive culture that values autonomy, initiative, and personal accountability.\nJob Duties:\nDevelop and support new analytical tools and reports, primarily using SQL and Tableau.\nGathers new reporting requirements from stakeholders.\nWork collaboratively to ensure reporting that is accurate, timely, and of high quality.\nSet strategies and take ownership in on-going analytics development.\nGenerate benchmark data on a requested basis.\nResponsible for data consolidation, analysis, and business reporting.\nDevelops and maintains reports for stakeholders at all levels of the organization.\nProvides support to research teams or management by collecting and analyzing data and reporting results based on the needs of end users.\nMaintains data integrity and data processing efficiency by working to eliminate redundancy and applying best practice data stewardship techniques.\nStays informed of the ways the organization uses its data.\nRecognize data issues and work with data quality team to resolve problems.\nMust continuously be learning and staying abreast of technology advances.\nProvide exceptional customer service and adhere to the Lockton philosophies.\nQualifications\nRequirements:\nBachelor's degree required. Major in Mathematics, Statistics, Finance, Insurance, or Economics preferred.\nAdvanced knowledge and experience using SQL.\nKnowledge of Tableau strongly preferred.\nUnderstand data sources, processes, formulas, and output.\nAbility to understand data integrity and correctness.\nPrevious experience working with claims data, CPT codes, and ICD-10 codes preferred.\nProven ability to manage multiple projects simultaneously.\nAptitude to develop unique, creative, and efficient work products.\nExcellent written and oral communication skills to effectively present information to associates at all levels of the Lockton organization.\nAssumes ownership for individual projects. Strong proactive style and self-motivated to actively seek solutions to problems without supervision.\nAbility to comply with all company policies and procedures, proactively protecting confidentiality of client and company information.\nShow more\nShow less",
      "job_skills":"SQL, Tableau, Data analysis, Data reporting, Data warehousing, Business intelligence, Data integrity, Data stewardship, Data quality, Claims data, CPT codes, ICD10 codes, Project management, Communication skills, Problemsolving skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr Data Analyst",
      "company":"Honeywell",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-honeywell-3787460849",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Innovate to solve the world's most important challenges\nHoneywell is a Fortune 100 company that invents and manufactures technologies to address critical challenges linked to global macrotrends such as safety, security, productivity, global urbanization, and energy. With approximately 129,000 employees worldwide, including more than 19,000 engineers and scientists, Honeywell has an unrelenting focus on quality, delivery, value, and technology in everything they make and do. Honeywell has been named a Top 100 Global Innovator for seven years in a row, recognizing the company\u201a\u00c4\u00f4s global reach of portfolio and invention influence.\nHoneywell Federal Manufacturing & Technologies (FM&T) manages and operates the U.S. Department of Energy\/National Nuclear Security Administration\u201a\u00c4\u00f4s (NNSA) Kansas City National Security Campus in Kansas City. This state-of-the-art engineering, manufacturing, and sourcing facility produces a wide array of intricate components to deliver trusted national security products and government services, primarily for the NNSA. Honeywell FM&T\u201a\u00c4\u00f4s integrity, commitment, and continuous improvement culture enable them to deliver responsive, collaborative, and innovative management and technology services and products that translate into cutting-edge solutions to complex national security issues.\nThe Sr. Data Analyst will provide senior-level support and analysis for KCNSC enterprise data projects, define processes, and adhere to them. The role is responsible for performing data analysis, data mapping, data integration, and data quality activities for Data Analytics and Data Governance activities as determined by KCNSC Data Office management.\nThis position will be in Kansas City, MO*** (Hybrid Role)\nPrimary Responsibilities\nUtilize analytical and technical skills for translating and analyzing business needs into requirements and lead the design and implementation of multiple complex analytics solutions (reports, dashboards, data mining) and\/or governance solutions (cataloging, data quality, access management.)\nWork with project work streams and business stakeholders to design, implement, and maintain best practice analytics and data governance information products and processes to support the business.\nPerform data analysis by querying data sets in databases, spreadsheets, semi-structured data, and flat file format to identify and document master data, reference data, transaction data, business rules, data integration rules, data\nmapping and transformations.\nDocument internal processes and audit procedures to ensure data integrity of solutions.\nResearch and resolve unexpected results or internal process flaws. Effectively prioritize and deploy solutions that can replace manual processes.\nDesign and support data models optimized to support analytical tools such as Microstrategy, Tableau, and PowerBI and create BI reports.\nSupport development of master data, data cataloging, and data quality processes in data management tools.\nGathers data from multiple sources and performs moderate to complex analysis, generating reports supportive of organizational metrics and client services.\nSupport a variety of information management projects of a highly varied nature, including data analysis, data mining, and data optimization.\nDevelop and follow standard operating procedures for regularly occurring processes.\nYou Must Have\nBachelor\u201a\u00c4\u00f4s Degree or 6 years equivalent experience.\nUS Citizenship is needed to obtain and maintain the required US Dept of Energy \"Q\" level security clearance.\nWe Value\n5 years of demonstrated data management experience, including merging, cleaning, and analyzing large amounts of data.\n3-5 years of technical experience utilizing database technologies and\/or data process analysis experience within information architectures \/ digital ecosystems.\nTechnical experience should include SQL, PL\/SQL, T\/SQL, NoSQL programming, and database objects such as stored procedures, materialized views, functions, etc., or analytics tools (Microstrategy, Tableau, PowerBI) or data management\ntools (MDM, Data Catalog, Data Quality tools.)\nExperience working with data models, warehouses, management, and movement.\nGood understanding of data virtualization concepts and experience developing a unified semantic model.\nDemonstrated ability to manage through ambiguity and competing priorities.\nExcellent oral and written communication and analytical skills. Strong interpersonal and collaborative work style.\nAbility to work with and professionally manage confidential information.\nStrong organizational and time management skills. Ability to lead\/drive priorities.\nExperience implementing impactful Analytics.\nAbility to translate business requirements into effective process management solutions.\nStrong MS Excel skills preferred.\nProactive analytical and collaborative problem-solving skills with business acumen.\nExperience modeling processes and business rules utilizing BPM tools.\nAbility to document business process & system requirements.\nAbility to communicate effectively with both senior managerial and technical teams.\nFMT2021\nAdditional Information\nJOB ID: req428433\nCategory: Finance\nLocation: 9221 Ward Parkway,Kansas City,Missouri,64114,United States\nExempt\nMust be a US Citizen due to contractual requirements.\nHoneywell FM&T Overview\nHoneywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, religion, or veteran status.\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Mapping, Data Integration, Data Quality, Data Governance, Data Analytics, Business Analytics, Data Visualization, Reporting, Dashboards, Data Mining, Master Data Management, Data Cataloguing, Data Virtualization, Unified Semantic Model, SQL, PL\/SQL, T\/SQL, NoSQL, Analytics Tools, Data Management Tools, Data Movement, Data Modelling, Data Warehousing, Data Warehousing, Business Process Management (BPM), Process Management, Business Rules, Microstrategy, Tableau, PowerBI, MS Excel",
      "Category":"Data Science"
  },
  {
      "job_title":"Sr. Data Analyst \/ Medical Coder (Medical Policies\/Regulations) - REMOTE in CA",
      "company":"RemoteWorker US",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-medical-coder-medical-policies-regulations-remote-in-ca-at-remoteworker-us-3780839538",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"JOB DESCRIPTION Job Summary Designs and implements processes and solutions associated with a wide variety of data sets used for data\/text mining, analysis, modeling, and predicting to enable informed business decisions. Gains insight into key business problems and deliverables by applying statistical analysis techniques to examine structured and unstructured data from multiple disparate sources. Collaborates across departments and with customers to define requirements and understand business problems. Uses advanced mathematical, statistical, querying, and reporting methods to develop solutions. Develops information tools, algorithms, dashboards, and queries to monitor and improve business performance. Creates solutions from initial concept to fully tested production and communicates results to a broad range of audiences. Effectively uses current and emerging technologies. KNOWLEDGE\/SKILLS\/ABILITIES With limited supervision, the Sr. Analyst, Data is responsible for data compilation, data management, data analysis, and reporting. Extracts and compiles various sources of information and large data sets from various systems or applications. Set up process for monitoring, tracking and trending information and data using various systems or applications. Prepares well-organized, easily understood reports, analysis, and summary of findings for use by management. Assists in preparation of regularly produced reports to support executive decision-making. Researches and analyze report results identifying opportunities and trends. Works with internal, external and enterprise individuals as needed to research, develop, and document new standard reports or processes. Consolidates data from multiple sources, using industry-based tools or manually; able to process data effectively using Microsoft Excel. Supports management and other team members as requested on all things data related. JOB QUALIFICATIONS Required Education Associate degree or equivalent combination of education and experience Required Experience 3-5 years Preferred Education Bachelor's Degree or equivalent combination of education and experience Preferred Experience 5-7 years Experience with Medical Policies, Regulatory Guidelines, Medical Coding, Payment Integrity and All Plan Letters. Strong Excel - VLOOKUP, Pivot Tables. Basic SQL skills - SQL queries. CPC certification . Strong communication skills. To all current Molina employees: If you are interested in applying for this position, please apply through the intranet job listing. Molina Healthcare offers a competitive benefits and compensation package. Molina Healthcare is an Equal Opportunity Employer (EOE) M\/F\/D\/V. Pay Range: $69,477 - $135,480 a year* *Actual compensation may vary from posting based on geographic location, work experience, education and\/or skill level.\nShow more\nShow less",
      "job_skills":"Data Mining, Data Analysis, Data Modeling, Data Prediction, Statistical Analysis, Mathematical Methods, Statistical Methods, Querying, Reporting, Data Compilation, Data Management, Microsoft Excel, VLOOKUP, Pivot Tables, SQL, SQL Queries, CPC Certification, Communication Skills",
      "Category":"Data Science"
  },
  {
      "job_title":"US Tech Sr. Business Analyst",
      "company":"PwC",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/us-tech-sr-business-analyst-at-pwc-3782845710",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nBusiness Analysis\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team are the general managers of commercial and internal products. They sit at the intersection of the business, user experience, and the technology that solve our customer and end-user problems. They design, develop and manage activities for a specific product or group of products from product definition and planning through production, release, and end of life. Product Management\u201a\u00c4\u00f4s involvement lasts throughout all stages of a product\u201a\u00c4\u00f4s lifecycle including modifications, upgrades, maintenance of the product or product line. For commercial products, it also includes commercialization, Go To Market planning, sales, and other key business support activities.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades\/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Manager, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nTake action to ensure everyone has a voice, inviting opinion from all.\nEstablish the root causes of issues and tackle them, rather than just the symptoms.\nInitiate open and honest coaching conversations at all levels.\nMove easily between big picture thinking and managing relevant detail.\nAnticipate stakeholder needs, and develop and discuss potential solutions, even before the stakeholder realises they are required.\nDevelop specialised expertise in one or more areas.\nAdvise stakeholders on relevant technical issues for their business area.\nNavigate the complexities of global teams and engagements.\nBuild trust with teams and stakeholders through open and honest conversation.\nUphold the firm's code of ethics and business conduct.\nBusiness Analysts apply analytical skills working with business and product owners to develop requirements and user stories stemming from product roadmaps. Analysts add value to the delivery team by working with the business and product owner to create clarity around business objectives through the development of and refinement of user stories. Our Business Analysts solve business problems working with delivery teams using Agile and scrum methodologies.\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n6 year(s) of relevant experience in progressive roles managing IT system\/software development and project management processes\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nInformation Technology, Computer Systems Analysis, Management Information Systems\nCertification(s) Preferred\nIIBA\nPreferred Knowledge\/Skills\nDemonstrates intimate knowledge of, and\/or proven record of success in, roles as a Business Analyst working on software development projects, preferably for a global network of professional services firms, including the following areas:\nUnderstanding of requirements from the business or stakeholder\u201a\u00c4\u00f4s perspective and translating the requirements into the appropriate deliverables in an Agile\/Scrum delivery model;\nLeading User Acceptance Testing;\nCollaborating and leading stakeholders through all phases of User Acceptance Testing, including review of User Acceptance Test cases for completeness;\nUnderstanding of the SDLC activities expected to deliver custom developed and packaged applications and Agile Requirements Methods; and,\nUnderstanding of all phases of applications systems analysis and the SDLC development methodology and Business Process Modeling. Demonstrates intimate ability, and\/or proven record of success, in roles considering the business implications of applying technology to the current business environment and preparing requirements from which applications can be developed including in the following areas:\nUnderstanding of requirements from the business or stakeholder\u201a\u00c4\u00f4s perspective and translating the requirements into the appropriate deliverables in an Agile\/Scrum delivery model;\nLeading User Acceptance Testing;\nCollaborating and leading stakeholders through all phases of User Acceptance Testing, including review of User Acceptance Test cases for completeness;\nUnderstanding of the SDLC activities expected to deliver custom developed and packaged applications and Agile Requirements Methods; and,\nUnderstanding of all phases of applications systems analysis and the SDLC development methodology and Business Process Modeling.\nAnalyzing business and user needs, establishing clear business value objectives, documenting requirements, and revising existing system logic or business process difficulties to select, build or modify large, complex or mission critical information systems to achieve business value;\nWorking with other Business Analysts to understand total testing scope to establish that the requested equals delivered functionality;\nSetting up testing suite test cases and assignment of testers;\nUsing Azure DevOps for reporting and metrics;\nPerforming Senior Business Analyst responsibilities working on large and complex software development, infrastructure, SaaS and\/or Cloud solutions;\nApplying analytical skills to evaluate and document accurate business requirements and present these requirements in a manner that is concise, measurable and flexible enough to meet project and stakeholder needs;\nManaging the quality and acceptance of vendor analysis and testing of SOW deliverables in a project setting;\nDeveloping and guiding the documentation of requirements and test cases so that the requirements and test cases are unambiguous, aligned, consistent and not in contradiction with each other;\nWorking collaboratively within a delivery team at all levels including stakeholder management, with considerate ability to take ownership of tasks and complete them with minimal direct supervision; and,\nDeveloping deep business and application domain knowledge for an assigned business portfolio and\/ or LoS to aid in critically evaluating the balance of both business needs and user requests.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniormanager\nShow more\nShow less",
      "job_skills":"Business Analysis, Agile, Scrum, IIBA, User Acceptance Testing, SDLC, Business Process Modeling, Azure DevOps, Stakeholder Management, SQL, Data Analysis",
      "Category":"Data Science"
  },
  {
      "job_title":"(Microsoft BI) Business Analyst",
      "company":"Inceed",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/microsoft-bi-business-analyst-at-inceed-3733136837",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Compensation: $35-$40 \/ Hr\nLocation:\nKansas City, MO\nBusiness Analyst:\nInceed has partnered with a great company to help find a skilled\nBusiness\nAnalyst\nto join their team!\nThis person will be responsible for helping accelerate and bringing knowledge on the Microsoft BI platform.\nResponsibilities:\nHelp Accelerate platform of Microsoft BI\nWorking daily within BI\nLeading and managing teams\nRequired Qualifications & Experience:\n3-5 years of Business Analyst experience\nStrong background with Microsoft BI\nNice to Have Skills & Experience:\nAccounting background\nMicrosoft BI \/ Power BI\nPerks & Benefits:\n3 different medical health insurance plans, dental, and vision insurance\nVoluntary and Long-term disability insurance\nPaid Time Off, 401k, and Holiday Pay*\nWeekly direct deposit or pay card deposit\nIf you are interested in learning more about the Business Analyst opportunity, please submit your resume for consideration. We are unable to provide sponsorship at this time.\nWe are Inceed, a staffing and direct placement firm who believes in the possibility of something better. Our mission is simple: We\u201a\u00c4\u00f4re here to help every person, whether client, candidate, or employee, find and secure what\u201a\u00c4\u00f4s better for them.\nInceed is an equal opportunity employer. Inceed prohibits discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.\nShow more\nShow less",
      "job_skills":"Microsoft BI, Power BI, Business Analyst, Accounting, Team Management, Leadership",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Business Analyst",
      "company":"Robert Half",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-business-analyst-at-robert-half-3774868465",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Position: SENIOR BUSINESS ANALYST (PERMANENT POSITION)\nLocation: ONSITE IN KANSAS CITY, MO\nSalary: UP TO $100K + BENEFITS\n*** For immediate and confidential consideration, please send a message to MEREDITH CARLE on LinkedIn or send an email to me with your resume. My email can be found on my LinkedIn page. ***\nJob Title: Sr. Epicor ERP Business Analyst\nJoin our dynamic client team as a Sr. Epicor ERP Business Analyst, where you'll play a pivotal role in revolutionizing our business processes. Collaborate with senior management and end users across all Epicor sites to enhance existing operations and pioneer new strategies, ensuring future business success. Dive into projects involving version upgrades, functional enhancements, and Epicor solution implementations at current and future locations.\nEssential Responsibilities:\n\u201a\u00c4\u00a2 Strategic Partnership: Act as a manufacturing\/production and supply chain expert, reshaping processes and enhancing business performance.\n\u201a\u00c4\u00a2 Innovative Solutions: Design and deploy business solutions, utilizing various tools for process mapping, technical components, and customization.\n\u201a\u00c4\u00a2 User Support: Provide end-user support, ensuring seamless Epicor experience across all locations.\n\u201a\u00c4\u00a2 Documentation & Training: Develop formal Epicor documentation, conduct training sessions, and facilitate effective communication with internal and external stakeholders.\n\u201a\u00c4\u00a2 Continuous Improvement: Stay updated with industry trends, participate in educational opportunities, and contribute to a culture of continuous learning.\nQualifications:\n\u201a\u00c4\u00a2 Education: Bachelor\u201a\u00c4\u00f4s Degree in Computer Science, Information Systems, Accounting, or equivalent experience.\n\u201a\u00c4\u00a2 Experience: Minimum 5 years of ERP implementation and support experience, particularly in manufacturing and supply chain environments.\n\u201a\u00c4\u00a2 Skills: Proficiency in Epicor 10, SQL, SSRS, and various supply chain processes. Exceptional problem-solving abilities and attention to detail.\nAdditional Requirements:\n\u201a\u00c4\u00a2 Interpersonal Skills: Strong communication skills, approachable demeanor, and ability to work independently.\n\u201a\u00c4\u00a2 Technological Proficiency: Expertise in Microsoft Outlook, Word, Excel, and PowerPoint.\n\u201a\u00c4\u00a2 Flexibility: Capability to multitask, manage time efficiently, and adapt to changing priorities.\n\u201a\u00c4\u00a2 Travel: Occasional travel, including overnight stays and international trips, may be required.\n*** For immediate and confidential consideration, please send a message to MEREDITH CARLE on LinkedIn or send an email to me with your resume. My email can be found on my LinkedIn page. Also, you may contact me by office: 515-303-4654 or mobile: 515-771-8142. Or one click apply on our Robert Half website. No third party inquiries please. Our client cannot provide sponsorship and cannot hire C2C. ***\nShow more\nShow less",
      "job_skills":"Epicor 10, SQL, SSRS, Supply Chain Management, ERP implementation and support, Microsoft Office Suite (Outlook Word Excel PowerPoint), Problemsolving, Attention to detail, Communication skills, Time management, Adaptability, Travel readiness",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Selby Jennings",
      "job_location":"Columbia, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-selby-jennings-3784593317",
      "search_city":"Hollywood",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"* This role being referred to does not provide sponsorship or employment-related benefits\nThe Data Analyst In this position you are responsible for programming the collection and normalization of data; reviewing, analyzing and mapping data for reporting purposes in systems, supporting and implementing integrations and migrating data between systems. Will also provide basic DBA support.\nESSENTIAL FUNCTIONS\nLead database design, data collection, data analysis\/comparison and data conversion in applications to be utilized.\nCommunicate with the appropriate internal and external personnel to understand their operational data needs and objectives; deliver actionable insights from the operational data\nLead end-to-end data migration and reporting efforts between systems and develop supporting documentation for data migration projects.\nDefine and document data verification criteria and ensure quality of all data conversion work.\nAssist in the development and application of data architectural strategy.\nIdentify and retrieve information from various data sources and organizes it to create meaningful data visualizations for understanding, operational reporting and decision making.\nDrive the development of processes supporting automation of the data extraction process, verification of data, data reconciliation and reporting.\nManage and optimize database inquiries for optimal end-user experience.\nAnalyze and advise management of workflow and data integrity issues; present resolution recommendations.\nIdentify, manage, troubleshoot and resolve database and data structure issues.\nSupport existing integrations and assist in development\/setup of new integrations.\nOther duties as assigned.\nQualifications\nRequired Qualifications\nThree years of data analysis experience\nExcellent communication and customer service skills\nSQL programming and query expertise\nExperience in dashboarding, reporting, visualizations, data modeling and migration between enterprise systems\nEDUCATION QUALIFICATIONS\nBachelor\u201a\u00c4\u00f4s degree required in Applied Math, Statistics, Computer Science or other related technical field\nShow more\nShow less",
      "job_skills":"Data Analysis, Data Collection, Data Normalization, Data Migration, Data Conversion, Data Visualization, Data Extraction, Data Reconciliation, Data Reporting, Data Architecture, Database Design, Database Administration, SQL Programming, Dashboarding, Data Modeling, Communication, Customer Service",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Catalog and Lineage Central Governance Analyst",
      "company":"PwC",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-catalog-and-lineage-central-governance-analyst-at-pwc-3785062701",
      "search_city":"Shawnee",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Specialty\/Competency:\nIFS - Information Technology (IT)\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data\/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nAdditional Responsibilities\nSupporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture.\nCustom Orgs\nGlobal LoS\n:\nInternal Firm Services\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nHigh School Diploma\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nBachelor Degree\nPreferred Fields Of Study\nComputer and Information Science, Data Processing\/Analytics\/Science\nAdditional Educational Preferences\nOther related fields of study with relevant experience may be considered.\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success as a team leader:\nPossessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects;\nDisplaying knowledge of data management and governance policies, standards, metrics, controls, and processes;\nHaving knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers;\nPossessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies;\nShowcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture;\nExhibiting proven knowledge and working experience in Microsoft Purview;\nCreating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers;\nShowcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;\nDisplaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog;\nConducting periodic reviews of the data catalogue to corroborate compliance with the DG standards;\nFacilitating the capture of metadata as core change and operational deliverables;\nDemonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers;\nDesigning, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview;\nIdentifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports;\nPossessing ability to create and maintain automated workflows for periodic metadata refresh;\nComplete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR\/HIPPA\/SPI (as applicable);\nHelping manage the inventory of data-related controls on systems that support segment processes and customers;\nShowcasing thorough understanding of data steward\/data owner operating model;\nAbility in designing and rolling out training programs to train the trainer\/end-users;\nBeing a collaborative team player; and,\nHaving a business outcome focused problem-solving mindset.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"Azure Purview, Metadata Management, Data Governance, Data Catalog, Business Glossary, Data Lineage, Data Model, Data Asset Identification, Data Classification, Taxonomy, Hierarchies, Data Dictionary, Data Steward, Data Owner, Sensitive Data, GDPR, HIPAA, SPI, H1B Lottery Policy, Affirmative Action, Equal Opportunity Employer, San Francisco Fair Chance Ordinance",
      "Category":"Data Science"
  },
  {
      "job_title":"Associate Research\/Data Analyst-QCEW",
      "company":"State of Missouri",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/associate-research-data-analyst-qcew-at-state-of-missouri-3789356818",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Why You\u201a\u00c4\u00f4ll Love Working For This Department\nYou will be joining a Department committed to a culture of TEAMWORK to accomplish our goals together, where we deliver excellence through COLLABORATION with partners and stakeholders, embody ACCOUNTABILITY through trust and professionalism, and embrace WORK-LIFE BALANCE by prioritizing respect, boundaries, and time. While working at DHEWD you will be helping to develop the workforce of the future! Join us as we pursue our vision of \u201a\u00c4\u00faEvery Missourian empowered with the skills and education needed for success.\u201a\u00c4\u00f9\nFocus of the Position:\nThis position works within Missouri\u201a\u00c4\u00f4s Quarterly Census of Employment and Wages (QCEW) team, a program administered by the Bureau of Labor Statistics (BLS). The QCEW unit is housed in the Missouri Economic Research and Information Center (MERIC), which is the state cooperative partner to BLS and the labor market information agency responsible for measuring labor market activity and the economy in Missouri. QCEW collects, verifies, and publishes a quarterly count of employment and wages for more than 95% of U.S. jobs, providing a vital benchmark for other Missouri and federal programs. As a member of this team, you will be responsible for researching and verifying the accuracy of employer information and wage and employment data submitted for the state of Missouri.\nWhat You\u201a\u00c4\u00f4ll Do\nTo perform this job successfully, an individual must be able to perform each essential function of the job with or without reasonable accommodation.\nWork within the QCEW program procedures to edit employment and wage data to ensure accurate and consistent data.\nAssign industry and geographic codes for new businesses using the North American Industry Classification System (NAICS) as outlined by the U.S. Bureau of Labor Statistics (BLS).\nConduct phone interviews with Missouri employers to identify primary business activity and verify large changes of employment and wage.\nResearch and explain fluctuations within the employment and wage data.\nGather information on Missouri\u201a\u00c4\u00f4s employment and wage data, utilizing good research skills, including attention to detail and accuracy.\nFollow guidelines and requirements put forth by the BLS in the Cooperative Agreement with Missouri.\nCommunicate effectively with federal and state government officials, economic development partners, and workforce agencies.\nConduct basic mathematical and statistical methods.\nExercise an interest in analyzing Missouri\u201a\u00c4\u00f4s economy.\nUtilize the Internet and various software applications, including Microsoft Word, Excel, PowerPoint and desktop publishing.\nMeet deadlines.\nDemonstrate regular and predictable attendance.\nMinimum Qualifications\nBeneficial education and\/or work-related experience includes technical or professional experience in business, personnel, public administration or closely related area, including military service.\nMore Reasons To Love This Position\nThe State of Missouri offers an excellent benefits package that includes a defined pension plan, generous amounts of leave and holiday time, and eligibility for health insurance coverage. Your total compensation is more than the dollars you receive in your paycheck. To help demonstrate the value of working for the State of Missouri, we have created an interactive Total Compensation Calculator. This tool provides a comprehensive view of benefits and more that are offered to prospective employees. The Total Compensation Calculator and other applicant resources can be found here .\nThe State of Missouri is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\nShow more\nShow less",
      "job_skills":"Teamwork, Collaboration, Accountability, Worklife balance, QCEW, Employment, Wage, Data, Verification, BLS, NAICS, Research, Communication, Statistics, Microsoft Word, Excel, PowerPoint, Desktop publishing, Business, Personnel, Public administration, Military service, Total Compensation Calculator",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Research\/Data Analyst - Epidemiology (4206900)",
      "company":"State of Missouri",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-research-data-analyst-epidemiology-4206900-at-state-of-missouri-3789727773",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Location:\nThis position will be located at 930 Wildwood Dr., Jefferson City, 65109 with the possibility of a hybrid or distributed work schedule once training is complete.\nWhy You'll Love This Position\nWe are seeking a highly motivated individual with a background in public health, statistics, research methods, and\/or health information analysis and presentation. This individual will work with a variety of programs and consult with them on their data needs. This part-time position will collaborate with internal and external epidemiologists, analysts, and program staff to conduct research on cutting-edge and emerging health issues.\nWhat You'll Do\nConduct routine data management activities, analyses and interpretations, report writing, and data visualization projects to meet grant reporting and evaluation needs for programs.\nDesign and execute complex analyses\/research that furthers program goals and supports the mission of public health organizations in Missouri.\nDevelop methods and tools for data collection and analysis in addition to creating and\/or updating data dissemination products such as grant-related reports, maps, presentations, factsheets, or dashboards.\nProvide analytical support for public health epidemiology \/ surveillance needs, including data linkages and analysis, program evaluation, needs assessment, and responding to data requests.\nWork on special data analytic projects that contribute towards the advancement of knowledge and practices for improving maternal child health, chronic disease and communicable disease epidemiology in Missouri.\nProvide analytical consultation and support to other internal and external programs as needed.\nMinimum Qualifications\nAll you need for success:\nBachelor\u201a\u00c4\u00f4s degree and 4-6 years of relevant experience and\/or appropriate certification (Substitutions allowed.)\nKnowledge of data management, research design, and current analytical\/statistical methods\nA high degree of analytical expertise, and the ability to use substantial independent judgment when applying technical concepts and methodologies\nAbility to plan and execute complex research studies, conduct comprehensive data analysis, and interpret data\nExperience with SAS, SQL, or other analytical software and general programming techniques required and their applications in public health\nExperience with Microsoft Office Suite and the ability to quickly learn new systems and applications (such as ArcGIS, SQL Server, or Tableau)\nLack of post-secondary education will not be used as the sole basis denying consideration to any applicant.\nIf You Have Questions About This Position Please Contact\nKatie Long, Katie.Long@health.mo.gov\nThe State of Missouri is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\nShow more\nShow less",
      "job_skills":"Public Health, Statistics, Research Methods, Health Information Analysis, Data Visualization, SAS, SQL, ArcGIS, SQL Server, Tableau, Microsoft Office Suite",
      "Category":"Data Science"
  },
  {
      "job_title":"IS Senior Analyst Application\/Technician (Remote) - Epic",
      "company":"Washington University in St. Louis",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/is-senior-analyst-application-technician-remote-epic-at-washington-university-in-st-louis-3727313539",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Scheduled Hours\n40\nPosition Summary\nApplication coordinators are the primary support contact for the application. They coordinate all issues that arise during the project for their application area and must be very knowledgeable about your organization\u201a\u00c4\u00f4s policies, procedures and business operations. Under general direction, formulates and defines specifications for complex operating software programming applications, modifies\/maintains complex existing applications using engineering releases and utilities from the vendor or performs software development tasks using industry-standard tools and techniques. Consults directly with vendors, clinical and business users, and provides second and third-tier support to end users to ensure reliable application system availability and performance.\nJob Description\nPrimary Duties & Responsibilities\nAnalyzes, develops, modifies, installs, tests and maintains operating systems and application software.\nProvides technical analysis and support to internal personnel to determine feasible system and database solutions to substantial design and function issues.\nPartners with outside vendors to resolve issues relating to software applications and packages for adaption and use system-wide.\nDiagnoses, isolates and de-bugs software problems and performs problem resolution.\nMonitors systems capacity and performance, plans and executes disaster recovery procedures.\nPreferred Qualifications\nBachelor\u201a\u00c4\u00f4s degree in related field; Epic experience and certification.\nGeneral knowledge of University and Medical School culture and practices.\nAbility to understand and make recommendations on effective IT and business practices.\nEffective technical analysis skills and experience.\nEffective verbal, written and interpersonal communication skills.\nAbility to work with confidential information and demonstrated effective Microsoft office suite skills.\nRequired Qualifications\nHigh school diploma or equivalent high school certification.\nTwo to five years of related experience.\nMust complete an internal skills assessment before or after hire.\nREQUIRED LICENSURE\/CERTIFICATION\/REGISTRATION: EPIC Certification required or to be completed after hire. Travel for EPIC training away from St. Louis, MO required.\nGrade\nG12\nSalary Range\n$57,300.00 - $97,700.00 \/ Annually\nThe salary range reflects base salaries paid for positions in a given job grade across the University. Individual rates within the range will be determined by factors including one's qualifications and performance, equity with others in the department, market rates for positions within the same grade and department budget.\nAccommodation\nIf you are unable to use our online application system and would like an accommodation, please email CandidateQuestions@wustl.edu or call the dedicated accommodation inquiry number at 314-935-1149 and leave a voicemail with the nature of your request.\nPre-Employment Screening\nAll external candidates receiving an offer for employment will be required to submit to pre-employment screening for this position. The screenings will include criminal background check and, as applicable for the position, other background checks, drug screen, an employment and education or licensure\/certification verification, physical examination, certain vaccinations and\/or governmental registry checks. All offers are contingent upon successful completion of required screening.\nBenefits Statement\nPersonal\nUp to 22 days of vacation, 10 recognized holidays, and sick time.\nCompetitive health insurance packages with priority appointments and lower copays\/coinsurance.\nWant to Live Near Your Work and\/or improve your commute? Take advantage of our free Metro transit U-Pass for eligible employees. We also offer a forgivable home loan of up to $12,500 for closing costs and a down payment for homes in eligible neighborhoods.\nWashU provides eligible employees with a defined contribution (403(b)) Retirement Savings Plan, which combines employee contributions and university contributions starting at 7%.\nWellness\nWellness challenges, annual health screenings, mental health resources, mindfulness programs and courses, employee assistance program (EAP), financial resources, access to dietitians, and more!\nFamily\nWe offer 4 weeks of caregiver leave to bond with your new child. Family care resources are also available for your continued childcare needs. Need adult care? We\u201a\u00c4\u00f4ve got you covered.\nWashU covers the cost of tuition for you and your family, including dependent undergraduate-level college tuition up to 100% at WashU and 40% elsewhere after seven years with us.\nFor policies, detailed benefits, and eligibility, please visit: https:\/\/hr.wustl.edu\/benefits\/\nEEO\/AA Statement\nWashington University in St. Louis is committed to the principles and practices of equal employment opportunity and especially encourages applications by those from underrepresented groups. It is the University\u201a\u00c4\u00f4s policy to provide equal opportunity and access to persons in all job titles without regard to race, ethnicity, color, national origin, age, religion, sex, sexual orientation, gender identity or expression, disability, protected veteran status, or genetic information.\nDiversity Statement\nWashington University is dedicated to building a diverse community of individuals who are committed to contributing to an inclusive environment \u201a\u00c4\u00ec fostering respect for all and welcoming individuals from diverse backgrounds, experiences and perspectives. Individuals with a commitment to these values are encouraged to apply.\nShow more\nShow less",
      "job_skills":"Operating Systems, Application Software, Database Solutions, Software Development, Problem Resolution, Disaster Recovery, EPIC, Microsoft Office Suite, Technical Analysis, Interpersonal Communication, Confidential Information Handling",
      "Category":"Data Science"
  },
  {
      "job_title":"Associate Research\/Data Analyst - 5034196",
      "company":"State of Missouri",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/associate-research-data-analyst-5034196-at-state-of-missouri-3781637863",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Associate Research\/Data Analyst\nDepartment of Revenue \u201a\u00c4\u00ec Taxation Division \u201a\u00c4\u00ec Income Tax Bureau\nAnnual Salary: $ 45,006.24\nLocation: 301 West High Street, Jefferson City, MO\nDOR\u201a\u00c4\u00f4s Vision: To provide every customer the best experience every time.\nHow This Position Supports The Department\u201a\u00c4\u00f4s Vision\nThis position is the Department of Revenue\u201a\u00c4\u00f4s Federal and State Coordinator and the liaison with the Internal Revenue Service and state tax agencies. The main responsibility of this position is to ensure federal tax information that the Department of Revenue receives from the Internal Revenue Service is safeguarded to the requirements in IRS Publication 1075. Create procedures and conduct educational sessions on IRS Pub 1075 requirements and on other Income Tax Bureau processes and functions. Advise Department of Revenue team members on IRS Pub 1075 requirements as needed. Analyze tax data. Work with other Departments to create agreements between the Department of Revenue and other agencies.\nThis position requires the candidate to work independently, have good organizational, written and verbal communication skills, and be able to prioritize duties and adjust as priorities change.\nDuties Performed To Support The Department\u201a\u00c4\u00f4s Vision\nSelf-Directed\nAttention to Detail\nOrganized\nEffective Writing\nProfessional\nExcellent Time Management\nSafeguarding Federal Tax Information\nCommunication between the Internal Revenue Service and the Missouri Department of Revenue\nCore Compentencies Needed\nComputer Literacy Effective Writing Excellent Customer Service\nSelf-directed Attention to Detail Analytical Thinking\nClear Communication Organizational Abilities\nQualifications\nKnowledge of basic research methods and analysis, computer information systems, and statistical software.\nAbility to perform basic queries and analysis of data.\nBachelor\u201a\u00c4\u00f4s degree and 0-2 years of relevant experience and\/or appropriate certification. (Substitutions may be allowed.)\nMore Reasons To Love This Position\nThe State of Missouri offers an excellent benefits package that includes a defined pension plan, generous amounts of leave and holiday time, and eligibility for health insurance coverage. Your total compensation is more than the dollars you receive in your paycheck. To help demonstrate the value of working for the State of Missouri, we have created an interactive Total Compensation Calculator. This tool provides a comprehensive view of benefits and more that are offered to prospective employees. The Total Compensation Calculator and other applicant resources can be found here .\nPlease Direct Any Questions About This Position To\nThe Missouri Department of Revenue Human Resources and Total Rewards office at (573) 751-1291.\nWe celebrate diversity and are committed to creating an inclusive environment for all employees\nThe State of Missouri is an equal opportunity employer.\nShow more\nShow less",
      "job_skills":"IRS Publication 1075, Federal Tax Information, Data Analysis, Statistical Software, Basic Research Methods, Computer Information Systems, Queries, Effective Communication, Computer Literacy",
      "Category":"Data Science"
  },
  {
      "job_title":"Website Business Analyst",
      "company":"Central Bank",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/website-business-analyst-at-central-bank-3786851712",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Central Bancompany is seeking a skilled and experienced Website Business Analyst. In this role, you will collaborate closely with the website team to prioritize projects, gather and document business requirements, and create user stories that capture specific features and functionalities, ensuring alignment with business goals and user needs. You will be responsible for utilizing activity diagrams, website journey maps, and other tools to define and communicate functional specifications\nTo be successful in this role, you will need a bachelor\u201a\u00c4\u00f4s degree in Computer Information, Business Administration, or related fields, 5+ years of experience in website design and development, with a strong understanding of website architecture, user experience, and industry best practices and 3+ years of project management, including oversight of projects from conception to completion.\nYou will have autonomy in this role, so we are looking for someone who is self-motivated, organized, takes ownership, and is a critical thinker. Join our dynamic team and contribute to the success of our website projects.\nThis position will be domiciled out of the Jefferson City, Missouri office.\nBS or BA in Computer Information Systems \/ Business Administration or equivalent, advance degree or working towards advanced degree desirable.\n5+ years of website design and development methodologies or related field a plus.\n3+ years of project management experience or the ability to demonstrate very strong organizational skills a plus.\nStrong aptitude for understanding both technology and business concepts and processes.\nProven ability to gather and document detailed product requirements (scope, background, business case, etc.) and write user stories.\nSkill set to create and utilize activity diagrams, website journey maps, flowcharts and other tools to help define and demonstrate functional specifications.\nCapacity to facilitate the prioritization of projects\/requests simultaneously and ensure timely completion in accordance with business initiatives.\nCollaborate with developers and designers throughout project life cycle as the project business owner to support the technical vision and analyze tradeoffs between usability and performance.\nStrong attention to detail and critical thinking.\nAbility to work with limited direction and take ownership - does not pass off work to others.\nCaring, positive, can-do attitude, and a motivated TEAM player.\nExcellent communication skills, both verbal and written, with the ability to effectively convey complex ideas and concepts to diverse stakeholders.\nA knowledge and understanding of technology and technology trends \u201a\u00c4\u00ec utilizes mobile devices and technology to manage personal finances.\nKnowledge of JIRA for managing the agile process will be important.\nAdvanced computer skills specifically in Adobe XD or FigJam a plus. Familiar with Microsoft suite of products (MS Office, Word, Excel, PowerPoint, Team).\nShow more\nShow less",
      "job_skills":"Website Business Analyst, Website Design, Website Development, Website Architecture, User Experience, Industry Best Practices, Project Management, Activity Diagrams, Website Journey Maps, User Stories, Computer Information Systems, Business Administration, Project Prioritization, Requirements Gathering, Documentation, Flowcharts, Functional Specifications, Agile Process, JIRA, Adobe XD, FigJam, Microsoft Office Suite, MS Word, MS Excel, MS PowerPoint, MS Team",
      "Category":"Data Science"
  },
  {
      "job_title":"Enterprise Technology - DIgital Business Analyst I",
      "company":"NBH Bank",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/enterprise-technology-digital-business-analyst-i-at-nbh-bank-3785887194",
      "search_city":"Kansas City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"It starts with our culture ...\nCommon sense has never been common.\nIf it were, the world would be a different place. Things would run smoothly and on time. People would do what they say and say what they do. Everything would be fair, without all the small talk. And banks would only sell you what you need. When a banker looked at a client, they wouldn\u201a\u00c4\u00f4t just see a number, they\u201a\u00c4\u00f4d see a dad or a mom or a graduate or a business owner. Our Bankers understand the complexities of people\u201a\u00c4\u00f4s lives and offer simple solutions.\nThat's the basics of Relationships. Fairness. Simplicity\u00ac\u00c6\nWhen you choose our Company, you have an opportunity to make an impact beyond the walls of our buildings.\nWe have a long-standing commitment to Equity, Diversity and Inclusion. Through our business relationships, investing, grants, and volunteerism, NBH Bank promotes the growth, revitalization and sustainability of the communities we serve. We believe that these are important elements in building and sustaining a successful organization and a positive, results-driven culture. We strive for all of our associates to feel welcome and empowered at work.\nThis type of position is ideal for someone looking to build a career in finance, banking, and technology. We will provide you training and coaching throughout your onboarding experience, as well as on the job. As you demonstrate success, there will be opportunities for advancement within our organization.\nFor this position, we are looking for a self-starting, results oriented team player to join us as a Digital Business Analyst I.\nAs a Digital Business Analyst I, you will be a liaison, facilitating communication and driving solutions for internal business units and stakeholders with external vendors and partners. You will be responsible for a variety of tasks including providing daily Product + Tier 2 Operational Support and oversight of the bank\u201a\u00c4\u00f4s digital products and services, as needed.\nThis position will follow a hybrid-working model (a combination of work from the office and at home based on manager discretion).\nYou will d evelop and implement solutions to:\nSupport business processes and automate work streams as appropriate.\nL ead and provide direction on the planning, design and execution of department processes, procedures and training.\nAnalyze bank current and future system processes and\/or procedures.\nRecommended solutions to improve the client experience, increase productivity and efficiency. Work with internal stakeholders to determine business requirements and priorities.\nAssist with workflow planning process including design, configuration\/develop, testing and delivery of solutions.\nParticipate in the research and evaluation of potential new vendors and technologies, and as appropriate costs and user applicability with current vendors and partners.\nProvide input\/interpretation to business designs and requirements to determine optimal solutions.\nAdditionally a Digital Business Analyst I will follow policies and procedures; complete administrative tasks correctly and on time; support the Bank\u201a\u00c4\u00f4s goals and values; will perform other duties as assigned; benefit the bank through outside activities, participate in coordination of disaster recovery planning and preparation, build a great rapport with clients and fellow associates, and treat others with respect and consideration regardless of their status or position.\nMinimum Requirements:\nBachelor\u201a\u00c4\u00f4s degree required in Business, Finance, Management or related discipline OR equivalent combination of education and related work experience.\nDesired Qualifications: To be considered an i deal candidate, you should possess some of the following qualifications:\nAdvanced degree or certification related to field\n1-2+ years of relevant job experience in banking\nExperience with bank systems, project management, vendor partnerships and resolution of complex system issues\nDesired Skills: Ideal candidates for this position should possess some or all of the following skills:\nExperience supporting processes and systems related to marketing, data and web analytics, online account opening, online banking, deposit and treasury functions, loan origination\/loan servicing (including SBA), core system support, payments, cards, compliance (KYC, KYB, AML, BSA), and other bank functions as determined.\nExceptional verbal, written and interpersonal communication skills with the ability to apply common sense to carry out instruction and speak clearly to associates\nAbsolute discretion when dealing with confidential matters\nExceptional verbal, written and interpersonal communication skills with the ability to apply common sense to carry out instructions and instruct others, train personnel, write procedures and correspondence, speak clearly to clients and associates\nStrong typing skills to meet production needs of the position\nAbility to perform extensive system configurations in banking platforms\nAbility to train and coach associates, as appropriate\nWork Environment:\nWe are a culture that believes that people are our greatest asset and are at the heart of everything we do. We take pride in bringing clarity and simplicity to our associates (employees) and clients. Our decisions are made efficiently, fairly and locally. Our success is directly tied to the communities we serve. It is equally important for us to look through the lens of our applicants and associates to identify their individual needs. As such, we want to share the following:\nWe are committed to our core value of meritocracy and supporting our associates in growing within their role\nFlexible scheduling: Hybrid office environment, manager permitting, with traditional hours\nMust be able to work at a rapid pace while sitting for long periods of time (typically no longer than 8 hours)\nMust be able to work overtime to the extent necessary\nMust be able to travel \u201a\u00c4\u00ec estimated at 5% to 10% of the time\nIncentive and Benefits:\nThis role is eligible to participate in our annual incentive plan.\nIn addition to your financial compensation, we also offer a generous benefits package that includes insurance, 401k, an associate stock purchase program, paid time off, associate banking perks. For more information about the benefits offered click here .\nIf this is what you believe in, then you\u201a\u00c4\u00f4re definitely right for us. Consider making an investment in us, so that we may invest in you and your bright future.\nThank you for your application!\nThe Bank is committed to providing qualified applicants and associates reasonable accommodation, when necessary, to enable the individuals to complete the application process and\/or perform the essential functions of the job. An applicant and\/or associate requiring reasonable accommodation to perform any essential job function, should contact Human Resources.\nThe Bank's policy is to provide equal opportunity to all people without regard to race, color, religion, national origin, ancestry, marital status, veteran status, age, disability, pregnancy, genetic information, citizenship status, sex, sexual orientation, gender identity or any other legally protected category. The Bank is proud to be a drug-free workplace.\nSelected candidate(s) for hire must complete the following prior to employment: a criminal history report, global screen, drug screen, employment credit report and if applicable, a driving record. Applicants must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.\nApply Now\nShow more\nShow less",
      "job_skills":"Banking, Business Analysis, Project Management, Vendor Partnerships, Data Analytics, Online Account Opening, Online Banking, Deposit and Treasury Functions, Loan Origination, Loan Servicing, Core System Support, Payments, Cards, Compliance, Customer Experience, Communication Skills, Interpersonal Skills, Problem Solving, Decision Making, Teamwork, Leadership, Training, Coaching",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Migration Analyst - Hybrid - Contractor (1 year)",
      "company":"Swank Motion Pictures, Inc.",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-migration-analyst-hybrid-contractor-1-year-at-swank-motion-pictures-inc-3766477789",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Swank Motion Pictures is looking for a technical business analyst to join an existing and growing team working on innovative and leading-edge technologies. We are looking for someone with strong data analysis skills necessary to work on multiple projects simultaneously with minimal oversight in an agile\/iterative IT environment. These projects are primarily custom software development and business process improvements. This position is a liaison between non-technical business stakeholders and technology teams. This position is in the IT department and will interact with multiple levels of management within the company. This position is intended to be a year-long position with the opportunity of becoming a permanent role within the group. At Swank Motion Pictures, we are not just looking for employees; we are investing in future leaders. For the Data Migration Analyst role, we offer a pathway for professional growth and development. As our company evolves, there will be abundant opportunities for you to expand your skill set, take on new challenges, and advance your career. We are committed to fostering a culture of learning and innovation where your contributions will be recognized and your professional aspirations supported.\nResponsibilities\nThis position has the primary responsibility to analyze corporate data and assist in its migration from one system to another. Corporate data includes but is not limited to accounts, contacts, agreements, orders, and invoices. The data migration analyst will elicit, verify, and document business-defined data migration rules; analyze data based on those rules for consistency, cleanliness, and outliers; perform quality control checks against data transfer files; and share findings from those checks with the data migration team. The Data Migration Analyst will be expected to develop and maintain comprehensive documentation, including data mappings, transformation rules, and workflow diagrams, to ensure clarity and consistency throughout the data migration process. This individual will be an integral part of a team consisting of data architects, system specialists, and project managers. The Data Migration Analyst will collaborate closely with data governance teams to uphold meaningful data quality and compliance standards across all stages of the migration process. This position is a hybrid position \u201a\u00c4\u00ec the individual must be willing to be in the office at least 2 days per week.\nRequirements\nSkills Needed\nInterpersonal skills to negotiate priorities and collaborate with both business and IT peers\nInterview skills to ask the proper questions for gathering essential requirements and listen attentively to their feedback\nAnalytical skills to critically evaluate data of different types, discern data patterns, and identify data outliers using a high level of attention to detail\nCommunication skills to effectively share ideas and requirements with both technical and non-technical audiences through meetings, working group sessions, whiteboard sessions using data visualization skills and too\nCreativity skills to be flexible and think outside the box when solving problems\nOrganizational skills to meet deadlines, ensure quality deliverables, and cope with rapidly changing information in a hybrid work environment\nExperience Needed\n3 to 5 years of experience executing business analysis with a focus on data analysis and migration\nExperience working with and analyzing large amounts of data via Excel \u201a\u00c4\u00ec SQL experience is nice to have but not required\nAn understanding of best practices for eliciting, analyzing, documenting, validating, and managing requirements, along with knowing when to apply them\nExperience facilitating meetings with both business and IT stakeholders from any level within the organization\nExperience eliciting requirements via one-on-one interviews, group meetings, brainstorming sessions, and other methods as needed\nExperience collaborating with Project Management, Development, and Quality Assurance personnel on software development projects\nDetailed expertise using Microsoft Word, PowerPoint, and Excel a must; familiarity with Atlassian Jira and Confluence preferred but not required\nEducational Requirements\nBachelor\u201a\u00c4\u00f4s degree in technology related field required\nBenefits\nWe are pleased to offer:\nComprehensive compensation and healthcare packages, including medical, dental, vision, and life insurance products\n401(K) plan with employer match\nCompetitive paid time off: vacation, personal time, holidays and winter break\nCompany sponsored volunteer & community outreach opportunities\nOrganizational growth potential through our company sponsored online learning platform\nEOE, including disability\/vets\nShow more\nShow less",
      "job_skills":"Agile, SQL, Jira, Confluence, Excel, PowerPoint, Microsoft Office, Atlassian, Data analysis, Data migration, Data governance, Data quality, Business analysis, Requirements gathering, Requirements analysis, Requirements documentation, Requirements validation, Requirements management, Business process improvement, Software development, Project management, Quality assurance, Communication, Interpersonal skills, Analytical skills, Creativity, Organizational skills",
      "Category":"Data Science"
  },
  {
      "job_title":"Analyst, Rates and Regulatory Affairs",
      "company":"Liberty",
      "job_location":"Joplin, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/analyst-rates-and-regulatory-affairs-at-liberty-3745158246",
      "search_city":"Joplin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Our purpose is sustaining energy and water for life, and it is demonstrated in everything we do as a business, and as an employee team.\nAt Liberty, we hire passionate people who care about doing the right thing for our customers. We are entrepreneurial, creative, and outcome-focused. Here, your natural talent and achievements will flourish in an inclusive environment of teamwork, trust and continuous learning. We are always pursuing excellence to exceed our ambitions goals, rewarding both the goal outcome and how we achieve it.\nPurpose\nThe Regulatory Analyst will report to the Director, Rates and Regulatory Affairs, and will undertake complex financial and operational research and analysis for priority regulatory projects or rate issues for Liberty\u201a\u00c4\u00f4s Central Region Utilities. Analysts will play a significant role in the preparation and implementation of required state and federal rate filings and various other regulatory filings. Have responsibility for specific calculations, reports, and analysis. May communicate with local regulatory authorities and other key stakeholders while ensuring that compliance requirements are met. This role will also provide decision support for various financial statement items, and monitor utility earnings or rates of return, to determine whether rate increases or decreases are necessary.\nAccountabilities\nReview and utilize the accounting records, operational data and financial records of the utility to complete various regulatory filings\nWork closely with Rates and Regulatory team members on various filings which include the preparation of supporting financial schedules and all supporting documentation. Plan and advise on the preparation and recording of rate case adjustments in conjunction with the Accounting and Budget department.\nParticipate and prepare written regulatory filing activities such as providing support to expert witnesses and drafting testimony\nAs designated, take responsibility for responding to data requests\/requests for information from the various utility commissions along with requests from other stakeholders.\nMaintain an ongoing data base of compliance requirements. Review final commission decisions to identify new and ongoing compliance requirements which are being imposed on the regulated entity.\nPrepare compliance filings to ensure accuracy and timeliness with filing deadlines as required.\nEstablishes and maintains productive relationships with regulatory authorities.\nDevelop strategy to maximize rate recovery of prudently incurred capital and operating expenses Conduct analysis to advice company\u201a\u00c4\u00f4s management on emerging regulations and developments in industry.\nReview and interpret new and pending local laws and regulations, which potentially affect the organization's business practices, and coordinates the development or revision of policies, procedures, contracts, and agreements to ensure compliance.\nMonitor industry information regarding federal, state and applicable laws and regulations as they relate to filing requirements for regulated utilities. Update key management on regulatory changes, developments, and implications of new requirements on functional areas. Education and Experience This Regulatory Analyst position is ideally suited for a detail and goal oriented individual with several years of professional experience in a role that requires complex financial analysis, in a fast-paced environment. These analysis skills may come from a variety of backgrounds such as financial planning and analysis, accounting, audit, financial planning, and economics, and business data analytics. The Analyst must be comfortable interacting with third parties such as lawyers, consultants, and regulatory staff in multiple states, and peers in industry.\nEducation and Experience\nLevel I\nDegree in Accounting, Audit, Finance, Economics, Statistics, Data Analytics or related field 0-3 years in a highly analytical role, preferably in a regulated environment\nExperience supporting regulatory filings and reporting preferred\nDetail-oriented and proficient in Microsoft Office, particularly in MS Excel Strong business insight with proven ability to develop strategic solutions to sophisticated problems.\nAbility to work under time constraints with firm deadlines.\nDemonstration of being a standout colleague who can think creatively. Some travel will be required\nLevel II\nDegree in Accounting, Audit, Finance, Economics, Statistics, Data Analytics or related field 3-5 years in a highly analytical role, preferably in a regulated environment\nKnowledge of local state commission regulations and filing requirements\nDetail-oriented and highly proficient in Microsoft Office, particularly in MS Excel Strong business insight with proven ability to develop strategic solutions to sophisticated problems.\nAbility to work under time constraints with firm deadlines.\nDemonstration of being a standout colleague who can think creatively. Some travel will be required\nLevel III\nDegree in Accounting, Audit, Finance, Accounting, Economics, Statistics, Audit, Data Analytics or related field 5+ years in a highly analytical role, preferably in a regulated environment\nSkilled knowledge and understanding of the regulatory environment\nKnowledge of local state commission regulations and filing requirements\nAbility to analyze, interpret and report complex information\nAbility to learn new processes and create procedures to implement the process\nDetail-oriented and highly proficient in Microsoft Office, particularly in MS Excel Strong business insight with proven ability to develop strategic solutions to sophisticated problems\nAbility to work under time constraints with firm deadlines\nDemonstrates a high level of initiative. Astute in carrying out assignments without direction\nDynamic team player that also works well independently\nDemonstration of being a standout colleague who can think creatively. Some travel will be required\nAlgonquin Power & Utilities Corp. is a growing renewable energy and utility company with over $15 billion of assets across North America and internationally.\nFor more than 30 years, Algonquin has demonstrated an unwavering commitment to delivering clean energy and water solutions. Our rapid growth has led both our regulated utility services and renewable energy business groups into different geographies and commodities, but our purpose remains unchanged \u201a\u00c4\u00ec Sustaining Energy and Water for Life.\nThrough our operating business (Liberty), we provide regulated electricity, water, and natural gas utility services to over 1 million customer connections, primarily in North America. And, our growing portfolio of clean, renewable wind, solar, hydro and thermal power generation facilities represent over 3 GW of renewable generation capacity in operation and under construction.\nWith our robust, diversified, and growing presence in communities across North America and internationally, we are continually demonstrating our \u201a\u00c4\u00faThink Global, Act Local\u201a\u00c4\u00f9 business model.\nWhat We Offer\nCompany funded Pension program\n401k with Company match\nFull insurance benefits (health\/dental\/vision\/life)\nCollaborative environment with a genuine flexible working policy\nShare purchase\/match plan\nDefined Contribution savings plan\nTop Talent Program\nVolunteer paid days off\nEmployee Assistance Program\nAchievement fund\nWe are focused on building a diverse and inclusive workforce. If you are excited about this role and are not certain you meet the all the qualification requirements, we encourage you to apply to further investigate the opportunity.\nWe are an equal opportunity employer and value each person\u201a\u00c4\u00f4s unique background, diversity, experiences, perspectives and talents. Full participation of all employees in a safe, healthy and respectful environment is key to individual and company success. We are committed to fully utilizing the abilities of all of our employees and expect each of our employees to honor this commitment in their daily responsibilities.\nShow more\nShow less",
      "job_skills":"Microsoft Office, Regulatory Affairs, Complex financial analysis, Accounting, Audit, Economics, Data Analytics, Statistics, Financial reporting, Excel, Compliance, Business analysis, Problem solving, Time management, Strategic thinking, Teamwork, Communication, Attention to detail, Initiative, Research, Analysis, Writing, Rate cases, Regulatory filings, Financial schedules, Testimony, Data requests, Compliance reporting, Budget management, Data management",
      "Category":"Data Science"
  },
  {
      "job_title":"Data Analyst",
      "company":"Stockell Consulting",
      "job_location":"Greater St. Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-stockell-consulting-3783391160",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Long term contract paying $100,000-$140,000 a year W2 plus PTO, medical, dental, 401k\nHybrid - Creve Couer, MO\nResponsibilities:\nAnalyze existing SQL code from stored procedures, scripts, and document flow to create mapping documents\nUnderstand and map source data fields from custodial and market data source.\nGather and document requirements for future system enhancement working with both the business and core systems teams.\nSend status reports on the activities planned vs completed\nPrepare business scenarios and UAT test cases\nSupport of Development, SIT and UAT teams on requirement clarification.\nWork closely with the engineering team to identify, troubleshoot, and resolve issues.\nShow more\nShow less",
      "job_skills":"SQL, Stored Procedures, Data Mapping, Source Data Fields, Requirements Gathering, UAT Test Cases, Business Scenarios, System Enhancement, Engineering, Troubleshooting",
      "Category":"Data Science"
  },
  {
      "job_title":"Senior Data Scientist, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-scientist-gt-school-remote-%2460-000-year-usd-at-crossover-3788456345",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nSenior Data Scientist Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-FortWort-SeniorDataScie.017\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, Generative AI, R, OOP, Data science, Machine learning, Natural language processing, Computer vision, Cloud computing, Distributed systems, Big data, Product development, Research, Iteration, Optimization, Data analysis, Problemsolving, Communication, Teamwork, Collaboration, Time management, Prioritization, Stakeholder management, Attention to detail, Adaptability, Flexibility, Initiative, Selfmotivation, Creativity, Innovation, Passion for learning, Commitment to excellence",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Science Advisor",
      "company":"Albemarle Corporation",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-science-advisor-at-albemarle-corporation-3742704373",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Are you inspired by \u201a\u00c4\u00fawhat\u201a\u00c4\u00f4s next\u201a\u00c4\u00f9? So are we.\nWhen you join the Albemarle team, you contribute to a better tomorrow. You will play a role in powering many of the world\u201a\u00c4\u00f4s largest and most critical industries, from energy and communications to transportation and electronics. We are putting innovation to work to improve people\u201a\u00c4\u00f4s lives and we want YOU to be a part of it.\nJob Description\nWe are seeking to hire Data Science Advisor member of the Enterprise Analytics team and has the technical and leadership skills required to advance Albemarle's digital business transformation goals.\nIn this role, you will combine expertise in modeling, data analysis, forecasting, visualization, and scenario testing to guide Albemarle product, research, and investment decisions. You will be the Subject Matter Expert and provide guidance and best practices to create models and analytics to answer strategic questions. You will support leaders across Product Management, Sales, R&D, Manufacturing, & Finance with industry thought leadership and tools to identify system dynamics, compare scenarios, understand risk, and make decisions.\nResponsibilities\nFacilitate strategic decision-making by applying quantitative methods such as machine learning\/statistics and fundamental modeling (e.g. chemistry, physics, economics, etc.)\nWork on a team to create comprehensive and linked models that identify, analyze, and forecast key metrics across the supply chain.\nDevelop scenarios of market dynamics and technology innovation that influence commercial strategy and R&D prioritization.\nCommunicate insights and recommendations clearly and visually through presentations and interactive tools.\nWork with an array of complex and unstructured internal and external data sources\nAct as Subject Matter Expert to help create applications for the Data Science Suite that demonstrate full stack data science skills.\nEducation\nMS\/PhD in Engineering, Science, Economics, Mathematics\/Statistics, or related.\nExperience\nRequired Experience:\n3+ years of market research, business intelligence or analysis experience (industry, research, consulting, etc.)\n3+ years data science, modeling, or programming (Python, MATLAB, R, C++, SQL, Java, etc.)\n3+ years data visualization (Plotly, Power BI, Tableau, Matplotlib, etc.)\nExperience using data to make strategic recommendations and inform decisions.\nA demonstrated ability to communicate findings in a clear and concise manner.\nWorking on a team, including co-development of models and results\nPreferred Experience\nForecasting market dynamics and\/or technology innovation\nEvaluating project economics and optimizing investment decisions\nPhysics-based or fundamental modeling approaches\nStatistical and machine learning methods\nMarket research\/intelligence\nDatabase\/Cloud (Databricks, Spark, Microsoft SQL, SAP HANA, Microsoft Cloud)\nFront-end development (HTML, CSS, JavaScript, Bootstrap, etc.)\nVersion-control (GitHub, etc.)\nChoose to unlock your full POTENTIAL. Apply today.\nShow more\nShow less",
      "job_skills":"Data Science, Modeling, Data Analysis, Forecasting, Visualization, Scenario Testing, Machine Learning, Statistics, Fundamental Modeling, Chemistry, Physics, Economics, Python, MATLAB, R, C++, SQL, Java, Plotly, Power BI, Tableau, Matplotlib, Databricks, Spark, Microsoft SQL, SAP HANA, Microsoft Cloud, HTML, CSS, JavaScript, Bootstrap, GitHub",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Labs - Data Scientist - Senior Associate",
      "company":"PwC",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/labs-data-scientist-senior-associate-at-pwc-3782251293",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Specialty\/Competency:\nData Science\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team designs, develops and programs the methods, processes, and systems that are used to collect all forms of data and develop models that serve predictions to applications, automated process flows, and stakeholders. A Data Scientist collects domain context from stakeholders, defines hypothesis and prediction tasks, identifies and creates supporting data sources, conducts experiments with various algorithms to model prediction tasks, undertakes validation and tests of models to improve performance, produces pipelines that can be used to automate training and predictions with unseen or production data, identifies meaningful insights from data sources, and contextualizes model outputs to communicate with stakeholders (product owners, process managers, and end consumers).\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nOur mandate is to quickly explore new technologies to determine what is relevant for our clients and Firm to invest in. Our work has a tremendous impact on how PwC and our clients do business. Our Data Scientists possess exceptional technical prowess matched by their ability to communicate results to other data scientists, clients, and internal stakeholders.\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nBachelor Degree\nAdditional Educational Requirements\nBachelor's degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and\/or progressively responsible work experience in technology for each missing year of college.\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nMaster Degree\nPreferred Fields Of Study\nComputer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management\/Research\nAdditional Educational Preferences\nPhD highly preferred\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success:\nExploring new analytical technologies and evaluate their technical and commercial viability;\nWorking across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications\/production ready tools;\nWorking across various data mediums: text, audio, imagery, sensory, and structured data;\nWorking in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients;\nTesting and rejecting hypotheses around data processing and ML model building;\nExperimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task;\nBuilding ML pipelines that ingest, clean data, and make predictions;\nFocusing on AI and ML techniques that are broadly applicable across all industries;\nStaying abreast of new AI research from leading labs by reading papers and experimenting with code;\nDeveloping innovative solutions and perspectives on AI that can be published in academic journals\/arXiv and shared with clients;\nApplying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.);\nUnderstanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique;\nUnderstanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow);\nUnderstanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application;\nBuilding ML models and systems, interpreting their output, and communicating the results; and,\nMoving models from development to production; conducting lab research and publishing work.\nDemonstrates thorough abilities and\/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:\nDemonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix;\nDemonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.);\nDemonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow;\nDemonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy;\nDemonstrating knowledge in NLU\/NLP domain: Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS;\nDemonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio); and,\nDemonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Robotics, Augmented Reality, Virtual Reality, Blockchain, Internet of Things, 3D Printing, Data Science, Data Analytics, Artificial Intelligence, Machine Learning Engineer, Software Engineering, Cloud Computing, Big Data Analytics, Data Mining, Data Visualization, Predictive Analytics, Prescriptive Analytics, Data Warehousing, Data Integration, Business Intelligence, Software Development, Agile Development, Scrum, Kanban, DevOps, Continuous Integration, Continuous Delivery, Version Control, Python, R, Java, JavaScript, C++, Unix, SQL, NoSQL, PostgreSQL, Neo4j, Hadoop, Cloudbased databases, Parquet, Python (Numpy Pandas etc.), Spark, Cloudbased solutions, Python (scikitlearn genism etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy, Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS, Python (Matplotlib Seaborn bokeh etc.), JavaScript (d3), Third party libraries (Power BI Tableau Data Studio), GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Science Architect (Digital Marketing)",
      "company":"SNIPEBRIDGE",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-science-architect-digital-marketing-at-snipebridge-3733716843",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"COMPANY\nOur client is a world leading manufacturing and distribution organization that creates innovative, high performance industrial surfaces. The company has been in business for over 60 years and is headquartered in Austin, Texas. It manufactures and distributesengineered surface options for use in furniture, office and retail spaces, countertops, worktops and other applications. They do business in more than 90 countries.\nPOSITION SUMMARY\nWe are looking for a Data Science Architect(Digital Marketing)who will work as a team member of the Global Digital Services team to lead, execute, and establish the data, analytics, and customer integration platforms that empower the marketing function to engage with, gain holistic insights into, and perform analysis related to customer perception, preferences, and behavior, to drive marketing qualified leads, and revenue outcomes. The ideal candidatewill beadept at linking traditional (structured data) as well as new (unstructured) data types related to audiences and customers and establishing the customer data integration framework. The candidate must have strong experience using a variety of data mining\/data analysis methods, using a variety of data tools, building and implementing models, using\/creating algorithms. They must have a proven ability to articulate potential business results with their databased analysis, dashboards and insights; andmust be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions available in data sets and working with stakeholders to improve business outcomes. This person must have strong technical, functional, project management, and communication skills.\nKEY ROLE & RESPONSIBILITIES\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nUnderstand and drive organizational change management to enable user adoption.\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. This would also involve tagging, aggregating, segmenting, trending the data to transform it into reports and dashboards.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nEstablish the customer data integration framework \/ unifying customer data from different structured and unstructured sources using the tools provided by Salesforce\/Adobe\/Snowflake and the likes\nStructured: CRM, online registrations, email campaigns, B2B, other lists\nUnstructured: social media, consumer reviews\/blogs, forums, user behavior etc.\nDevelop data models and AI and ML algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, effective lead generation and other business outcomes.\nDevelop company A\/B testing framework and test model quality.\nCollaboration with vendors, system integrators, on-shore\/off-shore partners, etc.\nCoordinate with different functional teams to implement models, monitor outcomes, and develop processes and tools to monitor and analyze model performance and data accuracy.\nKNOWLEDGE, SKILLS &ABILITIES\nStrong problem solving skills with an emphasis on product development.\nExcellent written and verbal communication skills for coordinating across teams.\nExperience using statistical computer languages to manipulate data and draw insights from large data sets.\nFamiliarity with marketing automation tools like Adobe Marketo or Salesforce Marketing Cloud.\nKnowledge of a variety of machine learning techniques and their real-world advantages\/drawbacks.\nFamiliarity with integrations between systems for key data elements using web services or point-to-point.\nKnowledge of Scrum and Agile methodology, a plus.\nREQUIRED EDUCATION & EXPERIENCE\nEducation:\nBachelor Degree Required\nDegree in Statistics, Mathematics, Computer Science or another quantitative field\nExperience:\n5-7 years of experience manipulating data sets and building statistical models, and is familiar with the following software\/tools:\nCoding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.\nExperiencewith marketing automation tools like AdobeMarketo\/Adobe Experience Cloudor Salesforce Marketing Cloud\/SalesforcePardotor similar.\nKnowledge and experience in statistical and data mining techniques.\nExperience querying databases and using statistical computer languages like Python.\nExperience analyzing data from 3rd party providers: Google Analytics, Adwords, Social media portals, Insights, etc.\nExperience with data query tools like MySQL\nExperience visualizing\/presenting data for stakeholders.\nWorking knowledge of AI & ML algorithms, and tools such as SageMaker\nShow more\nShow less",
      "job_skills":"Data Science, Data Architecture, Data Analytics, Customer Integration, Data Mining, Data Analysis, Predictive Modeling, Machine Learning, AI Algorithms, Scrum, Agile Methodology, Statistics, Mathematics, Computer Science, C, C++, Java, JavaScript, Adobe Marketo, Salesforce Marketing Cloud, Salesforce Pardot, Python, Google Analytics, Adwords, Social Media Portals, Insights, MySQL, Data Visualization, SageMaker",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Labs - Data Scientist - Senior Associate",
      "company":"PwC",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/labs-data-scientist-senior-associate-at-pwc-3782253044",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Specialty\/Competency:\nData Science\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team designs, develops and programs the methods, processes, and systems that are used to collect all forms of data and develop models that serve predictions to applications, automated process flows, and stakeholders. A Data Scientist collects domain context from stakeholders, defines hypothesis and prediction tasks, identifies and creates supporting data sources, conducts experiments with various algorithms to model prediction tasks, undertakes validation and tests of models to improve performance, produces pipelines that can be used to automate training and predictions with unseen or production data, identifies meaningful insights from data sources, and contextualizes model outputs to communicate with stakeholders (product owners, process managers, and end consumers).\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nOur mandate is to quickly explore new technologies to determine what is relevant for our clients and Firm to invest in. Our work has a tremendous impact on how PwC and our clients do business. Our Data Scientists possess exceptional technical prowess matched by their ability to communicate results to other data scientists, clients, and internal stakeholders.\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nBachelor Degree\nAdditional Educational Requirements\nBachelor's degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and\/or progressively responsible work experience in technology for each missing year of college.\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nMaster Degree\nPreferred Fields Of Study\nComputer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management\/Research\nAdditional Educational Preferences\nPhD highly preferred\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success:\nExploring new analytical technologies and evaluate their technical and commercial viability;\nWorking across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications\/production ready tools;\nWorking across various data mediums: text, audio, imagery, sensory, and structured data;\nWorking in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients;\nTesting and rejecting hypotheses around data processing and ML model building;\nExperimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task;\nBuilding ML pipelines that ingest, clean data, and make predictions;\nFocusing on AI and ML techniques that are broadly applicable across all industries;\nStaying abreast of new AI research from leading labs by reading papers and experimenting with code;\nDeveloping innovative solutions and perspectives on AI that can be published in academic journals\/arXiv and shared with clients;\nApplying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.);\nUnderstanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique;\nUnderstanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow);\nUnderstanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application;\nBuilding ML models and systems, interpreting their output, and communicating the results; and,\nMoving models from development to production; conducting lab research and publishing work.\nDemonstrates thorough abilities and\/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:\nDemonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix;\nDemonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.);\nDemonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow;\nDemonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy;\nDemonstrating knowledge in NLU\/NLP domain: Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS;\nDemonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio); and,\nDemonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"Artificial Intelligence, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Robotics, Augmented Reality, Virtual Reality, Blockchain, Internet of Things, Data Science, Data Analytics, Data Mining, Business Intelligence, Data Visualization, Data Warehousing, Big Data, Cloud Computing, Software Development, Programming Languages, Python, R, Java, JavaScript, C++, Unix, Data Storage Technologies, SQL, NoSQL, Postgres, Neo4j, Hadoop, Cloudbased Databases, Parquet, Data Processing Tools, Spark, Cloudbased Solutions, GCP DataFlow, Machine Learning Libraries, TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy, NLU\/NLP Domain, Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS, Visualization Tools, Matplotlib, Seaborn, Bokeh, D3, Power BI, Tableau, Data Studio, Productionization and Containerization Technologies, GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS, Scrum, Agile Methodology, Kanban, DevOps",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Labs - Data Scientist - Senior Associate",
      "company":"PwC",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/labs-data-scientist-senior-associate-at-pwc-3782252096",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Specialty\/Competency:\nData Science\nIndustry\/Sector:\nNot Applicable\nTime Type:\nFull time\nTravel Requirements:\nUp to 20%\nA career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team designs, develops and programs the methods, processes, and systems that are used to collect all forms of data and develop models that serve predictions to applications, automated process flows, and stakeholders. A Data Scientist collects domain context from stakeholders, defines hypothesis and prediction tasks, identifies and creates supporting data sources, conducts experiments with various algorithms to model prediction tasks, undertakes validation and tests of models to improve performance, produces pipelines that can be used to automate training and predictions with unseen or production data, identifies meaningful insights from data sources, and contextualizes model outputs to communicate with stakeholders (product owners, process managers, and end consumers).\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\nResponsibilities\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\nUse feedback and reflection to develop self awareness, personal strengths and address development areas.\nDelegate to others to provide stretch opportunities, coaching them to deliver results.\nDemonstrate critical thinking and the ability to bring order to unstructured problems.\nUse a broad range of tools and techniques to extract insights from current industry or sector trends.\nReview your work and that of others for quality, accuracy and relevance.\nKnow how and when to use tools available for a given situation and can explain the reasons for this choice.\nSeek and embrace opportunities which give exposure to different situations, environments and perspectives.\nUse straightforward communication, in a structured way, when influencing and connecting with others.\nAble to read situations and modify behavior to build quality relationships.\nUphold the firm's code of ethics and business conduct.\nOur mandate is to quickly explore new technologies to determine what is relevant for our clients and Firm to invest in. Our work has a tremendous impact on how PwC and our clients do business. Our Data Scientists possess exceptional technical prowess matched by their ability to communicate results to other data scientists, clients, and internal stakeholders.\nBasic Qualifications\nJob Requirements and Preferences\n:\nMinimum Degree Required\nBachelor Degree\nAdditional Educational Requirements\nBachelor's degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and\/or progressively responsible work experience in technology for each missing year of college.\nMinimum Years Of Experience\n2 year(s)\nPreferred Qualifications\nDegree Preferred\n:\nMaster Degree\nPreferred Fields Of Study\nComputer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management\/Research\nAdditional Educational Preferences\nPhD highly preferred\nPreferred Knowledge\/Skills\nDemonstrates thorough abilities and\/or a proven record of success:\nExploring new analytical technologies and evaluate their technical and commercial viability;\nWorking across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications\/production ready tools;\nWorking across various data mediums: text, audio, imagery, sensory, and structured data;\nWorking in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients;\nTesting and rejecting hypotheses around data processing and ML model building;\nExperimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task;\nBuilding ML pipelines that ingest, clean data, and make predictions;\nFocusing on AI and ML techniques that are broadly applicable across all industries;\nStaying abreast of new AI research from leading labs by reading papers and experimenting with code;\nDeveloping innovative solutions and perspectives on AI that can be published in academic journals\/arXiv and shared with clients;\nApplying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.);\nUnderstanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique;\nUnderstanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow);\nUnderstanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application;\nBuilding ML models and systems, interpreting their output, and communicating the results; and,\nMoving models from development to production; conducting lab research and publishing work.\nDemonstrates thorough abilities and\/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:\nDemonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix;\nDemonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.);\nDemonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow;\nDemonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy;\nDemonstrating knowledge in NLU\/NLP domain: Sentiment Analysis, Chatbots & Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS;\nDemonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio); and,\nDemonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS.\nLearn more about how we work: https:\/\/pwc.to\/how-we-work\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https:\/\/pwc.to\/H-1B-Lottery-Policy.\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https:\/\/pwc.to\/us-application-deadlines\nFor positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https:\/\/pwc.to\/payrange-v1-productstechseniorassociate\nShow more\nShow less",
      "job_skills":"Artificial Intelligence, Machine Learning, Natural Language Processing, Computer Vision, Robotics, Augmented Reality, Virtual Reality, Blockchain, Drones, Internet of Things, 3D Printing, Data Science, Data Analytics, Data Mining, Data Visualization, Business Intelligence, Software Development, Web Development, Mobile Development, Database Administration, Systems Administration, Network Administration, Information Security, Cloud Computing, DevOps, Agile Development, Lean Six Sigma, Project Management, Product Management, Business Analysis, Consulting, Communication, Teamwork, Problem Solving, Critical Thinking, Creativity, Innovation, Leadership, Ethics, Professionalism, Certifications:, PMP, CSM, CEH, CISSP, CCNA, CCNP, AWS Certified Solutions Architect, Azure Certified Solutions Architect, Google Cloud Certified Professional Cloud Architect, Skills:, Python, R, Java, JavaScript, C++, Unix, SQL, NoSQL, Postgres, Neo4j, Hadoop, GCP BigQuery, Parquet, Networkminer, Maltego, Wireshark, Metasploit, NVT, Nessus, OpenVAS, Security Onion, Snort, Suricata, Bro, Zeek, Splunk, ELK Stack, Graylog, Sumo Logic, QRadar, ArcSight, RSA NetWitness, FireEye Helix, Palo Alto Networks Cortex, Check Point Harmony, CrowdStrike Falcon, Carbon Black Defense, SentinelOne Singularity, Tanium Threat Response, Cybereason EDR, Sophos Intercept X, McAfee Endpoint Security, Trend Micro Apex One, ESET Endpoint Security, Kaspersky Endpoint Security, NortonLifeLock 360, Bitdefender Total Security, Avast Free Antivirus, AVG AntiVirus Free, Malwarebytes AntiMalware, Spybot  Search & Destroy, AdwCleaner, Junkware Removal Tool, BleachBit, CCleaner, Recuva, PhotoRec, TestDisk, EaseUS Data Recovery Wizard, RStudio, DMDE, Disk Drill, Recuva, PhotoRec, TestDisk, EaseUS Data Recovery Wizard, RStudio, DMDE, Disk Drill, Kali Linux, Parrot OS, BlackArch Linux, Tails OS, Whonix, Qubes OS, Alpine Linux, CoreOS, CentOS, Debian, Fedora, Gentoo, Linux Mint, Manjaro Linux, MX Linux, openSUSE, Pop!_OS, Red Hat Enterprise Linux, Slackware, Solus, Ubuntu, Void Linux, Zorin OS",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788461016",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-FortWort-DataResearchAn.011\nShow more\nShow less",
      "job_skills":"Generative AI, Python, JavaScript, JSON, OOP, R, Technical writing, Communication, Data Analytics, Highperformance coaching, Machine learning, Natural Language Processing, Data Science, AI model training",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Scientist, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-gt-school-remote-%2460-000-year-usd-at-crossover-3788460001",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Scientist Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Houston-DataScientist.014\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, Generative AI, Software Development, Product Development, Data Science, OOP Languages, R, English Communication, Communication Management, AI Outputs, Subject Matter Experts, Stakeholder Management, Online Job Application, JobRelated Skills",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788457259",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Houston-DataResearchAn.022\nShow more\nShow less",
      "job_skills":"Generative AI, Python, JavaScript, JSON, R, OOP, Data science, Research, Product development, Verbal communication, Written communication, English, Proactive communication, Time management, AI prompts engineering, AI outputs analyzing, New educational tools developing, Current products iterating, AI training models finetuning, Technical functionalities creating, EdTech, Data analytics, Coaching",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788452885",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-SanAnton-DataResearchAn.018\nShow more\nShow less",
      "job_skills":"Generative AI, AI Prompts, Python, JavaScript, JSON, Data Analysis, AI Training Models, Research, Technical Functionalities, English Communication, OOP Languages, Work Experience, Time Management, Stakeholder Management, Technology, Artificial Intelligence, Remote Work, Learning Science, Data Analytics, HighPerformance Coaching, EdTech Startup",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Senior Data Engineer - $180k-$220k (Snowflake, Coding)",
      "company":"CyberCoders",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-%24180k-%24220k-snowflake-coding-at-cybercoders-3766365260",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Permanently Remote in US\nJob Title:\nSenior Data Engineer - $180k-$220k + Bonus (Snowflake, Coding)\nSalary:\n$180k-$220k Base + Bonus, No Stock, 401k, Benefits\nRequirements:\nExpert w\/ Snowflake & Coding Ability\nBased in beautiful New York City, we are a cutting edge ad-tech org for television-based ads.\nWe are founded and owned by T.V.s largest publishers.\nOur mission is to be bring simplicity & scale to audience based campaigns in television.\nWe're working with over 100 advertisers and anticipating another year of significant growth!\nAs a rapidly growing company\n(founded in 2017 & up 140% year over year)\nwe've recently elevated our C-Suite Team in preparation for our next stage of growth and are building our Technology, Product, and Operations Executive Teams.\nWe have been in business for 7 years and have around 40 employees.\nDue to growth, we are actively hiring a Senior Data Engineer with\nSnowflake experience (ideally certified)\nAbility to write production level code (ideally JavaScript or Python)\nExperience building data pipelines from scratch and\/or working with APIs\nExperience with the following is a big plus!\nFivetran and\/or DBT\nYou will be working with 12 other engineers on the data side + several other technical folks.\nThis role will consist of tasks such as building out data pipelines, data architecture via snowflake, and data modeling.\nIf you have this experience, please apply immediately. We are actively interviewing this week and next for this high profile position.\nTop Reasons to Work with Us\nCompensation: $180k-$220k Base + Bonus, No Stock, 401k, Benefits\nRaid Growth: Founded in 2017 & up 140% year over year\nCulture: Fast paced, mission driven culture\nTechnology: Cutting edge technology\nWhat You Will Be Doing\nBuilding data pipelines from scratch\nData architecture via Snowflake\nData modeling\nTechnical review of everything this group builds.\nMange development velocity, team capacity, and backlogs\nPartner closely with the product team\nTake on key assignments and delegate as needed\nAct as the main technical point of contact for engineering\nTranslate technical requirements to the rest of the engineering team\nWhat You Need for this Position\nMust Have Experience\nSnowflake experience\nAbility to write production level code (ideally JavaScript or Python)\nExperience building data pipelines from scratch and\/or working with APIs\nSome Experience With:\n-\nFivetran and\/or DBT\nWhat's In It for You\n$180k-$220k Base + Bonus, No Stock, 401k, Benefits\n401k\nVacation\/PTO\nMedical\nDental\nVision\nBonus\n401k\nBenefits\nVacation\/PTO\nMedical\nDental\nVision\nBonus\nSo, if you are a Senior Data Engineer - $180k-$220k + Bonus (Snowflake, Coding) with experience, please apply today!\nColorado employees will receive paid sick leave. For additional information about available benefits, please contact Nitu Gulati-Pauly\nEmail Your Resume In Word To\nLooking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:\nNitu.Gulati-Pauly@cybercoders.com\nPlease do NOT change the email subject line in any way. You must keep the JobID: linkedin : MA5-1745335L570 -- in the email subject line for your application to be considered.***\nNitu Gulati-Pauly - VP of Recruiting - CyberCoders\nApplicants must be authorized to work in the U.S.\nCyberCoders is proud to be an Equal Opportunity Employer\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\nYour Right to Work\n\u201a\u00c4\u00ec In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\nShow more\nShow less",
      "job_skills":"Snowflake, Coding, JavaScript, Python, Data pipelines, APIs, Fivetran, DBT, Data architecture, Data modeling, Technical review, Mange development velocity, Team capacity, Backlogs, Partner closely with the product team, Take on key assignments, Delegate as needed, Act as the main technical point of contact for engineering, Translate technical requirements",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788458092",
      "search_city":"Mansfield",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Dallas-DataResearchAn.034\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, R, Object Oriented Programming, Generative AI, Machine Learning, AI Training Models, Data Analysis, Project Management, Task Prioritization, Stakeholder Management, Written Communication, Verbal Communication, Proficiency in Technical Field, Data Science, Technology, Programming, Financial Services",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788458253",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Austin-DataResearchAn.024\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, R, OOP, Generative AI, Data science, Research, Technology, Education, Written communication, Verbal communication",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Scientist, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-gt-school-remote-%2460-000-year-usd-at-crossover-3788451991",
      "search_city":"Hollywood",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Scientist Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Austin-DataScientist.008\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, Generative AI, Data Science, OOP, English communication, Machine Learning, Research, Product Development, Technology, Algorithms, Artificial Intelligence, R",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Scientist, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Round Rock, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-gt-school-remote-%2460-000-year-usd-at-crossover-3788456210",
      "search_city":"Hollywood",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Scientist Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-RoundRoc-DataScientist.010\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, R, Generative AI, OOP language, Data science, English communication, Written communication, Verbal communication, Data analytics",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Scientist, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Sugar Land, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-gt-school-remote-%2460-000-year-usd-at-crossover-3788457064",
      "search_city":"Bourne",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Scientist Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-SugarLan-DataScientist.006\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, Generative AI, Algorithms, Technology, Education, AI data analysis, R, OOP, Data science, Proficient written and verbal English communication skills, 2+ years of work experience in a technical field, Proactive communicator, Effective management of multiple priorities and stakeholders simultaneously",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Scientist, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Brownsville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-gt-school-remote-%2460-000-year-usd-at-crossover-3788458254",
      "search_city":"Bourne",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Scientist Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Brownsvi-DataScientist.010\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, R, OOP, Generative AI, Technology, Programming, Data science, Project management, Communication, Problem solving",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Scientist, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-gt-school-remote-%2460-000-year-usd-at-crossover-3788457109",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Scientist Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Dallas-DataScientist.012\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, R, OOP languages, Generative AI, Technology, Algorithms, Data science, Education tools, AI training models, Research, English communication skills, Proactive communication skills, Priority management, Stakeholder management, EdTech, Learning science, Data analytics, Highperformance coaching, Remote work",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Scientist, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Allen, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-gt-school-remote-%2460-000-year-usd-at-crossover-3788461020",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Scientist Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Allen-DataScientist.013\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, OOP, Generative AI, Education Technology, Data Science, Product Development, Machine Learning, Natural Language Processing, Coaching, Communication, Teamwork, Problem Solving, Research",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Brownsville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788620885",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Brownsvi-DataResearchAn.009\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, R, OOP, Generative AI, Data science, Machine learning, Research, Product development, Education technology, Data analysis, Communication, Collaboration, Time management, Problem solving, Innovation",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Round Rock, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788457154",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-RoundRoc-DataResearchAn.015\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, Generative AI, OOP languages, AI prompts, AI outputs, Product engineering, Education tools, Data science, Research, Technical functionalities, Data analytics, Subject matter experts, Remote work, Independent contractor agreement",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Engineer Co-Op",
      "company":"Bayer",
      "job_location":"Creve Coeur, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-co-op-at-bayer-3690877394",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Data Engineer Co Op\nYour Tasks And Responsibilities\nThe primary responsibilities of this role, data engineer Co-op, are to:\nCollaborate daily with a team of Data Engineers and Product Managers to build and support scalable data solutions;\nPartner with other teams, including application developers, data scientists and business colleagues, to identify solution needs;\nAuthor code to implement new solutions or add new features to existing solutions;\nDevelop any technical documentation needed to accurately represent application design and code;\nGain understanding of the business operations and functions for solutions owned within the team;\nSeek opportunities to discover new and better solutions;\nEffectively communicate within team and with direct lead;\nTake the initiative to do what needs to be done without being asked\nRequired Qualifications\nCandidate must be currently enrolled in a Bachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree program in any of the following: Computer Science, Computer Engineering, MIS, or related field;\nUpon completion of the co-op term, student must return to school to complete studies\nPreferred Qualifications\nExperience or education in the following areas: SDLC (software development lifecycle), Object Oriented or Functional Programming languages (ex: JavaScript, Swift, Java, C#, Scala, Ruby, Go) or languages such as C\/C++\nStrong written and verbal communication skills;\nFull time availability 40 hours a week, M-F. This is a HYBRID role based out of our Creve Couer office\nYOUR APPLICATION\nBayer offers a wide variety of competitive compensation and benefits programs. If you meet the requirements of this unique opportunity, and want to impact our mission Science for a better life, we encourage you to apply now. Be part of something bigger. Be you. Be Bayer.\nTo all recruitment agencies: Bayer does not accept unsolicited third party resumes.\nBayer is an Equal Opportunity Employer\/Disabled\/Veterans\nBayer is committed to providing access and reasonable accommodations in its application process for individuals with disabilities and encourages applicants with disabilities to request any needed accommodation(s) using the contact information below.\nBayer is an E-Verify Employer.\nLocation:\nUnited States : Missouri : Creve Coeur\nDivision:\nEnabling Functions\nReference Code:\n799317\nContact Us\nEmail:\nhrop_usa@bayer.com\nShow more\nShow less",
      "job_skills":"Data Engineering, Software Development Lifecycle (SDLC), Object Oriented Programming (OOP), Functional Programming, JavaScript, Swift, Java, C#, Scala, Ruby, Go, C\/C++, Written Communication, Verbal Communication",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788457146",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-StLouis-DataResearchAn.016\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, OOP, Data Science, Data Analytics, Data Research, Machine Learning, Generative AI, Algorithms, Research, Problem Solving, Communication, Collaboration, Project Management, Iteration, Finetuning, Product Development, Educational Tools, AI Prompts, AI Outputs, Training Models, OOP Languages, R",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Spatial Data Scientist (Active TS\/SCI required)",
      "company":"Xcellent Technology Solutions (XTS)",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/spatial-data-scientist-active-ts-sci-required-at-xcellent-technology-solutions-xts-3787759359",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Are you a highly driven Data Scientist looking to take your expertise deeper into Machine Learning and Artificial Intelligence?\nThis is your perfect opportunity to advance your data-driven ability further into the leading edge of Artificial Intelligence (AI)! In a data-driven world and AI being at the forefront, the need of utilizing and interpreting data\u201a\u00c4\u00eebig or small is more crucial than ever. You will be looked upon to your expertise in processing, analyzing, cleansing, transforming, and modeling geospatial imagery data to help make discoveries to ultimately empower the National Geospatial-Intelligence Agency (NGA) in making AI-driven solutions. As the Spatial Data Scientist, you will be the driving force behind NGA\u201a\u00c4\u00f4s AI-powered initiatives, driving your team in transforming data into actionable insights and predictive models. Join XTS today as we continue to leverage the power of data to drive success and bring modern geospatial analysis solutions to support the Intelligence Community!\nRequirements\nCurrent active Top Secret\/SCI clearance with the willingness to take a polygraph exam\nBachelor\u201a\u00c4\u00f4s Degree in Data Science, Statistics, Mathematics, Computer Science, Geographic Information Science or similar + 3 years of experience OR 7 + years of relevant experience\nDemonstrated experience with data collection, data cleaning and processing, data visualization, statistical analysis, data interpretation, etc. in order to extract valuable insights, make informed decisions, and drive organizations success.\nProgramming language experience in order to create machine-learning models and deal with large datasets. (i.e., Python, R, SQL, Java, JavaScript, C++, etc.)\nKnowledge and or experience with Text mining and machine learning techniques to extract and structure text data information for analysis\nDesired Skills\nExperience with Spatial Data Geometry Storage to perform spatial queries, manipulate and visualize geospatial data, and apply specialize algorithms for geospatial analysis\nExperience with distributed data and computing tools to handle large-scale data processing efficiently, and visualization tools to facilitate data exploration, communication, and the presentation of insights (i.e., ArcGIS, SPSS, SAS, MATLAB, Tableau, etc.)\nExperience manipulating data in PostgreSQL, ORACLE, SQL, or ACCESS database management system to ensure correct format, quality, and structure for analysis, modeling and producing valuable insights\nIf you are a driven Data Scientist looking to contribute and advance your data analysis skills in assisting the NGA push the boundaries of AI and ML for geospatial analysis, please send your resume directly to Lanchi Lai, (\n).\nXTS is a veteran-owned company that is highly employee focused. Offering exceptional tailored health care to fit employee\u201a\u00c4\u00f4s lifestyle and needs--dental, vision, PTO, and 401K with employer matching. Our continuation of fostering training and pathway towards career advancement to excel and meet your vision and goals. XTS continues to make a difference in our employee developments and providing the Intelligence Community with elite work forces to accomplish real world missions.\nPowered by JazzHR\nuFtVyH5uRU\nShow more\nShow less",
      "job_skills":"Data Science, Machine Learning, Artificial Intelligence, Geospatial Imagery Data, Data Processing, Data Analysis, Data Cleansing, Data Transformation, Data Modeling, Predictive Modeling, Python, R, SQL, Java, JavaScript, C++, Text Mining, Machine Learning Techniques, Spatial Data Geometry Storage, Geospatial Data, Geospatial Analysis, Distributed Data, Computing Tools, Data Visualization, ArcGIS, SPSS, SAS, MATLAB, Tableau, PostgreSQL, ORACLE, ACCESS, Database Management System",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Junior Data Scientist",
      "company":"Concero",
      "job_location":"Greater St. Louis",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/junior-data-scientist-at-concero-3771636398",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nOnsite St. Louis, MO\nData Scientist\n- Design and analyze lift experiments to drive product improvements with cross-functional teams.\n- Conduct research and analysis to improve the statistical\/ML model lift using experimental design and causal inference methods\n- Write SQL queries to clean, aggregate, and\/or impute data from multiple tables and\/or across jump servers\n- Manage IT tickets for simultaneous projects and tasks\n- Maintain proper project documentation (Project scope, business requirements, workflow charts, data mapping, etc.)\n- Build cross-functional relationships with SQL developers, business analysts, product marketing, Customer Success Managers (CSM), and other key stakeholders to identify opportunities to improve products, drive product launches, and influence product roadmaps\nQualifications\n- Bachelor's degree in a quantitative discipline (e.g., Statistics, Engineering, Biostatistics, Economics, Computer Science, Mathematics, Physics) and\/or 2+ years of equivalent practical experience\n- knowledge and experience in statistical methodologies, especially probability, hypothesis testing, experimental design, and causal inference\n- Familiarity with machine learning algorithms and A.I. methodologies\n- Understanding of project management principles\n- Basic understanding of A\/B testing\n- Practical experience querying and analyzing large datasets using SQL\n- Proficient in scripting languages like Java, JavaScript, Python, and\/or R\n- Able to work in an innovative and fast-paced environment\n#5737\nShow more\nShow less",
      "job_skills":"Data Science, Statistics, Machine Learning, Artificial Intelligence, Causal Inference, Probability, Hypothesis Testing, Experimental Design, Project Management, A\/B Testing, SQL, Java, JavaScript, Python, R",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3783184848",
      "search_city":"Collinsville",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-StLouis-DataResearchAn.015\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, OOP, Generative AI, Machine Learning, Data Science, Algorithms, Research, Product Development, Data Analysis, Communication, Collaboration, Time Management, Team Management, EdTech, Teaching, Learning",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Engineer Co-Op",
      "company":"Bayer",
      "job_location":"Creve Coeur, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-co-op-at-bayer-3690877394",
      "search_city":"Cahokia",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Data Engineer Co Op\nYour Tasks And Responsibilities\nThe primary responsibilities of this role, data engineer Co-op, are to:\nCollaborate daily with a team of Data Engineers and Product Managers to build and support scalable data solutions;\nPartner with other teams, including application developers, data scientists and business colleagues, to identify solution needs;\nAuthor code to implement new solutions or add new features to existing solutions;\nDevelop any technical documentation needed to accurately represent application design and code;\nGain understanding of the business operations and functions for solutions owned within the team;\nSeek opportunities to discover new and better solutions;\nEffectively communicate within team and with direct lead;\nTake the initiative to do what needs to be done without being asked\nRequired Qualifications\nCandidate must be currently enrolled in a Bachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree program in any of the following: Computer Science, Computer Engineering, MIS, or related field;\nUpon completion of the co-op term, student must return to school to complete studies\nPreferred Qualifications\nExperience or education in the following areas: SDLC (software development lifecycle), Object Oriented or Functional Programming languages (ex: JavaScript, Swift, Java, C#, Scala, Ruby, Go) or languages such as C\/C++\nStrong written and verbal communication skills;\nFull time availability 40 hours a week, M-F. This is a HYBRID role based out of our Creve Couer office\nYOUR APPLICATION\nBayer offers a wide variety of competitive compensation and benefits programs. If you meet the requirements of this unique opportunity, and want to impact our mission Science for a better life, we encourage you to apply now. Be part of something bigger. Be you. Be Bayer.\nTo all recruitment agencies: Bayer does not accept unsolicited third party resumes.\nBayer is an Equal Opportunity Employer\/Disabled\/Veterans\nBayer is committed to providing access and reasonable accommodations in its application process for individuals with disabilities and encourages applicants with disabilities to request any needed accommodation(s) using the contact information below.\nBayer is an E-Verify Employer.\nLocation:\nUnited States : Missouri : Creve Coeur\nDivision:\nEnabling Functions\nReference Code:\n799317\nContact Us\nEmail:\nhrop_usa@bayer.com\nShow more\nShow less",
      "job_skills":"Data Engineering, SDLC (Software Development Lifecycle), Object Oriented Programming, Functional Programming, Java, C#, Scala, Ruby, Go, C\/C++, JavaScript, Swift",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Scientist, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Allen, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-gt-school-remote-%2460-000-year-usd-at-crossover-3783183647",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Scientist Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Allen-DataScientist.012\nShow more\nShow less",
      "job_skills":"Generative AI, Python, JavaScript, JSON, Natural Language Processing, Data Science, Product Engineering, Research, Machine Learning, AI Training, Stakeholder Management, Communication Skills, Project Management, R, OOP Languages, Educational Technology, Data Analytics, Learning Science, Remote Work, Independent Contractor",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Insurance - Data Analyst - REMOTE",
      "company":"Wahve LLC",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/insurance-data-analyst-remote-at-wahve-llc-3785427375",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Put your Insurance Experience to work - FROM HOME!\nAt\nWahve\n, we value significant insurance experience and want to revolutionize the way people think about\nphasing into\nretirement\nby offering qualified candidates the opportunity to continue their career working from home. As we say -\nretire from the office but not from work\n. Our unique platform provides you with\nreal\nwork\/life balance and allows you to customize your own work schedule while continuing to utilize your insurance expertise in\na remote, long-term position\n.\nWhat You\u201a\u00c4\u00f4ll Love About Wahve\nWe created a welcoming place to work with friendly and professional leadership. We are known for the great care we take with our staff and our clients. We are passionate and determined about delivering the best customer service, preserving insurance industry knowledge, and making a difference by the work that we do.\nWhat We Are Seeking\nWe have assignments available to help our\ninsurance industry\nclients in\nData Analyst positions. Responsibilities include:\nBuild and maintain data warehouse, new reports, and ad hoc reports.\nWork with user groups to identify reporting issues\/enhancements and document business requirements.\nWill serve as a member of a project team and\/or work independently on projects.\nSupport and train internal users as needed.\nCompile and prepare data for customer analysis.\nExperience in C#, Visual Studio, JavaScript, CSS, and current web technologies such as .NET, ASP, JSON, and XML.\nExperience with ANY of the following technologies: SQL Server Reporting Services (SSRS), SSIS Reporting, Power BI, Dynamics CRM, Dynamics GP, Share point, Excel, Power Query, Power Pivot.\nAbility to compile data results and author commentary on industry studies is a plus.\nInsurance or financial services industry experience required.\nTO BECOME A WORK-AT-HOME VINTAGE EXPERT, WE REQUIRE\n25 years of full-time work experience\nExperience working in a data analysis role in the insurance or financial services industry - required\nBenefits Of Becoming a Wahve Vintage Expert\nRetire from the office but not from work.\nEliminate the office stress and the commute.\nChoose the work you would like to do now.\nCustomize your schedule - full or part time.\nContinue to earn an income.\nUtilize your years of insurance industry knowledge.\nBe part of our dynamic yet virtual team environment and connect with other experienced insurance professionals like yourself!\nHow To Get Started\nClick\nAPPLY NOW\nto complete our simple preliminary profile. Be sure to include your preferred contact information as one of our Qualification Specialists will connect with you promptly.\nWE LOOK FORWARD TO MEETING YOU!\nShow more\nShow less",
      "job_skills":"Insurance, Data Analysis, C#, Visual Studio, JavaScript, CSS, .NET, ASP, JSON, XML, SQL Server Reporting Services (SSRS), SSIS Reporting, Power BI, Dynamics CRM, Dynamics GP, SharePoint, Excel, Power Query, Power Pivot",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Senior Data Engineer - $180k-$220k (Snowflake, Coding)",
      "company":"CyberCoders",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-%24180k-%24220k-snowflake-coding-at-cybercoders-3766365260",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Permanently Remote in US\nJob Title:\nSenior Data Engineer - $180k-$220k + Bonus (Snowflake, Coding)\nSalary:\n$180k-$220k Base + Bonus, No Stock, 401k, Benefits\nRequirements:\nExpert w\/ Snowflake & Coding Ability\nBased in beautiful New York City, we are a cutting edge ad-tech org for television-based ads.\nWe are founded and owned by T.V.s largest publishers.\nOur mission is to be bring simplicity & scale to audience based campaigns in television.\nWe're working with over 100 advertisers and anticipating another year of significant growth!\nAs a rapidly growing company\n(founded in 2017 & up 140% year over year)\nwe've recently elevated our C-Suite Team in preparation for our next stage of growth and are building our Technology, Product, and Operations Executive Teams.\nWe have been in business for 7 years and have around 40 employees.\nDue to growth, we are actively hiring a Senior Data Engineer with\nSnowflake experience (ideally certified)\nAbility to write production level code (ideally JavaScript or Python)\nExperience building data pipelines from scratch and\/or working with APIs\nExperience with the following is a big plus!\nFivetran and\/or DBT\nYou will be working with 12 other engineers on the data side + several other technical folks.\nThis role will consist of tasks such as building out data pipelines, data architecture via snowflake, and data modeling.\nIf you have this experience, please apply immediately. We are actively interviewing this week and next for this high profile position.\nTop Reasons to Work with Us\nCompensation: $180k-$220k Base + Bonus, No Stock, 401k, Benefits\nRaid Growth: Founded in 2017 & up 140% year over year\nCulture: Fast paced, mission driven culture\nTechnology: Cutting edge technology\nWhat You Will Be Doing\nBuilding data pipelines from scratch\nData architecture via Snowflake\nData modeling\nTechnical review of everything this group builds.\nMange development velocity, team capacity, and backlogs\nPartner closely with the product team\nTake on key assignments and delegate as needed\nAct as the main technical point of contact for engineering\nTranslate technical requirements to the rest of the engineering team\nWhat You Need for this Position\nMust Have Experience\nSnowflake experience\nAbility to write production level code (ideally JavaScript or Python)\nExperience building data pipelines from scratch and\/or working with APIs\nSome Experience With:\n-\nFivetran and\/or DBT\nWhat's In It for You\n$180k-$220k Base + Bonus, No Stock, 401k, Benefits\n401k\nVacation\/PTO\nMedical\nDental\nVision\nBonus\n401k\nBenefits\nVacation\/PTO\nMedical\nDental\nVision\nBonus\nSo, if you are a Senior Data Engineer - $180k-$220k + Bonus (Snowflake, Coding) with experience, please apply today!\nColorado employees will receive paid sick leave. For additional information about available benefits, please contact Nitu Gulati-Pauly\nEmail Your Resume In Word To\nLooking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:\nNitu.Gulati-Pauly@cybercoders.com\nPlease do NOT change the email subject line in any way. You must keep the JobID: linkedin : MA5-1745335L570 -- in the email subject line for your application to be considered.***\nNitu Gulati-Pauly - VP of Recruiting - CyberCoders\nApplicants must be authorized to work in the U.S.\nCyberCoders is proud to be an Equal Opportunity Employer\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\nYour Right to Work\n\u201a\u00c4\u00ec In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\nCyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.\nShow more\nShow less",
      "job_skills":"Snowflake, JavaScript, Python, Data Pipelines, APIs, Fivetran, DBT, Data Architecture, Data Modeling, Team Management, Product Collaboration, Key Assignments, Technical Point of Contact, Translating Technical Requirements",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Brownsville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3783188341",
      "search_city":"Brownsville",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Brownsvi-DataResearchAn.008\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, Generative AI, Educational tools, OOP languages, Data science, R, English communication skills, Data analytics, AI outputs, Coaching, Git",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Scientist, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Brownsville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-scientist-gt-school-remote-%2460-000-year-usd-at-crossover-3783187379",
      "search_city":"Brownsville",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Scientist Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Brownsvi-DataScientist.009\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, R, OOP (ObjectOriented Programming), Machine Learning, Data Analytics, Data Science, Generative AI, Product Development, Research, Technical Writing, Communication, Stakeholder Management, Project Management, SQL",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Junior Data Scientist",
      "company":"Concero",
      "job_location":"Greater St. Louis",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/junior-data-scientist-at-concero-3771636398",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nOnsite St. Louis, MO\nData Scientist\n- Design and analyze lift experiments to drive product improvements with cross-functional teams.\n- Conduct research and analysis to improve the statistical\/ML model lift using experimental design and causal inference methods\n- Write SQL queries to clean, aggregate, and\/or impute data from multiple tables and\/or across jump servers\n- Manage IT tickets for simultaneous projects and tasks\n- Maintain proper project documentation (Project scope, business requirements, workflow charts, data mapping, etc.)\n- Build cross-functional relationships with SQL developers, business analysts, product marketing, Customer Success Managers (CSM), and other key stakeholders to identify opportunities to improve products, drive product launches, and influence product roadmaps\nQualifications\n- Bachelor's degree in a quantitative discipline (e.g., Statistics, Engineering, Biostatistics, Economics, Computer Science, Mathematics, Physics) and\/or 2+ years of equivalent practical experience\n- knowledge and experience in statistical methodologies, especially probability, hypothesis testing, experimental design, and causal inference\n- Familiarity with machine learning algorithms and A.I. methodologies\n- Understanding of project management principles\n- Basic understanding of A\/B testing\n- Practical experience querying and analyzing large datasets using SQL\n- Proficient in scripting languages like Java, JavaScript, Python, and\/or R\n- Able to work in an innovative and fast-paced environment\n#5737\nShow more\nShow less",
      "job_skills":"Data Analysis, Hypothesis Testing, Experimental Design, AI, Project Management, A\/B Testing, Machine Learning, Causal Inference, SQL, Statistical Methods, Python, Java, JavaScript, R",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788458092",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Dallas-DataResearchAn.034\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, Generative AI, Machine Learning, Algorithms, Data Science, Education Technology, Research, Product Development, Programming, Communication, Data Analysis, Stakeholder Management, Time Management, Project Management",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Quality Analyst (DQ Labs Exp)",
      "company":"Photon",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-quality-analyst-dq-labs-exp-at-photon-3774198193",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Who are we?\nFor the past 20 years, we have powered many Digital Experiences for the Fortune 500. Since 1999, we have grown from a few people to more than 4000 team members across the globe that are engaged in various Digital Modernization.\nBachelor's degree in statistics, mathematics, computer science, information management, or similar.\n10+ years of experience in data analysis.\nProficiency in programming languages, including Structured Query Language (SQL) and JavaScript.\nIn-depth knowledge of statistical methods and tests.\nExtensive experience with statistical packages, such as MS Excel, SAS, and SPSS\nExceptional analytical skills.\nAdvanced problem-solving skills.\nKnowledge of best practices in data analysis.\nExcellent interpersonal and communication skills.\nShow more\nShow less",
      "job_skills":"Statistics, Mathematics, Computer Science, Information Management, Data Analysis, SQL, JavaScript, Statistical Methods, Statistical Tests, Statistical Packages, Advanced ProblemSolving, Data Analysis Best Practices, Interpersonal Skills, Communication Skills",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788457259",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Houston-DataResearchAn.022\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, R, Generative AI, Data science, Research, Product development, Education, Technology, OOP, Data analytics, Coaching, Communication, Project management, Collaboration, Problem solving, Innovation",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788461016",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-FortWort-DataResearchAn.011\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, OOP languages, Generative AI, Natural language processing, Machine learning, Data science, Research, Product development, Project management, Technical writing, Verbal communication, Collaboration, Problemsolving, Critical thinking, Innovation, Adaptability, Time management, Prioritization, Stakeholder management",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Quality Analyst - (10+ years of Exp) - Full Time\/ W2 contract",
      "company":"Photon",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-quality-analyst-10%2B-years-of-exp-full-time-w2-contract-at-photon-3774817020",
      "search_city":"Dallas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Greetings everyone,\nI hope you are staying safe. We are hiring a\nData Quality Analyst - Dallas, TX (Hybrid) - Full Time \/ W2 contract\nto join our Digital Engineering team.\nWho are we?\nFor the past 20 years, we have powered many Digital Experiences for the Fortune 500. Since 1999, we have grown from a few people to more than 4000 team members across the globe that are engaged in various Digital Modernization. For a brief 1 minute video about us, you can check https:\/\/youtu.be\/uJWBWQZEA6o.\nData Quality Analyst - must have 10+ years of experience\nLocation - Dallas, TX (Hybrid) -\nFull Time or W2 contract\nResponsibilities\nPerforming statistical tests on large datasets to determine data quality and integrity.\nEvaluating system performance and design, as well as its effect on data quality.\nCollaborating with database developers to improve data collection and storage processes.\nRunning data queries to identify coding issues and data exceptions, as well as cleaning data.\nGathering data from primary or secondary data sources to identify and interpret trends.\nReporting data analysis findings to management to inform business decisions and prioritize information system needs.\nDocumenting processes and maintaining data records.\nAdhering to best practices in data analysis and collection.\nKeeping abreast of developments and trends in data quality analysis.\n\u201a\u00c4\u00e7\nRequirements\nBachelor's degree in statistics, mathematics, computer science, information management, or similar.\n10+ years of experience in data analysis.\nProficiency in programming languages, including Structured Query Language (SQL) and JavaScript.\nIn-depth knowledge of statistical methods and tests.\nExtensive experience with statistical packages, such as MS Excel, SAS, and SPSS\nExceptional analytical skills.\nAdvanced problem-solving skills.\nKnowledge of best practices in data analysis.\nExcellent interpersonal and communication skills.\nShow more\nShow less",
      "job_skills":"Data Quality Analysis, Statistical Analysis, Data Integrity, Data Collection, Data Cleaning, Data Interpretation, Data Visualization, SQL, JavaScript, MS Excel, SAS, SPSS, Structured Query Language, Statistical Methods, Statistical Packages",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788452885",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-SanAnton-DataResearchAn.018\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, R, OOP, Data science, Generative AI, Machine learning, Natural language processing, Algorithms, Data analysis, Product development, Research, Project management, Communication, Collaboration, Time management, Problem solving",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Brownsville, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788620885",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-Brownsvi-DataResearchAn.009\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, Generative AI, R, OOP, Data Science, Machine Learning, Algorithms, Data Analytics, Agile, Product Development, Coaching, Communication, Problem Solving, Collaboration, Research, Finetuning, Technical Writing, Data Visualization, Education, Technology, AI Prompts, AI Training, SQL, Git, Linux, Unix, Docker, Kubernetes, Scrum, Kanban, Jira, Slack, Confluence",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"Round Rock, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788457154",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-RoundRoc-DataResearchAn.015\nShow more\nShow less",
      "job_skills":"Python, JavaScript, JSON, R, OOP language, Generative AI, AI, Data science, Data analytics, Algorithms, Product development, Research, Technical writing and communication, Proficient in OOP languages, Data science, Data Research",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Sr. Web Analyst",
      "company":"Kendra Scott",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-web-analyst-at-kendra-scott-3749167541",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\nAbout Kendra Scott:\nWe are a fun, talented and driven team dedicated to providing our customers with gorgeous products and a WOW! experience. Family, fashion, and philanthropy are at the core of our company and though we move at a very fast pace, we are committed to maintaining a family-oriented work environment and giving back to our community. A passion for great design, dedication to innovation and a strong social media presence are our building blocks for creating a unique and engaging lifestyle brand across all channels, including retail stores, wholesale accounts and e-commerce. Our headquarters are located in the heart of Austin, Texas, and we embrace the unique vibe and energy of our hometown as an inspiration for our brand and company culture.\nPosition Overview\nWe\u201a\u00c4\u00f4re looking for a Sr. Web Analyst. This role is critical for our efforts to improve our website data collection, Google Analytics accuracy, reporting, and insights generation. Specifically, you will execute our tag management program via Google Tag Manager, define our datalayer needs in collaboration with Product and Development, report on digital trends, provide actionable insights on our digital business, and respond to ad-hoc requests. As a member of the broader eCommerce Analytics team, you will help to drive significant improvements in ecommerce revenue by deeply interrogating metrics and transforming data to insights; you\u201a\u00c4\u00f4ll proactively surface insights from data, advocate for them through elevated storytelling, and prove their value through testing.\nRoles & Responsibilities\nTagging & Datalayer\nExecute day-to-day operation of our new tag management and cookie privacy program\nExecute tagging, data variable collection, etc. via Google Tag Manager\nProvide input to improve and optimize our tag management and cookie privacy program\nPartner with Product, Development, Analytics and others to define our website datalayer and provide instructions to developers for datalayer improvements\nMaintain our Google Analytics tracking, updating dimensions, metrics, reports, etc.\nRegularly audit our datalayer and Google Analytics tracking to ensure accuracy and proactively suggest optimizations\nProvide expertise and hands-on delivery of javascript\/CSS\/HTML and other elements of tagging and data collection\nInsights, Analytics, and Reporting\nCreate and distribute all ecommerce performance reports (daily, monthly, quarterly, yearly, etc.)\nLeverage tools such as Google Analytics, Monetate, ContentSquare and others to proactively identify areas of improvement and surface insights that increase revenue, decrease costs, or improve the user experience\nLeverage Powerpoint and elevated storytelling to evangelize insights and advocate data-driven hypotheses for testing\nRespond to requests from various internal and external stakeholders for performance data and reporting\nPerform other ad hoc analysis and reporting as directed\nProvide and make recommendations for new and innovative tests, solutions for unmet reporting needs, and effective revenue and\/or loyalty-driving strategies\nOther\nOther duties as assigned \u201a\u00c4\u00ec the candidate will be cross trained in web analytics, Voice of Customer, Testing & Personalization, and advanced analytics methods, and will be expected to contribute to the entire team as needed\nProfessional Qualifications\nMinimum\nBachelor\u201a\u00c4\u00f4s degree in Economics, Computer Science, Mathematics, Statistics, Marketing; other subjects will be considered but a strong aptitude for mathematics and analytics must be shown\n2 \u201a\u00c4\u00ec 4 years analytical\/testing\/personalization\/user experience optimization and e-commerce experience with a strong, hands-on background in marketing, ecommerce, or analysis\nHands-on experience with Google Tag Manager, publishing tags, defining data variables, etc.\nHands-on experience using Google Analytics for reporting and insights, but also in defining dimensions, metrics, etc. in Google Analytics\nHands-on experience with Google DataStudio\/Looker DataStudio\nExperience writing datalayer specification instructions for developers\neCommerce and retail or commercial trading experience\nProven ability to leverage data to create value-add insights and storytelling\nPreferred\nMaster\u201a\u00c4\u00f4s degree in Economics, Mathematics, Statistics, or MBA\n2+ years experience and deep knowledge of Google Tag Manager, datalayer specification, Google Analytics or Adobe Analytics\nAbility to code javascript\/CSS\/HTML\neCommerce, retail, or commercial trading experience at luxury\/lifestyle brand\nExperience coding software such as SQL, R\/RStudio, Python; experience working with big data and associated techniques\nExperience with UX design and prototyping preferred\nHands-on experience with A\/B testing and personalization tools, particularly Monetate, but will also consider Optimizely, Maxymiser, Optimize 360, Granify\nPersonal Characteristics\nCustomer Centric.\nLove of the consumer that drives desire to create compelling, memorable, and engaging retail experiences online.\nValue the importance of the customer relationship and the importance of every interaction with the consumer.\nLeadership.\nDelight in sharing success with subordinates and peers.\nA natural collaborator and ability to influence others.\nTalent for mentoring, developing, recruiting, and inspiring teams.\nListen with empathy; be willing to champion ideas and people.\nAnalytical Thinker.\nUtilize data to inform decisions.\nFocus on KPIs that can be tracked, tested, reported, and used to create actionable decisions to ensure performance.\nDesire to raise the voice of our customer through data, analysis, and elevated storytelling.\nOrganized.\nOperate expeditiously, with prioritization of workload, to yield highest return on investment. Eliminate rather than create chaos.\nComfortable working under deadlines, managing multiple priorities, taking initiative, and paying close attention to detail.\nOutstanding Communicator.\nAbility to present to large groups while inspiring and motivating action for implementation of ideas. Comfortable presenting to senior executives.\nCandid, direct and honest.\nAdept at both written and verbal communication.\nDivision\nHome Office\nPosition Type\nFull Time\nZip Code\n78756\nCity\nAustin\nState\nTexas\nPay Class\nSalary Admin\nShow more\nShow less",
      "job_skills":"Google Analytics, Google Tag Manager, Google DataStudio, JavaScript, CSS, HTML, SQL, R\/RStudio, Python, Big data, UX design, A\/B testing, Monetate, Optimizely, Maxymiser, Optimize 360, Granify",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Research Analyst, gt.school (Remote) - $60,000\/year USD",
      "company":"Crossover",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-research-analyst-gt-school-remote-%2460-000-year-usd-at-crossover-3788457146",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Remote",
      "job_summary":"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?\nAre you ready to revolutionize education with the power of cutting-edge technology? We're seeking strategic problem solvers who thrive on developing and implementing innovative solutions and are eager to apply the power of generative AI to supercharge their work. Your consistent high performance and dedication will drive our mission to revolutionize education.\nAt gt.school, we're on a mission to accelerate the pace of learning by 5-10X, harnessing the incredible potential of technology, algorithms, and generative AI. We are creating a platform where students can discover, explore, and learn at an unprecedented rate. You'll play a pivotal role in bringing this vision to life. You'll have the opportunity to build new tools and operational processes, as well as streamline existing workflows for maximum efficiency.\nBut that's not all! At gt.school, we believe in your growth and development. You'll receive regular coaching and training from a team of global tech experts and operations professionals, ensuring your continuous improvement. We value collaboration and provide a supportive environment where you can meet with team members to work together on exciting projects.\nIf you're eager for a role that combines research, strategy, product development, and data science in the ever-evolving realm of education and technology, seize the moment and apply below. Let's embark on this exhilarating journey together!\nWhat You Will Be Doing\nEngineering generative AI prompts in Python\/JavaScript\/JSON\nAnalyze AI outputs and iterate on prompts to reach desired outcomes\nLeverage generative AI and technology to develop new educational tools, iterate on current products, and finetune AI training models\nResearch topics to support the product engineering team\nWhat You Won\u201a\u00c4\u00f4t Be Doing\nCollecting data or performing administrative tasks - we have a junior operations analyst team to do this type of work.\nWorking on unimportant projects - you'll be tasked with projects that are mission-critical\nData Research Analyst Key Responsibilities\nCreate technical functionalities that revolutionize the way education is delivered.\nBasic Requirements\nExcellent written and verbal English communication skills\nProficient in Python, R, JavaScript, or another OOP language\n2+ years of work experience working in a technical field (science, technology, programming, financial services, data science, etc.)\nConsistently able to work 40 hours per week, Monday through Friday, between 6AM and 6PM CST\nMust be a proactive communicator who can effectively manage multiple priorities and stakeholders simultaneously\nAbout Gt.school\nGT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.\nThere is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!\nWorking with Crossover\nThis is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD\/hour, which equates to $60,000 USD\/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com\/help-and-faqs for more details on this topic.\nWhat to expect next:\nYou will receive an email with a link to start your self-paced, online job application.\nOur hiring platform will guide you through a series of online \u201a\u00c4\u00fascreening\u201a\u00c4\u00f9 assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.\nImportant!\nIf you do not receive an email from us:\nFirst, emails may take up to 15 minutes to send, refresh and check again.\nSecond, check your spam and junk folders for an email from Crossover.com, mark as \u201a\u00c4\u00faNot Spam\u201a\u00c4\u00f9 since you will receive other emails as well.\nThird, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.\nIf all else fails, just reset your password by visiting https:\/\/www.crossover.com\/auth\/password-recovery if you already applied using LinkedIn EasyApply.\nCrossover Job Code: LJ-4880-US-StLouis-DataResearchAn.016\nShow more\nShow less",
      "job_skills":"Generative AI, Python, JavaScript, JSON, R, OOP languages, Data science, SQL, Machine learning, Hadoop, Spark, NoSQL, Agile, Scrum, Kanban, Jira, Asana, Trello, Slack, Google Suite, Microsoft Office 365",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Automation Engineer",
      "company":"The Wise Seeker",
      "job_location":"Arnold, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-automation-engineer-at-the-wise-seeker-3776917565",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"As the Data Automation Engineer, you'll be exposed and contribute to the development and application of innovative technologies such as machine learning, artificial intelligence, and advanced data analytics. Our work depends on a Data Engineer joining our team to support our intelligence customer in Springfield, VA or St. Louis, MO.\nWhat you will be working on:\nSupport the Geospatial Services and Solutions business area to provide high-quality, cost-effective solutions to the customer\nDesign and implement automation solutions to enhance data capture, data refinement, and processes. Coding examples include:\nInterfacing with device APIs in order to collect operational metrics\nProviding automated VoIP phone setup\nAdministering and automating data pipelines between different environments\nProduce and deploy code via GitLab projects in collaboration with other team members\nUtilize best practices for source control, testing, and deployment of software changes\nWork in close collaboration with other automation engineers, infrastructure administrators, and data scientists\nDiagnose, isolate, and expediently resolve complex problems pertaining to data structures\nDevelop methods of ensuring data incompatibilities among systems are systematically eliminated\nDevelop and recommend data management policies, standards, practices, and security measures to ensure effective and consistent data management operations\nParticipate in continuous improvement efforts to increase data availability, data quality, and speed of access\nMaintain up-to-date documentation of designs\/configurations, ensuring team members have continuity of recurring tasks\nIn office work requirement > 80%\nTravel requirement 0%\nWhat you will bring to us:\nBachelor's Degree in Computer Science or related technical discipline, or the equivalent combination of education, technical certifications or training, and work experience\n8+ years of related systems engineering experience\nScripting, coding, or software development experience\nComfort with Linux\/Windows command-line\nAutomation mindset\nSystem administration and\/or DevOps environment experience\nActive TS\/SCI clearance and eligibility to obtain a CI poly\nWould be nice if you bring the following:\nPython experience\nShell scripting experience such as Bash or PowerShell\nExperience with Database technologies such as Postgres, SQL Server, Oracle, or MySQL\nExperience writing and working with SQL commands\nVersion control experience with Git\nExperience with Gitlab and Git workflows\nFamiliarity with Agile Scrum methodologies\nTime management skills and the drive to work with limited supervision within a small team\nBonus Skills:\nWeb App development experience such as Flask, Django, React, etc.\nUI\/UX experience\nExperience with Analytics tools such as Tableau\nInfrastructure as Code experience\nExperience in technical operations at DoD\/IC agencies\nCloud experience such as AWS, Azure, GCP, etc.\nShow more\nShow less",
      "job_skills":"Machine Learning, Artificial Intelligence, Data Analytics, Data Engineering, Geospatial Services, Automation Solutions, Data Capture, Data Refinement, Device APIs, VoIP, Data Pipelines, GitLab, Source Control, Software Deployment, Data Structures, Data Management, Data Security, Data Availability, Data Quality, Data Access, Technical Documentation, Computer Science, Systems Engineering, Scripting, Coding, Software Development, Linux, Windows, Automation, System Administration, DevOps, Clearance, Python, Shell Scripting, Bash, PowerShell, Database Technologies, Postgres, SQL Server, Oracle, MySQL, SQL Commands, Version Control, Git, Gitlab, Agile Scrum, Time Management, Flask, Django, React, UI\/UX, Tableau, Infrastructure as Code, DoD\/IC agencies, Cloud, AWS, Azure, GCP",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Software Engineer - Core Data Engineering Platform (Dallas, TX)",
      "company":"Goldman Sachs",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/software-engineer-core-data-engineering-platform-dallas-tx-at-goldman-sachs-3754984618",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nWhat We Do\nAt Goldman Sachs, our Engineers don\u201a\u00c4\u00f4t just make things \u201a\u00c4\u00ec we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.\nEngineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.\nAbout Data Engineering\nData plays a critical role in every facet of the Goldman Sachs business. The Data Engineering group is at the core of that offering, focusing on providing the platform, processes, and governance, for enabling the availability of clean, organized, and impactful data to scale, streamline, and empower our core businesses.\nWithin Data Engineering, we focus on offering a comprehensive data platform, Legend, which we have made available as an open-source product. Legend includes a full data modeling environment, as well as the execution of data access and controls, and a vast set of value-add products which allow our business users to operate more efficiently.\nLeveraging our own Legend offering, our engineers build efficient data solutions that source, curate, and distribute critical data to our businesses, including financial product, pricing, transaction, and client reference data. Our engineers collaborate closely with the business to design and curate business-specific data models, and to transform and distribute data for optimal storage and retrieval.\nWho We Look For\nGoldman Sachs Engineers are innovators and problem-solvers, building solutions in risk management, big data, mobile and more. We look for creative collaborators who evolve, adapt to change and thrive in a fast-paced global environment.\nAs a\nFull-stack Software Engineer\non the Data Engineering team, you will be responsible for helping improve the Legend data platform, our curated data offerings, and how the business uses data. We tackle some of the most complex engineering problems across distributed software development, optimizing data access and delivery, enabling core access controls via well-defined security paradigms, building UIs to enable data visualization, using machine learning to curate data, or engaging with businesses to ensure their data needs are met, and we react quickly to new demands by rapidly evolving our data solutions.\nHow You Will Fulfill York Potential\nDesign & develop modern data management tools to curate our most important data sets, models and processes, while identifying areas for process automation and further efficiencies\nContribute to an open-source technology - https:\/\/github.com\/finos\/legend\nDrive adoption of cloud technology for data processing and warehousing\nEngage with data consumers and producers in order to design appropriate models to suit enable the business\nRelevant Technologies\n: Java, Python, AWS, React\nBasic Qualifications\nA Bachelor or Master degree in a computational field (Computer Science, Applied Mathematics, Engineering, or in a related quantitative discipline)\n2-7+ years of relevant work experience in a team-focused environment\n2-7+ years of experience in distributed system design\n2-7+ years of experience using Java, Python, and\/or React\n2-7+ years of experience or interest in functional programming languages\nStrong object-oriented design and programming skills and experience in OO languages (Java)\nStrong experience with cloud infrastructure (AWS, Azure, or GCP) and infrastructure as code (Terraform, CloudFormation, or ARM templates).\nProven experience applying domain driven design to build complex business applications\nDeep understanding of multidimensionality of data, data curation and data quality, such as traceability, security, performance latency and correctness across supply and demand processes\nIn-depth knowledge of relational and columnar SQL databases, including database design\nExpertise in data warehousing concepts (e.g. star schema, entitlement implementations, SQL v\/s NoSQL modeling, milestoning, indexing, partitioning)\nExperience in REST and\/or GraphQL\nExperience in creating Spark jobs for data transformation and aggregation\nComfort with Agile operating models (practical experience of Scrum \/ Kanban)\nGeneral knowledge of business processes, data flows and the quantitative models that generate or consume data\nExcellent communications skills and the ability to work with subject matter experts to extract critical business concepts\nIndependent thinker, willing to engage, challenge or learn\nAbility to stay commercially focused and to always push for quantifiable commercial impact\nStrong work ethic, a sense of ownership and urgency\nStrong analytical and problem solving skills\nEstablish trusted partnerships with key contacts and users across business and engineering teams\nPreferred Qualifications\nFinancial Services industry experience\nExperience with Pure \/ Legend \/ Alloy\nWorking knowledge of open-source tools such as AWS lambda, Prometheus\nAbout Goldman Sachs\nAt Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.\nWe believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com\/careers.\nWe\u201a\u00c4\u00f4re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https:\/\/www.goldmansachs.com\/careers\/footer\/disability-statement.html\n\u00ac\u00a9 The Goldman Sachs Group, Inc., 2023. All rights reserved.\nGoldman Sachs is an equal employment\/affirmative action employer Female\/Minority\/Disability\/Veteran\/Sexual Orientation\/Gender Identity\nShow more\nShow less",
      "job_skills":"Java, Python, AWS, React, Git, Scrum, Kanban, CloudFormation, ARM templates, Terraform, REST, GraphQL, Spark, SQL, NoSQL, Git, Data modeling, Machine Learning, Legend, Alloy, Pure, Prometheus, Lambda",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Senior Staff Data Engineer",
      "company":"SADA, An Insight company",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-staff-data-engineer-at-sada-an-insight-company-3743771158",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Join SADA as a Senior Staff Data Engineer, Corporate!\nYour Mission\nAs a Senior Staff Data Engineer, Corporate at SADA, you will have the opportunity to work with big data and emerging Google Cloud technologies to drive corporate services. You will have an opportunity to design, develop, and maintain the best Enterprise Data Warehouse solution to fit our corporate needs. You will be interacting with all of our business units and Google Cloud subject matter experts.\nFrom transforming business requirements, solution architecture, data modeling, architecting, ETL, metadata, and business continuity, you will have the opportunity to work collaboratively with architects and other engineers to recommend, prototype, build, and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data problems facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and covering a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring batch or streaming data pipelines, data lakes, and data warehouses.\nYou will be expected to run point on whole projects, end-to-end, and to mentor less experienced Data Engineers. You will be recognized as an expert within the team and will build a reputation with Google and our customers. You will demonstrate repeated delivery of project architectures and critical components that other engineers demur to you for lack of expertise. You will also participate in early-stage opportunity qualification calls, as well as guide client-facing technical discussions for established projects.\nPathway to Success\n#BeOneStepAhead: At SADA, we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage agility. This means that not only do our engineers know that change is inevitable, but they embrace this change to continuously expand their skills, preparing for future customer needs.\nYour success starts by positively impacting the direction of a fast-growing practice with vision and passion. You will be measured quarterly by the breadth, magnitude, and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, how well you collaborate with your peers and the consultative polish you bring to customer interactions.\nAs you continue to execute successfully, we will build a customized development plan together that takes you through the engineering or management growth tracks.\nExpectations\nInternal Facing - You will interact with internal customers and stakeholders regularly, sometimes daily, other times weekly\/bi-weekly. Expectations will be to capture requirements and deliver solutions suitable for corporate divisions.\nOnboarding\/Training - The first several weeks of onboarding are dedicated to learning and will include learning materials\/assignments and compliance training, and meetings with relevant individuals. Details of the timeline are shared closer to the start date.\nJob Requirements\nRequired Credentials:\nGoogle Professional Data Engineer Certified or able to complete within the first 45 days of employment\nRequired Qualifications:\nMastery in the following domain area:\nData warehouse modernization: building complete data warehouse solutions on BigQuery, including technical architectures, star\/snowflake schema designs, query optimization, ETL\/ELT pipelines, and reporting\/analytic tools. Must have expert-level experience working with Google's batch or streaming data processing solutions (such as BigQuery, Dataform, and BI Engine)\nProficiency in the following domain areas:\nBig Data: managing Hadoop clusters (all included services), troubleshooting cluster operation issues, migrating Hadoop workloads, architecting solutions on Hadoop, experience with NoSQL data stores like Cassandra and HBase, building batch\/streaming ETL pipelines with frameworks such as Spark, Spark Streaming, and Apache Beam, and working with messaging systems like Pub\/Sub, Kafka and RabbitMQ.\nData Catalog: Managing Data Catalogs, definitions, and data lineage.\nData Quality: Must have experience with DataForm, or other DQ solutions.\nData migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for minimizing downtime. It may involve conversion between relational and NoSQL data stores, or vice versa\nBackup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale\n4+ years of experience with Data modeling, SQL, ETL, Data Warehousing, and Data Lakes\n4+ years experience in writing production-grade data solutions (relational and NoSQL)in an enterprise-class RDBMS\n2+ years of experience with enterprise-class Business Intelligence tools such as Looker, PowerBI, Tableau, etc.\nMastery in writing software in Python\nExperience writing software in one or more languages, such as Javascript, Java, R, or Go\nExperience with systems monitoring\/alerting, capacity planning, and performance tuning\nHands-on experience building frontend applications with React\nHands-on experience with CI\/CD solutions (Cloud Build \/ Terraform)\nUseful Qualifications:\nExperience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub\/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc.)\nExperience with IoT architectures and building real-time data streaming pipelines\nExperience operationalizing machine learning models on large datasets\nDemonstrated leadership and self-direction -- a willingness to teach others and learn new techniques\nDemonstrated skills in selecting the right statistical tools given a data analysis problem\nAbility to balance and prioritize multiple conflicting requirements with great attention to detail\nExcellent verbal\/written communication & data presentation skills, including the ability to succinctly summarize key findings and effectively communicate with both business and technical teams\nAbout SADA An Insight Company\nValues:\nSADA stands for inclusion, fairness, and doing the right thing. From our very beginning, we've championed a diverse workplace where we support and learn from each other, amplifying the impact we make with our customers. We're proud that our teams are composed of contributors who represent a wide array of backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer. Our five core values are the foundation of everything we do:\nMake Them Rave\nBe Data Driven\nThink One Step Ahead\nDrive Purposeful Impact\nDo The Right Thing\nWork with the Best\n: SADA has been the largest Google Cloud partner in North America since 2016 and, for the sixth year in a row, has been named a Google Global Partner of the Year . This year, SADA was named a Google Cloud Global Partner of the year 2023. SADA has also been awarded Best Place to Work year after year by the Business Intelligence Group and Inc. Magazine, and was recognized as a Niche Player in the 2023 Gartner\u00ac\u00c6 Magic Quadrant\u201a\u00d1\u00a2 for Public Cloud IT Transformation Services.\nBenefits\n: Unlimited PTO, paid parental leave, competitive and attractive compensation, performance-based bonuses, paid holidays, generous medical, dental, vision plans, life, short and long-term disability insurance, 401K\/RRSP with match, as well as Google-certified training programs and a professional development stipend.\nBusiness Performance:\nSADA has been named to the INC 5000 Fastest-Growing Private Companies list for the last 10+ years in a row, garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers list for the past 5 years. The overall culture continues to evolve with engineering at its core:\n3200+ projects completed, 4000+ customers served, 10K+ workloads, and 30M+ users migrated to the cloud.\nTo request reasonable accommodation to participate in the job application or interview process, contact careers@sada.com. SADA complies with federal and state\/provincial disability laws and makes reasonable accommodations for applicants and candidates with disabilities.\nShow more\nShow less",
      "job_skills":"Google Professional Data Engineer Certified, Google Cloud Platform, Google's batch or streaming data processing solutions (BigQuery Dataform BI Engine), Hadoop clusters, Cassandra, HBase, Spark, Spark Streaming, Apache Beam, Pub\/Sub, Kafka, RabbitMQ, Data Catalogs, DataForm, Data migration, Data modeling, SQL, ETL, Data Warehousing, Data Lakes, Looker, PowerBI, Tableau, Python, Javascript, Java, R, Go, React, Cloud Build \/ Terraform, CloudSQL, Spanner, Cloud Storage, Dataflow, Dataproc, Bigtable, Dataprep, Composer, IoT architectures, Machine learning models, Statistics, Data presentation, Verbal communication, Written communication",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Senior Staff Data Engineer",
      "company":"Career Renew",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-staff-data-engineer-at-career-renew-3786585845",
      "search_city":"Dahlonega",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Career Renew is recruiting for one of its clients, a public cloud IT transformation services company, a Senior Staff Data Engineer in Austin, Texas - this is an onsite position.\nAs a Senior Staff Data Engineer, Corporate, you will have the opportunity to work with big data and emerging Google Cloud technologies to drive corporate services. You will have an opportunity to design, develop, and maintain the best Enterprise Data Warehouse solution to fit our corporate needs. You will be interacting with all of our business units and Google Cloud subject matter experts.\nFrom transforming business requirements, solution architecture, data modeling, architecting, ETL, metadata, and business continuity, you will have the opportunity to work collaboratively with architects and other engineers to recommend, prototype, build, and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data problems facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and covering a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring batch or streaming data pipelines, data lakes, and data warehouses.\nYou will be expected to run point on whole projects, end-to-end, and to mentor less experienced Data Engineers. You will be recognized as an expert within the team and will build a reputation with Google and our customers. You will demonstrate repeated delivery of project architectures and critical components that other engineers demur to you for lack of expertise. You will also participate in early-stage opportunity qualification calls, as well as guide client-facing technical discussions for established projects.\nRequirements\nMastery in the following domain area:\nData warehouse modernization: building complete data warehouse solutions on BigQuery, including technical architectures, star\/snowflake schema designs, query optimization, ETL\/ELT pipelines, and reporting\/analytic tools. Must have expert-level experience working with Google's batch or streaming data processing solutions (such as BigQuery, Dataform, and BI Engine)\nProficiency in the following domain areas:\nBig Data: managing Hadoop clusters (all included services), troubleshooting cluster operation issues, migrating Hadoop workloads, architecting solutions on Hadoop, experience with NoSQL data stores like Cassandra and HBase, building batch\/streaming ETL pipelines with frameworks such as Spark, Spark Streaming, and Apache Beam, and working with messaging systems like Pub\/Sub, Kafka and RabbitMQ.\nData Catalog: Managing Data Catalogs, definitions, and data lineage.\nData Quality: Must have experience with DataForm, or other DQ solutions.\nData migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for minimizing downtime. It may involve conversion between relational and NoSQL data stores, or vice versa\nBackup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale\n4+ years of experience with Data modeling, SQL, ETL, Data Warehousing, and Data Lakes\n4+ years experience in writing production-grade data solutions (relational and NoSQL)in an enterprise-class RDBMS\n2+ years of experience with enterprise-class Business Intelligence tools such as Looker, PowerBI, Tableau, etc.\nMastery in writing software in Python\nExperience writing software in one or more languages, such as Javascript, Java, R, or Go\nExperience with systems monitoring\/alerting, capacity planning, and performance tuning\nHands-on experience building frontend applications with React\nHands-on experience with CI\/CD solutions (Cloud Build \/ Terraform)\nExperience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub\/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc.)\nExperience with IoT architectures and building real-time data streaming pipelines\nExperience operationalizing machine learning models on large datasets\nDemonstrated leadership and self-direction -- a willingness to teach others and learn new techniques\nDemonstrated skills in selecting the right statistical tools given a data analysis problem\nAbility to balance and prioritize multiple conflicting requirements with great attention to detail\nExcellent verbal\/written communication & data presentation skills, including the ability to succinctly summarize key findings and effectively communicate with both business and technical teams\nBenefits\nUnlimited PTO, paid parental leave, competitive and attractive compensation, performance-based bonuses, paid holidays, generous medical, dental, vision plans, life, short and long-term disability insurance, 401K\/RRSP with match, as well as Google-certified training programs and a professional development stipend.\nShow more\nShow less",
      "job_skills":"Google Cloud Platform (GCP), BigQuery, Dataform, BI Engine, Hadoop, Cassandra, HBase, Spark, Spark Streaming, Apache Beam, Pub\/Sub, Kafka, RabbitMQ, Data Catalog, DataForm, SQL, ETL, Data Warehousing, Data Lakes, Looker, PowerBI, Tableau, Python, Javascript, Java, R, Go, React, Cloud Build, Terraform, CloudSQL, Spanner, Cloud Storage, Dataflow, Dataproc, Bigtable, Dataprep, Composer",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Warehouse Systems Analyst",
      "company":"The University of Texas at Dallas",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-warehouse-systems-analyst-at-the-university-of-texas-at-dallas-3784873547",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Responsible for design, implementation, and support of the University Data Warehouse applications, ETL processes, web applications, and visualizations. The systems analyst develops reporting and software integration solutions for Oracle-based ERPs, enterprise system data sources, tools automation, web-based reporting archive portal, and MS Windows Services.\nReporting to the Director of Data Warehouse, the systems analyst works with stakeholders to develop, update, and maintain data queries, institutional reports, automated processes, participate in data governance initiatives, and investigate new architectures and technologies in support of the strategic mission of the university.\nMinimum Education And Experience\nBachelor's degree in MIS, CS, Accounting, Business or a directly related field.\nMinimum of eight (8) years of experience in IT, 3+ years experience specifically in data warehouse\/decision support environment acting as either a business analyst or systems analyst or an equivalent combination of relevant education and experience.\nPreferred Education And Experience\nPreferred Education and Experience\nBachelor's degree in computer science or a related Field, 3 \u201a\u00c4\u00ec 5 years of relevant programming experience preferred. Experience with Oracle databases (creating\/maintaining packages, stored procedures, triggers); proficiency in SQL, DDL, MS Office products, VB.Net, PHP, Java, Grails, Angular, Apache, Tomcat, C#; functional knowledge of MS Windows and Linux or Unix servers.\nEssential Duties And Responsibilities\nManage Oracle\/Web applications and scripts dedicated to the maintenance and enhancement of the University Data Warehouse in support of student success, administration, and business operations.\nSupport database architecture, structures and techniques, and is responsible for adapting those to dynamic requirements from a variety of stakeholders.\nDevelop database applications, understand and interpret technical terminology and participate in architecture planning.\nInvestigate, analyze and Interpret data or information for accuracy and completeness so resulting reports may be used to make informed decisions, plans and schedules.\nAdditional Information\nThe ideal candidate will have experience working with stakeholders to build reports and data extracts and web-based applications. Ability to multitask, work effectively in team situations; strong written, oral, listening and interpersonal skills; responds effectively in a timely manner in a variety of situations; demonstrates integrity and ethical behavior in working with confidential information.\nApplicant understands different work styles, conflict resolution techniques and demonstrated ability to deal with employees in a positive manner. Can learn new technologies quickly and apply this new knowledge to further the goals of the department.\nThis role is eligible for a hybrid work schedule, subject to manager approval. A UT Dallas Remote Work Agreement will be required within 14 days upon approval after hire. Remote work arrangements are subject to regular review and re-approval and may be canceled at any time. The Data Warehouse Systems Analyst must be located within the DFW Area.\nWhat We Can Offer\nUT Dallas is an Equal Opportunity Employer. We offer an employee-friendly work environment with a comprehensive benefit package including:\nCompetitive Salary\nTuition Benefits\nInternal Training\nMedical insurance \u201a\u00c4\u00ec including\n100% paid\nemployee medical coverage for full-time employees\nDental Insurance\nVision Insurance\nLong and short-term disability\nRetirement Plan Options\nPaid time off\nPaid Holidays All UT Dallas employees have access to various\nprofessional development\nopportunities\n, including a membership to Academic Impressions, LinkedIn Learning, and UT Dallas Bright Leaders Program.\nVisit\nhttps:\/\/hr.utdallas.edu\/employees\/benefits\/\nfor more information.\nAbout Us\nUT Dallas is a top public research university located in one of the nation's fastest-growing metropolitan regions. Our seven schools offer more than 140 undergraduate and graduate programs, plus professional certificates and fast-track programs. Our student body is 31,000 strong, reflecting students from over 100 countries and a multiplicity of identities and experiences.\nUT Dallas is committed to graduating well-rounded members of the global community whose education has prepared them for rewarding lives and productive careers in a constantly changing world. A diversity of people, ideas, and perspectives is crucial to our vision and mission. UT Dallas is a place where members of the community from all backgrounds are welcomed, treated fairly, and encouraged in their pursuit of excellence. The University has a variety of programs and initiatives to support engagement and success for all members of the campus community. Employee benefits include a range of physical and mental wellness resources. \u201a\u00c4\u00faLilyPad\u201a\u00c4\u00f9 lactation facilities are located throughout the campus. There are several Employee Resource Groups (ERGs) comprised of individuals who share common interests to help build community among UT Dallas faculty and staff (e.g., Universal Access ERG, Military and Veteran ERG, UT Dallas Young Professionals). Rich with visual and performing arts venues, museum districts, professional and semi-professional athletics teams, botanical gardens, accessible trails and so much more, the Dallas-Fort Worth (DFW) metroplex has something for everyone to explore. UT Dallas partners with regional higher education institutions and school districts and with the\nRichardson Innovation Quarter\n(Richardson IQ), a major hub for innovation, entrepreneurship, and educational activities.\nImportant Message\nAll employees serve as a representative of the University and are expected to display respect, civility, professional courtesy, consideration of others and discretion in all interactions with members of the UT Dallas community and the general public.\nThe University of Texas at Dallas is committed to providing an educational, living, and working environment that is welcoming, respectful, and inclusive of all members of the university community. UT Dallas does not discriminate on the basis of race, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, national origin, disability, genetic information, or veteran status in its services, programs, activities, employment, and education, including in admission and enrollment. EOE, including disability\/veterans. The Universityis committed to providing access, equal opportunity, and reasonable accommodationfor individuals with disabilities.To request reasonable accommodation in the employment application and interview process, contact theADA Coordinator.For inquiries regarding nondiscrimination policies, contact theTitle IX Coordinator.\nShow more\nShow less",
      "job_skills":"University Data Warehouse, ETL processes, Web applications, Visualizations, Oraclebased ERPs, Enterprise system data sources, Tools automation, Webbased reporting archive portal, MS Windows Services, SQL, DDL, MS Office products, VB.Net, PHP, Java, Grails, Angular, Apache, Tomcat, C#, MS Windows, Linux, Unix servers, Oracle databases, Stored procedures, Triggers, Data governance initiatives, Architecture planning, Data analysis, Data extracts, Webbased applications, Stakeholder management, Conflict resolution, Teamwork, Communication skills, Ethics, Integrity, Adaptability, Learning agility",
      "Category":"Frontend Development"
  },
  {
      "job_title":"Data Engineer",
      "company":"Walmart",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-at-walmart-3768739077",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"Our organization, i.e., Enterprise Business Services \u201a\u00c4\u00ec Global Governance -Digital Citizenship Tech focuses on managing and delivering world-class products, driving policy compliance, creating partnerships, and developing pipelines and self-service tools. Responsible for Global Privacy Technology Product implementation(s) so that we can earn customers and associate trust.\nThis Principal Software Engineer will help develop the strategy for solution architecture including end state vision of PaaS\/SaaS offering and support architecture initiatives across Digital Citizenship and Global Governance organization. If you are passionate about working in ambiguous spaces, solving complex architectural problems, collaborating across enterprise leaders to drive consensus, influencing horizontally, and are experienced in architecting PaaS\/SaaS offerings, then this role is tailor-made for you!\nWhat you\u201a\u00c4\u00f4ll do:\nProvide deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends, and practices\nVisionaries, collaborating on Walmart\u201a\u00c4\u00f4s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates.\nMentor, coach and strengthen the technical expertise within the team.\nEvangelists, both internally and externally, helping to elevate the Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities.\nProvide guidance and drive engineering excellence covering site reliability, alerts & monitoring, product health and portability.\nWhat you\u201a\u00c4\u00f4ll bring:\nExperience providing technical and architectural guidance and help develop cost optimization strategies by deploying the right architecture and pricing models.\nFull stack development experience with Java, Node, React, Angular and microservices.\nExperience building long term strategy of building integrated packageable platforms (PaaS) scalable to Walmart global needs, complexity, and scale.\nCreate and capture best practices, technical content and new reference architectures (e.g., white papers, code samples, blog posts).\nDevelop areas of depth in technical domains relevant to your interests and your customer's outcomes.\nProvide guidance and drive engineering excellence covering site reliability, alerts & monitoring, product health and portability.\nAbout Walmart Global Tech\nImagine working in an environment where one line of code can make life easier for hundreds of millions of people and put a smile on their face. That\u201a\u00c4\u00f4s what we do at Walmart Global Tech. We\u201a\u00c4\u00f4re a team of 15,000+ software engineers, data scientists and service professionals within Walmart, the world\u201a\u00c4\u00f4s largest retailer, delivering innovations that improve how our customers shop and empower our 2.3 million associates. To others, innovation looks like an app, service, or some code, but Walmart has always been about people. People are why we innovate, and people power our innovations. Being human-led is our true disruption. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.\nFlexible, hybrid work\nWe use a hybrid way of working that is primarily virtual, while remaining near the locations Global Tech calls home. This approach helps us make quicker decisions, remove location barriers across our global team, be more flexible in our personal lives and spend less time commuting. Of course, being together in person is an important part of our culture and shared success. We use our campuses to collaborate and be together in person, as business needs require and for development and networking opportunities.\nBenefits\nBeyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more. Equal Opportunity Employer Walmart, Inc. is an Equal Opportunity Employer \u201a\u00c4\u00ec By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions \u201a\u00c4\u00ec while being inclusive of all people.\nThe above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.\nShow more\nShow less",
      "job_skills":"PaaS, SaaS, Java, Node.js, React, Angular, Microservices, Site reliability, Alerts & monitoring, Product health, Portability, White papers, Code samples, Blog posts",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Sr. Cloud Data Infrastructure Engineer",
      "company":"Intellectt Inc",
      "job_location":"Abbott, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-cloud-data-infrastructure-engineer-at-intellectt-inc-3707549053",
      "search_city":"Waco",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This is Tanmai from Intellect Inc. Please find the job description and reach out to me with an updated copy of your resume. You can send it to tanmai@intellectt.com or call me at +1(907) 802-6640\nRole\n: Sr. Cloud Data Infrastructure Engineer\nLocation\n: Abbott Park, IL - 60064\nDuration\n: 12 Months on W2\nShift Timings:\n8 AM to 5 PM\n100% Onsite role.\nNo option for hybrid or remote.\nJob Summary\nImplements cloud data infrastructure technology stack deployments and evolution for Abbott Enterprise cloudservices.\nFollows a DevSecOps operating model to continuously integrate, deploy and scale our cloud data\ninfrastructure services. Accountable for delivering a comprehensive set of cloud data infrastructure services including requirements definition, design, integration with infrastructure as code approach and handling operations.\nParticipates in proof-of-concept analysis and vendor solution evaluations. Effectively communicates\nand partners with IS cross-functional teams, IT divisional customers and stakeholders in support of cloud\ninitiatives.\nMaintain Cloud data Infrastructure architecture best practices with robust design & automation.\nJob Responsibilities\nServe as a Tech lead for Cloud Data infrastructure services\/platforms managed by Abbott BTS cloud services\nDevSecOps, Agile Delivery and SLC methodologies adjusted for cloud data infrastructure service delivery\nLeverage Site Reliability Engineering (SRE) principles to build highly reliable cloud data infrastructure,\nmanage and operate at scale, solve technical problems, and automate operational tasks\nUse Terraform modular approach to deploy all data infrastructure as code (IaC) based XaaS solutions\nEstablishes build-and-destroy models for cloud data infrastructure technologies\/platforms with blue\/green, canary deployment patterns.\nImplement CI\/CD pipelines for the deployment of cloud data infrastructure stacks for applications.\nDrive cloud data infrastructure service performance health, troubleshooting, operational metrics &capacity management\nManage cloud data protection and restoration including data backups, Site recovery & Replication\nEvolve Infrastructure as Code frameworks for data infra \/ platforms scaling adjustments and optimizations\nOptimize cloud data infra workloads for security, cost, performance, latency, reliability, and availability aspects\nAutomate cloud data infra Day2Ops tasks leveraging fully managed data platforms and orchestration tools\nSupport IT audits and compliance, adhering to applicable Corporate and Divisional Policies and procedures.\nImplement effective standards, methodologies, and processes, driving change proactively asappropriate for continuous improvement.\nOversee overall cloud infrastructure estate operational governance & framework for promotingoperational efficiencies\nMust Have Skills\nExperience with AWS RDS, Azure SQL, PostgreSQL, MongoDB Atlas, Cosmos DB database solutions\nExperience with Managed Kafka Data Streaming, ETL (Informatica, Azure Data Factory) platforms\nExperience with Datawarehouse (RedShift), Analytics (Synapse\/Databricks\/Snowflake) platforms\nExperience with Cloud Storage platforms (Managed Disks Azure Blob \/Files, AWS S3, EBS, EFS)\nExperience with Azure\/AWS native Data Protection & Backup\/Recovery, Site recovery solutions\nExperience with Terraform (IaC), Ansible (Configuration management), Packer (Gold images)\nExperience with Git (GitHub) and CI\/CD Pipelines (Jenkins, CI\/CD Argo, or Azure DevOps)\nExperience with any of the Observability\/Monitoring tools like Data Dog, New Relic, Dynatrace, LogicMonitor\nExperience with ServiceNow (ITSM) Ticketing Support and Process integrations\nEducation And Experience\nA bachelor's Degree is preferred in technology or management of information systems discipline.\nOverall 10 years of IT experience including cloud experience for at least 4 years potentially in a lead SME type of role.\nShow more\nShow less",
      "job_skills":"AWS RDS, Azure SQL, PostgreSQL, MongoDB Atlas, Cosmos DB, Managed Kafka Data Streaming, ETL, Informatica, Azure Data Factory, Datawarehouse, RedShift, Analytics, Synapse, Databricks, Snowflake, Cloud Storage platforms, Managed Disks Azure Blob, Azure Blob \/Files, AWS S3, EBS, EFS, Azure\/AWS native Data Protection, Backup\/Recovery, Site recovery solutions, Terraform (IaC), Ansible, Packer (Gold images), Git (GitHub), CI\/CD Pipelines, Jenkins, CI\/CD Argo, Azure DevOps, Observability\/Monitoring tools, Data Dog, New Relic, Dynatrace, LogicMonitor, ServiceNow (ITSM) Ticketing Support, Process integrations",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Big Data Developer",
      "company":"TekIntegral",
      "job_location":"Maryland Heights, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-developer-at-tekintegral-3665656721",
      "search_city":"Defiance",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Big Data Developer\nKforce has a client in Maryland Heights, MO that is seeking a Mid-Level - Java, Kafka Spark Hadoop Developer with expertise in Big Data and Streaming technologies to join our dynamic team.\nPay Rate: $55\/hr C2C\nLocation:\n13736 Riverport Dr, Maryland Heights, MO 63043\n3 days onsite 2 days remote\nSummary\nIn this role, you will contribute to cutting-edge Big Data and Streaming projects, working with a talented group of professionals in a challenging and rewarding environment. As a Developer, you will be responsible for designing, developing, and maintaining robust and scalable solutions utilizing Java, Scala, Kafka, Hadoop, Spark, Hive, HDFS, HBase, and NoSQL databases. You will work closely with cross-functional teams to implement data processing and analytics solutions that drive actionable insights from large-scale datasets.\nResponsibilities\nDesign, develop, and deploy high-performance, scalable, and fault-tolerant applications using Java and Scala\nDevelop and maintain real-time data processing pipelines using Kafka, Spark Streaming, and other streaming technologies\nImplement data ingestion, storage, and retrieval processes utilizing Hadoop, HDFS, Hive, HBase, and NoSQL databases; Translate them into efficient data processing workflows\nOptimize data processing and analytics algorithms for performance, scalability, and reliability\nTroubleshoot and resolve issues related to data processing, data quality, and performance bottlenecks\nConduct code reviews, ensure code quality, and adhere to best practices in software development\nStay updated with emerging trends and technologies in Big Data, Streaming, and NoSQL domains, and evaluate their applicability to enhance existing systems\nSkills\nBachelor's or Master's degree in Computer Science, Software Engineering, or a related field\nProven experience of 3 to 5 years as a Java\/Scala Developer working on Big Data and Streaming projects\nExperience with version control systems like Git and proficiency in Agile\/Scrum methodologies\nHands-on experience with Hadoop ecosystem components such as HDFS, Hive, and HBase\nIn-depth knowledge of Apache Kafka, including experience with producer\/consumer APIs, partitioning, message delivery semantics, and offset management\nFamiliarity with NoSQL databases like MongoDB, Cassandra, or Redis, and their integration with Big Data frameworks\nUnderstanding of distributed computing principles, data partitioning, and fault tolerance\nStrong programming skills in Java and\/or Scala, with a solid understanding of object-oriented and functional programming concepts\nStrong problem-solving skills and the ability to optimize algorithms and data processing workflows\nProficiency in Apache Spark for batch and stream processing, including Spark Core, Spark Streaming, and Spark SQL\nExcellent teamwork and communication skills, with the ability to collaborate effectively with cross-functional teams\nShow more\nShow less",
      "job_skills":"Java, Scala, Kafka, Hadoop, Spark, Hive, HDFS, HBase, NoSQL databases, Git, Agile, Scrum, Hadoop ecosystem components, Apache Kafka, MongoDB, Cassandra, Redis, Distributed computing principles, Objectoriented programming, Functional programming, Spark Core, Spark Streaming, Spark SQL",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Data Engineer (Associate)",
      "company":"National Geospatial-Intelligence Agency",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-associate-at-national-geospatial-intelligence-agency-3790053720",
      "search_city":"Ferguson",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Cover Letter\nApplicants are not required to submit a cover letter for employment consideration with the National Geospatial-Intelligence Agency. However, a cover letter is recommended. Applicants will have the option to attach a cover letter in the Qualifications - Attachments step of the online application.\nPay Band, Salary Range - Ext\n2023 DC Salary Chart Below:\nBand 03 $78,592 - $145,617\n2023 St. Louis Salary Chart Below:\nBand 03 $70,649 - $130,900\nPermanent Change in Station\nPERMANENT CHANGE IN STATION: PCS expenses may be authorized.\nNGA Marketing Message\nThe National Geospatial-Intelligence Agency (NGA), the World Leader in Geospatial Intelligence. Imagine being able to identify anything on, above, or beneath the Earth's surface and display that information visually to provide a meaningful foundation for decision-making to ensure the safety of the world. That's the job of the National Geospatial-Intelligence Agency.\nWe analyze imagery and data from many sources and incorporate it into visual displays of essential information for use in national defense, homeland security, and safety of navigation.\nCentral to the success of our mission are the extraordinary talents and skills of our teams of analysts and other professionals. We need the best minds to provide the information edge, continuing NGA's role as the premier provider of Geospatial Intelligence worldwide.\nKnow the World, Show the Way ... from Seabed to Space\nAssignment Description\nASSIGNMENT DESCRIPTION: Data Engineers develop, construct, test, and maintain architectures such as databases and large-scale data processing systems. They create pipelines of common architecture and infrastructure to optimize data for consumption through the design and construction of massive reservoirs for big data. They solve problems associated with database access and integration and unstructured data sets to provide clean, usable data for customers and IT counterparts. They cross collaborate with teams to ensure that their information and network security procedures align with Agency data policies, governance, standards, and requirements. Data engineers employ CI\/CD solutions to deploy machine learning\/AI models. These engineers serve as integrators between data architects, data scientists, data stewards, and other data consumers. They apply knowledge of cloud architecture, ETL (extract, transform, load) methods, scripting tools, programming languages, standards, and software packages (e.g., Nifi, Kakfa, and Informatica) to build the data pipelines that enable faster, better, data-informed decision-making within the Agency.\nPromotion Opportunity\nPROMOTION OPPORTUNITY: Promotion opportunities allow applicants at all band levels to be considered. Qualifications for NGA positions do not include specific time-in-band requirements. NGA will emphasize quality of experience, rather than duration, and assess how the quality of the experience demonstrates possession of the knowledge, skills, abilities, and competencies necessary for successful job performance in the NGA occupational structure\nDuties:\n1. Utilize a variety of languages and tools (e.g., scripting languages) to build data pipelines to pull together information from different source systems.\n2. Collaborate with data architects, modelers, and IT team members on project goals; ensure systems meet Agency requirements and industry practices.\n3. Design, construct, install, test, and maintain highly scalable data management systems.\n4. Develop data set processes for data discovery, modeling, mining, and production.\nQualifications Mandatory\nMANDATORY QUALIFICATION CRITERIA: For this particular job, applicants must meet all competencies reflected under the Mandatory Qualification Criteria to include education (if required). Online resumes must demonstrate qualification by providing specific examples and associated results, in response to the announcement\u201a\u00c4\u00f4s mandatory criteria specified in this vacancy announcement:\n1. Demonstrated experience working with data storage, access and exchange technologies (e.g. S3, FTP WFS, FeatureServer, Elasticsearch, SDK, etc.).\n2. Demonstrated proficiency in applied programming and\/or data manipulation with any programing language such as Python, R or Java.\n3. Demonstrated experience utilizing standards and best practices for data interfaces such as Extract-Transform-Load (ETL) and application programming interfaces (API).\nEDUCATION REQUIREMENT: A. Education: Bachelor's degree from an accredited college or university in Computer Science, Data Science, Engineering, Information Science, Information Systems Management, Mathematics, Operations Research, Physical Sciences, Statistics, Technology Management, or a degree that provided a minimum of 24 semester hours in one or more of the fields identified above and required the development or adaptation of applications, systems, or networks. -OR- B. Combination of Education and Experience: A minimum of 24 semester (36 quarter) hours of coursework in any area listed in option A, plus experience in developing, constructing, testing and maintaining architectures and\/or related technologies, or in a related field that demonstrates the ability to successfully perform the duties associated with this work. As a rule, every 30 semester (45 quarter) hours of coursework is equivalent to one year of experience. Candidates should show that their combination of education and experience totals 4 years. -OR- C. Experience: A minimum of 4 years of experience in developing, constructing, testing and maintaining architectures and\/or related technologies, or in a related field that demonstrates the ability to successfully perform the duties associated with this work. -AND- IT-related experience demonstrating each of the four competencies: Attention to Detail, Customer Service, Oral Communication, and Problem Solving.\nQualifications Desirable\nDESIRABLE QUALIFICATION CRITERIA: In addition to the mandatory qualifications, experience in the following is desired:\n1. Demonstrated experience working with one or more database management systems, e.g. relational (Oracle, MySQL, Postgresql, etc.), noSQL (MongoDB, Accumulo, etc.), graph (Allegrograph, JanusGraphy, Neo4J, etc.).\n2. Experience with simplification and optimization of data automation workflows; streamlining of extract-transform-load (ETL) operations.\n3. Experience with cloud services such as Amazon Web Services (AWS).\n4. Demonstrated experience with coding and scripting languages such as Python, JSON, BASH, and\/or PowerShell.\n5. Demonstrated experience with data modeling and\/or schema development.\nSpecial Info External\nAs a condition of employment at NGA, persons being considered for employment must meet NGA fitness for employment standards.\n- U.S. Citizenship Required\n- Security Clearance (Top Secret\/Sensitive Compartmented Information)\n- Polygraph Test Required\n- Position Subject to Drug Testing\n- Two Year Probationary Period\n- Direct Deposit Required\nApplicant Evaluation Process\nAPPLICANT EVALUATION PROCESS: Applicants will be evaluated for this job opportunity in three stages:\n1) All applicants will be evaluated using the Mandatory Qualification Criteria,\n2) Qualified applicants will then be evaluated by an expert or panel of experts using a combination of qualification criteria to determine the best-qualified candidates,\n3) Best-qualified applicants may then be further evaluated through an interview process.\nMilitary retiree applicants, if selected, may be impacted by the 180-day appointment restrictions of DODI 1402.01. HD personnel will provide additional information if applicable.\nAll candidates will be considered without regard to race, color, religion, sex, national origin, age, marital status, disability, or sexual orientation.\nNGA provides reasonable accommodations to applicants with disabilities. Applications will only be accepted online. If you need a reasonable accommodation for any part of the application and hiring process, please notify us at recruitment@nga.mil. The decision on granting reasonable accommodation will be on a case-by-case basis.\nDisabled applicants are encouraged to apply directly to external job announcements in addition to the Resume Repository. NGA reserves the right to direct hire Disabled Veterans with 30%+ Comp in alignment with the NGA Hiring Strategy. By selecting this option on the application form and applying to the NGA Resume Repository, you may be considered for future direct hire against critical mission vacancies. Participation does not guarantee employment.\nDCIPS Statement\nNGA utilizes all processes and procedures of the Defense Civilian Intelligence Personnel System (DCIPS). Non-executive NGA employees are assigned to five distinct pay bands based on the type and scope of work performed. The employee's base salary is established within their assigned pay band based on their unique qualifications. A performance pay process is conducted each year to determine a potential base pay salary increase and\/or bonus. An employee's annual performance evaluation is a key factor in the performance pay process. Employees on term or temporary appointments are not eligible to apply for internal assignment opportunity notices.\nBenefits\nPay is only part of the compensation you will earn working for the Federal Government. We offer a broad array of benefits programs and family friendly flexibilities to meet the needs of you and your family.\nFor more information on the array of benefits programs, please visit https:\/\/www.nga.mil\/careers\/Benefits_&_Pay.html.\nShow more\nShow less",
      "job_skills":"Databases, ETL (extract transform load), Jave, Python, R, SQL, S3, Snowflake, NoSQL, MongoDB, Accumulo, AWS, JSON, Oracle, MySQL, Postgresql, Neo4J, JanusGraphy, Allegrograph, Bash, PowerShell, Machine learning, Geospatial intelligence, Data pipelines, Data architecture, Data modeling, Data processing, Data integration, Data governance, Data analytics, Cloud computing, Scripting languages, Data visualization, Data security, Data engineering, Data scientists, Data stewards",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Data Engineer",
      "company":"National Geospatial-Intelligence Agency",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-at-national-geospatial-intelligence-agency-3790048895",
      "search_city":"Saint Louis",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Cover Letter\nApplicants are not required to submit a cover letter for employment consideration with the National Geospatial-Intelligence Agency. However, a cover letter is recommended. Applicants will have the option to attach a cover letter in the Qualifications - Attachments step of the online application.\nPay Band, Salary Range - Ext\n2023 Northern VA Salary Chart Below:\nBand 04 $112,015 - $172,075\n2023 St. Louis\/Arnold Salary Chart Below:\nBand 04 $100,694 - $154,685\n2023 Colorado Springs Salary Chart Below:\nBand 04 $100,703 - $154,698\nPermanent Change in Station\nPERMANENT CHANGE IN STATION: PCS expenses may be authorized.\nNGA Marketing Message\nThe National Geospatial-Intelligence Agency (NGA), the World Leader in Geospatial Intelligence. Imagine being able to identify anything on, above, or beneath the Earth's surface and display that information visually to provide a meaningful foundation for decision-making to ensure the safety of the world. That's the job of the National Geospatial-Intelligence Agency.\nWe analyze imagery and data from many sources and incorporate it into visual displays of essential information for use in national defense, homeland security, and safety of navigation.\nCentral to the success of our mission are the extraordinary talents and skills of our teams of analysts and other professionals. We need the best minds to provide the information edge, continuing NGA's role as the premier provider of Geospatial Intelligence worldwide.\nKnow the World, Show the Way ... from Seabed to Space\nAssignment Description\nASSIGNMENT DESCRIPTION: Data Engineers develop, construct, test, and maintain architectures such as databases and large-scale data processing systems. They create pipelines of common architecture and infrastructure to optimize data for consumption through the design and construction of massive reservoirs for big data. They solve problems associated with database access and integration and unstructured data sets to provide clean, usable data for customers and IT counterparts. They cross collaborate with teams to ensure that their information and network security procedures align with Agency data policies, governance, standards, and requirements. Data engineers employ CI\/CD solutions to deploy machine learning\/AI models. These engineers serve as integrators between data architects, data scientists, data stewards, and other data consumers. They apply knowledge of cloud architecture, ETL (extract, transform, load) methods, scripting tools, programming languages, standards, and software packages (e.g., Nifi, Kakfa, and Informatica) to build the data pipelines that enable faster, better, data-informed decision-making within the Agency.\nQualifications Mandatory\nMANDATORY QUALIFICATION CRITERIA: For this particular job, applicants must meet all competencies reflected under the Mandatory Qualification Criteria to include education (if required). Online resumes must demonstrate qualification by providing specific examples and associated results, in response to the announcement\u201a\u00c4\u00f4s mandatory criteria specified in this vacancy announcement:\n1. Demonstrated proficiency in applied programming and\/or manipulation of data with any programing language such as Python, R, or Java.\n2. Demonstrated experience utilizing and promoting standards and best practices for data interfaces such as extract-transform-load (ETL) and application programming interfaces (API).\n3. Demonstrated experience consulting solutions for data storage, access and exchange technologies (e.g. S3, FTP WFS, FeatureServer, Elasticsearch, SDK or similar).\n4. Verified skill providing substantive advice on complex, sensitive, and\/or strategic project or program issues, applying advanced knowledge of the interdependencies of programs and groups and their implications for solutions that support the mission.\n5. Demonstrated a sophisticated understanding and skill in applying broad or in-depth expertise in highly complex and ambiguous situations; is an acknowledged authority, advisor, or key resource.\n6. Experience identifying and translating customer needs to create data products that satisfy customer requirements.\nEDUCATION REQUIREMENT: A. Education: Bachelor's degree from an accredited college or university in Computer Science, Data Science, Engineering, Information Science, Information Systems Management, Mathematics, Operations Research, Physical Sciences, Statistics, Technology Management, or a degree that provided a minimum of 24 semester hours in one or more of the fields identified above and required the development or adaptation of applications, systems, or networks. -OR- B. Combination of Education and Experience: A minimum of 24 semester (36 quarter) hours of coursework in any area listed in option A, plus experience in developing, constructing, testing and maintaining architectures and\/or related technologies, or in a related field that demonstrates the ability to successfully perform the duties associated with this work. As a rule, every 30 semester (45 quarter) hours of coursework is equivalent to one year of experience. Candidates should show that their combination of education and experience totals 4 years. -OR- C. Experience: A minimum of 4 years of experience in developing, constructing, testing and maintaining architectures and\/or related technologies, or in a related field that demonstrates the ability to successfully perform the duties associated with this work. -AND- IT-related experience demonstrating each of the four competencies: Attention to Detail, Customer Service, Oral Communication, and Problem Solving.\nQualifications Desirable\nDESIRABLE QUALIFICATION CRITERIA: In addition to the mandatory qualifications, experience in the following is desired:\n1. Certification in cloud native services such as Amazon Web Services (AWS), containers, Kubernetes, DevSecOps pipeline tooling, and\/or microservices architecture.\n2. Demonstrated expert experience with coding and scripting languages such as Python, JSON, BASH, and\/or PowerShell.\n3. Demonstrate expert experience implementing, configuring, or designing databases with one or more current database technologies. e.g., relational (Oracle, MySQL, Postgresql, etc.), NoSQL (MongoDB, Accumulo, Elastic, etc.), graph (Allegrograph, JanusGraphy).\n4. Demonstrated experience with infrastructure as code technology such as terraform, cloud formation, ansible, or similar.\nSpecial Info External\nAs a condition of employment at NGA, persons being considered for employment must meet NGA fitness for employment standards.\n- U.S. Citizenship Required\n- Security Clearance (Top Secret\/Sensitive Compartmented Information)\n- Polygraph Test Required\n- Position Subject to Drug Testing\n- Two Year Probationary Period\n- Direct Deposit Required\nApplicant Evaluation Process\nAPPLICANT EVALUATION PROCESS: Applicants will be evaluated for this job opportunity in three stages:\n1) All applicants will be evaluated using the Mandatory Qualification Criteria,\n2) Qualified applicants will then be evaluated by an expert or panel of experts using a combination of qualification criteria to determine the best-qualified candidates,\n3) Best-qualified applicants may then be further evaluated through an interview process.\nMilitary retiree applicants, if selected, may be impacted by the 180-day appointment restrictions of DODI 1402.01. HD personnel will provide additional information if applicable.\nAll candidates will be considered without regard to race, color, religion, sex, national origin, age, marital status, disability, or sexual orientation.\nNGA provides reasonable accommodations to applicants with disabilities. Applications will only be accepted online. If you need a reasonable accommodation for any part of the application and hiring process, please notify us at recruitment@nga.mil. The decision on granting reasonable accommodation will be on a case-by-case basis.\nDisabled applicants are encouraged to apply directly to external job announcements in addition to the Resume Repository. NGA reserves the right to direct hire Disabled Veterans with 30%+ Comp in alignment with the NGA Hiring Strategy. By selecting this option on the application form and applying to the NGA Resume Repository, you may be considered for future direct hire against critical mission vacancies. Participation does not guarantee employment.\nDCIPS Statement\nNGA utilizes all processes and procedures of the Defense Civilian Intelligence Personnel System (DCIPS). Non-executive NGA employees are assigned to five distinct pay bands based on the type and scope of work performed. The employee's base salary is established within their assigned pay band based on their unique qualifications. A performance pay process is conducted each year to determine a potential base pay salary increase and\/or bonus. An employee's annual performance evaluation is a key factor in the performance pay process. Employees on term or temporary appointments are not eligible to apply for internal assignment opportunity notices.\nBenefits\nPay is only part of the compensation you will earn working for the Federal Government. We offer a broad array of benefits programs and family friendly flexibilities to meet the needs of you and your family.\nFor more information on the array of benefits programs, please visit https:\/\/www.nga.mil\/careers\/Benefits_&_Pay.html.\nShow more\nShow less",
      "job_skills":"Python, R, Java, ETL, API, S3, FTP, WFS, FeatureServer, Elasticsearch, SDK, Data storage, Data access, Data exchange technologies, Amazon Web Services (AWS), Containers, Kubernetes, DevSecOps, Microservices architecture, JSON, BASH, PowerShell, Oracle, MySQL, Postgresql, MongoDB, Accumulo, Elastic, Allegrograph, JanusGraphy, Terraform, Cloud formation, Ansible",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Big Data Developer",
      "company":"TekIntegral",
      "job_location":"Maryland Heights, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-developer-at-tekintegral-3665656721",
      "search_city":"Cahokia",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Big Data Developer\nKforce has a client in Maryland Heights, MO that is seeking a Mid-Level - Java, Kafka Spark Hadoop Developer with expertise in Big Data and Streaming technologies to join our dynamic team.\nPay Rate: $55\/hr C2C\nLocation:\n13736 Riverport Dr, Maryland Heights, MO 63043\n3 days onsite 2 days remote\nSummary\nIn this role, you will contribute to cutting-edge Big Data and Streaming projects, working with a talented group of professionals in a challenging and rewarding environment. As a Developer, you will be responsible for designing, developing, and maintaining robust and scalable solutions utilizing Java, Scala, Kafka, Hadoop, Spark, Hive, HDFS, HBase, and NoSQL databases. You will work closely with cross-functional teams to implement data processing and analytics solutions that drive actionable insights from large-scale datasets.\nResponsibilities\nDesign, develop, and deploy high-performance, scalable, and fault-tolerant applications using Java and Scala\nDevelop and maintain real-time data processing pipelines using Kafka, Spark Streaming, and other streaming technologies\nImplement data ingestion, storage, and retrieval processes utilizing Hadoop, HDFS, Hive, HBase, and NoSQL databases; Translate them into efficient data processing workflows\nOptimize data processing and analytics algorithms for performance, scalability, and reliability\nTroubleshoot and resolve issues related to data processing, data quality, and performance bottlenecks\nConduct code reviews, ensure code quality, and adhere to best practices in software development\nStay updated with emerging trends and technologies in Big Data, Streaming, and NoSQL domains, and evaluate their applicability to enhance existing systems\nSkills\nBachelor's or Master's degree in Computer Science, Software Engineering, or a related field\nProven experience of 3 to 5 years as a Java\/Scala Developer working on Big Data and Streaming projects\nExperience with version control systems like Git and proficiency in Agile\/Scrum methodologies\nHands-on experience with Hadoop ecosystem components such as HDFS, Hive, and HBase\nIn-depth knowledge of Apache Kafka, including experience with producer\/consumer APIs, partitioning, message delivery semantics, and offset management\nFamiliarity with NoSQL databases like MongoDB, Cassandra, or Redis, and their integration with Big Data frameworks\nUnderstanding of distributed computing principles, data partitioning, and fault tolerance\nStrong programming skills in Java and\/or Scala, with a solid understanding of object-oriented and functional programming concepts\nStrong problem-solving skills and the ability to optimize algorithms and data processing workflows\nProficiency in Apache Spark for batch and stream processing, including Spark Core, Spark Streaming, and Spark SQL\nExcellent teamwork and communication skills, with the ability to collaborate effectively with cross-functional teams\nShow more\nShow less",
      "job_skills":"Java, Scala, Kafka, Hadoop, Spark, Spark Streaming, Hive, HDFS, HBase, NoSQL, MongoDB, Cassandra, Redis, Git, Agile, Scrum, Objectoriented programming, Functional programming, Distributed computing, Data partitioning, Fault tolerance, Data processing, Data analytics, Teamwork, Communication",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-capital-one-3774775828",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Plano 1 (31061), United States of America, Plano, TexasLead Data Engineer\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, i inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Lead Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nOn this team, we are building a suite of products to help our dealers connect with potential car buyers! This team is focusing on building the data infrastructure (right from ingestion to consumption) for all of our products from ground up. We build intelligence for scaling to more dealers and build personalized customer experience.\nWhat You\u201a\u00c4\u00f4ll Do:\nCollaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\nWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems\nUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake\nShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community\nCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\nPerform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 6 years of experience in application development (Internship experience does not apply)\nAt least 2 years of experience in big data technologies\nAt least 1 year experience with cloud computing (AWS, Microsoft Azure, Google Cloud)\nPreferred Qualifications:\n7+ years of experience in application development including Python, SQL, Scala, or Java\n4+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n4+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)\n4+ year experience working on real-time data and streaming applications\n4+ years of experience with NoSQL implementation (Mongo, Cassandra)\n4+ years of data warehousing experience (Redshift or Snowflake)\n4+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Agile engineering practices, Hadoop, Hive, Java, Scala, Python, Unix\/Linux, SQL, NoSQL, MapReduce, EMR, Kafka, Spark, Gurobi, Redshift, Snowflake, Machine learning, Distributed microservices, Open Source RDBMS, MySQL, MongoDB, Cassandra, Realtime data, Streaming applications, Data warehousing, Cloud computing, AWS, Microsoft Azure, Google Cloud",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Senior Data Engineer (Python)",
      "company":"Capital One",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-python-at-capital-one-3783102110",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Center 1 (19052), United States of America, McLean, VirginiaSenior Data Engineer (Python)\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking\nData Engineers\nwho are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you\u201a\u00c4\u00f4ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\nWhat You\u201a\u00c4\u00f4ll Do:\nCollaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\nWork with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems\nUtilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake\nShare your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community\nCollaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\nPerform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance\nBasic Qualifications:\nBachelor\u201a\u00c4\u00f4s Degree\nAt least 4 years of experience in application development (Internship experience does not apply)\nAt least 1 year of experience in big data technologies\nPreferred Qualifications:\n5+ years of experience in application development including Python, SQL, Scala, or Java\n2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)\n3+ years experience with Distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)\n2+ year experience working on real-time data and streaming applications\n2+ years of experience with NoSQL implementation (Mongo, Cassandra)\n2+ years of data warehousing experience (Redshift or Snowflake)\n3+ years of experience with UNIX\/Linux including basic commands and shell scripting\n2+ years of experience with Agile engineering practices\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\nThe minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\nSan Francisco, California (Hybrid On-Site): $171,500 - $195,800 for Senior Data Engineer\nCandidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u201a\u00c4\u00f4s offer letter.\nThis role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and\/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\nThis role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u201a\u00c4\u00f4s Fair Chance Act; Philadelphia\u201a\u00c4\u00f4s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).\nShow more\nShow less",
      "job_skills":"Data Engineering, Python, Java, Scala, Open Source RDBMS, NoSQL databases, Redshift, Snowflake, Agile development, Unit testing, Cloud Computing, AWS, Microsoft Azure, Google Cloud, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL, UNIX\/Linux, Realtime data, Streaming applications, Data warehousing, MongoDB, Cassandra",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Sr. Data Analytics Engineer",
      "company":"JoCo",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analytics-engineer-at-joco-3776668230",
      "search_city":"Vineland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"What is the position?\nThe Sr. Data Analytics Engineer will be responsible for working with data architects, software developers, and analysts to optimize data architecture and flow.\nWhat will you do?\nAs a Sr. Data Analytics Engineer, you will:\nConceptualize and analyze data pipelines and data architectures, ensuring business requirements are met and identifying acquisition opportunities.\nIncrease efficiency and productivity through the automation of data preparation and integration tasks.\nSupport integrations utilizing various programming languages and tools.\nPrepare data for predictive and prescriptive modeling.\nSuggest methods for continuous data improvement.\nEstablish procedures for data mining, modeling, and production.\nAdvocate the organization's analytics and data capabilities to leaders to attain their business objectives.\nUphold data compliance initiatives to guarantee responsible use of provisioned data by users.\nWhat are the requirements?\nBachelor's degree in information systems, computer science, or related field\n5+ years of experience in data management (data modeling, integration, optimization, etc.)\n3+ years of experience working with stakeholders\/teams to support data analytics and management\nA background working with Oil & Gas equipment data is preferred\nExperience with analytics tools using Python, Java, C++, Scala\nExperience with programming languages such as SQL, PL\/SQL, etc.\nKnowledge of NoSQL\/Hadoop-oriented databases such as Cassandra, MongoDB, etc.\nExperience using SQL on Hadooop tools\nExperience using open-source, commercial message queing technologies such as Kafka, Azure, JMS, Amazon Simple Queuing Service, Service Bus, etc.\nExperience using stream data technologies such as Amazon Kinesis, Apache Nifi, Apache Kafka Streams, Apache Beam, etc.\nKnowledge of technologies such as Impala, HIVE, Presto, etc. (open source perspective) and Dremio, Informatica, HDF, Talend, etc. (commercial vendor perspective)\nKnowledge of agile methodologies\nFamiliar with data analytics & business intelligence software tools such as Tableau, PowerBi, Qlik, etc.\nFamiliar with troubleshooting, generating solutions, and providing solutions to those with minimal technical knowledge\nAbility to work across many deployment environments and operating systems\nAbility to optimize data pipelines\/ integrated datasets\nAbility to integrate IT output into business processes\nVerbal and written communication skills, attention to detail, and interpersonal skills\nWillingness to travel (~5%)\nYou would be really happy working here if:\nYou can strategize, understanding the goals of the company and creating effective plans to achieve those goals.\nYou are left-brained and understand that the devil\u201a\u00c4\u00f4s in the details, proactively seeking them out and understanding how they contribute to the whole of a project.\nShow more\nShow less",
      "job_skills":"Data Analytics, Data Architecture, Data Pipelines, Automation, Data Integration, Python, Java, C++, Scala, SQL, PL\/SQL, NoSQL, Hadoop, Cassandra, MongoDB, Kafka, Azure, JMS, Amazon Simple Queuing Service, Service Bus, Amazon Kinesis, Apache Nifi, Apache Kafka Streams, Apache Beam, Impala, HIVE, Presto, Dremio, Informatica, HDF, Talend, Agile Methodologies, Tableau, PowerBi, Qlik, Troubleshooting, Data Pipelines Optimization, Data Integration, IT Integration, Verbal Communication, Written Communication, Attention to Detail, Interpersonal Skills, Travel (5%), Strategizing, Planning",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Lead Data Engineer",
      "company":"Jobs for Humanity",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-at-jobs-for-humanity-3769292786",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Description\nJobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.\nCompany Name: Capital One\nJob Description\nJob Title: Lead Data Engineer Location: Plano, Texas, United States of America Are you passionate about technology and problem-solving? Do you enjoy working in a fast-paced and collaborative environment? At Capital One, we are a diverse group of individuals who love to innovate and make a positive impact on our customers' lives. We are looking for Data Engineers who are excited about combining data with emerging technologies. As a Lead Data Engineer, you will be at the forefront of driving transformation within Capital One. What You'll Do: - Collaborate with agile teams to design, develop, test, implement, and support technical solutions using full-stack development tools and technologies. - Work with a team of experienced developers in machine learning, distributed microservices, and full stack systems. - Utilize programming languages like Java, Scala, Python, and open source databases to build data infrastructure. - Stay updated with the latest tech trends, experiment with new technologies, and participate in technology communities. - Collaborate with digital product managers to deliver cloud-based solutions that empower millions of Americans financially. - Conduct unit tests and code reviews to ensure high-quality, performant code. Basic Qualifications: - Bachelor's Degree. - At least 6 years of experience in application development. - At least 2 years of experience in big data technologies. - At least 1 year of experience with cloud computing (AWS, Microsoft Azure, Google Cloud). Preferred Qualifications: - 7+ years of experience in application development including Python, SQL, Scala, or Java. - 4+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud). - 4+ years of experience with distributed data\/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL). - 4+ years of experience working on real-time data and streaming applications. - 4+ years of experience with NoSQL implementation (MongoDB, Cassandra). - 4+ years of data warehousing experience (Redshift or Snowflake). - 4+ years of experience with UNIX\/Linux. - 2+ years of experience with Agile engineering practices. At Capital One, we offer comprehensive and competitive benefits that support your well-being. Visit our website to learn more about our benefits. Eligibility varies based on employment status. Note: Capital One does not sponsor employment authorization for this position. We are an equal opportunity employer committed to diversity and inclusion in the workplace. We encourage all qualified applicants to apply, regardless of their gender, race, age, religion, disability, sexual orientation, or any other protected status. If you need accommodation during the application process, please contact Capital One Recruiting. Any information shared will be kept confidential and used only for providing necessary accommodations. For technical support or questions about our recruiting process, please email Careers@capitalone.com. Please note that Capital One Financial is comprised of different entities. Positions posted in specific countries are for those respective entities. --- Response: Subject: Lead Data Engineer Application Dear Hiring Team, I am writing to express my interest in the position of Lead Data Engineer at Capital One. I am passionate about technology and problem-solving, and I believe my skills and experience make me a strong fit for this role. Please find my application details below: - Name: [Your Name] - Contact Information: [Phone Number, Email Address] - Location: [City, State, Country] - Availability: [Full-time, Part-time] - Preferred Salary: [Salary Expectations] [Include a brief introduction about yourself, highlighting your relevant experience and skills.] I am excited about the opportunity to work with the Capital One team in driving a major transformation within the company. I believe my expertise in [mention relevant technologies or tools] and my experience in [mention any industry-specific experience] make me a valuable addition to the team. In my previous roles, I have collaborated closely with agile teams, designed and developed technical solutions, and implemented cloud-based solutions. I am skilled in programming languages like [list relevant programming languages], and I have experience working with [list relevant technologies or tools]. I am also committed to staying up-to-date with the latest tech trends and continually expanding my knowledge. I am confident in my ability to contribute to the success of Capital One's data infrastructure projects. I am a dedicated team player and am always eager to learn and grow in my career. I believe that my passion for technology and problem-solving, combined with my strong interpersonal and communication skills, will enable me to thrive in this role. Thank you for considering my application. I look forward to the opportunity to discuss how I can contribute to the success of Capital One as a Lead Data Engineer. Please find my resume attached for your review. If you require any additional information, please do not hesitate to contact me. Sincerely, [Your Name] --- Bullet points: - Passionate about technology and problem-solving - Collaborate with agile teams to design, develop, and implement technical solutions - Skilled in programming languages like Java, Scala, Python, and open source databases - Stay updated with the latest tech trends and participate in technology communities - Experience with cloud computing (AWS, Microsoft Azure, Google Cloud) - Deliver cloud-based solutions that empower millions of Americans financially - Conduct unit tests and code reviews to ensure high-quality, performant code - Bachelor's Degree required - At least 6 years of experience in application development - Experience with big data technologies - Preferred experience with distributed data\/computing tools, real-time data and streaming applications, NoSQL implementation, data warehousing, UNIX\/Linux, and Agile engineering practices.\nShow more\nShow less",
      "job_skills":"Java, Scala, Python, SQL, R, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, MySQL, MongoDB, Cassandra, Redshift, Snowflake, UNIX\/Linux, AWS, Microsoft Azure, Google Cloud, Agile",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"SR. Data Engineer (1008352)",
      "company":"The Judge Group",
      "job_location":"Arlington, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-1008352-at-the-judge-group-3747091845",
      "search_city":"Fort Worth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Location:\nArlington, TX\nSalary:\nNegotiable\nDescription:\nOur client is currently seeking a SR. Data Engineer\nOverview\nWe are expanding our efforts into complementary data technologies for decision support in areas of ingesting and processing large data sets including data commonly referred to as semi-structured or unstructured data. Our interests are in enabling data science and search based applications on large and low latent data sets in both a batch and streaming context for processing. To that end, this role will engage with team counterparts in exploring and deploying technologies for creating data sets using a combination of batch and streaming transformation processes. These data sets support both off-line and in-line machine learning training and model execution. Other data sets support search engine based analytics. Exploration and deployment of technologies activities include identifying opportunities that impact business strategy, collaborating on the selection of data solutions software, and contributing to the identification of hardware requirements based on business requirements. Responsibility also includes coding, testing, and documentation of new or modified scalable analytic data systems including automation for deployment and monitoring. This role participates along with team counterparts to develop solutions in an end-to-end framework on a group of core data technologies. Other aspects of the role include developing standards and processes for data engineering projects and cloud initiatives.\nResponsibilities\nCode, test, deploy, Orchestrate, monitor, document and troubleshoot cloud-based data engineering processing and associated automation in accordance with best practices and security standards throughout the development lifecycle\nWork closely with data scientists, data architects, ETL developers, other IT counterparts, and business partners to identify, capture, collect, and format data from the external sources, internal systems and the data warehouse to extract features of interest\nSignificantly contribute to the evaluation, research, experimentation efforts with batch and streaming data engineering technologies to keep pace with industry innovation while assessing business impact and viability for use cases associated with efforts in hand\nWork with data engineering related groups to inform on and showcase capabilities of emerging technologies and to enable the adoption of these new technologies and associated techniques\nSignificantly contribute to the definition and refinement of processes and procedures for the data engineering practice\nEducate and develop ETL developers on data engineering cloud-bases initiatives so as to enable transition to data engineer and practice\nPerform other duties as assigned\nConform with all company policies and procedures\nQualifications\nExperience with processing large data sets using Hadoop, HDFS, Spark, Kafka, Flume or similar distributed systems\nExperience with ingesting various source data formats such as JSON, Parquet, SequenceFile, Cloud Databases, MQ, Relational Databases such as Oracle\nExperience with Cloud technologies (such as Azure, AWS, GCP) and native toolsets such as Azure ARM Templates, Hashicorp Terraform, AWS Cloud Formation\nUnderstanding of cloud computing technologies, business drivers and emerging computing trends\nThorough understanding of Hybrid Cloud Computing: virtualization technologies, Infrastructure as a Service, Platform as a Service and Software as a Service Cloud delivery models and the current competitive landscape\nWorking knowledge of Object Storage technologies to include but not limited to Data Lake Storage Gen2, S3, Minio, Ceph, ADLS etc\nExperience with containerization to include but not limited to Dockers, Kubernetes, Spark on Kubernetes, Spark Operator\nWorking knowledge of Agile development \/SAFe, Scrum and Application Lifecycle Management\nStrong background with source control management systems (GIT or Subversion); Build Systems (Maven, Gradle, Webpack); Code Quality (Sonar); Artifact Repository Managers (Artifactory), Continuous Integration\/ Continuous Deployment (Azure DevOps)\nExperience with NoSQL data stores such as CosmosDB, MongoDB, Cassandra, Redis, Riak or other technologies that embed NoSQL with search such as MarkLogic or Lily Enterprise\nCreating and maintaining ETL processes\nKnowledgeable of best practices in information technology governance and privacy compliance\nExperience with Adobe solutions (ideally Adobe Experience Platform, DTM\/Launch) and REST APIs\nSkills\nTroubleshoot complex problems and works across teams to meet commitments\nExcellent computer skills and proficiency in digital data collection\nAbility to work in an Agile\/Scrum team environment\nStrong interpersonal, verbal, and writing skills\nDigital technology solutions (DMPs, CDPs, Tag Management Platforms, Cross-Device Tracking, SDKs, etc)\nKnowledge of Real Time-CDP and Journey Analytics solutions\nUnderstanding of big data platforms and architectures, data stream processing pipeline\/platform, data lake and data lake houses\nSQL experience: querying data and sharing what insights can be derived\nUnderstanding of cloud solutions such as Google Cloud Platform, Microsoft Azure & Amazon AWS cloud architecture & services\nUnderstanding of GDPR, privacy & security topics\nEducation\nBachelor\u201a\u00c4\u00f4s Degree in related field or equivalent work experience required\nExperience\n5-7 years of hands-on experience with data engineering required\n4-6 years of hands-on experience with processing large data sets required\n4-6 years of hands-on experience with SQL, data modeling, relational databases and\/or no SQL databases required\nContact:\nmkozekwa@judge.com\nThis job and many more are available through The Judge Group. Find us on the web at www.judge.com\nShow more\nShow less",
      "job_skills":"Hadoop, HDFS, Spark, Kafka, Flume, JSON, Parquet, SequenceFile, Cloud Databases, MQ, Oracle, Azure, AWS, GCP, Azure ARM Templates, Hashicorp Terraform, AWS Cloud Formation, Data Lake Storage Gen2, S3, Minio, Ceph, ADLS, Docker, Kubernetes, Spark on Kubernetes, Spark Operator, Agile, SAFe, Scrum, Application Lifecycle Management, GIT, Subversion, Maven, Gradle, Webpack, Sonar, Artifactory, Azure DevOps, CosmosDB, MongoDB, Cassandra, Redis, Riak, MarkLogic, Lily Enterprise, ETL, Adobe Experience Platform, DTM\/Launch, REST APIs, DMPs, CDPs, Tag Management Platforms, CrossDevice Tracking, SDKs, Real TimeCDP, Journey Analytics, Data stream processing, Data lake, Data lake houses, SQL, Google Cloud Platform, Microsoft Azure, Amazon AWS, GDPR, Data modeling, Relational databases, No SQL databases",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Software Engineer - Data Infrastructure",
      "company":"Canonical",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/software-engineer-data-infrastructure-at-canonical-2540512445",
      "search_city":"Austin",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Canonical is building a comprehensive automation suite to provide multi-cloud and on-premise data solutions for the enterprise. The data platform team is a collaborative team that develops a full range of data stores and data technologies, spanning from big data, through NoSQL, cache-layer capabilities, and analytics; all the way to structured SQL engines.\nWe are facing the interesting problem of fault-tolerant mission-critical distributed systems and intend to deliver the world's best automation solution for delivering data platforms.\nWe have a number of openings ranging anywhere from junior to senior level. We will help you identify a suitable position depending on your experience and interests. Engineers who thrive at Canonical are mindful of open-source community dynamics and equally aware of the needs of large, innovative organisations.\nLocation: This is a Globally remote role\nWhat your day will look like\nThe data platform team is responsible for the automation of data platform operations. This includes ensuring fault-tolerant replication, TLS, installation, and much more; but also provides domain-specific expertise on the actual data system to other teams within Canonical. This role is focused on the creation and automation of features of data platforms, not analysing the data in them.\nCollaborate proactively with a distributed team\nWrite high-quality, idiomatic Python code to create new features\nDebug issues and interact with upstream communities publicly\nWork with helpful and talented engineers including experts in many fields\nDiscuss ideas and collaborate on finding good solutions\nWork from home with global travel for 2 to 4 weeks per year for internal and external events\nWhat we are looking for in you\nProven hands-on experience in software development using Python\nProven hands-on experience in distributed systems\nHave a Bachelor\u201a\u00c4\u00f4s or equivalent in Computer Science, STEM, or a similar degree\nWillingness to travel up to 4 times a year for internal events\nAdditional Skills That You Might Also Bring\nYou might also bring a subset of experience from the following, which will determine the exact role and level we consider you for:\nExperience operating and managing data platform technologies like PostgreSQL, MySQL, MongoDB, OpenSearch, Kafka, Yugabyte, Trino, Superset, Atlas, Ranger, and Redis\nExperience with Linux systems administration, package management, and operations\nExperience with the public cloud or a private cloud solution like OpenStack\nExperience with operating Kubernetes clusters and a belief that it can be used for serious persistent data services\nWhat we offer you\nYour base pay will depend on various factors including your geographical location, level of experience, knowledge and skills. In addition to the benefits above, certain roles are also eligible for additional benefits and rewards including annual bonuses and sales incentives based on revenue or utilisation. Our compensation philosophy is to ensure equity right across our global workforce.\nIn addition to a competitive base pay, we provide all team members with additional benefits, which reflect our values and ideals. Please note that additional benefits may apply depending on the work location and, for more information on these, please ask your Talent Partner.\nFully remote working environment - we\u201a\u00c4\u00f4ve been working remotely since 2004!\nPersonal learning and development budget of 2,000USD per annum\nAnnual compensation review\nRecognition rewards\nAnnual holiday leave\nParental Leave\nEmployee Assistance Programme\nOpportunity to travel to new locations to meet colleagues at \u201a\u00c4\u00f2sprints\u201a\u00c4\u00f4\nPriority Pass for travel and travel upgrades for long haul company events\nAbout Canonical\nCanonical is a pioneering tech firm that is at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world on a daily basis. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do.\nCanonical has been a remote-first company since its inception in 2004. Work at Canonical is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical provides a unique window into the world of 21st-century digital business.\nCanonical is an equal-opportunity employer\nWe are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.\nShow more\nShow less",
      "job_skills":"Python, Distributed Systems, Linux Systems Administration, Package Management, Operations, Public Cloud, Private Cloud, Kubernetes Clusters, PostgreSQL, MySQL, MongoDB, OpenSearch, Kafka, Yugabyte, Trino, Superset, Atlas, Ranger, Redis",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Sr. Cloud Data Infrastructure Engineer",
      "company":"Intellectt Inc",
      "job_location":"Abbott, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-cloud-data-infrastructure-engineer-at-intellectt-inc-3707549053",
      "search_city":"Waco",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"This is Tanmai from Intellect Inc. Please find the job description and reach out to me with an updated copy of your resume. You can send it to tanmai@intellectt.com or call me at +1(907) 802-6640\nRole\n: Sr. Cloud Data Infrastructure Engineer\nLocation\n: Abbott Park, IL - 60064\nDuration\n: 12 Months on W2\nShift Timings:\n8 AM to 5 PM\n100% Onsite role.\nNo option for hybrid or remote.\nJob Summary\nImplements cloud data infrastructure technology stack deployments and evolution for Abbott Enterprise cloudservices.\nFollows a DevSecOps operating model to continuously integrate, deploy and scale our cloud data\ninfrastructure services. Accountable for delivering a comprehensive set of cloud data infrastructure services including requirements definition, design, integration with infrastructure as code approach and handling operations.\nParticipates in proof-of-concept analysis and vendor solution evaluations. Effectively communicates\nand partners with IS cross-functional teams, IT divisional customers and stakeholders in support of cloud\ninitiatives.\nMaintain Cloud data Infrastructure architecture best practices with robust design & automation.\nJob Responsibilities\nServe as a Tech lead for Cloud Data infrastructure services\/platforms managed by Abbott BTS cloud services\nDevSecOps, Agile Delivery and SLC methodologies adjusted for cloud data infrastructure service delivery\nLeverage Site Reliability Engineering (SRE) principles to build highly reliable cloud data infrastructure,\nmanage and operate at scale, solve technical problems, and automate operational tasks\nUse Terraform modular approach to deploy all data infrastructure as code (IaC) based XaaS solutions\nEstablishes build-and-destroy models for cloud data infrastructure technologies\/platforms with blue\/green, canary deployment patterns.\nImplement CI\/CD pipelines for the deployment of cloud data infrastructure stacks for applications.\nDrive cloud data infrastructure service performance health, troubleshooting, operational metrics &capacity management\nManage cloud data protection and restoration including data backups, Site recovery & Replication\nEvolve Infrastructure as Code frameworks for data infra \/ platforms scaling adjustments and optimizations\nOptimize cloud data infra workloads for security, cost, performance, latency, reliability, and availability aspects\nAutomate cloud data infra Day2Ops tasks leveraging fully managed data platforms and orchestration tools\nSupport IT audits and compliance, adhering to applicable Corporate and Divisional Policies and procedures.\nImplement effective standards, methodologies, and processes, driving change proactively asappropriate for continuous improvement.\nOversee overall cloud infrastructure estate operational governance & framework for promotingoperational efficiencies\nMust Have Skills\nExperience with AWS RDS, Azure SQL, PostgreSQL, MongoDB Atlas, Cosmos DB database solutions\nExperience with Managed Kafka Data Streaming, ETL (Informatica, Azure Data Factory) platforms\nExperience with Datawarehouse (RedShift), Analytics (Synapse\/Databricks\/Snowflake) platforms\nExperience with Cloud Storage platforms (Managed Disks Azure Blob \/Files, AWS S3, EBS, EFS)\nExperience with Azure\/AWS native Data Protection & Backup\/Recovery, Site recovery solutions\nExperience with Terraform (IaC), Ansible (Configuration management), Packer (Gold images)\nExperience with Git (GitHub) and CI\/CD Pipelines (Jenkins, CI\/CD Argo, or Azure DevOps)\nExperience with any of the Observability\/Monitoring tools like Data Dog, New Relic, Dynatrace, LogicMonitor\nExperience with ServiceNow (ITSM) Ticketing Support and Process integrations\nEducation And Experience\nA bachelor's Degree is preferred in technology or management of information systems discipline.\nOverall 10 years of IT experience including cloud experience for at least 4 years potentially in a lead SME type of role.\nShow more\nShow less",
      "job_skills":"AWS, Azure, RDS, SQL, PostgreSQL, MongoDB Atlas, Cosmos DB, Kafka, ETL, Informatica, Azure Data Factory, Redshift, Analytics, Synapse, Databricks, Snowflake, Cloud Storage, Managed Disks, Azure Blob, Files, AWS S3, EBS, EFS, Git, GitHub, CI\/CD, Jenkins, Argo, Azure DevOps, ServiceNow, Terraform, Ansible, Packer, Data Dog, New Relic, Dynatrace, LogicMonitor",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Database Engineer - TS\/SCI (Relo Assistance Available)",
      "company":"CyberCoders",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/database-engineer-ts-sci-relo-assistance-available-at-cybercoders-3786097726",
      "search_city":"McKinney",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"If you are a Database Engineer with an active TS\/SCI Security Clearance, please read on!\nJob Title:\nDatabase Engineer\nLocation:\nRichardson, TX or Dulles, VA **Relocation assistance is available**\nSalary:\n$150,000 - $250,000 DOE + extensive benefits, PTO, 401(k) with a company match, and more\nRequirements:\n6+ years of experience as a Database Engineer, willing to obtain a CompTIA Security+ certification, and an active TS\/SCI with Poly Security Clearance\nThis would be an amazing opportunity for you if you are looking for a role that will provide professional growth and new challenges yet balanced with great culture and quality of life!\nTop Reasons to Work with Us\nCertified 8a and verified Service-Disabled Veteran-Owned Small Business\nGovernment service partner that delivers innovative and high-value solutions to unique customer problems & mission critical operations\nHave the opportunity to work in a variety of different areas including Military Intelligence & Cyber Ops, Cyber Security, Enterprise IT Management, SaaS, Software Development, and System Engineering\nFull-time employment with a long-term contract opportunity with a globally recognized company\nWhat You Will Be Doing\nWork with the whole database lifecycle\nSupport System Engineers, Software Engineers, Testers, and Operations staff\nRemain proactive in troubleshooting database issues which includes performance tuning\nPerform backup & recovery\nMaintain database deployments\nInstallation, configuration, and maintenance of databases\nAdditional tasks\/duties as assigned\nWhat You Need for this Position\nRequired\nActive TS\/SCI Security Clearance\nCompTIA Security+ Certification (or willing to obtain one within a month of joining the program)\nOracle\/PostgreSQL\n6+ years of experience working as a Database Engineer\nHistory of working in a software development environment and following software processes (SCM\/Etc.)\nHistory of working with the whole database life cycle\nExperience with backup, recovery, and database deployments\nStrong Linux skills which includes scripting\nProcedural SQL scripting skills (plsql\/pgsql)\nPreferred\nMongoDB\nOracle Spatial\nAWS RDS\nAnsible\nNagios\nWhat's In It for You\nCompetitive salary ($150,000 - $250,000 DOE)\nExtensive benefits (medical, dental, vision)\nRelocation assistance\nPTO\nFederal holidays and birthday PTO\n401(k) with a company match\nWe are actively interviewing so APPLY TODAY!\nEmail Your Resume In Word To\nLooking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:\nGage.Wolinski@CyberCoders.com\nPlease do NOT change the email subject line in any way. You must keep the JobID: linkedin : GW1-1778712 -- in the email subject line for your application to be considered.***\nGage Wolinski - Recruiter - CyberCoders\nApplicants must be authorized to work in the U.S.\nCyberCoders is proud to be an Equal Opportunity Employer\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\nYour Right to Work\n\u201a\u00c4\u00ec In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\nCyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.\nShow more\nShow less",
      "job_skills":"Oracle, PostgreSQL, MongoDB, Oracle Spatial, AWS RDS, Ansible, Nagios, Linux, Scripting, SQL, PlSQL, PgSQL, Software Development, Troubleshooting, Performance Tuning, Backup, Recovery, Database Deployments, Installation, Configuration, Maintenance",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Sr Data Analyst",
      "company":"Arnex Solutions LLC",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-analyst-at-arnex-solutions-llc-3735359221",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Title: Senior Data Analyst\nLocation : Dallas, TX local only\nDuration : 6+ monhts\nJob Description Senior Data Analyst\nPrimary responsibilities of the Senior Data Analyst include supporting and analyzing data anomalies for multiple\nenvironments including but not limited to Data Warehouse, ODS, Data Replication\/ETL Data Management initiatives.\nThe candidate will be in a supporting role and will work closely with Business, DBA, ETL and Data Management teams\nproviding analysis and support for complex Data related initiatives. This individual will also be responsible for assisting in\ninitial setup and on-going documentation\/configuration related to Data Governance and Master Data Management solutions.\nThis candidate must have a passion for data, along with good SQL, analytical and communication skills.\nResponsibilitiesInvestigate and Analyze data anomalies and data issues reported by Business\nWork with ETL, Replication and DBA teams to determine data transformations, data movement and\nderivations and document accordingly\nWork with support teams to ensure consistent and pro-active support methodologies are adhered to for all\naspects of data movements and data transformations\nAssist in break fix and production validation as it relates to data derivations, replication and structures\nAssist in configuration and on-going setup of Data Virtualization tool\nAssist in keeping documentation up to date as it relates to Data Standardization definitions, Data Dictionary and\nData Lineage\nGather information from various Sources and interpret Patterns and Trends\nQualifications\n4+ years of SQL experience working in OLTP, Data Warehouse and Big Data databases\n4+ years in a Data Analyst role\nStrong attention to Detail\n2+ years writing medium to complex stored procedures a plus\nAbility to collaborate effectively and work as part of a team\nExtensive background in writing complex queries\nExtensive working knowledge of all aspects of Data Movement and Processing, including ETL, API,\nOLAP and best practices for data tracking\nGood Communication Skills\nSelf-Motivated\nWorks well in a team environment\nDenodo Experience a Plus\nBig Data Experience a plus (Hadoop, MongoDB, Exadata)\nShow more\nShow less",
      "job_skills":"SQL, Data Analysis, Data Management, Data Governance, Master Data Management, Data Virtualization, Data Dictionary, Data Lineage, Data Standardization, Denodo, Hadoop, MongoDB, Exadata",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Hybrid Work - Need Sr.\u00ac\u2020Data Analyst-locals in Dallas TX",
      "company":"Steneral Consulting",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/%C2%A0hybrid-work-need-sr-%C2%A0data-analyst-locals-in-dallas-tx-at-steneral-consulting-3690903517",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job:\nSr. Data Analyst\nLocation:\nDallas, TX 75202 hybrid onsite 1-2 days\/week\nTerm:\n6+ mos. (high probability to extend)\nSenior Data Analyst\nPrimary responsibilities of the Senior Data Analyst include supporting and analyzing data anomalies for multiple environments including but not limited to\nData Warehouse, ODS, Data Replication\/ETL Data Management\ninitiatives. The candidate will be in a supporting role and will work closely with Business, DBA, ETL and Data Management teams providing analysis and support for complex Data related initiatives. This individual will also be responsible for assisting in initial setup and on-going documentation\/configuration related to\nData Governance and Master Data Management\nsolutions. This candidate must have a passion for data, along with good SQL, analytical and communication skills.\nResponsibilities\nInvestigate and Analyze data anomalies and data issues reported by Business\nWork with ETL, Replication and DBA teams to determine data transformations, data movement and derivations and document accordingly\nWork with support teams to ensure consistent and pro-active support methodologies are adhered to for all aspects of data movements and data transformations\nAssist in break fix and production validation as it relates to data derivations, replication and structures\nAssist in configuration and on-going setup of Data Virtualization tool\nAssist in keeping documentation up to date as it relates to Data Standardization definitions, Data Dictionary and Data Lineage\nGather information from various Sources and interpret Patterns and Trends\nQualifications\n4+ years of SQL experience working in OLTP, Data Warehouse and Big Data databases\n4+ years in a Data Analyst role\nStrong attention to Detail\n2+ years writing medium to complex stored procedures (SQL)\nAbility to collaborate effectively and work as part of a team\nExtensive background in writing complex SQL queries\nExtensive working knowledge of all aspects of Data Movement and Processing, including ETL, API, OLAP and best practices for data tracking\nGood Communication skills\nSelf-Motivated\nWorks well in a team environment\nDenodo Experience a plus\nBig Data Experience (Hadoop, MongoDB, Exadata)\nShow more\nShow less",
      "job_skills":"SQL, Data Warehouse, ODS, ETL, Data Management, Data Governance, Master Data Management, Data Virtualization, Data Standardization, Data Dictionary, Data Lineage, OLTP, Big Data, Data Movement, Processing, API, OLAP, Hadoop, MongoDB, Exadata, Stored Procedures",
      "Category":"Full-Stack Development"
  },
  {
      "job_title":"Senior Oracle Database Engineer (Requires ACTIVE Secret Security with Security Clearance",
      "company":"ClearanceJobs",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-oracle-database-engineer-requires-active-secret-security-with-security-clearance-at-clearancejobs-3782601659",
      "search_city":"Leavenworth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Description\nTEKsystems is seeking an experienced Oracle Database Administrator for a long-term contract supporting a data center local to the Kansas City area. As a Senior Oracle Database Administrator you will be responsible for planning, engineering, operating, maintaining, and problem resolution of the Oracle Database Platform as a Service capabilities. You will also work with associated hybrid cloud datacenter infrastructure and teams: virtualization; backup\/storage; operating systems management; networking; and management, monitoring and automation tools. You will support system operations, hardening, migration capabilities, customer interaction and support, and patching. You will also be involved in planning and executing cloud migration and operations activities.\nThe program operates and provides cybersecurity services to support the client application hosting environment. The team also provides engineering and implementation services to deploy and operate the on-prem, hybrid-cloud and cloud datacenter environments. This is an opportunity to shape the way the client achieves its goals to provide enterprise application hosting while ensuring daily support and secure operations for a world-wide warfighter community.\nResponsibilities * As a Senior Oracle Database Administrator you will be responsible for planning, engineering, operating, maintaining, and problem resolution of the Oracle Database Platform as a Service capabilities\nYou will also work with associated hybrid cloud datacenter infrastructure and teams: virtualization; backup\/storage; operating systems management; networking; and management, monitoring and automation tools\nYou will support system operations, hardening, migration capabilities, customer interaction and support, and patching\nYou will also be involved in planning and executing cloud migration and operations activities\nAdminister Oracle Platform as a Service hosting environment (Oracle 19c on RHEL operating as virtualized databases)\nMonitor, triage, respond to events, incidents, tasks, changes including working ticket queues and executing approved Data Center projects and activities across the Oracle service area\nMonitor, execute and troubleshoot RMAN backup\/restore\nImplement and manage oracle networking with SSL\/TLS\nDevelop, update, and troubleshoot scripts used to manage the Oracle environment\nCurrent scripts include bash, python, and ansible\nProvides cluster and datacenter database administration, operational support, and problem resolution\nCollaborates with other datacenter engineers on incident, event, and problem resolution; expertise in Red Hat Enterprise Linux 7 and 8 desired; experience with VMWare virtualization and cloud platforms desired\nWorks with various vendors to install, upgrade, configure, administer, automate, and optimize Oracle virtualization architecture and associated software, providing a secure, reliable, and highly available data base platform to Data Center customers and services\nPerforms software installation and upgrade automation including scripting in bash and python as well as automation of data center efforts using VMWare tools (VMWare Ops Manager, vRealize Automation\/Orchestrator)\nDevelops and maintains a comprehensive system event, performance, and capacity monitoring plan\nTroubleshoots problems, takes appropriate corrective action and\/or interacts with IT staff or vendors in performing complex testing, support and troubleshooting functions\nCoordinates troubleshooting and collaborates with customers to resolve customer database operation incidents\nProvides 24x7x365 on-call support in rotation with Technical Lead nights\/weekends with after hours response required in support of some incidents\nSupports monthly and quarterly security\/application patching process\nQualifications: * BS+ 8-10 MS + 5-7 years experience, will consider HS+12 years experience\nExperiencing implementing DISA STIGs and security controls\nExperience implementing\/configuring and troubleshooting RMAN backup\/restore\nExperience with Oracle networking with SSL\/TLS\nExperience with Data Guard implementations\nSenior level experience in VMWare vRealize Operations Suite (Operations Manager), HP Blade System (or similar hardware platform), Log Management tool (SysLog\/Log Insight), NetBackup, Red Hat Enterprise Linux; 7.x\/8.x, DISA STIGs\/SRG\nIAT Level II Certification (DOD 8570\/8140), e.g. CompTIA Security+, CASP, CISSP, CISM, CIS,\nOracle Certification required: Oracle Database Certified Master\nActive DoD SECRET Security Clearance\nMust be legally eligible for employment in the US.\nSkills\nDatabase administrator, Oracle database, Oracle\nTop Skills Details\nDatabase administrator, Oracle database, Oracle\nExperience Level\nExpert Level\n#CJ About TEKsystems: We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company. The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Senior Research\/Data Analyst IA020124",
      "company":"State of Missouri",
      "job_location":"Jefferson City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-research-data-analyst-ia020124-at-state-of-missouri-3784938593",
      "search_city":"Jefferson City",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Senior Research\/Data Analyst \u201a\u00c4\u00ec\nPublic Service Commission \/ Industry Analysis Division \/ Water, Sewer, and Steam Department\nJob Posting Number:\nIA020124\nSalary:\nStarting salary will be commensurate with education and experience. Annual salary range: $66,053 - $70,980\nJob Location:\nThis position is located at 200 Madison Street, Jefferson City, MO 65102\nWhy You\u201a\u00c4\u00f4ll Love This Position\nThe Missouri Public Service Commission regulates investor-owned electric, natural gas, steam, water and sewer utilities in Missouri. We ensure that Missourians receive safe and reliable utility services at just, reasonable and affordable rates. The Water and Sewer Department performs evaluations and on-going reviews of all tariff filings made by companies to ensure compliance with Commission rules and procedures. The department participates in all formal and informal rate filings made by regulated companies by reviewing existing and proposed rate design proposals and determining the appropriateness and need for plant additions. The department provides responses to customer inquiries and complaints concerning rate matters and quality of service issues and performs periodic inspections of company facilities and operations to ensure that companies are in compliance with Commission rules and are operating adequately. The department also participates in the review of finance cases filed before the Commission to ensure the appropriateness of the projects being financed and participates in the review of certificate applications before the Commission.\nWhat You\u201a\u00c4\u00f4ll Do\nPerform reviews and analysis of policies and programs affecting rates used to charge water, sewer, and steam customers in the state of Missouri.\nEnsure customers receive safe and adequate service.\nCoordinate technical aspects of rate cases before the Commission.\nNegotiate with utility representatives and interveners.\nReview legislative proposals and participate in rule making.\nProvide input and testify on issues as an expert witness.\nResearch new environmental requirements affecting water, sewer, and steam utilities.\nMake recommendations to utilities to ensure rule and regulation compliance.\nPosition may require occasional in- and out-of-state travel.\nMinimum Qualifications\nAll you need for success:\nA Bachelor\u201a\u00c4\u00f4s degree from an accredited four-year college or university and;\n4-6 years of relevant experience and\/or appropriate certification.\nProfessional experience in a utility or regulatory environment preferred.\nKnowledge of drinking water or wastewater environmental regulations a plus.\nMust have strong interpersonal, communication, active listening, and writing skills.\nPersonal computer experience required, Microsoft Office experience required.\nAbility to work within a team setting or independently is required.\nMust have initiative and strong work ethic.\nIf you have questions about this position, please contact:\npscjobs@psc.mo.gov\nTo be considered for this position, please submit an application, resume, and provide a copy of each transcript from all colleges\/universities attended, and a one to two page technical writing sample by 5:00 pm January 12, 2024. For additional information about this position, you may visit http:\/\/psc.mo.gov\/General\/Career_Opportunities .\nThe State of Missouri is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Sr. Data Engineer - Remote Nationwide",
      "company":"Lumeris",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-remote-nationwide-at-lumeris-3742350838",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"In order to apply for a position at Lumeris, you must create an account using your email address and a password of your choosing. This account will allow you to receive notifications each step of the way through the job application process. With these updates, you\u201a\u00c4\u00f4ll never have to wonder where you are in the process. Additionally, we can easily send pertinent documents to you for your review. Once you create the account, you may apply to any position you feel is a good fit without having to re-enter information. Thank you for your interest in Lumeris.\nPosition:\nSr. Data Engineer - Remote Nationwide\nPosition Summary:\nPlays a key role in handling and optimizing data processing systems while guiding client onboarding activities. Responsible for ensuring the efficient flow, integration, and quality of data across the organization, as well as successfully onboarding client data by providing guidance and expertise. Collaborates closely with cross-functional teams, troubleshooting data-related issues, and implementing best practices to enhance data operations workflows. Provides technical guidance and mentorship to junior team members.\nJob Description:\nJob Description\nPrimary Responsibilities\nGuides the design, build, and maintenance of data processing pipelines and workflows, ensuring efficient data integration, transformation, and delivery.\nOversees client onboarding activities, working closely with clients to understand their data requirements and mapping them to our specifications.\nProvides technical guidance and expertise during client onboarding, ensuring smooth integration of client data into our systems and adherence to data quality standards.\nCollaborates with cross-functional teams to ensure accurate and timely onboarding of client data.\nDesigns and implements data quality controls and validation processes to ensure the accuracy, completeness, and consistency of client data.\nMentors and supports junior team members, providing guidance, training, and performance feedback to foster their development.\nMonitors and troubleshoots data pipelines, identifying and resolving data-related issues to ensure data integrity and reliability.\nOptimizes data operations workflows, automating repetitive tasks, and implementing industry-leading practices to enhance operational efficiency.\nMonitors and reviews data operations performance metrics, identifying areas for improvement and implementing solutions to enhance data processing speed and efficiency.\nStay up-to-date on emerging technologies, tools, and trends in data operations, evaluating their potential impact and making recommendations for adoption or improvement.\nCollaborates with data governance teams to ensure compliance with data security, privacy, and regulatory requirements.\nQualifications\nBachelor's Degree in related field (Computer Science, Information Systems, etc.) or equivalent\n5+ years of relevant data engineering\/operations experience or the knowledge, skills, and abilities to succeed in the role\nStrong understanding of data processing concepts, data integration, and ETL (Extract, Transform, Load) processes\nProficiency in programming languages such as Python, Java, or Scala\nThorough knowledge of database systems and proven SQL proficiency\nExperience with cloud-based data platforms, such as AWS or Azure\nStrong problem-solving and troubleshooting skills, with the ability to review and resolve complex data-related issues\nExcellent communication and collaboration skills, with the ability to work effectively with cross-functional teams and clients\nStrong attention to detail and commitment to data accuracy and quality\nAbility to impact results, oversee and prioritize workload, and respond to changing demands\nPreferred\nKnowledge of data governance principles and best practices\nFamiliarity with data processing frameworks and tools, such as Apache Spark, Hadoop, or Airflow\nWorking Conditions\nWhile performing the duties of this job, the employee works in normal office working conditions.\nDisclaimer\nThe job description describes the general nature and level of work being performed by people assigned to this job and is not intended to be an exhaustive list of all responsibilities, duties and skills required. The physical activities, demands and working conditions represent those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential job duties and responsibilities.\nLumeris is an EEO\/AA employer M\/F\/V\/D.\nThe hiring range for this position is:\n$98,400.00-$132,225.00\nFactors that may be used to determine your actual pay rate include your specific skills, experience, qualifications, location, and comparison to other employees already in this role. This role may also be eligible for incentive compensation. At Lumeris, we are committed to providing a total rewards package that supports your overall well-being. Our benefits include medical, vision, dental, well-being programs, 401(k) with company matching, life insurance, paid time off including paid leave, and so much more. Learn more by visiting our Careers Page.\nMember Facing Position:\nNo- Not Member Facing Position\nLocation:\nSt. Louis, MO\nTime Type:\nFull time\nLumeris and its partners are committed to protecting our high-risk members & prospects when conducting business in-person. All personnel who interact with at-risk members or prospects are required to have completed, at a minimum, the initial series of an approved COVID-19 vaccine. If this role has been identified as member-facing, proof of vaccination will be required as a condition of employment.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Big Data Developer",
      "company":"NR Consulting",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/big-data-developer-at-nr-consulting-3768030057",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Job Description\n4+ Years of experience with Scala is must\n4+ Years of experience with Spark is must.\nExtensive hands on experience on SQL and PL\/SQL\n3 + Years of Experience with Big Data and NoSQL platforms and technologies, specifically hands-on experience with one or more major Hadoop distributions and various ecosystem components (e.g. MapReduce, MLLib, Impala, HBase, Spark etc.).\nShould have experience either in Cloudera or Hortonworks\nGood Knowledge on Unix Schell Scripting and Java\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Data Governance Analyst Specialist",
      "company":"Kforce Inc",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-governance-analyst-specialist-at-kforce-inc-3777073285",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Responsibilities\nKforce has a client that is seeking a Data Governance Analyst Specialist in Kansas City, MO. Key Tasks:\nData Governance Analyst Specialist will execute the organization's data governance operating model and collaborate with various Company business and technical teams to implement enterprise data policies and standards for the organization\nMonitor progress of Data Domain teams with respect to the rollout of data governance practices and provide education, training, and support as needed\nEnsure data aligns with regulatory requirements as needed\nOversight and regular review of Data Domain Team deliverables related to data governance practices; Data maps; Data issue tracking; Metadata documentation; Data procedures documentation; Service Level Agreements; Access and security requirements; Audit and retention requirements\nPartner with Data Owners and Data Stewards to develop workflows, dashboards, and automation of data governance activities within our data governance tools\nAs a Data Governance Analyst Specialist, you will partner with HR's Learning and Development team to curate and deploy Data Governance, Data Stewardship, and Tool required training\nAct as a Collibra administrator and help train domain teams and consumers on the platform; Drive adoption of, and guide proper use of, features and functionality available within the tool\nWork closely with our tool vendors on roadmap items for implementation and provide feedback for additional improvements that would benefit Company\nManage internal data products, including reference data, metadata, data quality results, and SharePoint content\nRequirements\nBachelor's degree and\/or equivalent combination of education and work experience in related field; Finance, Accounting, or related education preferred\n2 or more years of confirmed experience working on a team engaged in data governance, data management, or data operations\nExperience with data governance, metadata, data mapping, and data lineage tools, such as Collibra, Informatica, IBM IGC, etc.\nFamiliarity with data security and protection methodologies\nComfortable with working in an agile work environment\nDemonstrated effectiveness working in a dynamic and high-paced environment\nValidated innovator and a strategic problem solver in the data governance space\nOutstanding interpersonal skills including the ability to communicate with individuals at all levels of the organization in both verbal and written form\nAbility to approach and solve problems in an analytical and methodical manner\nAbility to be proactive and collaborative in ambiguous situations\nPreferred\n2+ years of experience in the asset management industry, with strong domain knowledge of data management technology and operations\nExperience working with cloud technologies\nExperience in policy and standards development and maintenance\nExperience with MuleSoft Any point Studio or BPMN are a plus\nProject Management, Agile and\/or Six Sigma skills are a plus\nThe pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.\nWe offer comprehensive benefits including medical\/dental\/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.\nNote: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.\nThis job is not eligible for bonuses, incentives or commissions.\nKforce is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\nSalary: $83,000 - $123,000 per year\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Merkle",
      "job_location":"Kansas City, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-merkle-3778437384",
      "search_city":"Independence",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Company Description\nDentsu\/Merkle is a modern marketing solutions company. Our mission is to help clients navigate, progress and thrive in a world of change. Businesses rely on our integrated network of agencies and specialized practices to champion meaningful progress through creative, media, commerce, data and technology. Part of Dentsu Group, our global network comprises 66,000 diverse people in 143 countries, who are dedicated to teaming for growth and good. Some of our award-winning agencies include 360i, Carat, dentsu mcgarrybowen, DEG, dentsuX, iProspect and Merkle. Follow us on Twitter @DentsuUSA and visit dentsu.com\/us.\nWe are champions for meaningful progress and we strive to be a force for good\u201a\u00c4\u00eefor our people, for our clients, for the industry and for our society. We keep our people at the center, creating space for growth, understanding and learning so they can thrive. We embed diversity, in our mindset, in our solutions and in our teams to empower an inclusive, equitable and culturally fluent environment. Building this culture within our teams makes us better collaborators with each other and with our clients, driving better outcomes for all.\nWhy Join Us?\nMerkle is the leader in data-driven performance marketing. We help brands achieve tremendous competitive advantage. We thrive because we employ the best in the business. Merkle's energy lives in everything we do, and it shows in the way we deliver to our clients. Additionally, we are recognized as top global partners by some of the world's leading technology firms including Adobe, Google, AWS, Salesforce, and more.\nJob Description\nAs a Sr. Data Engineer, you will be a core member of the data engineering team: developing new or enhancing existing data products as we build a meta data driven, big data solution, processing and transforming data to produce high quality data assets for our customers. You will work with passionate, goal-oriented Data Engineers to solve complex problems. You will collaborate with Operations and Delivery teams to provide market focused data solutions to our customers. You will participate in a growing, high performing data engineering team that embraces change, is continuously improving, and rapidly builds, tests, enhances, and scales data transformational solutions that drive incremental business value for our customers and partners.\nKey Responsibilities:\nCreate or assemble large, complex data sets that meet functional and non-functional business requirements\nDocument requirements from End Users to development user stories, capturing all the details and acceptance criteria required\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data builds, and implementing data QA and reporting\nCoordinate with cross-functional teams, such as Identity and Data Science teams, to develop new data products, making sure each team has the data required\nWork with data and analytic experts to strive for greater functionality of the data\nDevelop Proof of Concepts for new or updated data needs as required\nTriage data build or release issues as required\nSupport integration with internal solutions\nQualifications\nBachelor's degree in Mathematics, Statistics, Economics, Computer Science or other equivalent experience\n10+ year experience with data engineering, data modeling and\/or data processing\n5+ years' experience with SQL, relational databases, and data warehouses\nExperience with Python\nExperience with Snowflake\nExperience in cloud base technologies (AWS, GCP, Azure)\nExperience working in Agile teams and CI\/CD environments\nExperience with Linux and Windows is a plus\nExperience with Jenkins, Airflow, or other orchestration tools is a plus\nExperience with code repositories such as Git, Bitbucket, Github, etc.\nExperience in Tableau is a plus\nSkills:\nStrong analytic skills working with B2B, B2C, and Digital data assets for the purposes of customer experience marketing and analytics\nAble to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement\nAble to build processes supporting data transformation, data structures, metadata, dependency and workload management\nDemonstrated ability to manipulate, process and extract value from large disconnected datasets\nDemonstrated strong organizational, leadership, and communication skills\nDemonstrated ability to work with cross-functional teams in a dynamic environment\nFamiliarity with statistical concepts, modeling, and the ability to integrate data and analytics\nAble to manage ambiguity, asking questions to gain clarity and understanding\nAble to learn new emerging technologies quickly and apply innovative ideas to resolve problems\nAble to investigate and determine solutions to solve complex problems, offering options and recommendations to business stakeholders or leadership for decisions\nAble to analyze data, with a high attention to detail, and identify data patterns and anomalies\nAble to assess and manage big data and data that scales\nAble to focus on results and business outcomes, meeting business expectations\nAdditional Information\nThe anticipated salary range for this position is (\n$94,000k-$152,375k\n). Actual salary will be based on a variety of factors including relevant experience, knowledge, skills and other factors permitted by law. A range of medical, dental, vision, 401(k) matching, paid time off, and\/or other benefits also are available. For more information regarding dentsu benefits, please visit dentsubenefitsplus.com.\nAbout Dentsu\nDentsu is the network designed for what\u201a\u00c4\u00f4s next, helping clients predict and plan for disruptive future opportunities in the sustainable economy. Taking a people-centered approach to business transformation, dentsu combines Japanese innovation with a diverse, global perspective to drive client growth and to shape society www.dentsu.com.\nWe are champions for meaningful progress and we strive to be a force for good\u201a\u00c4\u00eefor our people, for our clients, for the industry and for our society. We keep our people at the center, creating space for growth, understanding and learning so they can thrive. We embed diversity, in our mindset, in our solutions and in our teams to empower an inclusive, equitable and culturally fluent environment. Building this culture within our teams makes us better collaborators with each other and with our clients, driving better outcomes for all.\nDentsu (the \"Company\") is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant or employee of the Company, on the basis of age, sex, sexual orientation, race, color, creed, religion, ethnicity, national origin, alienage or citizenship, disability, marital status, veteran or military status, genetic information, or any other legally-recognized protected basis under federal, state or local laws, regulations or ordinances. Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and\/or certain state or local laws. A reasonable accommodation is a change in the way things are normally done that will ensure an equal employment opportunity without imposing an undue hardship on the Company. Please contact your recruiter if you need assistance completing any forms or to otherwise participate in the application process or to request or discuss an accommodation in connection with a job at the Company to which you are applying.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Lead Azure Data Warehouse Engineer",
      "company":"Kelly",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-azure-data-warehouse-engineer-at-kelly-3762629270",
      "search_city":"East Saint Louis",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Business Intelligence and Data Warehousing Developer",
      "company":"MRE Consulting",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/business-intelligence-and-data-warehousing-developer-at-mre-consulting-3762672692",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Hybrid",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Senior Data Engineer - Onsite in Houston, Tx",
      "company":"TekIntegral",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-onsite-in-houston-tx-at-tekintegral-3642306042",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Sr. Data Engineer - Local to TX Only",
      "company":"Mphasis",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-local-to-tx-only-at-mphasis-3759781785",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description:\n9+ years of professional work experience designing and implementing\ndata pipelines in a cloud environment is required.\n5+ years of experience migrating\/developing data solutions in the AWS cloud is required.\n2+ years of experience building\/implementing data pipelines using\nDatabricks or similar cloud database.\nExpert level knowledge of using SQL to write complex, highly optimized queries across large volumes of data.\nHands-on object-oriented programming experience using Python is required.\nProfessional work\nexperience building real-time data streams using Spark and Experience in Spark.\nKnowledge or experience in architectural best practices in building data lakes\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Sr Data Scientist, Houston, Texas( Remote but Local Only)",
      "company":"Stellent IT",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-scientist-houston-texas-remote-but-local-only-at-stellent-it-3584717446",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"Sr Data Scientist,\nHouston, Texas( Remote but Local Only)\nPhone + Skype\nJd\nThe position can be worked remotely but they would like someone local to the Houston area.\nMust be a Sr Engineer capable of working on a team and supporting multiple projects at any given time with limited supervision. Must be Senior.\nTeck stack Azure, Azure Synapse, Databricks, Python, and SQL\nSAP experience is a big plus.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Lead Data engineer Fortune 100 Co Hiring ASAP Salary up to $140K per year +10% Bonus",
      "company":"Confidential",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-fortune-100-co-hiring-asap-salary-up-to-%24140k-per-year-%2B10%25-bonus-at-confidential-3776642242",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Lead Data Engineer Fortune 100 Co Hiring ASAP Salary up to $140K per year +10% Bonus",
      "company":"Confidential",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-fortune-100-co-hiring-asap-salary-up-to-%24140k-per-year-%2B10%25-bonus-at-confidential-3777004484",
      "search_city":"Baytown",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Data Center Engineer",
      "company":"World Wide Technology",
      "job_location":"Roanoke, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-center-engineer-at-world-wide-technology-3776646730",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"World Wide Technology Holding Co, LLC. (WWT) has an opportunity available for a\nData Center Engineer\nto support our client in an ongoing Data Center refresh project.\nData Center Engineer\nLocation:\nRoanoke, TX\nAvailable Shifts:\n(2 Openings) 7 PM \u201a\u00c4\u00ec 7 AM CST Thursday, Friday, Saturday, and Alternating Wednesdays.\n(1 Opening) 7 AM \u201a\u00c4\u00ec 7 PM CST Thursday, Friday, Saturday, and Alternating Wednesdays.\nDuration:\n12 Months\nContract Designation:\nFull-Time Contingent \u201a\u00c4\u00ec Contractors will be eligible for WWT\u201a\u00c4\u00f4s Full Time Employee Benefits Package including Medical, Vision, Dental, PTO, Paid Holidays, and more.\nResponsibilities:\nInstalling\/de-installing\/relocating all distributed systems and network hardware (CSUs, DSUs, routers, switches, encryptors, firewalls, etc.) in the Americas Data Centers within the internal service level mandates\nInstalling\/de-installing \/extending\/relocating\/testing all carrier circuits to the network hardware\nInstalling\/de-installing\/relocating all patch cabling for systems and network hardware\nInstalling\/de-installing\/relocating all Data Center hardware\nAssist with the coordination of cabinet power, circuit, and patch infrastructure installations w\/various facilities, electrical and communications vendors\nAssist with the coordination of network component configurations\nCoordinate and Install SAN cabling infrastructure\nManaging network ports and assist with the management of all consumable items (cables, labels, tie wraps, rail kits, etc.)\nMaintaining the integrity of the data center facilities, systems and communications environments through general housekeeping and best operations practices\nProvide hands-on, break\/fix level 2 support for the data center systems and communications environments\nCoordinating and approving data center infrastructure change controls\nEnsuring compliance with data center standards, policies and processes for all non-DCSD sponsored changes\nCoordinate activities in support of all projects and technical requests within the Americas Data Centers\nManage CTI-approved third-party vendors in support of local\/regional business service commitments and to assure adherence to Corporate and CTI standards\nProvide clear and detailed turnover to next shift workers for continuity\nMedia Management duties including the following:\nPerforming daily tape ejects to increase current day processing capacity.\nMonitoring of tape related console messages.\nManaging all daily ad-hoc tape\/job requests and scratch activity.\nManaging all physical and electronic vaulting activity.\nManage tape destruction process, ensuring all proper documentation has been recorded and approved.\nMonitoring scratch levels on display screens, on-line library web specialist or visually monitoring panel on libraries.\nReplacing any\/all damaged media.\nMonitoring of tape related console messages, working with the global command center and the on-site hardware teams.\nSupporting all physical off-site vaulting activities.\nEnsure destruction procedures are followed.\nSupporting all site and application specific disaster recovery\/COB tests\/exercises.\nAssisting in supporting all reconciliation and QA efforts including: Year End, Physical Inventory, Vertices. Hard-drive inventory levels, Other duties as assigned by management.\nQualifications:\nRequired skills include 3+ years of experience in the implementation, maintenance and analysis of data center facilities, hardware, communications infrastructure, strategies, tools and effective troubleshooting techniques.\nBasic background on enterprise data center facilities and infrastructure environments such as PDUs, RPPs, network and SAN infrastructures. In depth knowledge on complex, Enterprise class inter-networked environments involving a combination of switched\/routed\/shared Ethernet, TwinAx (100GigE, 25GigE,10GigE, GigE, 100M, and 10M), token ring, SAN, and wide area connectivity.\nStrong knowledge of WAN technologies (OC-x, DS-x), subnetting and TCP\/IP protocol a must.\nExcellent communication and writing skills a must.\nKnowledge of trouble ticketing systems, change control, Project processes and associated tools.\nLogical problem- solving techniques and associated experience in system, data center facilities, and telecommunications.\nExperience with project management.\nFinancial Services industry knowledge a plus\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Business Intelligence Analyst \u201a\u00c4\u00ec Data Visualizations",
      "company":"The University of Texas at Dallas",
      "job_location":"Richardson, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/business-intelligence-analyst-%E2%80%93-data-visualizations-at-the-university-of-texas-at-dallas-3785764105",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"The Business Intelligence Analyst position in OISDS will work collaboratively as a member of the team and will interact with internal and external stakeholders to support a variety of data management, training, analysis and benchmarking initiatives at The University of Texas at Dallas. The person in this role will assist with the ongoing development and implementation of tools to promote the development and use of analytic dashboards designed for wide distribution to UT Dallas campus stakeholders.\nThe primary functions of this role will be to\n1)\nassist OISDS with building relationships with campus constituents to develop analytic data resources and institutional research studies,\n2)\nassist with training and knowledge transfer activities related to OISDS tools, and\n3)\nconduct internal institutional research studies, assist with external data requests, perform data analysis, generate analytics, and communicate results involving internal data across numerous domains.\nIn this role, the Business Intelligence Analyst will provide direct support to internal and external stakeholders, manage relationships with data providers and end users. This role will also be tasked with enhancing existing and developing new analytics and data resources. The person in this role will report to the Associate Director for Institutional Research and Analytics.\nMinimum Education And Experience\nBachelors degree in related field.\nFour (4) years related professional experience.\nEquivalent combination of education and experience may be considered.\nPreferred Education And Experience\nMaster's Degree in a related field and two years of data analysis work experience.\nPossess a strong working knowledge of SQL and SAS programming.\nExperience in predictive analytics and machine learning.\nExperience working in an institutional research setting, a basic working knowledge of financial aid, admissions, and student data sources in a higher education setting (e.g., institutional, Federal (Integrated Post-Secondary Educational Data System), and the State via the Texas Higher Education Coordinating Board.\nBasic working knowledge of economic and accounting principles and practices, legal statutes, and analysis and reporting of financial data.\nExperience in designing business intelligence and\/or qualitative\/quantitative research studies to assist organizations in developing data-informed strategies.\nEssential Duties And Responsibilities\nReporting to the Associate Director, this Business Intelligence Analyst will focus on the development of data visualizations for business intelligence solutions. The person in this role will work closely with the stakeholders to support the vision and delivery of optimized and accessible institutional data to deliver metrics capable of making data informed decisions across the University through reporting and analytics.\nDesigns and develops intuitive dashboards, reports, and interactive visualizations to present complex data in a clear and concise manner.\nUtilizes data visualization tools to create dynamic and interactive visualizations that allow end users to explore data and uncover patterns and trends.\nInterprets data and provides insights to stakeholders through visualizations, enabling them to make informed decisions and identify actionable items.\nConducts data analysis and validations to ensure the accuracy and integrity used for visualization.\nMaintains knowledge of best practices and emerging trends in data visualizations and provides recommendations for continuous improvement.\nAdditional Information\nRemote Work:\nThis role is eligible for a hybrid (partly remote\/partly in office) work schedule, subject to business need and manager approval. A UT Dallas Remote Work Agreement will be required within 14 days after approval. The Business Intelligence Analyst \u201a\u00c4\u00ec Data Visualizations must be located within the DFW Area and have the ability to be on campus within 24 hours of notice.\nWhat We Can Offer\nUT Dallas is an Equal Opportunity Employer. We offer an employee-friendly work environment with a comprehensive benefit package including:\nCompetitive Salary\nTuition Benefits\nInternal Training\nMedical insurance \u201a\u00c4\u00ec including\n100% paid\nemployee medical coverage for full-time employees\nDental Insurance\nVision Insurance\nLong and short-term disability\nRetirement Plan Options\nPaid time off\nPaid Holidays All UT Dallas employees have access to various\nprofessional development\nopportunities\n, including a membership to Academic Impressions, LinkedIn Learning, and UT Dallas Bright Leaders Program.\nVisit\nhttps:\/\/hr.utdallas.edu\/employees\/benefits\/\nfor more information.\nAbout Us\nUT Dallas is a top public research university located in one of the nation's fastest-growing metropolitan regions. Our seven schools offer more than 140 undergraduate and graduate programs, plus professional certificates and fast-track programs. Our student body is 31,000 strong, reflecting students from over 100 countries and a multiplicity of identities and experiences. UT Dallas is committed to graduating well-rounded members of the global community whose education has prepared them for rewarding lives and productive careers in a constantly changing world.\nThe University has a variety of programs and initiatives to support engagement and success for all members of the campus community. Employee benefits include a range of physical and mental wellness resources. \u201a\u00c4\u00faLilyPad\u201a\u00c4\u00f9 lactation facilities are located throughout the campus. There are several Employee Resource Groups (ERGs) comprised of individuals who share common interests to help build community among UT Dallas faculty and staff (e.g., Universal Access ERG, Military and Veteran ERG, UT Dallas Young Professionals).\nRich with visual and performing arts venues, museum districts, professional and semi-professional athletics teams, botanical gardens, accessible trails and so much more, the Dallas-Fort Worth (DFW) metroplex has something for everyone to explore. UT Dallas partners with regional higher education institutions and school districts and with the\nRichardson Innovation Quarter\n(Richardson IQ), a major hub for innovation, entrepreneurship, and educational activities.\nImportant Message\nAll employees serve as a representative of the University and are expected to display respect, civility, professional courtesy, consideration of others and discretion in all interactions with members of the UT Dallas community and the general public.\nThe University of Texas at Dallas is committed to providing an educational, living, and working environment that is welcoming, respectful, and inclusive of all members of the university community. UT Dallas does not discriminate on the basis of race, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, national origin, disability, genetic information, or veteran status in its services, programs, activities, employment, and education, including in admission and enrollment. EOE, including disability\/veterans. The Universityis committed to providing access, equal opportunity, and reasonable accommodationfor individuals with disabilities.To request reasonable accommodation in the employment application and interview process, contact theADA Coordinator.For inquiries regarding nondiscrimination policies, contact theTitle IX Coordinator.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Sr Data Engineer",
      "company":"PepsiCo",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-data-engineer-at-pepsico-3688944155",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Overview\nPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo\u201a\u00c4\u00f4s global business scale to enable business insights, advanced analytics and new product development. PepsiCo\u201a\u00c4\u00f4s Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\nWhat PepsiCo Data Management and Operations does:\nMaintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company\nResponsible for day-to-day data collection, transportation, maintenance\/curation and access to the PepsiCo corporate data asset\nWork cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders\nIncrease awareness about available data and democratize access to it across the company\nAs a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.\nResponsibilities\nActive contributor to code development in projects and services.\nManage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.\nBuild and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.\nResponsible for implementing best practices around systems integration, security, performance and data management.\nEmpower the business by creating value through the increased adoption of data, data science and business intelligence landscape.\nCollaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.\nEvolve the architectural capabilities and maturity of the data platform by engaging with enterprise architects and strategic internal and external partners.\nDevelop and optimize procedures to \u201a\u00c4\u00faproductionalize\u201a\u00c4\u00f9 data science models.\nDefine and manage SLA\u201a\u00c4\u00f4s for data products and processes running in production.\nSupport large-scale experimentation done by data scientists.\nPrototype new approaches and build solutions at scale.\nResearch in state-of-the-art methodologies.\nCreate documentation for learnings and knowledge transfer.\nCreate and audit reusable packages or libraries.\nQualifications\nBA\/BS in Computer Science, Math, Physics, or other technical fields.\n6+ years of overall technology experience that includes at least 4+ years of hands-on software development, data engineering, and systems architecture.\n4+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.\n4+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).\n2+ years in cloud data engineering experience in Azure.\nFluent with Azure cloud services. Azure Certification is a plus.\nExperience with integration of multi cloud services with on-premises technologies.\nExperience with data modeling, data warehousing, and building high-volume ETL\/ELT pipelines.\nExperience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.\nExperience building\/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.\nExperience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.\nExperience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.\nExperience with version control systems like Github and deployment & CI tools.\nExperience with Azure Data Factory, Azure Databricks and Azure Machine learning tools.\nExperience with Statistical\/ML techniques is a plus.\nExperience with building solutions in the retail or in the supply chain space is a plus\nUnderstanding of metadata management, data lineage, and data glossaries is a plus.\nWorking knowledge of agile development, including DevOps and DataOps concepts.\nFamiliarity with business intelligence tools (such as PowerBI).\nSkills, Abilities And Knowledge\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nProven track record of leading, mentoring data teams.\nStrong change manager. Comfortable with change, especially that which arises through company growth.\nAbility to understand and translate business requirements into data and technical requirements.\nHigh degree of organization and ability to manage multiple, competing projects and priorities simultaneously.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong leadership, organizational and interpersonal skills; comfortable managing trade-offs.\nFoster a team culture of accountability, communication, and self-management.\nProactively drives impact and engagement while bringing others along.\nConsistently attain\/exceed individual and team goals\nAbility to lead others without direct authority in a matrixed environment.\nCompetencies\nHighly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business.\nUnderstands both the engineering and business side of the Data Products released.\nPlaces the user in the center of decision making.\nTeams up and collaborates for speed, agility, and innovation.\nExperience with and embraces agile methodologies.\nStrong negotiation and decision-making skill.\nExperience managing and working with globally distributed teams.\nEEO Statement\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.\nPepsiCo is an Equal Opportunity Employer: Female \/ Minority \/ Disability \/ Protected Veteran \/ Sexual Orientation \/ Gender Identity\nIf you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.\nPlease view our Pay Transparency Statement\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Data Engineer",
      "company":"BVS",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-at-bvs-3675242954",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Hello Professionals,\nI've multiple Data Engineer positions.\nLooking for 10+ years experience for all the below roles\nPassport number mandatory for the submissions.\nCongnizant is the Client, $55\/hr on C2C is the rate and all are day-one onsite.\nE-mail me the resumes at Harry@bvispro.com.\nJob Title: Data Engineer\nSkills: Java and AWS\nLocation: Columbus, OH or Plano, TX.(Day-one onsite)\nJob Title: Data Engineer\nSkills: AWS and Scala\nLocation: Columbus, OH or Plano, TX.(Day-one onsite)\nJob Title: DBA\nSkills: MongoDB DBA\nLocation: Tampa, FL..(Day-one onsite)\nJob Title: Data Engineer\nSkills: PySpark, Spark and Python\nLocation: Columbus, OH or Plano, TX.(Day-one onsite)\nJob Title: Data Engineer\nSkills: Lake formation, Redshift, Spark, Impala and Kafka.\nLocation: Columbus, OH or Plano, TX.(Day-one onsite)\nJob Title: Data Engineer\nSkills: Spark, Java, Oracle, Kubernetes, AWSand UNIX\nLocation: Columbus, OH or Plano, TX.(Day-one onsite)\nThanks & Regards\nHarry Cena\nBusiness Value Intelligence Services\nWebsite :- http:\/\/www.bvispro.com\nE-mail: Harry@bvispro.com\nDesk : +1339-274-2332\nAddress :- 234 Littleton Road, Unit 1B\nWestford-MA-01886 USA.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Senior Data Engineer",
      "company":"Diverse Lynx",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-at-diverse-lynx-3779270566",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Lead Data Engineer - Clinical Data Repository",
      "company":"CVS Health",
      "job_location":"Irving, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-data-engineer-clinical-data-repository-at-cvs-health-3777367698",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand \u201a\u00c4\u00ee with heart at its center \u201a\u00c4\u00ee our purpose sends a personal message that how we deliver our services is just as important as what we deliver.\nOur Heart At Work Behaviors\u201a\u00d1\u00a2 support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.\nPosition Summary\nA Brief Overview:\nAs a member of the Data and Analytics organization, you will be responsible fordesigning, building, and maintaining best-in-class data pipelines aimed at driving best-in-class solutions.You will collaborate with analytic partners and business partners from product strategy, program management, IT, data strategy, and predictive analytics teams to develop effective solutions.\nWhat you will do:\nBuild high-performing clinical data processing frameworks leveraging Google Cloud Platform and utilizing GCP Services like Dataflow, Pub-Sub, Composer, Healthcare API and Big Query.\nCollaborate with solution strategist and enterprise architects and lead solution discovery, design clinical data mapping and transformation solution using HL7 interoperability guidelines.\nDesign and develop clinical data pipelines for ingestion, enrichment, and consumption frameworks for onboarding clinical data from various data sources formatted in various industry standards (FHIR, C-CDA, HL7 V2, JSON, XML, etc.).\nSupport modeling\/diagramming and build design specifications for health care data objects and surrounding data processing logic.\nPerform Health care Data Analysis, Data profiling of source data to derive meaningful insights, and document data requirements to support the new data source onboarding.\nBuild state-of-the-art data pipelines supporting both batch and real-time streams to enable Clinical data collection, storage, processing, transformation, aggregation, and dissemination through heterogeneous channels. .\nDevelop proof of concepts for batch\/real-time data engineering solutions that leverage emerging technologies.\nRequired Qualifications\n10+years of hands-on experience inarchitecture, design, and development of enterprise data processing applications (ETL\/ELT).\n8+years of hands-on and robust experience in Python, Unix Shell scripting, SQL and handling of JSON, XML data.\n4+years of experience in building batch and streaming data pipelines using cloud data engineering technologies ( in GCP\/AWS\/Azure etc)\n3+years of experience working with tools to automate CI\/CD pipelines (e.g., Jenkins, GIT)\nMust have great articulation and communication skills.\nWorking in a fluid environment, defining, and owning priorities that adapt to our larger goals. You can bring clarity to ambiguity while remaining open-minded to new information.\nPreferred Qualifications\nGCP data engineering technologies such as Cloud Dataflow, Cloud Storage, Pub\/sub, Cloud Composer, Big Query, and Health care API (FHIR store)\nKnowledge and Experience in Big Query is strongly preferable.\nExperience working with health care data and understanding of analytics and how it is leveraged within the healthcare industries.\nExperience in working cross functional initiatives communicating effectively and confidently with business partners, project team members and senior management.\nKnowledge and experience HL7 FHIR, HL7V2 and C-CDA standards is a strong plus\nGCP data engineering certification.\nEducation\nBachelor's degree or equivalent work experience in Computer Science, Mathematics, Statistics, Business Analytics, Economics, Physics, Engineering, or related discipline. Master's degree strongly preferred.\nPay Range\nThe typical pay range for this role is:\n$115,000.00 - $230,000.00\nThis pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. This position also includes an award target in the company\u201a\u00c4\u00f4s equity award program.\nIn addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company\u201a\u00c4\u00f4s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (\u201a\u00c4\u00faPTO\u201a\u00c4\u00f9) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.\nFor more detailed information on available benefits, please visitjobs.CVSHealth.com\/benefits\nCVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.\nYou are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.\nCVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services throughColleagueRelations@CVSHealth.comIf you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Senior Healthcare Data Analyst",
      "company":"Verdant Infotech Solutions",
      "job_location":"Copper Canyon, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-healthcare-data-analyst-at-verdant-infotech-solutions-3785507836",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Location: Remote\nDuration: 6+ month CTH\nStatus: Able to be hired, no sponsors\nInterview: Video\nTop 3 for MPC: (just give a few bullet points specifically to how they used the skills)\nStrong working knowledge of Teradata, Talend and SSIS\nStored Procedure creation\nExperience analyzing Healthcare Data\nResource needed immediately to complete work related to Client implementation.\nResponsibilities\nWalk me through the day to day responsibilities of this the role and a description of the project (Outside of Workday JD):\nRoutine meetings with team for normal scrum ceremonies.\nMeeting on projects: with PMs\/POs, Business Partners, Vendors, and internal team members to create\/ refine\/ build requirements for developer to create new processes.\nWorking with Analyst partners to develop data extracts for various vendors, health plans, and or state entities.\nDescribe the performance expectations\/metrics for this individual and their team:\nProvide advanced development and analytical support on projects.\nAbility to extract, load, model and reconcile large amounts to data across multiple system platforms and sources.\nTell Me About What Their First Day Looks Like\nScrum ceremonies, meetings with the teams and manager, working on gaining needed access for the role.\nWhat previous job titles or background work will in this role?\nSenior Data Engineer\nSkills\nTeradata, Talend, SSIS\nStored Procedure creation\nHealth Care data analysis \u201a\u00c4\u00ec health care data set\nGood written and communicative skills in a diverse culture\nAnalytical thinking\/ skills and understanding relational databases\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Senior DevOps Data Platform Engineer \/ Kafka Administrator",
      "company":"RedRiver Systems, LLC",
      "job_location":"Addison, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-devops-data-platform-engineer-kafka-administrator-at-redriver-systems-llc-3785492982",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Data Engineer with SDET",
      "company":"Prime Software Technologies, Inc.",
      "job_location":"Austin, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-with-sdet-at-prime-software-technologies-inc-3785360655",
      "search_city":"La Habra",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Senior Cassandra Database Engineer",
      "company":"Wells Fargo",
      "job_location":"Westlake, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-cassandra-database-engineer-at-wells-fargo-3766518486",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"At Wells Fargo, we are looking for talented people who will put our customers at the center of everything we do. We are seeking candidates who embrace diversity, equity and inclusion in a workplace where everyone feels valued and inspired. Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.\nAbout This Role\nWells Fargo is seeking a Senior Cassandra Database Engineer to administer Cassandra database technology. This role is part of the Digital Technology and Innovation group in our Technology Organization. Learn more about the career areas and lines of business at wellsfargojobs.com .\nIn This Role, You Will\nInstallation and adminstration of Cassandra databases\nDocumentation of guides for production database administrators\nDefining standards for installation, deployment, security, authentication and authorization, management policies and best practices\nDefining and implementing backup and restoration strategies\nDefining and implementing monitoring and alarming strategies\nPerform the planning, research, design, implementation, maintenance, and control of server class databases\nConsult with and advise management and multiple clients on high impact data or database management issues, influencing strategic direction.\nRequired Qualifications, US:\n4+ years of experience with implementing and administrating Cassandra database\n4+ years experience with Datastax Cassandra\n4+ years of experience with Datastax Ops Centre backup\/restoration and monitoring\/alarm implementation\n4+ years of experience with Ansible automation tool or equivalent\n4+ years of Shell or Python or Perl experience\nDesired Certifications and Qualifications:\nDatastax Certified Cassandra Administrator\nDatastax Certified Cassandra Developer\nProven experience with Mongodb or other SQL and NoSQL databases a plus\nExperience with Agile methodology\nDemonstrated experience with UNIX and Shell Scripting\nDemonstrated experience in designing for high volume OLTP applications\nDemonstrated experience in Change Management and SDLC\nExperience with Version Control System such as Git\nExperience with Issue and Tracking software such as Jira\nPay Range\n$84,000.00 - $179,200.00\nBenefits\nWells Fargo provides all eligible full- and part-time employees with a comprehensive set of benefits designed to protect their physical and financial health and to help them make the most of their financial future. Visit Benefits - Wells Fargo Careers for an overview of the following benefit plans and programs offered to employees.\n401(k) Plan\nPaid Time Off\nParental Leave\nCritical Caregiving Leave\nDiscounts and Savings\nHealth Benefits\nCommuter Benefits\nTuition Reimbursement\nScholarships for dependent children\nAdoption Reimbursement\nWe Value Diversity\nAt Wells Fargo, we believe in diversity, equity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national origin, religion, age, sexual orientation, gender identity, gender expression, genetic information, individuals with disabilities, pregnancy, marital status, status as a protected veteran or any other status protected by applicable law.\nEmployees support our focus on building strong customer relationships balanced with a strong risk mitigating and compliance-driven culture which firmly establishes those disciplines as critical to the success of our customers and company. They are accountable for execution of all applicable risk programs (Credit, Market, Financial Crimes, Operational, Regulatory Compliance), which includes effectively following and adhering to applicable Wells Fargo policies and procedures, appropriately fulfilling risk and compliance obligations, timely and effective escalation and remediation of issues, and making sound risk decisions. There is emphasis on proactive monitoring, governance, risk identification and escalation, as well as making sound risk decisions commensurate with the business unit's risk appetite and all risk and compliance program requirements.\nCandidates applying to job openings posted in US: All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other legally protected characteristic.\nDrug and Alcohol Policy\nWells Fargo maintains a drug free workplace. Please see our Drug and Alcohol Policy to learn more.\nReference Number\nR-276818-9\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Senior Data Engineer, Enterprise Data and Analytics",
      "company":"First Command Financial Services, Inc.",
      "job_location":"Fort Worth, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-engineer-enterprise-data-and-analytics-at-first-command-financial-services-inc-3773358880",
      "search_city":"Arlington",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Description\nHow Will Your Role Impact First Command?\nThe Senior Data Engineer is a leader across the data organization. They work closely with members across teams and with business owners and leaders. In conjunction with development responsibilities, the Senior Data Engineer establishes and champions best practices and processes for data engineering. They work closely with architects to define, lead and assist in the vision and design of business solutions, and they are drivers of improvement for our processes and technical practices. The Senior Data Engineer is a person who needs little to no supervision or oversight. They are self-motivated individuals who have strong time management skills which facilitates working on special interest initiatives.\nWhat Will You Be Doing?\nCollaborates with architecture and technical leadership to define the vision and solutions\nCollaborate alongside other engineers of various disciplines to take the design and create executable pieces of work\nParticipates in all phases of development\nEstablishes and champions First Command data and data engineering standards\/best practices\nCommunicate and work alongside members of their team in support of their day-to-day work items\nWorks with business partners to ensure alignment between the ask and the output\nParticipate and lead peer reviews and champion peer review best practices and culture\nKey player and leader in an Agile environment, participating in daily huddles, sprint planning, retrospectives, etc.\nMentors junior team members in best practices and standards\nServe as escalation point for other team members on technical issues\nLeads effort to create and document deployment and release plans\nWorks with architects to evaluate new technologies and patterns that will inform the technology roadmap\nLeads Communities of Practices or other cross functional training opportunities\nLeads troubleshooting processes to determine root cause analysis\nWhat Skills\/Qualifications Do You Need?\nEducation\nBachelor\u201a\u00c4\u00f4s Degree required; MBA or MS or equivalent a plus.\nRequired Qualifications\n7+ years of applied experience in data integration, ETL, and data management or comparable positions that handle large\/complex data sets, developing automation, and fostering business partner relationships\nExpert in one or more of the following ETL tools such as Azure Data Factory, Informatica, Matillion, Fivetran and DBT\nExperience working with a diverse set of data sources such as Flat File, Database, API, Event Streaming\nExpert in SQL with knowledge of T-SQL\nStrong experience in data modeling, data warehousing, and MDM solutions\nFamiliar with Azure Synapse or Snowflake\nFamiliar with Databricks Delta Lake\nFamiliar with a scripting language such as python, powershell, or bash\nFamiliar with data lake design patterns\nExcellent written communication and presentation skills\nProficient in understanding of data mapping and lineage strategies\nProficient in understanding in conceptual, logical, and physical data design\nProficient in understanding of data management practices, data architecture principles, and data governance process\nPreferred Qualifications\nExpert in Azure Data Factory, Data Bricks, and Python\nStrong dimensional modelling skills\nFamiliarity with DevOps principles and processes\nApplied experience in Agile, SAFe, or Scrum\nFinancial services industry experience or other highly regulated industry experience a plus\nCertifications related to Data Integration or Data Engineering a plus\nFamiliarity with data science and analytics tools such as Alteryx, SPSS, SAS, Tableau, PowerBI\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Principal Data Protection Engineer",
      "company":"Verizon",
      "job_location":"Southlake, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/principal-data-protection-engineer-at-verizon-3770984464",
      "search_city":"Denton",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Senior data analyst",
      "company":"Enexus Global Inc.",
      "job_location":"Dallas, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-data-analyst-at-enexus-global-inc-3772648996",
      "search_city":"Nome",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"I am sharing a W2 contract. Kindly please check and let us know if you are interested.\nTitle:\nSr. Data Analyst\nLocation:\nDallas TX (will only need to go into the office on Fridays)\nTop Skills\n9+ years of SQL experience working in OLTP, Data Warehouse and Big Data databases\n7+ years in a Data Analyst role\nStrong attention to Detail\n4+ years writing medium to complex stored procedures a plus\nAbility to collaborate effectively and work as part of a team\nExtensive background in writing complex queries\nExtensive working knowledge of all aspects of Data Movement and Processing, including ETL, API, OLAP and best practices for data tracking\nDenodo Experience a plus\nBig Data Experience a plus (Hadoop, MongoDB, Exadata)\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Data Engineer\/Architect",
      "company":"NR Consulting",
      "job_location":"San Antonio, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-architect-at-nr-consulting-3768016796",
      "search_city":"San Antonio",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Title\n: Data Engineer\/Architect\nWork Location:\nSan Antonio, TX (Hybrid)\nPosition Type:\nContract with possible extension\nDuration:\n12 + Months\nJob Description:\nData Engineer\/Architect, Work like Solution Architect\/Sr Developer, Experience of building Automated data pipelines, Cloud Migration, Working knowledge with API & strong Programming skills.\nSkills : Strong in SQL, Python (Basic data engg but strong in Problem solving), OpenShift\/Docker, Snowflake or Cloud Migration, Gitlab CICD\/DevOps.\nStrong communication & passion to explore new skills\/solutions.\nPreferred : DBT, Snowflake, Data Modeling, Unix & Hadoop, Financial domain & Data, OpenShift & DevOps.\nDesired Skills:\ndata pipelines, Cloud Migration, API, SQL, Python, OpenShift\/Docker, Snowflake, DevOps\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Data Analyst",
      "company":"Primary Services",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-primary-services-3784844664",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Job Opening for Data Engineer -locals - Houston, TX",
      "company":"Steneral Consulting",
      "job_location":"Houston, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/job-opening-for-data-engineer-locals-houston-tx-at-steneral-consulting-3642300252",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Data Analyst",
      "company":"Sunbelt Solomon",
      "job_location":"Temple, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-sunbelt-solomon-3762242004",
      "search_city":"Temple",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Mid level Data Analyst-Sql & Python",
      "company":"neteffects",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/mid-level-data-analyst-sql-python-at-neteffects-3762668718",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Lead Cybersecurity Data Visualization Engineer",
      "company":"Spectrum",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/lead-cybersecurity-data-visualization-engineer-at-spectrum-3666197319",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Company Overview\nSpectrum\u201a\u00c4\u00f4s Product and Technology team creates, develops, and operates the nation\u201a\u00c4\u00f4s fastest mobile service, most reliable internet service, most viewed live TV app, and the most advanced WiFi, serving nearly 100 million users and 500 million devices. We are transforming the next era of connectivity and entertainment experiences. The diversity of experience available within Spectrum\u201a\u00c4\u00f4s Product and Technology team is unmatched and there are opportunities to grow your career as a designer, architect, engineer, developer, operator, or data scientist. We are creative, disciplined, hard-working, complex-problem solvers that believe in collaborating to deliver the highest quality customer experience.\nBE PART OF THE CONNECTION\nAs a Lead Cybersecurity Data Visualization Specialist, you'll be responsible for managing complex data and reporting to better assist management in maximizing resources in various departments or lines of business. Responsible for creating and producing forecasts, reports, ad hoc requests, dashboards, etc. in order to provide insights to determine operational impact, trends, and opportunities. This role requires thorough understanding of business analysis and data methodology. This position is considered a subject matter expert in data reporting and analysis.\nThis role will be responsible for mentoring and assisting as part of a team doing Tableau dashboard development and Executive and operational Cyber Metrics reporting.\nWhat Our Lead Cybersecurity Data Visualization Specialists Enjoy Most\nAnalyzing data from multiple data sets with more being added as Cybersecurity projects progress\nCollaborating with a team of security engineers, architects, and compliance analysts to help understand the \"why\" in the data\nYour efforts will help to positively impact Charter's Cybersecurity footprint\nRequired Qualifications\nWHAT YOU\u201a\u00c4\u00f4LL BRING TO SPECTRUM\nExperience:\n7+ years of data analysis and reporting or related experience\nEducation:\nBachelor\u201a\u00c4\u00f4s degree or equivalent years of experience\nTechnical skills:\nExpert level knowledge of SQL\nComprehensive knowledge of automation solutions such as Alteryx, etc.\nKnowledge of advanced visualization tools such as Tableau Demonstrated understanding of design and implementation practices within data visualization tools\nDemonstrated knowledge of scripting methods such as PowerShell, Python, etc\nSkills:\nKnowledge of software applications such as Word, Excel, etc.\nExpert level knowledge of SQL\nComprehensive knowledge of automation solutions such as Alteryx, etc.\nKnowledge of advanced visualization tools such as Tableau\nDemonstrated understanding of design and implementation practices within data visualization tools\nDemonstrated knowledge of SQL, PowerShell, Python, etc.\nAbilities:\nAbility to read, write, speak and understand English\nAbility to prioritize and organize effectively\nAbility to work independently, as well as in a collaborative and dynamic team environment\nAbility to handle multiple projects and priorities\nAbility to analyze and interpret data\nAbility to quickly identify business problems\/opportunities\nAbility to communicate verbally and in writing in a clear and straightforward manner\nAbility to communicate with all levels of management and company personnel\nAbility to manage multiple projects at one time\nAbility to document, prepare and present data-driven presentations\nTravel Ability:\nNone\/up to 10%\nSchedule:\nFull time\nCorporate business environment\nThis position is eligible to work in a hybrid work model (combination of in-office and remote days)\nSPECTRUM CONNECTS YOU TO MORE\nInnovative Tools & Tech: Work with high-performing software and applications on the forefront of the digital telecommunications industry.\nDynamic Growth: The growth of our industry and evolving technology will power your career as you move up or around the company.\nSupportive Teams: Who you are matters here. And, we aim to foster an inclusive workplace where every person is empowered to bring their best ideas.\nTotal Rewards: See all the ways we invest in you\u201a\u00c4\u00eeat work and in life\nApply now, connect a friend to this opportunity or\nsign up for jo\nb alerts\n!\nBDA354 2023-16263 2023\nHere, employees don\u201a\u00c4\u00f4t just have jobs, they build careers. That\u201a\u00c4\u00f4s why we believe in offering a comprehensive pay and benefits package that rewards employees for their contributions to our success, supports all aspects of their well-being, and delivers real value at every stage of life.\nA qualified applicant\u201a\u00c4\u00f4s criminal history, if any, will be considered in a manner consistent with applicable laws, including local ordinances.\nGet to Know Us\nCharter Communications is known in the United States by our Spectrum brands, including: Spectrum Internet\u00ac\u00c6, TV, Mobile and Voice, Spectrum Networks, Spectrum Enterprise and Spectrum Reach. When you join us, you\u201a\u00c4\u00f4re joining a strong community of more than 101,000 individuals working together to serve more than 32 million customers in 41 states and keep them connected to what matters most. Watch this video to learn more.\nWho You Are Matters Here\nWe\u201a\u00c4\u00f4re committed to growing a workforce that reflects our communities, and providing equal opportunities for employment and advancement. EOE, including disability\/vets. Learn about our inclusive culture.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Marketing Data and BI Analyst",
      "company":"The Timberline Group, LLC",
      "job_location":"St Louis, MO",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/marketing-data-and-bi-analyst-at-the-timberline-group-llc-3603585542",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Opportunity Overview\nThe Journey & Touchpoint Analytics Team within the department is responsible for defining and implementing an approach to collecting behavior\/interaction data, developing comprehensive reporting across journeys and touchpoints, and enabling self-service by other stakeholders.\nJourney & Touchpoint Analytics supports the Experience, Brand & Marketing division's measurement, analytics, data and reporting needs for paid, owned, earned and shared channels and numerous campaigns and projects. Analysts on the team are responsible for consulting with the marketing strategists, copywriters, channel managers and leadership to:\nUnderstand their business objectives, strategies, business questions and coach them on measures of success\/KPIs\nDefine measurement plans, data requirements, benchmarks and forecasts, and utilize analytics tool suite to meet their needs\nDeliver reports, research, analysis or custom insights and present findings to teams\nAdvise teams on how they might apply learnings to their channels, campaigns, projects to optimize the client experience and improve business results\nResponsibility Summary\/Job Description\nDesign, create and deliver project team and management-level reports and visualizations\nPerform analysis to transform data into actionable insights and inform decision-making and present findings to project team stakeholders and leaders\nDevelop and deliver measurement plans and supporting deliverables to enable teams to measure performance of projects, channels and campaigns\nConsult on data and tagging requirements and best practices to ensure alignment and consistency with marketing's measurement framework\nSupport IT projects related to development of new digital marketing prototypes, including data requirements, design, user acceptance testing, implementation and verification\nCoordinate analytics platform training with vendors and project teams\nOnboard data from marketing tools to support recurring dashboards\nQuery data from internal databases (currently Oracle, eventually Snowflake) to support outreach and reporting needs.\nProject Details\nJourney & Touchpoint Analytics supports the Experience, Brand & Marketing division's measurement, analytics, data and reporting needs to measure and optimize the experience of potential clients, current clients and the branch teams who serve them.\nExperience Measures is a fast-growing team with high visibility across platform. Given the critical need for data and insights to deliver measurable business outcomes for our clients and the firm, this role will directly enable the measurement of our many websites and digital touchpoints. This role will support the migration to Google Analytics 4 and will be involved with a number of other technologies, including Salesforce Marketing Cloud, Marketing Cloud Intelligence (FKA Datorama), Tableau, Snowflake, Oracle, etc.\nClient is in the midst of a firm transformation to becoming a purpose-driven organization. We're partnering with our clients and colleagues to create positive impact on everyone's lives - bettering our communities and society. Client is at the leading edge of this transformation, championing better tools, data and insights to measure and enhance the experience of our clients and branch teams. This role will directly contribute to enhancing Clients\u201a\u00c4\u00f4 web analytics capabilities across multiple digital properties.\nTeam Details\nThe Team has 6 full-time associates, two full-time contractors and a team leader. We also lead a matrixed analytics team, through which two additional analysts, a data scientist and 3 partner vendors work as a part of our team. We focus on behavioral data in digital tools and help make the experience our clients have and the experience our branches have serving them the best it can be.\nWe work alongside two sister teams that focus on first-party research, including surveys and focus groups.\nClient is headquartered in St. Louis, but our team works from all around the country. We work flexibly to support work\/life balance.\nPosition Requirements\nRequired Qualifications\nUnderstanding of digital marketing campaigns, channels and best practices for measuring individual and omni-channel performance and principles of multi-touch attribution\nAdvanced experience with Excel to blend\/transform multiple data sets into interactive reports\nExperience querying data from databases such as Oracle SQL or Snowflake databases\nExperience with BI visualization tools such as: Tableau, Power BI, Salesforce Marketing Cloud Intelligence (formerly Datorama).\nExperience analyzing and delivering marketing campaigns or channels analysis, presenting to internal business receivers and influencing business decisions\nSelf-starter with interest and ability to quickly learn new analytics and MarTech platforms and identify creative solutions to connect data across sources\nAbility to deliver results in fast-paced environment with varying scope and deadlines\nBachelor's Degree required with an emphasis in finance, business, economics, data science, math, analytics or marketing preferred. Relevant work experience will be considered.\n3-5 years of relevant work experience\nPreferred Qualifications\nExperience with Salesforce products and reporting\nIn particular, Marketing Intelligence Cloud (FKA Datorama), Tableau and Marketing Cloud products.\nProficiency interacting with various database and file storage systems (DB2, IDMS, Oracle, Snowflake)\nExperience with data manipulation languages such as SQL, Impala, PL\/SQL, Hive, Pig, XML\nExperience with statistical tools such as SAS, SPSS, R, or Python preferred.\nClicktale\/Contentsquare or similar tool experience\nKnowledge of marketing technology stack and best practices for integrating tools and data\nThe Timberline Group\nPhone: 636-209-5537\n623 Missouri Ave #104, Sullivan, Mo 63080\nwww.timberlinegrp.com\nresumes@timberlinegrp.com\n\"Delivering quality solutions through quality people\"\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Data Analyst",
      "company":"SBS Creatix",
      "job_location":"Greater St. Louis",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-analyst-at-sbs-creatix-3770505264",
      "search_city":"Belleville",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Data Engineer (U.S. remote)",
      "company":"Railroad19",
      "job_location":"Texas, United States",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-engineer-u-s-remote-at-railroad19-3769045277",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Remote",
      "job_summary":"#Hiringnow\nWe are actively hiring (Data Engineers)\nWe seek a\nData Engineer\nto be a strong technical resource on a dynamic and growing team of engineers. Our ideal candidate is passionate about creating well-architecture solutions containing thoroughly tested code. The ability to communicate effectively and create relationships by empathizing with client goals is a highly valued skill within our company culture.\nCore Responsibilities:\nDevelop new and enhance existing application services\nWriting tests to maintain code quality\nUnderstand and adapt to our client's evolving business requirements within the television advertising domain.\nParticipate in detailed technical design sessions to understand client needs and provide productive feedback\nIdentify new opportunities, tools, and services to enhance the software platform\nSupport and troubleshoot issues, identify the root cause, and proactively recommend corrective actions\nSkills & Experience:\nScala 2.12+ development experience\nPassionate about developing clean and maintainable code with little or no side-effects\nExperience building Restful APIs in Scala using Spark 2.4\nStrong hands-on experience with AWS running spark jobs on ephemeral EMR clusters on AWS and S3.\nExperience with relational and non-relational databases\nWillingness to learn new technologies and takes pride in keeping up with the latest technologies and practices within the Scala and Spark development community\nExcellent oral and written communication skills\nStrong analytical and problem-solving skills\nSelf-directed and can effectively deliver solutions with little oversight\nBachelor's or master's degree in computer science, computer engineering, or other technical disciplines or equivalent work experience is preferred but not required\n$120,000 - $160,000 a year\nSalary is commensurate with experience.-\nWe are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal-opportunity workplace.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Data Quality Analyst",
      "company":"Xoriant",
      "job_location":"Plano, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/data-quality-analyst-at-xoriant-3768457194",
      "search_city":"Garland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Xoriant reasonably expects the pay rate for this position to be within the following range: $45\/hour-$55\/hour (Depend upon experience).\nJob Title: Data, Reporting, and Quality Assurance Analyst\nDuration: 6+ Months Contract with extension\nLocation: Plano, TX -Onsite\nRole:\nThis role plays a crucial part in ensuring data accuracy, generating meaningful reports, and maintaining data quality standards.\nRoles and Responsibilities\n1. Data Analysis and Transformation:\nExtracting and inspecting data from various sources to identify discrepancies, anomalies, and inaccuracies.\nCleaning and transforming raw data into usable formats, ensuring consistency and completeness.\n2. Reporting and Visualization:\nCollaborating with stakeholders to define reporting requirements and expectations.\nBuilding and maintaining accurate and visually appealing reports using data visualization tools.\nCreating dashboards and executive summaries that convey key insights effectively.\n3. Data Quality Assurance:\nDeveloping and implementing data quality checks to identify and resolve data integrity issues.\nCollaborating with cross-functional teams to address data-related problems and ensure high-quality standards.\n4. Process Improvement:\nIdentifying opportunities to enhance data processes, reporting methodologies, and data collection methods.\nRecommending and implementing improvements to streamline data flow and optimize reporting efficiency.\n5. Documentation:\nDocumenting data processing steps, transformations, and data quality protocols.\nMaintaining clear and organized documentation for future reference and audits.\nMinimum Qualification:\nBachelor's degree in a related field (such as Computer Science, Business Analytics, or Information Systems).\nProven experience in data analysis, reporting, and data quality assurance.\nProficiency in data manipulation and transformation using tools like SQL, Excel, or scripting languages.\nFamiliarity with data visualization tools such as Power BI or similar.\nQuickbase certification or proficiency\nStrong analytical mindset and attention to detail to ensure data accuracy.\nAbility to communicate complex technical concepts to non-technical stakeholders.\nProblem-solving skills and the ability to proactively identify and address data issues.\nExperience with data cleaning and transformation techniques.\nKnowledge of data governance and data quality best practices.\nStrong organizational and time-management skills to handle multiple tasks and priorities.\nThanks !\nHussain Adenwala\nSenior Recruiting Consultant\nO: 408-550-1252\nHussain.adenwala@xoriant.com\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Information Technology Business Analyst",
      "company":"TOP Group - Japanese Recruiting Agency",
      "job_location":"Coppell, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/information-technology-business-analyst-at-top-group-japanese-recruiting-agency-3779371301",
      "search_city":"Corinth",
      "search_country":"United States",
      "job level":"Associate",
      "job_type":"Onsite",
      "job_summary":"Our client, a global Japanese IT services provider is searching for a Japanese or Mandarin bilingual IT system support engineer to join their team\nTitle:\nIT Business Analyst\nIndustry:\nIT Development & Operations\nType:\nFull Time Direct Hire Exempt\nLocation:\nDallas TX with travel required\nSalary:\nDepending on Experience of candidate between 65-85k\nQUALIFICATIONS:\nBusiness level proficiency in Japanese or Mandarin language\nBachelor's Degree\nBackground knowledge in IT or computer science\nAbility to travel up to 20-30% of the time during peak busy seasons\nExcellent communication skills\nJOB DUTIES:\nProvide training and support to global users for applications\nSystem installation, testing and maintenance for group logistics companies\nTest and debug applications systems\nReview, analyze and evaluate business systems to meet user needs\nProvide objectives and scope to overall business strategies\nDocument requirements and formulate systems to meet business strategies\n***Please submit your application with a 1\u201a\u00c4\u00ec2 page resume. Only qualified applicants will be contacted***\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Sr. Analyst, Power BI",
      "company":"Conn's HomePlus",
      "job_location":"The Woodlands, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/sr-analyst-power-bi-at-conn-s-homeplus-3784431361",
      "search_city":"Texas",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Hybrid",
      "job_summary":"Overview\n\u201a\u00c4\u00ec The Sr. Analyst, Power BI is a key role within the Data and Analytics function. Responsible for delivery of actionable insights to the corporate leaders and various functions to support Conn\u201a\u00c4\u00f4s Homeplus business. It\u201a\u00c4\u00f4s a collaborative role that works across IT and functional units. The right analytics across the various functions have the potential to drive value across the enterprise.\nKey Duties & Responsibilities\nUnderstand the different datasets and the business model.\nHelp stakeholders generate actionable insights from data.\nDeep analytical skills to interpret data and tell a story.\nBuild statistical models in snowflake and visualize them.\nUnderstand business requirements to set functional specifications for reporting applications.\nBuild automated reports and dashboards with the help of Power BI and other reporting tools.\nDevelop operational and functional reporting dashboards.\nDocument requirements and identify data sources and integration needs.\nEnhance existing data sources, reports and dashboards as needed.\nProvide support for existing reports and dashboards.\nAddress queries about data, reports and insights from users.\nRequired Experience\nMinimum 6-8 years\u201a\u00c4\u00f4 experience in data and analytics with at least 3 years with PowerBI\nDeep statistical modeling experience\nExtensive analytical capability to turn information to knowledge.\nDeep technical expertise with Power BI Premium Capacity and DAX\nExperience with Snowflake, Data Warehouse, SQL Server, Power Query, MDX, Power Platform\nHave knowledge of database fundamentals such as multidimensional database design, relational database design, and more\nPL 300, Power BI certification required.\nExperience with Marketing, Merchandising and Corp Systems reporting.\nPrior modeling experience with a focus on dimensional modeling\nGraduate degree in Computer Science or Statistics\nPreferred Experience\nExperience within a retail organization\nSkills & Abilities\nOrganized and detail-oriented.\nAble to multi-task and shift priorities, as required.\nDelivery focused and service-oriented mindset.\nGood communication skills\nTeam player\nWork CST hours\nWorking Conditions\nWork is performed in an office (retail, distribution, call center) environment.\nMay require prolonged periods of sitting\/standing.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  },
  {
      "job_title":"Senior Business Analyst",
      "company":"ProPetro Services, Inc",
      "job_location":"Midland, TX",
      "job_link":"https:\/\/www.linkedin.com\/jobs\/view\/senior-business-analyst-at-propetro-services-inc-3766149032",
      "search_city":"Midland",
      "search_country":"United States",
      "job level":"Mid senior",
      "job_type":"Onsite",
      "job_summary":"Job Details\nJob Location\n307 OPERATIONS OFFICE - Midland, TX\nPosition Type\nExperienced\nDescription\nThe Senior Business Analyst acts as a senior liaison between finance, operations and IT on major projects and reporting; identifies current business or financial gaps; and aids the Finance team with software roles and segregation of duties.\nAssist in regular monitoring, maintenance, and analysis of high visibility projects\nIdentify trends that drive operations and communicate findings to appropriate business owners\nAid the Finance team with software roles and proper segregation of duties by maintaining familiarity with internal SOX controls\nAssist with special projects and data compilation as necessary\nProvide finance support for all new and ongoing strategic initiatives\nLead major project initiatives and meet agreed upon deadlines with little daily supervision\nDefine, measure and analyze agreed upon Key Performance Indicators (KPIs) as well as develop improvement plans\nMaintain compliance with Health, Safety, and Environmental (HSE) policies by attending all required HSE training sessions, safety meetings, and always utilize proper Personal Protective Equipment (PPE)\nOther job duties as assigned\nQualifications\nMinimum 4 years of prior experience in financial or business systems highly preferred\nBachelor\u201a\u00c4\u00f4s or Master\u201a\u00c4\u00f4s degree in Accounting, Finance, Business Administration, or similar area of study, required. Experience will be considered in lieu of a degree.\nStrong quantitative and analytical skills and the ability to interpret financial data, including financial statements, key financial ratios, valuation models\nAdvanced skills in Microsoft Office 365 applications (most notably excel, PowerPoint, and Word) and able to quickly learn other work-related software\nStrong oral and written communication skills, can effectively interact with leaders and personnel at all levels of the organization\nHighly organized and structured in approach to plan and prioritize workflow\nMust be skilled at flowcharting and mapping objectives\nHighly self-motivated and proactive\nPhysical Demands\nThe physical demands described here represent those required for an employee to successfully perform the role\u201a\u00c4\u00f4s essential functions. Reasonable accommodation may be made for individuals with disabilities to perform their major responsibilities. While performing the duties of this job, the employee is regularly required to sit, stand, or walk; use hands to manipulate, handle, or feel; reach with hands and arms; stoop or bend; and talk or hear. The employee must occasionally lift and\/or move up to 20 lbs.\nWork Environment\nThe work environment characteristics described here represent environmental conditions an employee will encounter while performing the role\u201a\u00c4\u00f4s essential functions. The noise level in some work environments can be moderate and an employee may encounter extreme weather conditions while performing major duties. Reasonable accommodation may be provided for individuals with disabilities to perform their major responsibilities.\nDisclaimer\nThe information provided in this job description indicates the general nature and level of work performed by employees within the role\u201a\u00c4\u00f4s classification. This job description is not to be interpreted as a comprehensive inventory of all duties, responsibilities, qualifications required of employees assigned to this role.\nShow more\nShow less",
      "job_skills":"",
      "Category":"Other"
  }

]
